{"/home/travis/build/npmtest/node-npmtest-npm/test.js":"/* istanbul instrument in package npmtest_npm */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-npm/lib.npmtest_npm.js":"/* istanbul instrument in package npmtest_npm */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_npm = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_npm = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-npm/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-npm && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_npm */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_npm\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_npm.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_npm.rollup.js'] =\n            local.assetsDict['/assets.npmtest_npm.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_npm.__dirname + '/lib.npmtest_npm.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/npm.js":";(function () {\n  // windows: running 'npm blah' in this folder will invoke WSH, not node.\n  /*globals WScript*/\n  if (typeof WScript !== 'undefined') {\n    WScript.echo(\n      'npm does not work when run\\n' +\n      'with the Windows Scripting Host\\n\\n' +\n      '\"cd\" to a different directory,\\n' +\n      'or type \"npm.cmd <args>\",\\n' +\n      'or type \"node npm <args>\".'\n    )\n    WScript.quit(1)\n    return\n  }\n\n  var unsupported = require('../lib/utils/unsupported.js')\n  unsupported.checkForBrokenNode()\n\n  var gfs = require('graceful-fs')\n  // Patch the global fs module here at the app level\n  var fs = gfs.gracefulify(require('fs'))\n\n  var EventEmitter = require('events').EventEmitter\n  var npm = module.exports = new EventEmitter()\n  var npmconf = require('./config/core.js')\n  var log = require('npmlog')\n\n  var tty = require('tty')\n  var path = require('path')\n  var abbrev = require('abbrev')\n  var which = require('which')\n  var glob = require('glob')\n  var rimraf = require('rimraf')\n  var lazyProperty = require('lazy-property')\n  var parseJSON = require('./utils/parse-json.js')\n  var aliases = require('./config/cmd-list').aliases\n  var cmdList = require('./config/cmd-list').cmdList\n  var plumbing = require('./config/cmd-list').plumbing\n  var output = require('./utils/output.js')\n  var startMetrics = require('./utils/metrics.js').start\n\n  npm.config = {\n    loaded: false,\n    get: function () {\n      throw new Error('npm.load() required')\n    },\n    set: function () {\n      throw new Error('npm.load() required')\n    }\n  }\n\n  npm.commands = {}\n\n  // TUNING\n  npm.limit = {\n    fetch: 10,\n    action: 10\n  }\n  // ***\n\n  npm.rollbacks = []\n\n  try {\n    // startup, ok to do this synchronously\n    var j = parseJSON(fs.readFileSync(\n      path.join(__dirname, '../package.json')) + '')\n    npm.version = j.version\n  } catch (ex) {\n    try {\n      log.info('error reading version', ex)\n    } catch (er) {}\n    npm.version = ex\n  }\n\n  var commandCache = {}\n  var aliasNames = Object.keys(aliases)\n\n  var littleGuys = [ 'isntall', 'verison' ]\n  var fullList = cmdList.concat(aliasNames).filter(function (c) {\n    return plumbing.indexOf(c) === -1\n  })\n  var abbrevs = abbrev(fullList)\n\n  // we have our reasons\n  fullList = npm.fullList = fullList.filter(function (c) {\n    return littleGuys.indexOf(c) === -1\n  })\n\n  var registryRefer\n  var registryLoaded\n\n  Object.keys(abbrevs).concat(plumbing).forEach(function addCommand (c) {\n    Object.defineProperty(npm.commands, c, { get: function () {\n      if (!loaded) {\n        throw new Error(\n          'Call npm.load(config, cb) before using this command.\\n' +\n            'See the README.md or cli.js for example usage.'\n        )\n      }\n      var a = npm.deref(c)\n      if (c === 'la' || c === 'll') {\n        npm.config.set('long', true)\n      }\n\n      npm.command = c\n      if (commandCache[a]) return commandCache[a]\n\n      var cmd = require(path.join(__dirname, a + '.js'))\n\n      commandCache[a] = function () {\n        var args = Array.prototype.slice.call(arguments, 0)\n        if (typeof args[args.length - 1] !== 'function') {\n          args.push(defaultCb)\n        }\n        if (args.length === 1) args.unshift([])\n\n        // Options are prefixed by a hyphen-minus (-, \\u2d).\n        // Other dash-type chars look similar but are invalid.\n        Array(args[0]).forEach(function (arg) {\n          if (/^[\\u2010-\\u2015\\u2212\\uFE58\\uFE63\\uFF0D]/.test(arg)) {\n            log.error('arg', 'Argument starts with non-ascii dash, this is probably invalid:', arg)\n          }\n        })\n\n        if (!registryRefer) {\n          registryRefer = [a].concat(args[0]).map(function (arg) {\n            // exclude anything that might be a URL, path, or private module\n            // Those things will always have a slash in them somewhere\n            if (arg && arg.match && arg.match(/\\/|\\\\/)) {\n              return '[REDACTED]'\n            } else {\n              return arg\n            }\n          }).filter(function (arg) {\n            return arg && arg.match\n          }).join(' ')\n          if (registryLoaded) npm.registry.refer = registryRefer\n        }\n\n        cmd.apply(npm, args)\n      }\n\n      Object.keys(cmd).forEach(function (k) {\n        commandCache[a][k] = cmd[k]\n      })\n\n      return commandCache[a]\n    }, enumerable: fullList.indexOf(c) !== -1, configurable: true })\n\n    // make css-case commands callable via camelCase as well\n    if (c.match(/\\-([a-z])/)) {\n      addCommand(c.replace(/\\-([a-z])/g, function (a, b) {\n        return b.toUpperCase()\n      }))\n    }\n  })\n\n  function defaultCb (er, data) {\n    log.disableProgress()\n    if (er) console.error(er.stack || er.message)\n    else output(data)\n  }\n\n  npm.deref = function (c) {\n    if (!c) return ''\n    if (c.match(/[A-Z]/)) {\n      c = c.replace(/([A-Z])/g, function (m) {\n        return '-' + m.toLowerCase()\n      })\n    }\n    if (plumbing.indexOf(c) !== -1) return c\n    var a = abbrevs[c]\n    if (aliases[a]) a = aliases[a]\n    return a\n  }\n\n  var loaded = false\n  var loading = false\n  var loadErr = null\n  var loadListeners = []\n\n  function loadCb (er) {\n    loadListeners.forEach(function (cb) {\n      process.nextTick(cb.bind(npm, er, npm))\n    })\n    loadListeners.length = 0\n  }\n\n  npm.load = function (cli, cb_) {\n    if (!cb_ && typeof cli === 'function') {\n      cb_ = cli\n      cli = {}\n    }\n    if (!cb_) cb_ = function () {}\n    if (!cli) cli = {}\n    loadListeners.push(cb_)\n    if (loaded || loadErr) return cb(loadErr)\n    if (loading) return\n    loading = true\n    var onload = true\n\n    function cb (er) {\n      if (loadErr) return\n      loadErr = er\n      if (er) return cb_(er)\n      if (npm.config.get('force')) {\n        log.warn('using --force', 'I sure hope you know what you are doing.')\n      }\n      npm.config.loaded = true\n      loaded = true\n      loadCb(loadErr = er)\n      onload = onload && npm.config.get('onload-script')\n      if (onload) {\n        try {\n          require(onload)\n        } catch (err) {\n          log.warn('onload-script', 'failed to require onload script', onload)\n          log.warn('onload-script', err)\n        }\n        onload = false\n      }\n    }\n\n    log.pause()\n\n    load(npm, cli, cb)\n  }\n\n  function load (npm, cli, cb) {\n    which(process.argv[0], function (er, node) {\n      if (!er && node.toUpperCase() !== process.execPath.toUpperCase()) {\n        log.verbose('node symlink', node)\n        process.execPath = node\n        process.installPrefix = path.resolve(node, '..', '..')\n      }\n\n      // look up configs\n      var builtin = path.resolve(__dirname, '..', 'npmrc')\n      npmconf.load(cli, builtin, function (er, config) {\n        if (er === config) er = null\n\n        npm.config = config\n        if (er) return cb(er)\n\n        // if the 'project' config is not a filename, and we're\n        // not in global mode, then that means that it collided\n        // with either the default or effective userland config\n        if (!config.get('global') &&\n            config.sources.project &&\n            config.sources.project.type !== 'ini') {\n          log.verbose(\n            'config',\n            'Skipping project config: %s. (matches userconfig)',\n            config.localPrefix + '/.npmrc'\n          )\n        }\n\n        // Include npm-version and node-version in user-agent\n        var ua = config.get('user-agent') || ''\n        ua = ua.replace(/\\{node-version\\}/gi, process.version)\n        ua = ua.replace(/\\{npm-version\\}/gi, npm.version)\n        ua = ua.replace(/\\{platform\\}/gi, process.platform)\n        ua = ua.replace(/\\{arch\\}/gi, process.arch)\n        config.set('user-agent', ua)\n\n        if (config.get('metrics-registry') == null) {\n          config.set('metrics-registry', config.get('registry'))\n        }\n\n        var color = config.get('color')\n\n        log.level = config.get('loglevel')\n        log.heading = config.get('heading') || 'npm'\n        log.stream = config.get('logstream')\n\n        switch (color) {\n          case 'always':\n            log.enableColor()\n            npm.color = true\n            break\n          case false:\n            log.disableColor()\n            npm.color = false\n            break\n          default:\n            if (process.stdout.isTTY) npm.color = true\n            else if (!tty.isatty) npm.color = true\n            else if (tty.isatty(1)) npm.color = true\n            else npm.color = false\n            break\n        }\n\n        if (config.get('unicode')) {\n          log.enableUnicode()\n        } else {\n          log.disableUnicode()\n        }\n\n        if (config.get('progress') && (process.stderr.isTTY || (tty.isatty && tty.isatty(2)))) {\n          log.enableProgress()\n        } else {\n          log.disableProgress()\n        }\n\n        glob(path.resolve(npm.cache, '_logs', '*-debug.log'), function (er, files) {\n          if (er) return cb(er)\n\n          while (files.length >= npm.config.get('logs-max')) {\n            rimraf.sync(files[0])\n            files.splice(0, 1)\n          }\n        })\n\n        log.resume()\n\n        var umask = npm.config.get('umask')\n        npm.modes = {\n          exec: parseInt('0777', 8) & (~umask),\n          file: parseInt('0666', 8) & (~umask),\n          umask: umask\n        }\n\n        var gp = Object.getOwnPropertyDescriptor(config, 'globalPrefix')\n        Object.defineProperty(npm, 'globalPrefix', gp)\n\n        var lp = Object.getOwnPropertyDescriptor(config, 'localPrefix')\n        Object.defineProperty(npm, 'localPrefix', lp)\n\n        config.set('scope', scopeifyScope(config.get('scope')))\n        npm.projectScope = config.get('scope') ||\n         scopeifyScope(getProjectScope(npm.prefix))\n\n        // at this point the configs are all set.\n        // go ahead and spin up the registry client.\n        lazyProperty(npm, 'registry', function () {\n          registryLoaded = true\n          var CachingRegClient = require('./cache/caching-client.js')\n          var registry = new CachingRegClient(npm.config)\n          registry.version = npm.version\n          registry.refer = registryRefer\n          return registry\n        })\n\n        startMetrics()\n\n        return cb(null, npm)\n      })\n    })\n  }\n\n  Object.defineProperty(npm, 'prefix',\n    {\n      get: function () {\n        return npm.config.get('global') ? npm.globalPrefix : npm.localPrefix\n      },\n      set: function (r) {\n        var k = npm.config.get('global') ? 'globalPrefix' : 'localPrefix'\n        npm[k] = r\n        return r\n      },\n      enumerable: true\n    })\n\n  Object.defineProperty(npm, 'bin',\n    {\n      get: function () {\n        if (npm.config.get('global')) return npm.globalBin\n        return path.resolve(npm.root, '.bin')\n      },\n      enumerable: true\n    })\n\n  Object.defineProperty(npm, 'globalBin',\n    {\n      get: function () {\n        var b = npm.globalPrefix\n        if (process.platform !== 'win32') b = path.resolve(b, 'bin')\n        return b\n      }\n    })\n\n  Object.defineProperty(npm, 'dir',\n    {\n      get: function () {\n        if (npm.config.get('global')) return npm.globalDir\n        return path.resolve(npm.prefix, 'node_modules')\n      },\n      enumerable: true\n    })\n\n  Object.defineProperty(npm, 'globalDir',\n    {\n      get: function () {\n        return (process.platform !== 'win32')\n             ? path.resolve(npm.globalPrefix, 'lib', 'node_modules')\n             : path.resolve(npm.globalPrefix, 'node_modules')\n      },\n      enumerable: true\n    })\n\n  Object.defineProperty(npm, 'root',\n    { get: function () { return npm.dir } })\n\n  Object.defineProperty(npm, 'cache',\n    { get: function () { return npm.config.get('cache') },\n      set: function (r) { return npm.config.set('cache', r) },\n      enumerable: true\n    })\n\n  var tmpFolder\n  var rand = require('crypto').randomBytes(4).toString('hex')\n  Object.defineProperty(npm, 'tmp',\n    {\n      get: function () {\n        if (!tmpFolder) tmpFolder = 'npm-' + process.pid + '-' + rand\n        return path.resolve(npm.config.get('tmp'), tmpFolder)\n      },\n      enumerable: true\n    })\n\n  // the better to repl you with\n  Object.getOwnPropertyNames(npm.commands).forEach(function (n) {\n    if (npm.hasOwnProperty(n) || n === 'config') return\n\n    Object.defineProperty(npm, n, { get: function () {\n      return function () {\n        var args = Array.prototype.slice.call(arguments, 0)\n        var cb = defaultCb\n\n        if (args.length === 1 && Array.isArray(args[0])) {\n          args = args[0]\n        }\n\n        if (typeof args[args.length - 1] === 'function') {\n          cb = args.pop()\n        }\n        npm.commands[n](args, cb)\n      }\n    }, enumerable: false, configurable: true })\n  })\n\n  if (require.main === module) {\n    require('../bin/npm-cli.js')\n  }\n\n  function scopeifyScope (scope) {\n    return (!scope || scope[0] === '@') ? scope : ('@' + scope)\n  }\n\n  function getProjectScope (prefix) {\n    try {\n      var pkg = JSON.parse(fs.readFileSync(path.join(prefix, 'package.json')))\n      if (typeof pkg.name !== 'string') return ''\n      var sep = pkg.name.indexOf('/')\n      if (sep === -1) return ''\n      return pkg.name.slice(0, sep)\n    } catch (ex) {\n      return ''\n    }\n  }\n})()\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/unsupported.js":"'use strict'\nvar semver = require('semver')\nvar supportedNode = '>= 4'\nvar knownBroken = '>=0.1 <=0.7'\n\nvar checkVersion = exports.checkVersion = function (version) {\n  var versionNoPrerelease = version.replace(/-.*$/, '')\n  return {\n    broken: semver.satisfies(versionNoPrerelease, knownBroken),\n    unsupported: !semver.satisfies(versionNoPrerelease, supportedNode)\n  }\n}\n\nexports.checkForBrokenNode = function () {\n  var nodejs = checkVersion(process.version)\n  if (nodejs.broken) {\n    console.error('ERROR: npm is known not to run on Node.js ' + process.version)\n    console.error(\"You'll need to upgrade to a newer version in order to use this\")\n    console.error('version of npm. You can find the latest version at https://nodejs.org/')\n    process.exit(1)\n  }\n}\n\nexports.checkForUnsupportedNode = function () {\n  var nodejs = checkVersion(process.version)\n  if (nodejs.unsupported) {\n    var log = require('npmlog')\n    log.warn('npm', 'npm does not support Node.js ' + process.version)\n    log.warn('npm', 'You should probably upgrade to a newer version of node as we')\n    log.warn('npm', \"can't make any promises that npm will work with this version.\")\n    log.warn('npm', 'You can find the latest version at https://nodejs.org/')\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/semver/semver.js":"exports = module.exports = SemVer;\n\n// The debug function is excluded entirely from the minified version.\n/* nomin */ var debug;\n/* nomin */ if (typeof process === 'object' &&\n    /* nomin */ process.env &&\n    /* nomin */ process.env.NODE_DEBUG &&\n    /* nomin */ /\\bsemver\\b/i.test(process.env.NODE_DEBUG))\n  /* nomin */ debug = function() {\n    /* nomin */ var args = Array.prototype.slice.call(arguments, 0);\n    /* nomin */ args.unshift('SEMVER');\n    /* nomin */ console.log.apply(console, args);\n    /* nomin */ };\n/* nomin */ else\n  /* nomin */ debug = function() {};\n\n// Note: this is the semver.org version of the spec that it implements\n// Not necessarily the package version of this code.\nexports.SEMVER_SPEC_VERSION = '2.0.0';\n\nvar MAX_LENGTH = 256;\nvar MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;\n\n// The actual regexps go on exports.re\nvar re = exports.re = [];\nvar src = exports.src = [];\nvar R = 0;\n\n// The following Regular Expressions can be used for tokenizing,\n// validating, and parsing SemVer version strings.\n\n// ## Numeric Identifier\n// A single `0`, or a non-zero digit followed by zero or more digits.\n\nvar NUMERICIDENTIFIER = R++;\nsrc[NUMERICIDENTIFIER] = '0|[1-9]\\\\d*';\nvar NUMERICIDENTIFIERLOOSE = R++;\nsrc[NUMERICIDENTIFIERLOOSE] = '[0-9]+';\n\n\n// ## Non-numeric Identifier\n// Zero or more digits, followed by a letter or hyphen, and then zero or\n// more letters, digits, or hyphens.\n\nvar NONNUMERICIDENTIFIER = R++;\nsrc[NONNUMERICIDENTIFIER] = '\\\\d*[a-zA-Z-][a-zA-Z0-9-]*';\n\n\n// ## Main Version\n// Three dot-separated numeric identifiers.\n\nvar MAINVERSION = R++;\nsrc[MAINVERSION] = '(' + src[NUMERICIDENTIFIER] + ')\\\\.' +\n                   '(' + src[NUMERICIDENTIFIER] + ')\\\\.' +\n                   '(' + src[NUMERICIDENTIFIER] + ')';\n\nvar MAINVERSIONLOOSE = R++;\nsrc[MAINVERSIONLOOSE] = '(' + src[NUMERICIDENTIFIERLOOSE] + ')\\\\.' +\n                        '(' + src[NUMERICIDENTIFIERLOOSE] + ')\\\\.' +\n                        '(' + src[NUMERICIDENTIFIERLOOSE] + ')';\n\n// ## Pre-release Version Identifier\n// A numeric identifier, or a non-numeric identifier.\n\nvar PRERELEASEIDENTIFIER = R++;\nsrc[PRERELEASEIDENTIFIER] = '(?:' + src[NUMERICIDENTIFIER] +\n                            '|' + src[NONNUMERICIDENTIFIER] + ')';\n\nvar PRERELEASEIDENTIFIERLOOSE = R++;\nsrc[PRERELEASEIDENTIFIERLOOSE] = '(?:' + src[NUMERICIDENTIFIERLOOSE] +\n                                 '|' + src[NONNUMERICIDENTIFIER] + ')';\n\n\n// ## Pre-release Version\n// Hyphen, followed by one or more dot-separated pre-release version\n// identifiers.\n\nvar PRERELEASE = R++;\nsrc[PRERELEASE] = '(?:-(' + src[PRERELEASEIDENTIFIER] +\n                  '(?:\\\\.' + src[PRERELEASEIDENTIFIER] + ')*))';\n\nvar PRERELEASELOOSE = R++;\nsrc[PRERELEASELOOSE] = '(?:-?(' + src[PRERELEASEIDENTIFIERLOOSE] +\n                       '(?:\\\\.' + src[PRERELEASEIDENTIFIERLOOSE] + ')*))';\n\n// ## Build Metadata Identifier\n// Any combination of digits, letters, or hyphens.\n\nvar BUILDIDENTIFIER = R++;\nsrc[BUILDIDENTIFIER] = '[0-9A-Za-z-]+';\n\n// ## Build Metadata\n// Plus sign, followed by one or more period-separated build metadata\n// identifiers.\n\nvar BUILD = R++;\nsrc[BUILD] = '(?:\\\\+(' + src[BUILDIDENTIFIER] +\n             '(?:\\\\.' + src[BUILDIDENTIFIER] + ')*))';\n\n\n// ## Full Version String\n// A main version, followed optionally by a pre-release version and\n// build metadata.\n\n// Note that the only major, minor, patch, and pre-release sections of\n// the version string are capturing groups.  The build metadata is not a\n// capturing group, because it should not ever be used in version\n// comparison.\n\nvar FULL = R++;\nvar FULLPLAIN = 'v?' + src[MAINVERSION] +\n                src[PRERELEASE] + '?' +\n                src[BUILD] + '?';\n\nsrc[FULL] = '^' + FULLPLAIN + '$';\n\n// like full, but allows v1.2.3 and =1.2.3, which people do sometimes.\n// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty\n// common in the npm registry.\nvar LOOSEPLAIN = '[v=\\\\s]*' + src[MAINVERSIONLOOSE] +\n                 src[PRERELEASELOOSE] + '?' +\n                 src[BUILD] + '?';\n\nvar LOOSE = R++;\nsrc[LOOSE] = '^' + LOOSEPLAIN + '$';\n\nvar GTLT = R++;\nsrc[GTLT] = '((?:<|>)?=?)';\n\n// Something like \"2.*\" or \"1.2.x\".\n// Note that \"x.x\" is a valid xRange identifer, meaning \"any version\"\n// Only the first item is strictly required.\nvar XRANGEIDENTIFIERLOOSE = R++;\nsrc[XRANGEIDENTIFIERLOOSE] = src[NUMERICIDENTIFIERLOOSE] + '|x|X|\\\\*';\nvar XRANGEIDENTIFIER = R++;\nsrc[XRANGEIDENTIFIER] = src[NUMERICIDENTIFIER] + '|x|X|\\\\*';\n\nvar XRANGEPLAIN = R++;\nsrc[XRANGEPLAIN] = '[v=\\\\s]*(' + src[XRANGEIDENTIFIER] + ')' +\n                   '(?:\\\\.(' + src[XRANGEIDENTIFIER] + ')' +\n                   '(?:\\\\.(' + src[XRANGEIDENTIFIER] + ')' +\n                   '(?:' + src[PRERELEASE] + ')?' +\n                   src[BUILD] + '?' +\n                   ')?)?';\n\nvar XRANGEPLAINLOOSE = R++;\nsrc[XRANGEPLAINLOOSE] = '[v=\\\\s]*(' + src[XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:\\\\.(' + src[XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:\\\\.(' + src[XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:' + src[PRERELEASELOOSE] + ')?' +\n                        src[BUILD] + '?' +\n                        ')?)?';\n\nvar XRANGE = R++;\nsrc[XRANGE] = '^' + src[GTLT] + '\\\\s*' + src[XRANGEPLAIN] + '$';\nvar XRANGELOOSE = R++;\nsrc[XRANGELOOSE] = '^' + src[GTLT] + '\\\\s*' + src[XRANGEPLAINLOOSE] + '$';\n\n// Tilde ranges.\n// Meaning is \"reasonably at or greater than\"\nvar LONETILDE = R++;\nsrc[LONETILDE] = '(?:~>?)';\n\nvar TILDETRIM = R++;\nsrc[TILDETRIM] = '(\\\\s*)' + src[LONETILDE] + '\\\\s+';\nre[TILDETRIM] = new RegExp(src[TILDETRIM], 'g');\nvar tildeTrimReplace = '$1~';\n\nvar TILDE = R++;\nsrc[TILDE] = '^' + src[LONETILDE] + src[XRANGEPLAIN] + '$';\nvar TILDELOOSE = R++;\nsrc[TILDELOOSE] = '^' + src[LONETILDE] + src[XRANGEPLAINLOOSE] + '$';\n\n// Caret ranges.\n// Meaning is \"at least and backwards compatible with\"\nvar LONECARET = R++;\nsrc[LONECARET] = '(?:\\\\^)';\n\nvar CARETTRIM = R++;\nsrc[CARETTRIM] = '(\\\\s*)' + src[LONECARET] + '\\\\s+';\nre[CARETTRIM] = new RegExp(src[CARETTRIM], 'g');\nvar caretTrimReplace = '$1^';\n\nvar CARET = R++;\nsrc[CARET] = '^' + src[LONECARET] + src[XRANGEPLAIN] + '$';\nvar CARETLOOSE = R++;\nsrc[CARETLOOSE] = '^' + src[LONECARET] + src[XRANGEPLAINLOOSE] + '$';\n\n// A simple gt/lt/eq thing, or just \"\" to indicate \"any version\"\nvar COMPARATORLOOSE = R++;\nsrc[COMPARATORLOOSE] = '^' + src[GTLT] + '\\\\s*(' + LOOSEPLAIN + ')$|^$';\nvar COMPARATOR = R++;\nsrc[COMPARATOR] = '^' + src[GTLT] + '\\\\s*(' + FULLPLAIN + ')$|^$';\n\n\n// An expression to strip any whitespace between the gtlt and the thing\n// it modifies, so that `> 1.2.3` ==> `>1.2.3`\nvar COMPARATORTRIM = R++;\nsrc[COMPARATORTRIM] = '(\\\\s*)' + src[GTLT] +\n                      '\\\\s*(' + LOOSEPLAIN + '|' + src[XRANGEPLAIN] + ')';\n\n// this one has to use the /g flag\nre[COMPARATORTRIM] = new RegExp(src[COMPARATORTRIM], 'g');\nvar comparatorTrimReplace = '$1$2$3';\n\n\n// Something like `1.2.3 - 1.2.4`\n// Note that these all use the loose form, because they'll be\n// checked against either the strict or loose comparator form\n// later.\nvar HYPHENRANGE = R++;\nsrc[HYPHENRANGE] = '^\\\\s*(' + src[XRANGEPLAIN] + ')' +\n                   '\\\\s+-\\\\s+' +\n                   '(' + src[XRANGEPLAIN] + ')' +\n                   '\\\\s*$';\n\nvar HYPHENRANGELOOSE = R++;\nsrc[HYPHENRANGELOOSE] = '^\\\\s*(' + src[XRANGEPLAINLOOSE] + ')' +\n                        '\\\\s+-\\\\s+' +\n                        '(' + src[XRANGEPLAINLOOSE] + ')' +\n                        '\\\\s*$';\n\n// Star ranges basically just allow anything at all.\nvar STAR = R++;\nsrc[STAR] = '(<|>)?=?\\\\s*\\\\*';\n\n// Compile to actual regexp objects.\n// All are flag-free, unless they were created above with a flag.\nfor (var i = 0; i < R; i++) {\n  debug(i, src[i]);\n  if (!re[i])\n    re[i] = new RegExp(src[i]);\n}\n\nexports.parse = parse;\nfunction parse(version, loose) {\n  if (version instanceof SemVer)\n    return version;\n\n  if (typeof version !== 'string')\n    return null;\n\n  if (version.length > MAX_LENGTH)\n    return null;\n\n  var r = loose ? re[LOOSE] : re[FULL];\n  if (!r.test(version))\n    return null;\n\n  try {\n    return new SemVer(version, loose);\n  } catch (er) {\n    return null;\n  }\n}\n\nexports.valid = valid;\nfunction valid(version, loose) {\n  var v = parse(version, loose);\n  return v ? v.version : null;\n}\n\n\nexports.clean = clean;\nfunction clean(version, loose) {\n  var s = parse(version.trim().replace(/^[=v]+/, ''), loose);\n  return s ? s.version : null;\n}\n\nexports.SemVer = SemVer;\n\nfunction SemVer(version, loose) {\n  if (version instanceof SemVer) {\n    if (version.loose === loose)\n      return version;\n    else\n      version = version.version;\n  } else if (typeof version !== 'string') {\n    throw new TypeError('Invalid Version: ' + version);\n  }\n\n  if (version.length > MAX_LENGTH)\n    throw new TypeError('version is longer than ' + MAX_LENGTH + ' characters')\n\n  if (!(this instanceof SemVer))\n    return new SemVer(version, loose);\n\n  debug('SemVer', version, loose);\n  this.loose = loose;\n  var m = version.trim().match(loose ? re[LOOSE] : re[FULL]);\n\n  if (!m)\n    throw new TypeError('Invalid Version: ' + version);\n\n  this.raw = version;\n\n  // these are actually numbers\n  this.major = +m[1];\n  this.minor = +m[2];\n  this.patch = +m[3];\n\n  if (this.major > MAX_SAFE_INTEGER || this.major < 0)\n    throw new TypeError('Invalid major version')\n\n  if (this.minor > MAX_SAFE_INTEGER || this.minor < 0)\n    throw new TypeError('Invalid minor version')\n\n  if (this.patch > MAX_SAFE_INTEGER || this.patch < 0)\n    throw new TypeError('Invalid patch version')\n\n  // numberify any prerelease numeric ids\n  if (!m[4])\n    this.prerelease = [];\n  else\n    this.prerelease = m[4].split('.').map(function(id) {\n      if (/^[0-9]+$/.test(id)) {\n        var num = +id;\n        if (num >= 0 && num < MAX_SAFE_INTEGER)\n          return num;\n      }\n      return id;\n    });\n\n  this.build = m[5] ? m[5].split('.') : [];\n  this.format();\n}\n\nSemVer.prototype.format = function() {\n  this.version = this.major + '.' + this.minor + '.' + this.patch;\n  if (this.prerelease.length)\n    this.version += '-' + this.prerelease.join('.');\n  return this.version;\n};\n\nSemVer.prototype.toString = function() {\n  return this.version;\n};\n\nSemVer.prototype.compare = function(other) {\n  debug('SemVer.compare', this.version, this.loose, other);\n  if (!(other instanceof SemVer))\n    other = new SemVer(other, this.loose);\n\n  return this.compareMain(other) || this.comparePre(other);\n};\n\nSemVer.prototype.compareMain = function(other) {\n  if (!(other instanceof SemVer))\n    other = new SemVer(other, this.loose);\n\n  return compareIdentifiers(this.major, other.major) ||\n         compareIdentifiers(this.minor, other.minor) ||\n         compareIdentifiers(this.patch, other.patch);\n};\n\nSemVer.prototype.comparePre = function(other) {\n  if (!(other instanceof SemVer))\n    other = new SemVer(other, this.loose);\n\n  // NOT having a prerelease is > having one\n  if (this.prerelease.length && !other.prerelease.length)\n    return -1;\n  else if (!this.prerelease.length && other.prerelease.length)\n    return 1;\n  else if (!this.prerelease.length && !other.prerelease.length)\n    return 0;\n\n  var i = 0;\n  do {\n    var a = this.prerelease[i];\n    var b = other.prerelease[i];\n    debug('prerelease compare', i, a, b);\n    if (a === undefined && b === undefined)\n      return 0;\n    else if (b === undefined)\n      return 1;\n    else if (a === undefined)\n      return -1;\n    else if (a === b)\n      continue;\n    else\n      return compareIdentifiers(a, b);\n  } while (++i);\n};\n\n// preminor will bump the version up to the next minor release, and immediately\n// down to pre-release. premajor and prepatch work the same way.\nSemVer.prototype.inc = function(release, identifier) {\n  switch (release) {\n    case 'premajor':\n      this.prerelease.length = 0;\n      this.patch = 0;\n      this.minor = 0;\n      this.major++;\n      this.inc('pre', identifier);\n      break;\n    case 'preminor':\n      this.prerelease.length = 0;\n      this.patch = 0;\n      this.minor++;\n      this.inc('pre', identifier);\n      break;\n    case 'prepatch':\n      // If this is already a prerelease, it will bump to the next version\n      // drop any prereleases that might already exist, since they are not\n      // relevant at this point.\n      this.prerelease.length = 0;\n      this.inc('patch', identifier);\n      this.inc('pre', identifier);\n      break;\n    // If the input is a non-prerelease version, this acts the same as\n    // prepatch.\n    case 'prerelease':\n      if (this.prerelease.length === 0)\n        this.inc('patch', identifier);\n      this.inc('pre', identifier);\n      break;\n\n    case 'major':\n      // If this is a pre-major version, bump up to the same major version.\n      // Otherwise increment major.\n      // 1.0.0-5 bumps to 1.0.0\n      // 1.1.0 bumps to 2.0.0\n      if (this.minor !== 0 || this.patch !== 0 || this.prerelease.length === 0)\n        this.major++;\n      this.minor = 0;\n      this.patch = 0;\n      this.prerelease = [];\n      break;\n    case 'minor':\n      // If this is a pre-minor version, bump up to the same minor version.\n      // Otherwise increment minor.\n      // 1.2.0-5 bumps to 1.2.0\n      // 1.2.1 bumps to 1.3.0\n      if (this.patch !== 0 || this.prerelease.length === 0)\n        this.minor++;\n      this.patch = 0;\n      this.prerelease = [];\n      break;\n    case 'patch':\n      // If this is not a pre-release version, it will increment the patch.\n      // If it is a pre-release it will bump up to the same patch version.\n      // 1.2.0-5 patches to 1.2.0\n      // 1.2.0 patches to 1.2.1\n      if (this.prerelease.length === 0)\n        this.patch++;\n      this.prerelease = [];\n      break;\n    // This probably shouldn't be used publicly.\n    // 1.0.0 \"pre\" would become 1.0.0-0 which is the wrong direction.\n    case 'pre':\n      if (this.prerelease.length === 0)\n        this.prerelease = [0];\n      else {\n        var i = this.prerelease.length;\n        while (--i >= 0) {\n          if (typeof this.prerelease[i] === 'number') {\n            this.prerelease[i]++;\n            i = -2;\n          }\n        }\n        if (i === -1) // didn't increment anything\n          this.prerelease.push(0);\n      }\n      if (identifier) {\n        // 1.2.0-beta.1 bumps to 1.2.0-beta.2,\n        // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0\n        if (this.prerelease[0] === identifier) {\n          if (isNaN(this.prerelease[1]))\n            this.prerelease = [identifier, 0];\n        } else\n          this.prerelease = [identifier, 0];\n      }\n      break;\n\n    default:\n      throw new Error('invalid increment argument: ' + release);\n  }\n  this.format();\n  this.raw = this.version;\n  return this;\n};\n\nexports.inc = inc;\nfunction inc(version, release, loose, identifier) {\n  if (typeof(loose) === 'string') {\n    identifier = loose;\n    loose = undefined;\n  }\n\n  try {\n    return new SemVer(version, loose).inc(release, identifier).version;\n  } catch (er) {\n    return null;\n  }\n}\n\nexports.diff = diff;\nfunction diff(version1, version2) {\n  if (eq(version1, version2)) {\n    return null;\n  } else {\n    var v1 = parse(version1);\n    var v2 = parse(version2);\n    if (v1.prerelease.length || v2.prerelease.length) {\n      for (var key in v1) {\n        if (key === 'major' || key === 'minor' || key === 'patch') {\n          if (v1[key] !== v2[key]) {\n            return 'pre'+key;\n          }\n        }\n      }\n      return 'prerelease';\n    }\n    for (var key in v1) {\n      if (key === 'major' || key === 'minor' || key === 'patch') {\n        if (v1[key] !== v2[key]) {\n          return key;\n        }\n      }\n    }\n  }\n}\n\nexports.compareIdentifiers = compareIdentifiers;\n\nvar numeric = /^[0-9]+$/;\nfunction compareIdentifiers(a, b) {\n  var anum = numeric.test(a);\n  var bnum = numeric.test(b);\n\n  if (anum && bnum) {\n    a = +a;\n    b = +b;\n  }\n\n  return (anum && !bnum) ? -1 :\n         (bnum && !anum) ? 1 :\n         a < b ? -1 :\n         a > b ? 1 :\n         0;\n}\n\nexports.rcompareIdentifiers = rcompareIdentifiers;\nfunction rcompareIdentifiers(a, b) {\n  return compareIdentifiers(b, a);\n}\n\nexports.major = major;\nfunction major(a, loose) {\n  return new SemVer(a, loose).major;\n}\n\nexports.minor = minor;\nfunction minor(a, loose) {\n  return new SemVer(a, loose).minor;\n}\n\nexports.patch = patch;\nfunction patch(a, loose) {\n  return new SemVer(a, loose).patch;\n}\n\nexports.compare = compare;\nfunction compare(a, b, loose) {\n  return new SemVer(a, loose).compare(b);\n}\n\nexports.compareLoose = compareLoose;\nfunction compareLoose(a, b) {\n  return compare(a, b, true);\n}\n\nexports.rcompare = rcompare;\nfunction rcompare(a, b, loose) {\n  return compare(b, a, loose);\n}\n\nexports.sort = sort;\nfunction sort(list, loose) {\n  return list.sort(function(a, b) {\n    return exports.compare(a, b, loose);\n  });\n}\n\nexports.rsort = rsort;\nfunction rsort(list, loose) {\n  return list.sort(function(a, b) {\n    return exports.rcompare(a, b, loose);\n  });\n}\n\nexports.gt = gt;\nfunction gt(a, b, loose) {\n  return compare(a, b, loose) > 0;\n}\n\nexports.lt = lt;\nfunction lt(a, b, loose) {\n  return compare(a, b, loose) < 0;\n}\n\nexports.eq = eq;\nfunction eq(a, b, loose) {\n  return compare(a, b, loose) === 0;\n}\n\nexports.neq = neq;\nfunction neq(a, b, loose) {\n  return compare(a, b, loose) !== 0;\n}\n\nexports.gte = gte;\nfunction gte(a, b, loose) {\n  return compare(a, b, loose) >= 0;\n}\n\nexports.lte = lte;\nfunction lte(a, b, loose) {\n  return compare(a, b, loose) <= 0;\n}\n\nexports.cmp = cmp;\nfunction cmp(a, op, b, loose) {\n  var ret;\n  switch (op) {\n    case '===':\n      if (typeof a === 'object') a = a.version;\n      if (typeof b === 'object') b = b.version;\n      ret = a === b;\n      break;\n    case '!==':\n      if (typeof a === 'object') a = a.version;\n      if (typeof b === 'object') b = b.version;\n      ret = a !== b;\n      break;\n    case '': case '=': case '==': ret = eq(a, b, loose); break;\n    case '!=': ret = neq(a, b, loose); break;\n    case '>': ret = gt(a, b, loose); break;\n    case '>=': ret = gte(a, b, loose); break;\n    case '<': ret = lt(a, b, loose); break;\n    case '<=': ret = lte(a, b, loose); break;\n    default: throw new TypeError('Invalid operator: ' + op);\n  }\n  return ret;\n}\n\nexports.Comparator = Comparator;\nfunction Comparator(comp, loose) {\n  if (comp instanceof Comparator) {\n    if (comp.loose === loose)\n      return comp;\n    else\n      comp = comp.value;\n  }\n\n  if (!(this instanceof Comparator))\n    return new Comparator(comp, loose);\n\n  debug('comparator', comp, loose);\n  this.loose = loose;\n  this.parse(comp);\n\n  if (this.semver === ANY)\n    this.value = '';\n  else\n    this.value = this.operator + this.semver.version;\n\n  debug('comp', this);\n}\n\nvar ANY = {};\nComparator.prototype.parse = function(comp) {\n  var r = this.loose ? re[COMPARATORLOOSE] : re[COMPARATOR];\n  var m = comp.match(r);\n\n  if (!m)\n    throw new TypeError('Invalid comparator: ' + comp);\n\n  this.operator = m[1];\n  if (this.operator === '=')\n    this.operator = '';\n\n  // if it literally is just '>' or '' then allow anything.\n  if (!m[2])\n    this.semver = ANY;\n  else\n    this.semver = new SemVer(m[2], this.loose);\n};\n\nComparator.prototype.toString = function() {\n  return this.value;\n};\n\nComparator.prototype.test = function(version) {\n  debug('Comparator.test', version, this.loose);\n\n  if (this.semver === ANY)\n    return true;\n\n  if (typeof version === 'string')\n    version = new SemVer(version, this.loose);\n\n  return cmp(version, this.operator, this.semver, this.loose);\n};\n\n\nexports.Range = Range;\nfunction Range(range, loose) {\n  if ((range instanceof Range) && range.loose === loose)\n    return range;\n\n  if (!(this instanceof Range))\n    return new Range(range, loose);\n\n  this.loose = loose;\n\n  // First, split based on boolean or ||\n  this.raw = range;\n  this.set = range.split(/\\s*\\|\\|\\s*/).map(function(range) {\n    return this.parseRange(range.trim());\n  }, this).filter(function(c) {\n    // throw out any that are not relevant for whatever reason\n    return c.length;\n  });\n\n  if (!this.set.length) {\n    throw new TypeError('Invalid SemVer Range: ' + range);\n  }\n\n  this.format();\n}\n\nRange.prototype.format = function() {\n  this.range = this.set.map(function(comps) {\n    return comps.join(' ').trim();\n  }).join('||').trim();\n  return this.range;\n};\n\nRange.prototype.toString = function() {\n  return this.range;\n};\n\nRange.prototype.parseRange = function(range) {\n  var loose = this.loose;\n  range = range.trim();\n  debug('range', range, loose);\n  // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`\n  var hr = loose ? re[HYPHENRANGELOOSE] : re[HYPHENRANGE];\n  range = range.replace(hr, hyphenReplace);\n  debug('hyphen replace', range);\n  // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`\n  range = range.replace(re[COMPARATORTRIM], comparatorTrimReplace);\n  debug('comparator trim', range, re[COMPARATORTRIM]);\n\n  // `~ 1.2.3` => `~1.2.3`\n  range = range.replace(re[TILDETRIM], tildeTrimReplace);\n\n  // `^ 1.2.3` => `^1.2.3`\n  range = range.replace(re[CARETTRIM], caretTrimReplace);\n\n  // normalize spaces\n  range = range.split(/\\s+/).join(' ');\n\n  // At this point, the range is completely trimmed and\n  // ready to be split into comparators.\n\n  var compRe = loose ? re[COMPARATORLOOSE] : re[COMPARATOR];\n  var set = range.split(' ').map(function(comp) {\n    return parseComparator(comp, loose);\n  }).join(' ').split(/\\s+/);\n  if (this.loose) {\n    // in loose mode, throw out any that are not valid comparators\n    set = set.filter(function(comp) {\n      return !!comp.match(compRe);\n    });\n  }\n  set = set.map(function(comp) {\n    return new Comparator(comp, loose);\n  });\n\n  return set;\n};\n\n// Mostly just for testing and legacy API reasons\nexports.toComparators = toComparators;\nfunction toComparators(range, loose) {\n  return new Range(range, loose).set.map(function(comp) {\n    return comp.map(function(c) {\n      return c.value;\n    }).join(' ').trim().split(' ');\n  });\n}\n\n// comprised of xranges, tildes, stars, and gtlt's at this point.\n// already replaced the hyphen ranges\n// turn into a set of JUST comparators.\nfunction parseComparator(comp, loose) {\n  debug('comp', comp);\n  comp = replaceCarets(comp, loose);\n  debug('caret', comp);\n  comp = replaceTildes(comp, loose);\n  debug('tildes', comp);\n  comp = replaceXRanges(comp, loose);\n  debug('xrange', comp);\n  comp = replaceStars(comp, loose);\n  debug('stars', comp);\n  return comp;\n}\n\nfunction isX(id) {\n  return !id || id.toLowerCase() === 'x' || id === '*';\n}\n\n// ~, ~> --> * (any, kinda silly)\n// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0\n// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0\n// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0\n// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0\n// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0\nfunction replaceTildes(comp, loose) {\n  return comp.trim().split(/\\s+/).map(function(comp) {\n    return replaceTilde(comp, loose);\n  }).join(' ');\n}\n\nfunction replaceTilde(comp, loose) {\n  var r = loose ? re[TILDELOOSE] : re[TILDE];\n  return comp.replace(r, function(_, M, m, p, pr) {\n    debug('tilde', comp, _, M, m, p, pr);\n    var ret;\n\n    if (isX(M))\n      ret = '';\n    else if (isX(m))\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0';\n    else if (isX(p))\n      // ~1.2 == >=1.2.0 <1.3.0\n      ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0';\n    else if (pr) {\n      debug('replaceTilde pr', pr);\n      if (pr.charAt(0) !== '-')\n        pr = '-' + pr;\n      ret = '>=' + M + '.' + m + '.' + p + pr +\n            ' <' + M + '.' + (+m + 1) + '.0';\n    } else\n      // ~1.2.3 == >=1.2.3 <1.3.0\n      ret = '>=' + M + '.' + m + '.' + p +\n            ' <' + M + '.' + (+m + 1) + '.0';\n\n    debug('tilde return', ret);\n    return ret;\n  });\n}\n\n// ^ --> * (any, kinda silly)\n// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0\n// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0\n// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0\n// ^1.2.3 --> >=1.2.3 <2.0.0\n// ^1.2.0 --> >=1.2.0 <2.0.0\nfunction replaceCarets(comp, loose) {\n  return comp.trim().split(/\\s+/).map(function(comp) {\n    return replaceCaret(comp, loose);\n  }).join(' ');\n}\n\nfunction replaceCaret(comp, loose) {\n  debug('caret', comp, loose);\n  var r = loose ? re[CARETLOOSE] : re[CARET];\n  return comp.replace(r, function(_, M, m, p, pr) {\n    debug('caret', comp, _, M, m, p, pr);\n    var ret;\n\n    if (isX(M))\n      ret = '';\n    else if (isX(m))\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0';\n    else if (isX(p)) {\n      if (M === '0')\n        ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0';\n      else\n        ret = '>=' + M + '.' + m + '.0 <' + (+M + 1) + '.0.0';\n    } else if (pr) {\n      debug('replaceCaret pr', pr);\n      if (pr.charAt(0) !== '-')\n        pr = '-' + pr;\n      if (M === '0') {\n        if (m === '0')\n          ret = '>=' + M + '.' + m + '.' + p + pr +\n                ' <' + M + '.' + m + '.' + (+p + 1);\n        else\n          ret = '>=' + M + '.' + m + '.' + p + pr +\n                ' <' + M + '.' + (+m + 1) + '.0';\n      } else\n        ret = '>=' + M + '.' + m + '.' + p + pr +\n              ' <' + (+M + 1) + '.0.0';\n    } else {\n      debug('no pr');\n      if (M === '0') {\n        if (m === '0')\n          ret = '>=' + M + '.' + m + '.' + p +\n                ' <' + M + '.' + m + '.' + (+p + 1);\n        else\n          ret = '>=' + M + '.' + m + '.' + p +\n                ' <' + M + '.' + (+m + 1) + '.0';\n      } else\n        ret = '>=' + M + '.' + m + '.' + p +\n              ' <' + (+M + 1) + '.0.0';\n    }\n\n    debug('caret return', ret);\n    return ret;\n  });\n}\n\nfunction replaceXRanges(comp, loose) {\n  debug('replaceXRanges', comp, loose);\n  return comp.split(/\\s+/).map(function(comp) {\n    return replaceXRange(comp, loose);\n  }).join(' ');\n}\n\nfunction replaceXRange(comp, loose) {\n  comp = comp.trim();\n  var r = loose ? re[XRANGELOOSE] : re[XRANGE];\n  return comp.replace(r, function(ret, gtlt, M, m, p, pr) {\n    debug('xRange', comp, ret, gtlt, M, m, p, pr);\n    var xM = isX(M);\n    var xm = xM || isX(m);\n    var xp = xm || isX(p);\n    var anyX = xp;\n\n    if (gtlt === '=' && anyX)\n      gtlt = '';\n\n    if (xM) {\n      if (gtlt === '>' || gtlt === '<') {\n        // nothing is allowed\n        ret = '<0.0.0';\n      } else {\n        // nothing is forbidden\n        ret = '*';\n      }\n    } else if (gtlt && anyX) {\n      // replace X with 0\n      if (xm)\n        m = 0;\n      if (xp)\n        p = 0;\n\n      if (gtlt === '>') {\n        // >1 => >=2.0.0\n        // >1.2 => >=1.3.0\n        // >1.2.3 => >= 1.2.4\n        gtlt = '>=';\n        if (xm) {\n          M = +M + 1;\n          m = 0;\n          p = 0;\n        } else if (xp) {\n          m = +m + 1;\n          p = 0;\n        }\n      } else if (gtlt === '<=') {\n        // <=0.7.x is actually <0.8.0, since any 0.7.x should\n        // pass.  Similarly, <=7.x is actually <8.0.0, etc.\n        gtlt = '<';\n        if (xm)\n          M = +M + 1;\n        else\n          m = +m + 1;\n      }\n\n      ret = gtlt + M + '.' + m + '.' + p;\n    } else if (xm) {\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0';\n    } else if (xp) {\n      ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0';\n    }\n\n    debug('xRange return', ret);\n\n    return ret;\n  });\n}\n\n// Because * is AND-ed with everything else in the comparator,\n// and '' means \"any version\", just remove the *s entirely.\nfunction replaceStars(comp, loose) {\n  debug('replaceStars', comp, loose);\n  // Looseness is ignored here.  star is always as loose as it gets!\n  return comp.trim().replace(re[STAR], '');\n}\n\n// This function is passed to string.replace(re[HYPHENRANGE])\n// M, m, patch, prerelease, build\n// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5\n// 1.2.3 - 3.4 => >=1.2.0 <3.5.0 Any 3.4.x will do\n// 1.2 - 3.4 => >=1.2.0 <3.5.0\nfunction hyphenReplace($0,\n                       from, fM, fm, fp, fpr, fb,\n                       to, tM, tm, tp, tpr, tb) {\n\n  if (isX(fM))\n    from = '';\n  else if (isX(fm))\n    from = '>=' + fM + '.0.0';\n  else if (isX(fp))\n    from = '>=' + fM + '.' + fm + '.0';\n  else\n    from = '>=' + from;\n\n  if (isX(tM))\n    to = '';\n  else if (isX(tm))\n    to = '<' + (+tM + 1) + '.0.0';\n  else if (isX(tp))\n    to = '<' + tM + '.' + (+tm + 1) + '.0';\n  else if (tpr)\n    to = '<=' + tM + '.' + tm + '.' + tp + '-' + tpr;\n  else\n    to = '<=' + to;\n\n  return (from + ' ' + to).trim();\n}\n\n\n// if ANY of the sets match ALL of its comparators, then pass\nRange.prototype.test = function(version) {\n  if (!version)\n    return false;\n\n  if (typeof version === 'string')\n    version = new SemVer(version, this.loose);\n\n  for (var i = 0; i < this.set.length; i++) {\n    if (testSet(this.set[i], version))\n      return true;\n  }\n  return false;\n};\n\nfunction testSet(set, version) {\n  for (var i = 0; i < set.length; i++) {\n    if (!set[i].test(version))\n      return false;\n  }\n\n  if (version.prerelease.length) {\n    // Find the set of versions that are allowed to have prereleases\n    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0\n    // That should allow `1.2.3-pr.2` to pass.\n    // However, `1.2.4-alpha.notready` should NOT be allowed,\n    // even though it's within the range set by the comparators.\n    for (var i = 0; i < set.length; i++) {\n      debug(set[i].semver);\n      if (set[i].semver === ANY)\n        continue;\n\n      if (set[i].semver.prerelease.length > 0) {\n        var allowed = set[i].semver;\n        if (allowed.major === version.major &&\n            allowed.minor === version.minor &&\n            allowed.patch === version.patch)\n          return true;\n      }\n    }\n\n    // Version has a -pre, but it's not one of the ones we like.\n    return false;\n  }\n\n  return true;\n}\n\nexports.satisfies = satisfies;\nfunction satisfies(version, range, loose) {\n  try {\n    range = new Range(range, loose);\n  } catch (er) {\n    return false;\n  }\n  return range.test(version);\n}\n\nexports.maxSatisfying = maxSatisfying;\nfunction maxSatisfying(versions, range, loose) {\n  return versions.filter(function(version) {\n    return satisfies(version, range, loose);\n  }).sort(function(a, b) {\n    return rcompare(a, b, loose);\n  })[0] || null;\n}\n\nexports.minSatisfying = minSatisfying;\nfunction minSatisfying(versions, range, loose) {\n  return versions.filter(function(version) {\n    return satisfies(version, range, loose);\n  }).sort(function(a, b) {\n    return compare(a, b, loose);\n  })[0] || null;\n}\n\nexports.validRange = validRange;\nfunction validRange(range, loose) {\n  try {\n    // Return '*' instead of '' so that truthiness works.\n    // This will throw if it's invalid anyway\n    return new Range(range, loose).range || '*';\n  } catch (er) {\n    return null;\n  }\n}\n\n// Determine if version is less than all the versions possible in the range\nexports.ltr = ltr;\nfunction ltr(version, range, loose) {\n  return outside(version, range, '<', loose);\n}\n\n// Determine if version is greater than all the versions possible in the range.\nexports.gtr = gtr;\nfunction gtr(version, range, loose) {\n  return outside(version, range, '>', loose);\n}\n\nexports.outside = outside;\nfunction outside(version, range, hilo, loose) {\n  version = new SemVer(version, loose);\n  range = new Range(range, loose);\n\n  var gtfn, ltefn, ltfn, comp, ecomp;\n  switch (hilo) {\n    case '>':\n      gtfn = gt;\n      ltefn = lte;\n      ltfn = lt;\n      comp = '>';\n      ecomp = '>=';\n      break;\n    case '<':\n      gtfn = lt;\n      ltefn = gte;\n      ltfn = gt;\n      comp = '<';\n      ecomp = '<=';\n      break;\n    default:\n      throw new TypeError('Must provide a hilo val of \"<\" or \">\"');\n  }\n\n  // If it satisifes the range it is not outside\n  if (satisfies(version, range, loose)) {\n    return false;\n  }\n\n  // From now on, variable terms are as if we're in \"gtr\" mode.\n  // but note that everything is flipped for the \"ltr\" function.\n\n  for (var i = 0; i < range.set.length; ++i) {\n    var comparators = range.set[i];\n\n    var high = null;\n    var low = null;\n\n    comparators.forEach(function(comparator) {\n      if (comparator.semver === ANY) {\n        comparator = new Comparator('>=0.0.0')\n      }\n      high = high || comparator;\n      low = low || comparator;\n      if (gtfn(comparator.semver, high.semver, loose)) {\n        high = comparator;\n      } else if (ltfn(comparator.semver, low.semver, loose)) {\n        low = comparator;\n      }\n    });\n\n    // If the edge version comparator has a operator then our version\n    // isn't outside it\n    if (high.operator === comp || high.operator === ecomp) {\n      return false;\n    }\n\n    // If the lowest version comparator has an operator and our version\n    // is less than it then it isn't higher than the range\n    if ((!low.operator || low.operator === comp) &&\n        ltefn(version, low.semver)) {\n      return false;\n    } else if (low.operator === ecomp && ltfn(version, low.semver)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexports.prerelease = prerelease;\nfunction prerelease(version, loose) {\n  var parsed = parse(version, loose);\n  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/graceful-fs/graceful-fs.js":"var fs = require('fs')\nvar polyfills = require('./polyfills.js')\nvar legacy = require('./legacy-streams.js')\nvar queue = []\n\nvar util = require('util')\n\nfunction noop () {}\n\nvar debug = noop\nif (util.debuglog)\n  debug = util.debuglog('gfs4')\nelse if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ')\n    console.error(m)\n  }\n\nif (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n  process.on('exit', function() {\n    debug(queue)\n    require('assert').equal(queue.length, 0)\n  })\n}\n\nmodule.exports = patch(require('./fs.js'))\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH) {\n  module.exports = patch(fs)\n}\n\n// Always patch fs.close/closeSync, because we want to\n// retry() whenever a close happens *anywhere* in the program.\n// This is essential when multiple graceful-fs instances are\n// in play at the same time.\nmodule.exports.close =\nfs.close = (function (fs$close) { return function (fd, cb) {\n  return fs$close.call(fs, fd, function (err) {\n    if (!err)\n      retry()\n\n    if (typeof cb === 'function')\n      cb.apply(this, arguments)\n  })\n}})(fs.close)\n\nmodule.exports.closeSync =\nfs.closeSync = (function (fs$closeSync) { return function (fd) {\n  // Note that graceful-fs also retries when fs.closeSync() fails.\n  // Looks like a bug to me, although it's probably a harmless one.\n  var rval = fs$closeSync.apply(fs, arguments)\n  retry()\n  return rval\n}})(fs.closeSync)\n\nfunction patch (fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs)\n  fs.gracefulify = patch\n  fs.FileReadStream = ReadStream;  // Legacy name.\n  fs.FileWriteStream = WriteStream;  // Legacy name.\n  fs.createReadStream = createReadStream\n  fs.createWriteStream = createWriteStream\n  var fs$readFile = fs.readFile\n  fs.readFile = readFile\n  function readFile (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readFile(path, options, cb)\n\n    function go$readFile (path, options, cb) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readFile, [path, options, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  var fs$writeFile = fs.writeFile\n  fs.writeFile = writeFile\n  function writeFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$writeFile(path, data, options, cb)\n\n    function go$writeFile (path, data, options, cb) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$writeFile, [path, data, options, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  var fs$appendFile = fs.appendFile\n  if (fs$appendFile)\n    fs.appendFile = appendFile\n  function appendFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$appendFile(path, data, options, cb)\n\n    function go$appendFile (path, data, options, cb) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$appendFile, [path, data, options, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  var fs$readdir = fs.readdir\n  fs.readdir = readdir\n  function readdir (path, options, cb) {\n    var args = [path]\n    if (typeof options !== 'function') {\n      args.push(options)\n    } else {\n      cb = options\n    }\n    args.push(go$readdir$cb)\n\n    return go$readdir(args)\n\n    function go$readdir$cb (err, files) {\n      if (files && files.sort)\n        files.sort()\n\n      if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n        enqueue([go$readdir, [args]])\n      else {\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n        retry()\n      }\n    }\n  }\n\n  function go$readdir (args) {\n    return fs$readdir.apply(fs, args)\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs)\n    ReadStream = legStreams.ReadStream\n    WriteStream = legStreams.WriteStream\n  }\n\n  var fs$ReadStream = fs.ReadStream\n  ReadStream.prototype = Object.create(fs$ReadStream.prototype)\n  ReadStream.prototype.open = ReadStream$open\n\n  var fs$WriteStream = fs.WriteStream\n  WriteStream.prototype = Object.create(fs$WriteStream.prototype)\n  WriteStream.prototype.open = WriteStream$open\n\n  fs.ReadStream = ReadStream\n  fs.WriteStream = WriteStream\n\n  function ReadStream (path, options) {\n    if (this instanceof ReadStream)\n      return fs$ReadStream.apply(this, arguments), this\n    else\n      return ReadStream.apply(Object.create(ReadStream.prototype), arguments)\n  }\n\n  function ReadStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose)\n          that.destroy()\n\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n        that.read()\n      }\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (this instanceof WriteStream)\n      return fs$WriteStream.apply(this, arguments), this\n    else\n      return WriteStream.apply(Object.create(WriteStream.prototype), arguments)\n  }\n\n  function WriteStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy()\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n      }\n    })\n  }\n\n  function createReadStream (path, options) {\n    return new ReadStream(path, options)\n  }\n\n  function createWriteStream (path, options) {\n    return new WriteStream(path, options)\n  }\n\n  var fs$open = fs.open\n  fs.open = open\n  function open (path, flags, mode, cb) {\n    if (typeof mode === 'function')\n      cb = mode, mode = null\n\n    return go$open(path, flags, mode, cb)\n\n    function go$open (path, flags, mode, cb) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$open, [path, flags, mode, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  return fs\n}\n\nfunction enqueue (elem) {\n  debug('ENQUEUE', elem[0].name, elem[1])\n  queue.push(elem)\n}\n\nfunction retry () {\n  var elem = queue.shift()\n  if (elem) {\n    debug('RETRY', elem[0].name, elem[1])\n    elem[0].apply(null, elem[1])\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/graceful-fs/polyfills.js":"var fs = require('./fs.js')\nvar constants = require('constants')\n\nvar origCwd = process.cwd\nvar cwd = null\n\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform\n\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\ntry {\n  process.cwd()\n} catch (er) {}\n\nvar chdir = process.chdir\nprocess.chdir = function(d) {\n  cwd = null\n  chdir.call(process, d)\n}\n\nmodule.exports = patch\n\nfunction patch (fs) {\n  // (re-)implement some things that are known busted or missing.\n\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') &&\n      process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs)\n  }\n\n  // lutimes implementation, or no-op\n  if (!fs.lutimes) {\n    patchLutimes(fs)\n  }\n\n  // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n  fs.chown = chownFix(fs.chown)\n  fs.fchown = chownFix(fs.fchown)\n  fs.lchown = chownFix(fs.lchown)\n\n  fs.chmod = chmodFix(fs.chmod)\n  fs.fchmod = chmodFix(fs.fchmod)\n  fs.lchmod = chmodFix(fs.lchmod)\n\n  fs.chownSync = chownFixSync(fs.chownSync)\n  fs.fchownSync = chownFixSync(fs.fchownSync)\n  fs.lchownSync = chownFixSync(fs.lchownSync)\n\n  fs.chmodSync = chmodFixSync(fs.chmodSync)\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync)\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync)\n\n  fs.stat = statFix(fs.stat)\n  fs.fstat = statFix(fs.fstat)\n  fs.lstat = statFix(fs.lstat)\n\n  fs.statSync = statFixSync(fs.statSync)\n  fs.fstatSync = statFixSync(fs.fstatSync)\n  fs.lstatSync = statFixSync(fs.lstatSync)\n\n  // if lchmod/lchown do not exist, then make them no-ops\n  if (!fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchmodSync = function () {}\n  }\n  if (!fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchownSync = function () {}\n  }\n\n  // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n  if (platform === \"win32\") {\n    fs.rename = (function (fs$rename) { return function (from, to, cb) {\n      var start = Date.now()\n      var backoff = 0;\n      fs$rename(from, to, function CB (er) {\n        if (er\n            && (er.code === \"EACCES\" || er.code === \"EPERM\")\n            && Date.now() - start < 60000) {\n          setTimeout(function() {\n            fs.stat(to, function (stater, st) {\n              if (stater && stater.code === \"ENOENT\")\n                fs$rename(from, to, CB);\n              else\n                cb(er)\n            })\n          }, backoff)\n          if (backoff < 100)\n            backoff += 10;\n          return;\n        }\n        if (cb) cb(er)\n      })\n    }})(fs.rename)\n  }\n\n  // if read() returns EAGAIN, then just try it again.\n  fs.read = (function (fs$read) { return function (fd, buffer, offset, length, position, callback_) {\n    var callback\n    if (callback_ && typeof callback_ === 'function') {\n      var eagCounter = 0\n      callback = function (er, _, __) {\n        if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n        }\n        callback_.apply(this, arguments)\n      }\n    }\n    return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n  }})(fs.read)\n\n  fs.readSync = (function (fs$readSync) { return function (fd, buffer, offset, length, position) {\n    var eagCounter = 0\n    while (true) {\n      try {\n        return fs$readSync.call(fs, fd, buffer, offset, length, position)\n      } catch (er) {\n        if (er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          continue\n        }\n        throw er\n      }\n    }\n  }})(fs.readSync)\n}\n\nfunction patchLchmod (fs) {\n  fs.lchmod = function (path, mode, callback) {\n    fs.open( path\n           , constants.O_WRONLY | constants.O_SYMLINK\n           , mode\n           , function (err, fd) {\n      if (err) {\n        if (callback) callback(err)\n        return\n      }\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      fs.fchmod(fd, mode, function (err) {\n        fs.close(fd, function(err2) {\n          if (callback) callback(err || err2)\n        })\n      })\n    })\n  }\n\n  fs.lchmodSync = function (path, mode) {\n    var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n    // prefer to return the chmod error, if one occurs,\n    // but still try to close, and report closing errors if they occur.\n    var threw = true\n    var ret\n    try {\n      ret = fs.fchmodSync(fd, mode)\n      threw = false\n    } finally {\n      if (threw) {\n        try {\n          fs.closeSync(fd)\n        } catch (er) {}\n      } else {\n        fs.closeSync(fd)\n      }\n    }\n    return ret\n  }\n}\n\nfunction patchLutimes (fs) {\n  if (constants.hasOwnProperty(\"O_SYMLINK\")) {\n    fs.lutimes = function (path, at, mt, cb) {\n      fs.open(path, constants.O_SYMLINK, function (er, fd) {\n        if (er) {\n          if (cb) cb(er)\n          return\n        }\n        fs.futimes(fd, at, mt, function (er) {\n          fs.close(fd, function (er2) {\n            if (cb) cb(er || er2)\n          })\n        })\n      })\n    }\n\n    fs.lutimesSync = function (path, at, mt) {\n      var fd = fs.openSync(path, constants.O_SYMLINK)\n      var ret\n      var threw = true\n      try {\n        ret = fs.futimesSync(fd, at, mt)\n        threw = false\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd)\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd)\n        }\n      }\n      return ret\n    }\n\n  } else {\n    fs.lutimes = function (_a, _b, _c, cb) { if (cb) process.nextTick(cb) }\n    fs.lutimesSync = function () {}\n  }\n}\n\nfunction chmodFix (orig) {\n  if (!orig) return orig\n  return function (target, mode, cb) {\n    return orig.call(fs, target, mode, function (er) {\n      if (chownErOk(er)) er = null\n      if (cb) cb.apply(this, arguments)\n    })\n  }\n}\n\nfunction chmodFixSync (orig) {\n  if (!orig) return orig\n  return function (target, mode) {\n    try {\n      return orig.call(fs, target, mode)\n    } catch (er) {\n      if (!chownErOk(er)) throw er\n    }\n  }\n}\n\n\nfunction chownFix (orig) {\n  if (!orig) return orig\n  return function (target, uid, gid, cb) {\n    return orig.call(fs, target, uid, gid, function (er) {\n      if (chownErOk(er)) er = null\n      if (cb) cb.apply(this, arguments)\n    })\n  }\n}\n\nfunction chownFixSync (orig) {\n  if (!orig) return orig\n  return function (target, uid, gid) {\n    try {\n      return orig.call(fs, target, uid, gid)\n    } catch (er) {\n      if (!chownErOk(er)) throw er\n    }\n  }\n}\n\n\nfunction statFix (orig) {\n  if (!orig) return orig\n  // Older versions of Node erroneously returned signed integers for\n  // uid + gid.\n  return function (target, cb) {\n    return orig.call(fs, target, function (er, stats) {\n      if (!stats) return cb.apply(this, arguments)\n      if (stats.uid < 0) stats.uid += 0x100000000\n      if (stats.gid < 0) stats.gid += 0x100000000\n      if (cb) cb.apply(this, arguments)\n    })\n  }\n}\n\nfunction statFixSync (orig) {\n  if (!orig) return orig\n  // Older versions of Node erroneously returned signed integers for\n  // uid + gid.\n  return function (target) {\n    var stats = orig.call(fs, target)\n    if (stats.uid < 0) stats.uid += 0x100000000\n    if (stats.gid < 0) stats.gid += 0x100000000\n    return stats;\n  }\n}\n\n// ENOSYS means that the fs doesn't support the op. Just ignore\n// that, because it doesn't matter.\n//\n// if there's no getuid, or if getuid() is something other\n// than 0, and the error is EINVAL or EPERM, then just ignore\n// it.\n//\n// This specific case is a silent failure in cp, install, tar,\n// and most other unix tools that manage permissions.\n//\n// When running as root, or if other types of errors are\n// encountered, then it's strict.\nfunction chownErOk (er) {\n  if (!er)\n    return true\n\n  if (er.code === \"ENOSYS\")\n    return true\n\n  var nonroot = !process.getuid || process.getuid() !== 0\n  if (nonroot) {\n    if (er.code === \"EINVAL\" || er.code === \"EPERM\")\n      return true\n  }\n\n  return false\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/graceful-fs/fs.js":"'use strict'\n\nvar fs = require('fs')\n\nmodule.exports = clone(fs)\n\nfunction clone (obj) {\n  if (obj === null || typeof obj !== 'object')\n    return obj\n\n  if (obj instanceof Object)\n    var copy = { __proto__: obj.__proto__ }\n  else\n    var copy = Object.create(null)\n\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key))\n  })\n\n  return copy\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/graceful-fs/legacy-streams.js":"var Stream = require('stream').Stream\n\nmodule.exports = legacy\n\nfunction legacy (fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  }\n\n  function ReadStream (path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n\n    Stream.call(this);\n\n    var self = this;\n\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n\n    this.flags = 'r';\n    this.mode = 438; /*=0666*/\n    this.bufferSize = 64 * 1024;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function() {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n      self._read();\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n\n    Stream.call(this);\n\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438; /*=0666*/\n    this.bytesWritten = 0;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n      this.flush();\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/core.js":"var CC = require('config-chain').ConfigChain\nvar inherits = require('inherits')\nvar configDefs = require('./defaults.js')\nvar types = configDefs.types\nvar once = require('once')\nvar fs = require('fs')\nvar path = require('path')\nvar nopt = require('nopt')\nvar ini = require('ini')\nvar Umask = configDefs.Umask\nvar mkdirp = require('mkdirp')\nvar umask = require('../utils/umask')\nvar isWindows = require('../utils/is-windows.js')\n\nexports.load = load\nexports.Conf = Conf\nexports.loaded = false\nexports.rootConf = null\nexports.usingBuiltin = false\nexports.defs = configDefs\n\nObject.defineProperty(exports, 'defaults', { get: function () {\n  return configDefs.defaults\n}, enumerable: true })\n\nObject.defineProperty(exports, 'types', { get: function () {\n  return configDefs.types\n}, enumerable: true })\n\nexports.validate = validate\n\nvar myUid = process.env.SUDO_UID !== undefined\n          ? process.env.SUDO_UID : (process.getuid && process.getuid())\nvar myGid = process.env.SUDO_GID !== undefined\n          ? process.env.SUDO_GID : (process.getgid && process.getgid())\n\nvar loading = false\nvar loadCbs = []\nfunction load () {\n  var cli, builtin, cb\n  for (var i = 0; i < arguments.length; i++) {\n    switch (typeof arguments[i]) {\n      case 'string': builtin = arguments[i]; break\n      case 'object': cli = arguments[i]; break\n      case 'function': cb = arguments[i]; break\n    }\n  }\n\n  if (!cb) cb = function () {}\n\n  if (exports.loaded) {\n    var ret = exports.loaded\n    if (cli) {\n      ret = new Conf(ret)\n      ret.unshift(cli)\n    }\n    return process.nextTick(cb.bind(null, null, ret))\n  }\n\n  // either a fresh object, or a clone of the passed in obj\n  if (!cli) {\n    cli = {}\n  } else {\n    cli = Object.keys(cli).reduce(function (c, k) {\n      c[k] = cli[k]\n      return c\n    }, {})\n  }\n\n  loadCbs.push(cb)\n  if (loading) return\n\n  loading = true\n\n  cb = once(function (er, conf) {\n    if (!er) {\n      exports.loaded = conf\n      loading = false\n    }\n    loadCbs.forEach(function (fn) {\n      fn(er, conf)\n    })\n    loadCbs.length = 0\n  })\n\n  // check for a builtin if provided.\n  exports.usingBuiltin = !!builtin\n  var rc = exports.rootConf = new Conf()\n  if (builtin) {\n    rc.addFile(builtin, 'builtin')\n  } else {\n    rc.add({}, 'builtin')\n  }\n\n  rc.on('load', function () {\n    load_(builtin, rc, cli, cb)\n  })\n  rc.on('error', cb)\n}\n\nfunction load_ (builtin, rc, cli, cb) {\n  var defaults = configDefs.defaults\n  var conf = new Conf(rc)\n\n  conf.usingBuiltin = !!builtin\n  conf.add(cli, 'cli')\n  conf.addEnv()\n\n  conf.loadPrefix(function (er) {\n    if (er) return cb(er)\n\n    // If you're doing `npm --userconfig=~/foo.npmrc` then you'd expect\n    // that ~/.npmrc won't override the stuff in ~/foo.npmrc (or, indeed\n    // be used at all).\n    //\n    // However, if the cwd is ~, then ~/.npmrc is the home for the project\n    // config, and will override the userconfig.\n    //\n    // If you're not setting the userconfig explicitly, then it will be loaded\n    // twice, which is harmless but excessive.  If you *are* setting the\n    // userconfig explicitly then it will override your explicit intent, and\n    // that IS harmful and unexpected.\n    //\n    // Solution: Do not load project config file that is the same as either\n    // the default or resolved userconfig value.  npm will log a \"verbose\"\n    // message about this when it happens, but it is a rare enough edge case\n    // that we don't have to be super concerned about it.\n    var projectConf = path.resolve(conf.localPrefix, '.npmrc')\n    var defaultUserConfig = rc.get('userconfig')\n    var resolvedUserConfig = conf.get('userconfig')\n    if (!conf.get('global') &&\n        projectConf !== defaultUserConfig &&\n        projectConf !== resolvedUserConfig) {\n      conf.addFile(projectConf, 'project')\n      conf.once('load', afterPrefix)\n    } else {\n      conf.add({}, 'project')\n      afterPrefix()\n    }\n  })\n\n  function afterPrefix () {\n    conf.addFile(conf.get('userconfig'), 'user')\n    conf.once('error', cb)\n    conf.once('load', afterUser)\n  }\n\n  function afterUser () {\n    // globalconfig and globalignorefile defaults\n    // need to respond to the 'prefix' setting up to this point.\n    // Eg, `npm config get globalconfig --prefix ~/local` should\n    // return `~/local/etc/npmrc`\n    // annoying humans and their expectations!\n    if (conf.get('prefix')) {\n      var etc = path.resolve(conf.get('prefix'), 'etc')\n      mkdirp(etc, function () {\n        defaults.globalconfig = path.resolve(etc, 'npmrc')\n        defaults.globalignorefile = path.resolve(etc, 'npmignore')\n        afterUserContinuation()\n      })\n    } else {\n      afterUserContinuation()\n    }\n  }\n\n  function afterUserContinuation () {\n    conf.addFile(conf.get('globalconfig'), 'global')\n\n    // move the builtin into the conf stack now.\n    conf.root = defaults\n    conf.add(rc.shift(), 'builtin')\n    conf.once('load', function () {\n      conf.loadExtras(afterExtras)\n    })\n  }\n\n  function afterExtras (er) {\n    if (er) return cb(er)\n\n    // warn about invalid bits.\n    validate(conf)\n\n    var cafile = conf.get('cafile')\n\n    if (cafile) {\n      return conf.loadCAFile(cafile, finalize)\n    }\n\n    finalize()\n  }\n\n  function finalize (er) {\n    if (er) {\n      return cb(er)\n    }\n\n    exports.loaded = conf\n    cb(er, conf)\n  }\n}\n\n// Basically the same as CC, but:\n// 1. Always ini\n// 2. Parses environment variable names in field values\n// 3. Field values that start with ~/ are replaced with process.env.HOME\n// 4. Can inherit from another Conf object, using it as the base.\ninherits(Conf, CC)\nfunction Conf (base) {\n  if (!(this instanceof Conf)) return new Conf(base)\n\n  CC.call(this)\n\n  if (base) {\n    if (base instanceof Conf) {\n      this.root = base.list[0] || base.root\n    } else {\n      this.root = base\n    }\n  } else {\n    this.root = configDefs.defaults\n  }\n}\n\nConf.prototype.loadPrefix = require('./load-prefix.js')\nConf.prototype.loadCAFile = require('./load-cafile.js')\nConf.prototype.loadUid = require('./load-uid.js')\nConf.prototype.setUser = require('./set-user.js')\nConf.prototype.findPrefix = require('./find-prefix.js')\nConf.prototype.getCredentialsByURI = require('./get-credentials-by-uri.js')\nConf.prototype.setCredentialsByURI = require('./set-credentials-by-uri.js')\nConf.prototype.clearCredentialsByURI = require('./clear-credentials-by-uri.js')\n\nConf.prototype.loadExtras = function (cb) {\n  this.setUser(function (er) {\n    if (er) return cb(er)\n    this.loadUid(function (er) {\n      if (er) return cb(er)\n      // Without prefix, nothing will ever work\n      mkdirp(this.prefix, cb)\n    }.bind(this))\n  }.bind(this))\n}\n\nConf.prototype.save = function (where, cb) {\n  var target = this.sources[where]\n  if (!target || !(target.path || target.source) || !target.data) {\n    var er\n    if (where !== 'builtin') er = new Error('bad save target: ' + where)\n    if (cb) {\n      process.nextTick(cb.bind(null, er))\n      return this\n    }\n    return this.emit('error', er)\n  }\n\n  if (target.source) {\n    var pref = target.prefix || ''\n    Object.keys(target.data).forEach(function (k) {\n      target.source[pref + k] = target.data[k]\n    })\n    if (cb) process.nextTick(cb)\n    return this\n  }\n\n  var data = ini.stringify(target.data)\n\n  var then = function then (er) {\n    if (er) return done(er)\n\n    fs.chmod(target.path, mode, done)\n  }\n\n  var done = function done (er) {\n    if (er) {\n      if (cb) return cb(er)\n      else return this.emit('error', er)\n    }\n    this._saving --\n    if (this._saving === 0) {\n      if (cb) cb()\n      this.emit('save')\n    }\n  }\n\n  then = then.bind(this)\n  done = done.bind(this)\n  this._saving ++\n\n  var mode = where === 'user' ? '0600' : '0666'\n  if (!data.trim()) {\n    fs.unlink(target.path, function () {\n      // ignore the possible error (e.g. the file doesn't exist)\n      done(null)\n    })\n  } else {\n    mkdirp(path.dirname(target.path), function (er) {\n      if (er) return then(er)\n      fs.writeFile(target.path, data, 'utf8', function (er) {\n        if (er) return then(er)\n        if (where === 'user' && myUid && myGid) {\n          fs.chown(target.path, +myUid, +myGid, then)\n        } else {\n          then()\n        }\n      })\n    })\n  }\n\n  return this\n}\n\nConf.prototype.addFile = function (file, name) {\n  name = name || file\n  var marker = { __source__: name }\n  this.sources[name] = { path: file, type: 'ini' }\n  this.push(marker)\n  this._await()\n  fs.readFile(file, 'utf8', function (er, data) {\n    // just ignore missing files.\n    if (er) return this.add({}, marker)\n\n    this.addString(data, file, 'ini', marker)\n  }.bind(this))\n  return this\n}\n\n// always ini files.\nConf.prototype.parse = function (content, file) {\n  return CC.prototype.parse.call(this, content, file, 'ini')\n}\n\nConf.prototype.add = function (data, marker) {\n  try {\n    Object.keys(data).forEach(function (k) {\n      data[k] = parseField(data[k], k)\n    })\n  } catch (e) {\n    this.emit('error', e)\n    return this\n  }\n  return CC.prototype.add.call(this, data, marker)\n}\n\nConf.prototype.addEnv = function (env) {\n  env = env || process.env\n  var conf = {}\n  Object.keys(env)\n    .filter(function (k) { return k.match(/^npm_config_/i) })\n    .forEach(function (k) {\n      if (!env[k]) return\n\n      // leave first char untouched, even if\n      // it is a '_' - convert all other to '-'\n      var p = k.toLowerCase()\n               .replace(/^npm_config_/, '')\n               .replace(/(?!^)_/g, '-')\n      conf[p] = env[k]\n    })\n  return CC.prototype.addEnv.call(this, '', conf, 'env')\n}\n\nfunction parseField (f, k) {\n  if (typeof f !== 'string' && !(f instanceof String)) return f\n\n  // type can be an array or single thing.\n  var typeList = [].concat(types[k])\n  var isPath = typeList.indexOf(path) !== -1\n  var isBool = typeList.indexOf(Boolean) !== -1\n  var isString = typeList.indexOf(String) !== -1\n  var isUmask = typeList.indexOf(Umask) !== -1\n  var isNumber = typeList.indexOf(Number) !== -1\n\n  f = ('' + f).trim()\n\n  if (f.match(/^\".*\"$/)) {\n    try {\n      f = JSON.parse(f)\n    } catch (e) {\n      throw new Error('Failed parsing JSON config key ' + k + ': ' + f)\n    }\n  }\n\n  if (isBool && !isString && f === '') return true\n\n  switch (f) {\n    case 'true': return true\n    case 'false': return false\n    case 'null': return null\n    case 'undefined': return undefined\n  }\n\n  f = envReplace(f)\n\n  if (isPath) {\n    var homePattern = isWindows ? /^~(\\/|\\\\)/ : /^~\\//\n    if (f.match(homePattern) && process.env.HOME) {\n      f = path.resolve(process.env.HOME, f.substr(2))\n    }\n    f = path.resolve(f)\n  }\n\n  if (isUmask) f = umask.fromString(f)\n\n  if (isNumber && !isNaN(f)) f = +f\n\n  return f\n}\n\nfunction envReplace (f) {\n  if (typeof f !== 'string' || !f) return f\n\n  // replace any ${ENV} values with the appropriate environ.\n  var envExpr = /(\\\\*)\\$\\{([^}]+)\\}/g\n  return f.replace(envExpr, function (orig, esc, name) {\n    esc = esc.length && esc.length % 2\n    if (esc) return orig\n    if (undefined === process.env[name]) {\n      throw new Error('Failed to replace env in config: ' + orig)\n    }\n\n    return process.env[name]\n  })\n}\n\nfunction validate (cl) {\n  // warn about invalid configs at every level.\n  cl.list.forEach(function (conf) {\n    nopt.clean(conf, configDefs.types)\n  })\n\n  nopt.clean(cl.root, configDefs.types)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/config-chain/index.js":"var ProtoList = require('proto-list')\n  , path = require('path')\n  , fs = require('fs')\n  , ini = require('ini')\n  , EE = require('events').EventEmitter\n  , url = require('url')\n  , http = require('http')\n\nvar exports = module.exports = function () {\n  var args = [].slice.call(arguments)\n    , conf = new ConfigChain()\n\n  while(args.length) {\n    var a = args.shift()\n    if(a) conf.push\n          ( 'string' === typeof a\n            ? json(a)\n            : a )\n  }\n\n  return conf\n}\n\n//recursively find a file...\n\nvar find = exports.find = function () {\n  var rel = path.join.apply(null, [].slice.call(arguments))\n\n  function find(start, rel) {\n    var file = path.join(start, rel)\n    try {\n      fs.statSync(file)\n      return file\n    } catch (err) {\n      if(path.dirname(start) !== start) // root\n        return find(path.dirname(start), rel)\n    }\n  }\n  return find(__dirname, rel)\n}\n\nvar parse = exports.parse = function (content, file, type) {\n  content = '' + content\n  // if we don't know what it is, try json and fall back to ini\n  // if we know what it is, then it must be that.\n  if (!type) {\n    try { return JSON.parse(content) }\n    catch (er) { return ini.parse(content) }\n  } else if (type === 'json') {\n    if (this.emit) {\n      try { return JSON.parse(content) }\n      catch (er) { this.emit('error', er) }\n    } else {\n      return JSON.parse(content)\n    }\n  } else {\n    return ini.parse(content)\n  }\n}\n\nvar json = exports.json = function () {\n  var args = [].slice.call(arguments).filter(function (arg) { return arg != null })\n  var file = path.join.apply(null, args)\n  var content\n  try {\n    content = fs.readFileSync(file,'utf-8')\n  } catch (err) {\n    return\n  }\n  return parse(content, file, 'json')\n}\n\nvar env = exports.env = function (prefix, env) {\n  env = env || process.env\n  var obj = {}\n  var l = prefix.length\n  for(var k in env) {\n    if(k.indexOf(prefix) === 0)\n      obj[k.substring(l)] = env[k]\n  }\n\n  return obj\n}\n\nexports.ConfigChain = ConfigChain\nfunction ConfigChain () {\n  EE.apply(this)\n  ProtoList.apply(this, arguments)\n  this._awaiting = 0\n  this._saving = 0\n  this.sources = {}\n}\n\n// multi-inheritance-ish\nvar extras = {\n  constructor: { value: ConfigChain }\n}\nObject.keys(EE.prototype).forEach(function (k) {\n  extras[k] = Object.getOwnPropertyDescriptor(EE.prototype, k)\n})\nConfigChain.prototype = Object.create(ProtoList.prototype, extras)\n\nConfigChain.prototype.del = function (key, where) {\n  // if not specified where, then delete from the whole chain, scorched\n  // earth style\n  if (where) {\n    var target = this.sources[where]\n    target = target && target.data\n    if (!target) {\n      return this.emit('error', new Error('not found '+where))\n    }\n    delete target[key]\n  } else {\n    for (var i = 0, l = this.list.length; i < l; i ++) {\n      delete this.list[i][key]\n    }\n  }\n  return this\n}\n\nConfigChain.prototype.set = function (key, value, where) {\n  var target\n\n  if (where) {\n    target = this.sources[where]\n    target = target && target.data\n    if (!target) {\n      return this.emit('error', new Error('not found '+where))\n    }\n  } else {\n    target = this.list[0]\n    if (!target) {\n      return this.emit('error', new Error('cannot set, no confs!'))\n    }\n  }\n  target[key] = value\n  return this\n}\n\nConfigChain.prototype.get = function (key, where) {\n  if (where) {\n    where = this.sources[where]\n    if (where) where = where.data\n    if (where && Object.hasOwnProperty.call(where, key)) return where[key]\n    return undefined\n  }\n  return this.list[0][key]\n}\n\nConfigChain.prototype.save = function (where, type, cb) {\n  if (typeof type === 'function') cb = type, type = null\n  var target = this.sources[where]\n  if (!target || !(target.path || target.source) || !target.data) {\n    // TODO: maybe save() to a url target could be a PUT or something?\n    // would be easy to swap out with a reddis type thing, too\n    return this.emit('error', new Error('bad save target: '+where))\n  }\n\n  if (target.source) {\n    var pref = target.prefix || ''\n    Object.keys(target.data).forEach(function (k) {\n      target.source[pref + k] = target.data[k]\n    })\n    return this\n  }\n\n  var type = type || target.type\n  var data = target.data\n  if (target.type === 'json') {\n    data = JSON.stringify(data)\n  } else {\n    data = ini.stringify(data)\n  }\n\n  this._saving ++\n  fs.writeFile(target.path, data, 'utf8', function (er) {\n    this._saving --\n    if (er) {\n      if (cb) return cb(er)\n      else return this.emit('error', er)\n    }\n    if (this._saving === 0) {\n      if (cb) cb()\n      this.emit('save')\n    }\n  }.bind(this))\n  return this\n}\n\nConfigChain.prototype.addFile = function (file, type, name) {\n  name = name || file\n  var marker = {__source__:name}\n  this.sources[name] = { path: file, type: type }\n  this.push(marker)\n  this._await()\n  fs.readFile(file, 'utf8', function (er, data) {\n    if (er) this.emit('error', er)\n    this.addString(data, file, type, marker)\n  }.bind(this))\n  return this\n}\n\nConfigChain.prototype.addEnv = function (prefix, env, name) {\n  name = name || 'env'\n  var data = exports.env(prefix, env)\n  this.sources[name] = { data: data, source: env, prefix: prefix }\n  return this.add(data, name)\n}\n\nConfigChain.prototype.addUrl = function (req, type, name) {\n  this._await()\n  var href = url.format(req)\n  name = name || href\n  var marker = {__source__:name}\n  this.sources[name] = { href: href, type: type }\n  this.push(marker)\n  http.request(req, function (res) {\n    var c = []\n    var ct = res.headers['content-type']\n    if (!type) {\n      type = ct.indexOf('json') !== -1 ? 'json'\n           : ct.indexOf('ini') !== -1 ? 'ini'\n           : href.match(/\\.json$/) ? 'json'\n           : href.match(/\\.ini$/) ? 'ini'\n           : null\n      marker.type = type\n    }\n\n    res.on('data', c.push.bind(c))\n    .on('end', function () {\n      this.addString(Buffer.concat(c), href, type, marker)\n    }.bind(this))\n    .on('error', this.emit.bind(this, 'error'))\n\n  }.bind(this))\n  .on('error', this.emit.bind(this, 'error'))\n  .end()\n\n  return this\n}\n\nConfigChain.prototype.addString = function (data, file, type, marker) {\n  data = this.parse(data, file, type)\n  this.add(data, marker)\n  return this\n}\n\nConfigChain.prototype.add = function (data, marker) {\n  if (marker && typeof marker === 'object') {\n    var i = this.list.indexOf(marker)\n    if (i === -1) {\n      return this.emit('error', new Error('bad marker'))\n    }\n    this.splice(i, 1, data)\n    marker = marker.__source__\n    this.sources[marker] = this.sources[marker] || {}\n    this.sources[marker].data = data\n    // we were waiting for this.  maybe emit 'load'\n    this._resolve()\n  } else {\n    if (typeof marker === 'string') {\n      this.sources[marker] = this.sources[marker] || {}\n      this.sources[marker].data = data\n    }\n    // trigger the load event if nothing was already going to do so.\n    this._await()\n    this.push(data)\n    process.nextTick(this._resolve.bind(this))\n  }\n  return this\n}\n\nConfigChain.prototype.parse = exports.parse\n\nConfigChain.prototype._await = function () {\n  this._awaiting++\n}\n\nConfigChain.prototype._resolve = function () {\n  this._awaiting--\n  if (this._awaiting === 0) this.emit('load', this)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/config-chain/node_modules/proto-list/proto-list.js":"\nmodule.exports = ProtoList\n\nfunction setProto(obj, proto) {\n  if (typeof Object.setPrototypeOf === \"function\")\n    return Object.setPrototypeOf(obj, proto)\n  else\n    obj.__proto__ = proto\n}\n\nfunction ProtoList () {\n  this.list = []\n  var root = null\n  Object.defineProperty(this, 'root', {\n    get: function () { return root },\n    set: function (r) {\n      root = r\n      if (this.list.length) {\n        setProto(this.list[this.list.length - 1], r)\n      }\n    },\n    enumerable: true,\n    configurable: true\n  })\n}\n\nProtoList.prototype =\n  { get length () { return this.list.length }\n  , get keys () {\n      var k = []\n      for (var i in this.list[0]) k.push(i)\n      return k\n    }\n  , get snapshot () {\n      var o = {}\n      this.keys.forEach(function (k) { o[k] = this.get(k) }, this)\n      return o\n    }\n  , get store () {\n      return this.list[0]\n    }\n  , push : function (obj) {\n      if (typeof obj !== \"object\") obj = {valueOf:obj}\n      if (this.list.length >= 1) {\n        setProto(this.list[this.list.length - 1], obj)\n      }\n      setProto(obj, this.root)\n      return this.list.push(obj)\n    }\n  , pop : function () {\n      if (this.list.length >= 2) {\n        setProto(this.list[this.list.length - 2], this.root)\n      }\n      return this.list.pop()\n    }\n  , unshift : function (obj) {\n      setProto(obj, this.list[0] || this.root)\n      return this.list.unshift(obj)\n    }\n  , shift : function () {\n      if (this.list.length === 1) {\n        setProto(this.list[0], this.root)\n      }\n      return this.list.shift()\n    }\n  , get : function (key) {\n      return this.list[0][key]\n    }\n  , set : function (key, val, save) {\n      if (!this.length) this.push({})\n      if (save && this.list[0].hasOwnProperty(key)) this.push({})\n      return this.list[0][key] = val\n    }\n  , forEach : function (fn, thisp) {\n      for (var key in this.list[0]) fn.call(thisp, key, this.list[0][key])\n    }\n  , slice : function () {\n      return this.list.slice.apply(this.list, arguments)\n    }\n  , splice : function () {\n      // handle injections\n      var ret = this.list.splice.apply(this.list, arguments)\n      for (var i = 0, l = this.list.length; i < l; i++) {\n        setProto(this.list[i], this.list[i + 1] || this.root)\n      }\n      return ret\n    }\n  }\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/ini/ini.js":"\nexports.parse = exports.decode = decode\nexports.stringify = exports.encode = encode\n\nexports.safe = safe\nexports.unsafe = unsafe\n\nvar eol = process.platform === \"win32\" ? \"\\r\\n\" : \"\\n\"\n\nfunction encode (obj, opt) {\n  var children = []\n    , out = \"\"\n\n  if (typeof opt === \"string\") {\n    opt = {\n      section: opt,\n      whitespace: false\n    }\n  } else {\n    opt = opt || {}\n    opt.whitespace = opt.whitespace === true\n  }\n\n  var separator = opt.whitespace ? \" = \" : \"=\"\n\n  Object.keys(obj).forEach(function (k, _, __) {\n    var val = obj[k]\n    if (val && Array.isArray(val)) {\n        val.forEach(function(item) {\n            out += safe(k + \"[]\") + separator + safe(item) + \"\\n\"\n        })\n    }\n    else if (val && typeof val === \"object\") {\n      children.push(k)\n    } else {\n      out += safe(k) + separator + safe(val) + eol\n    }\n  })\n\n  if (opt.section && out.length) {\n    out = \"[\" + safe(opt.section) + \"]\" + eol + out\n  }\n\n  children.forEach(function (k, _, __) {\n    var nk = dotSplit(k).join('\\\\.')\n    var section = (opt.section ? opt.section + \".\" : \"\") + nk\n    var child = encode(obj[k], {\n      section: section,\n      whitespace: opt.whitespace\n    })\n    if (out.length && child.length) {\n      out += eol\n    }\n    out += child\n  })\n\n  return out\n}\n\nfunction dotSplit (str) {\n  return str.replace(/\\1/g, '\\u0002LITERAL\\\\1LITERAL\\u0002')\n         .replace(/\\\\\\./g, '\\u0001')\n         .split(/\\./).map(function (part) {\n           return part.replace(/\\1/g, '\\\\.')\n                  .replace(/\\2LITERAL\\\\1LITERAL\\2/g, '\\u0001')\n        })\n}\n\nfunction decode (str) {\n  var out = {}\n    , p = out\n    , section = null\n    , state = \"START\"\n           // section     |key = value\n    , re = /^\\[([^\\]]*)\\]$|^([^=]+)(=(.*))?$/i\n    , lines = str.split(/[\\r\\n]+/g)\n    , section = null\n\n  lines.forEach(function (line, _, __) {\n    if (!line || line.match(/^\\s*[;#]/)) return\n    var match = line.match(re)\n    if (!match) return\n    if (match[1] !== undefined) {\n      section = unsafe(match[1])\n      p = out[section] = out[section] || {}\n      return\n    }\n    var key = unsafe(match[2])\n      , value = match[3] ? unsafe((match[4] || \"\")) : true\n    switch (value) {\n      case 'true':\n      case 'false':\n      case 'null': value = JSON.parse(value)\n    }\n\n    // Convert keys with '[]' suffix to an array\n    if (key.length > 2 && key.slice(-2) === \"[]\") {\n        key = key.substring(0, key.length - 2)\n        if (!p[key]) {\n          p[key] = []\n        }\n        else if (!Array.isArray(p[key])) {\n          p[key] = [p[key]]\n        }\n    }\n\n    // safeguard against resetting a previously defined\n    // array by accidentally forgetting the brackets\n    if (Array.isArray(p[key])) {\n      p[key].push(value)\n    }\n    else {\n      p[key] = value\n    }\n  })\n\n  // {a:{y:1},\"a.b\":{x:2}} --> {a:{y:1,b:{x:2}}}\n  // use a filter to return the keys that have to be deleted.\n  Object.keys(out).filter(function (k, _, __) {\n    if (!out[k] || typeof out[k] !== \"object\" || Array.isArray(out[k])) return false\n    // see if the parent section is also an object.\n    // if so, add it to that, and mark this one for deletion\n    var parts = dotSplit(k)\n      , p = out\n      , l = parts.pop()\n      , nl = l.replace(/\\\\\\./g, '.')\n    parts.forEach(function (part, _, __) {\n      if (!p[part] || typeof p[part] !== \"object\") p[part] = {}\n      p = p[part]\n    })\n    if (p === out && nl === l) return false\n    p[nl] = out[k]\n    return true\n  }).forEach(function (del, _, __) {\n    delete out[del]\n  })\n\n  return out\n}\n\nfunction isQuoted (val) {\n  return (val.charAt(0) === \"\\\"\" && val.slice(-1) === \"\\\"\")\n         || (val.charAt(0) === \"'\" && val.slice(-1) === \"'\")\n}\n\nfunction safe (val) {\n  return ( typeof val !== \"string\"\n         || val.match(/[=\\r\\n]/)\n         || val.match(/^\\[/)\n         || (val.length > 1\n             && isQuoted(val))\n         || val !== val.trim() )\n         ? JSON.stringify(val)\n         : val.replace(/;/g, '\\\\;').replace(/#/g, \"\\\\#\")\n}\n\nfunction unsafe (val, doUnesc) {\n  val = (val || \"\").trim()\n  if (isQuoted(val)) {\n    // remove the single quotes before calling JSON.parse\n    if (val.charAt(0) === \"'\") {\n      val = val.substr(1, val.length - 2);\n    }\n    try { val = JSON.parse(val) } catch (_) {}\n  } else {\n    // walk the val to find the first not-escaped ; character\n    var esc = false\n    var unesc = \"\";\n    for (var i = 0, l = val.length; i < l; i++) {\n      var c = val.charAt(i)\n      if (esc) {\n        if (\"\\\\;#\".indexOf(c) !== -1)\n          unesc += c\n        else\n          unesc += \"\\\\\" + c\n        esc = false\n      } else if (\";#\".indexOf(c) !== -1) {\n        break\n      } else if (c === \"\\\\\") {\n        esc = true\n      } else {\n        unesc += c\n      }\n    }\n    if (esc)\n      unesc += \"\\\\\"\n    return unesc\n  }\n  return val\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/inherits/inherits.js":"try {\n  var util = require('util');\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  module.exports = require('./inherits_browser.js');\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/defaults.js":"// defaults, types, and shorthands.\n\nvar path = require('path')\nvar url = require('url')\nvar Stream = require('stream').Stream\nvar semver = require('semver')\nvar stableFamily = semver.parse(process.version)\nvar nopt = require('nopt')\nvar os = require('os')\nvar osenv = require('osenv')\nvar umask = require('../utils/umask')\nvar hasUnicode = require('has-unicode')\n\nvar log\ntry {\n  log = require('npmlog')\n} catch (er) {\n  var util = require('util')\n  log = { warn: function (m) {\n    console.warn(m + ' ' + util.format.apply(util, [].slice.call(arguments, 1)))\n  } }\n}\n\nexports.Umask = Umask\nfunction Umask () {}\nfunction validateUmask (data, k, val) {\n  return umask.validate(data, k, val)\n}\n\nfunction validateSemver (data, k, val) {\n  if (!semver.valid(val)) return false\n  data[k] = semver.valid(val)\n}\n\nfunction validateStream (data, k, val) {\n  if (!(val instanceof Stream)) return false\n  data[k] = val\n}\n\nnopt.typeDefs.semver = { type: semver, validate: validateSemver }\nnopt.typeDefs.Stream = { type: Stream, validate: validateStream }\nnopt.typeDefs.Umask = { type: Umask, validate: validateUmask }\n\nnopt.invalidHandler = function (k, val, type) {\n  log.warn('invalid config', k + '=' + JSON.stringify(val))\n\n  if (Array.isArray(type)) {\n    if (type.indexOf(url) !== -1) type = url\n    else if (type.indexOf(path) !== -1) type = path\n  }\n\n  switch (type) {\n    case Umask:\n      log.warn('invalid config', 'Must be umask, octal number in range 0000..0777')\n      break\n    case url:\n      log.warn('invalid config', \"Must be a full url with 'http://'\")\n      break\n    case path:\n      log.warn('invalid config', 'Must be a valid filesystem path')\n      break\n    case Number:\n      log.warn('invalid config', 'Must be a numeric value')\n      break\n    case Stream:\n      log.warn('invalid config', 'Must be an instance of the Stream class')\n      break\n  }\n}\n\nif (!stableFamily || (+stableFamily.minor % 2)) stableFamily = null\nelse stableFamily = stableFamily.major + '.' + stableFamily.minor\n\nvar defaults\n\nvar temp = osenv.tmpdir()\nvar home = osenv.home()\n\nvar uidOrPid = process.getuid ? process.getuid() : process.pid\n\nif (home) process.env.HOME = home\nelse home = path.resolve(temp, 'npm-' + uidOrPid)\n\nvar cacheExtra = process.platform === 'win32' ? 'npm-cache' : '.npm'\nvar cacheRoot = process.platform === 'win32' && process.env.APPDATA || home\nvar cache = path.resolve(cacheRoot, cacheExtra)\n\nvar globalPrefix\nObject.defineProperty(exports, 'defaults', {get: function () {\n  if (defaults) return defaults\n\n  if (process.env.PREFIX) {\n    globalPrefix = process.env.PREFIX\n  } else if (process.platform === 'win32') {\n    // c:\\node\\node.exe --> prefix=c:\\node\\\n    globalPrefix = path.dirname(process.execPath)\n  } else {\n    // /usr/local/bin/node --> prefix=/usr/local\n    globalPrefix = path.dirname(path.dirname(process.execPath))\n\n    // destdir only is respected on Unix\n    if (process.env.DESTDIR) {\n      globalPrefix = path.join(process.env.DESTDIR, globalPrefix)\n    }\n  }\n\n  defaults = {\n    access: null,\n    'always-auth': false,\n    also: null,\n    'auth-type': 'legacy',\n\n    'bin-links': true,\n    browser: null,\n\n    ca: null,\n    cafile: null,\n\n    cache: cache,\n\n    'cache-lock-stale': 60000,\n    'cache-lock-retries': 10,\n    'cache-lock-wait': 10000,\n\n    'cache-max': Infinity,\n    'cache-min': 10,\n\n    cert: null,\n\n    color: true,\n    depth: Infinity,\n    description: true,\n    dev: false,\n    'dry-run': false,\n    editor: osenv.editor(),\n    'engine-strict': false,\n    force: false,\n\n    'fetch-retries': 2,\n    'fetch-retry-factor': 10,\n    'fetch-retry-mintimeout': 10000,\n    'fetch-retry-maxtimeout': 60000,\n\n    git: 'git',\n    'git-tag-version': true,\n\n    global: false,\n    globalconfig: path.resolve(globalPrefix, 'etc', 'npmrc'),\n    'global-style': false,\n    group: process.platform === 'win32' ? 0\n            : process.env.SUDO_GID || (process.getgid && process.getgid()),\n    'ham-it-up': false,\n    heading: 'npm',\n    'if-present': false,\n    'ignore-scripts': false,\n    'init-module': path.resolve(home, '.npm-init.js'),\n    'init-author-name': '',\n    'init-author-email': '',\n    'init-author-url': '',\n    'init-version': '1.0.0',\n    'init-license': 'ISC',\n    json: false,\n    key: null,\n    'legacy-bundling': false,\n    link: false,\n    'local-address': undefined,\n    loglevel: 'warn',\n    logstream: process.stderr,\n    'logs-max': 10,\n    long: false,\n    maxsockets: 50,\n    message: '%s',\n    'metrics-registry': null,\n    'node-version': process.version,\n    'onload-script': false,\n    only: null,\n    optional: true,\n    parseable: false,\n    prefix: globalPrefix,\n    production: process.env.NODE_ENV === 'production',\n    'progress': !process.env.TRAVIS && !process.env.CI,\n    'proprietary-attribs': true,\n    proxy: null,\n    'https-proxy': null,\n    'user-agent': 'npm/{npm-version} ' +\n                    'node/{node-version} ' +\n                    '{platform} ' +\n                    '{arch}',\n    'rebuild-bundle': true,\n    registry: 'https://registry.npmjs.org/',\n    rollback: true,\n    save: false,\n    'save-bundle': false,\n    'save-dev': false,\n    'save-exact': false,\n    'save-optional': false,\n    'save-prefix': '^',\n    scope: '',\n    'scripts-prepend-node-path': 'warn-only',\n    searchopts: '',\n    searchexclude: null,\n    searchlimit: 20,\n    searchstaleness: 15 * 60,\n    'send-metrics': false,\n    shell: osenv.shell(),\n    shrinkwrap: true,\n    'sign-git-tag': false,\n    'sso-poll-frequency': 500,\n    'sso-type': 'oauth',\n    'strict-ssl': true,\n    tag: 'latest',\n    'tag-version-prefix': 'v',\n    tmp: temp,\n    unicode: hasUnicode(),\n    'unsafe-perm': process.platform === 'win32' ||\n                     process.platform === 'cygwin' ||\n                     !(process.getuid && process.setuid &&\n                       process.getgid && process.setgid) ||\n                     process.getuid() !== 0,\n    usage: false,\n    user: process.platform === 'win32' ? 0 : 'nobody',\n    userconfig: path.resolve(home, '.npmrc'),\n    umask: process.umask ? process.umask() : umask.fromString('022'),\n    version: false,\n    versions: false,\n    viewer: process.platform === 'win32' ? 'browser' : 'man',\n\n    _exit: true\n  }\n\n  return defaults\n}})\n\nexports.types = {\n  access: [null, 'restricted', 'public'],\n  'always-auth': Boolean,\n  also: [null, 'dev', 'development'],\n  'auth-type': ['legacy', 'sso', 'saml', 'oauth'],\n  'bin-links': Boolean,\n  browser: [null, String],\n  ca: [null, String, Array],\n  cafile: path,\n  cache: path,\n  'cache-lock-stale': Number,\n  'cache-lock-retries': Number,\n  'cache-lock-wait': Number,\n  'cache-max': Number,\n  'cache-min': Number,\n  cert: [null, String],\n  color: ['always', Boolean],\n  depth: Number,\n  description: Boolean,\n  dev: Boolean,\n  'dry-run': Boolean,\n  editor: String,\n  'engine-strict': Boolean,\n  force: Boolean,\n  'fetch-retries': Number,\n  'fetch-retry-factor': Number,\n  'fetch-retry-mintimeout': Number,\n  'fetch-retry-maxtimeout': Number,\n  git: String,\n  'git-tag-version': Boolean,\n  global: Boolean,\n  globalconfig: path,\n  'global-style': Boolean,\n  group: [Number, String],\n  'https-proxy': [null, url],\n  'user-agent': String,\n  'ham-it-up': Boolean,\n  'heading': String,\n  'if-present': Boolean,\n  'ignore-scripts': Boolean,\n  'init-module': path,\n  'init-author-name': String,\n  'init-author-email': String,\n  'init-author-url': ['', url],\n  'init-license': String,\n  'init-version': semver,\n  json: Boolean,\n  key: [null, String],\n  'legacy-bundling': Boolean,\n  link: Boolean,\n  // local-address must be listed as an IP for a local network interface\n  // must be IPv4 due to node bug\n  'local-address': getLocalAddresses(),\n  loglevel: ['silent', 'error', 'warn', 'http', 'info', 'verbose', 'silly'],\n  logstream: Stream,\n  'logs-max': Number,\n  long: Boolean,\n  maxsockets: Number,\n  message: String,\n  'metrics-registry': [null, String],\n  'node-version': [null, semver],\n  'onload-script': [null, String],\n  only: [null, 'dev', 'development', 'prod', 'production'],\n  optional: Boolean,\n  parseable: Boolean,\n  prefix: path,\n  production: Boolean,\n  progress: Boolean,\n  'proprietary-attribs': Boolean,\n  proxy: [null, false, url], // allow proxy to be disabled explicitly\n  'rebuild-bundle': Boolean,\n  registry: [null, url],\n  rollback: Boolean,\n  save: Boolean,\n  'save-bundle': Boolean,\n  'save-dev': Boolean,\n  'save-exact': Boolean,\n  'save-optional': Boolean,\n  'save-prefix': String,\n  scope: String,\n  'scripts-prepend-node-path': [false, true, 'auto', 'warn-only'],\n  searchopts: String,\n  searchexclude: [null, String],\n  searchlimit: Number,\n  searchstaleness: Number,\n  'send-metrics': Boolean,\n  shell: String,\n  shrinkwrap: Boolean,\n  'sign-git-tag': Boolean,\n  'sso-poll-frequency': Number,\n  'sso-type': [null, 'oauth', 'saml'],\n  'strict-ssl': Boolean,\n  tag: String,\n  tmp: path,\n  unicode: Boolean,\n  'unsafe-perm': Boolean,\n  usage: Boolean,\n  user: [Number, String],\n  userconfig: path,\n  umask: Umask,\n  version: Boolean,\n  'tag-version-prefix': String,\n  versions: Boolean,\n  viewer: String,\n  _exit: Boolean\n}\n\nfunction getLocalAddresses () {\n  var interfaces\n  // #8094: some environments require elevated permissions to enumerate\n  // interfaces, and synchronously throw EPERM when run without\n  // elevated privileges\n  try {\n    interfaces = os.networkInterfaces()\n  } catch (e) {\n    interfaces = {}\n  }\n\n  return Object.keys(interfaces).map(function (nic) {\n    return interfaces[nic].filter(function (addr) {\n      return addr.family === 'IPv4'\n    })\n    .map(function (addr) {\n      return addr.address\n    })\n  }).reduce(function (curr, next) {\n    return curr.concat(next)\n  }, []).concat(undefined)\n}\n\nexports.shorthands = {\n  s: ['--loglevel', 'silent'],\n  d: ['--loglevel', 'info'],\n  dd: ['--loglevel', 'verbose'],\n  ddd: ['--loglevel', 'silly'],\n  noreg: ['--no-registry'],\n  N: ['--no-registry'],\n  reg: ['--registry'],\n  'no-reg': ['--no-registry'],\n  silent: ['--loglevel', 'silent'],\n  verbose: ['--loglevel', 'verbose'],\n  quiet: ['--loglevel', 'warn'],\n  q: ['--loglevel', 'warn'],\n  h: ['--usage'],\n  H: ['--usage'],\n  '?': ['--usage'],\n  help: ['--usage'],\n  v: ['--version'],\n  f: ['--force'],\n  desc: ['--description'],\n  'no-desc': ['--no-description'],\n  'local': ['--no-global'],\n  l: ['--long'],\n  m: ['--message'],\n  p: ['--parseable'],\n  porcelain: ['--parseable'],\n  g: ['--global'],\n  S: ['--save'],\n  D: ['--save-dev'],\n  E: ['--save-exact'],\n  O: ['--save-optional'],\n  y: ['--yes'],\n  n: ['--no-yes'],\n  B: ['--save-bundle'],\n  C: ['--prefix']\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/nopt/lib/nopt.js":"// info about each config option.\n\nvar debug = process.env.DEBUG_NOPT || process.env.NOPT_DEBUG\n  ? function () { console.error.apply(console, arguments) }\n  : function () {}\n\nvar url = require(\"url\")\n  , path = require(\"path\")\n  , Stream = require(\"stream\").Stream\n  , abbrev = require(\"abbrev\")\n  , osenv = require(\"osenv\")\n\nmodule.exports = exports = nopt\nexports.clean = clean\n\nexports.typeDefs =\n  { String  : { type: String,  validate: validateString  }\n  , Boolean : { type: Boolean, validate: validateBoolean }\n  , url     : { type: url,     validate: validateUrl     }\n  , Number  : { type: Number,  validate: validateNumber  }\n  , path    : { type: path,    validate: validatePath    }\n  , Stream  : { type: Stream,  validate: validateStream  }\n  , Date    : { type: Date,    validate: validateDate    }\n  }\n\nfunction nopt (types, shorthands, args, slice) {\n  args = args || process.argv\n  types = types || {}\n  shorthands = shorthands || {}\n  if (typeof slice !== \"number\") slice = 2\n\n  debug(types, shorthands, args, slice)\n\n  args = args.slice(slice)\n  var data = {}\n    , key\n    , argv = {\n        remain: [],\n        cooked: args,\n        original: args.slice(0)\n      }\n\n  parse(args, data, argv.remain, types, shorthands)\n  // now data is full\n  clean(data, types, exports.typeDefs)\n  data.argv = argv\n  Object.defineProperty(data.argv, 'toString', { value: function () {\n    return this.original.map(JSON.stringify).join(\" \")\n  }, enumerable: false })\n  return data\n}\n\nfunction clean (data, types, typeDefs) {\n  typeDefs = typeDefs || exports.typeDefs\n  var remove = {}\n    , typeDefault = [false, true, null, String, Array]\n\n  Object.keys(data).forEach(function (k) {\n    if (k === \"argv\") return\n    var val = data[k]\n      , isArray = Array.isArray(val)\n      , type = types[k]\n    if (!isArray) val = [val]\n    if (!type) type = typeDefault\n    if (type === Array) type = typeDefault.concat(Array)\n    if (!Array.isArray(type)) type = [type]\n\n    debug(\"val=%j\", val)\n    debug(\"types=\", type)\n    val = val.map(function (val) {\n      // if it's an unknown value, then parse false/true/null/numbers/dates\n      if (typeof val === \"string\") {\n        debug(\"string %j\", val)\n        val = val.trim()\n        if ((val === \"null\" && ~type.indexOf(null))\n            || (val === \"true\" &&\n               (~type.indexOf(true) || ~type.indexOf(Boolean)))\n            || (val === \"false\" &&\n               (~type.indexOf(false) || ~type.indexOf(Boolean)))) {\n          val = JSON.parse(val)\n          debug(\"jsonable %j\", val)\n        } else if (~type.indexOf(Number) && !isNaN(val)) {\n          debug(\"convert to number\", val)\n          val = +val\n        } else if (~type.indexOf(Date) && !isNaN(Date.parse(val))) {\n          debug(\"convert to date\", val)\n          val = new Date(val)\n        }\n      }\n\n      if (!types.hasOwnProperty(k)) {\n        return val\n      }\n\n      // allow `--no-blah` to set 'blah' to null if null is allowed\n      if (val === false && ~type.indexOf(null) &&\n          !(~type.indexOf(false) || ~type.indexOf(Boolean))) {\n        val = null\n      }\n\n      var d = {}\n      d[k] = val\n      debug(\"prevalidated val\", d, val, types[k])\n      if (!validate(d, k, val, types[k], typeDefs)) {\n        if (exports.invalidHandler) {\n          exports.invalidHandler(k, val, types[k], data)\n        } else if (exports.invalidHandler !== false) {\n          debug(\"invalid: \"+k+\"=\"+val, types[k])\n        }\n        return remove\n      }\n      debug(\"validated val\", d, val, types[k])\n      return d[k]\n    }).filter(function (val) { return val !== remove })\n\n    if (!val.length) delete data[k]\n    else if (isArray) {\n      debug(isArray, data[k], val)\n      data[k] = val\n    } else data[k] = val[0]\n\n    debug(\"k=%s val=%j\", k, val, data[k])\n  })\n}\n\nfunction validateString (data, k, val) {\n  data[k] = String(val)\n}\n\nfunction validatePath (data, k, val) {\n  if (val === true) return false\n  if (val === null) return true\n\n  val = String(val)\n\n  var isWin       = process.platform === 'win32'\n    , homePattern = isWin ? /^~(\\/|\\\\)/ : /^~\\//\n    , home        = osenv.home()\n\n  if (home && val.match(homePattern)) {\n    data[k] = path.resolve(home, val.substr(2))\n  } else {\n    data[k] = path.resolve(val)\n  }\n  return true\n}\n\nfunction validateNumber (data, k, val) {\n  debug(\"validate Number %j %j %j\", k, val, isNaN(val))\n  if (isNaN(val)) return false\n  data[k] = +val\n}\n\nfunction validateDate (data, k, val) {\n  var s = Date.parse(val)\n  debug(\"validate Date %j %j %j\", k, val, s)\n  if (isNaN(s)) return false\n  data[k] = new Date(val)\n}\n\nfunction validateBoolean (data, k, val) {\n  if (val instanceof Boolean) val = val.valueOf()\n  else if (typeof val === \"string\") {\n    if (!isNaN(val)) val = !!(+val)\n    else if (val === \"null\" || val === \"false\") val = false\n    else val = true\n  } else val = !!val\n  data[k] = val\n}\n\nfunction validateUrl (data, k, val) {\n  val = url.parse(String(val))\n  if (!val.host) return false\n  data[k] = val.href\n}\n\nfunction validateStream (data, k, val) {\n  if (!(val instanceof Stream)) return false\n  data[k] = val\n}\n\nfunction validate (data, k, val, type, typeDefs) {\n  // arrays are lists of types.\n  if (Array.isArray(type)) {\n    for (var i = 0, l = type.length; i < l; i ++) {\n      if (type[i] === Array) continue\n      if (validate(data, k, val, type[i], typeDefs)) return true\n    }\n    delete data[k]\n    return false\n  }\n\n  // an array of anything?\n  if (type === Array) return true\n\n  // NaN is poisonous.  Means that something is not allowed.\n  if (type !== type) {\n    debug(\"Poison NaN\", k, val, type)\n    delete data[k]\n    return false\n  }\n\n  // explicit list of values\n  if (val === type) {\n    debug(\"Explicitly allowed %j\", val)\n    // if (isArray) (data[k] = data[k] || []).push(val)\n    // else data[k] = val\n    data[k] = val\n    return true\n  }\n\n  // now go through the list of typeDefs, validate against each one.\n  var ok = false\n    , types = Object.keys(typeDefs)\n  for (var i = 0, l = types.length; i < l; i ++) {\n    debug(\"test type %j %j %j\", k, val, types[i])\n    var t = typeDefs[types[i]]\n    if (t &&\n      ((type && type.name && t.type && t.type.name) ? (type.name === t.type.name) : (type === t.type))) {\n      var d = {}\n      ok = false !== t.validate(d, k, val)\n      val = d[k]\n      if (ok) {\n        // if (isArray) (data[k] = data[k] || []).push(val)\n        // else data[k] = val\n        data[k] = val\n        break\n      }\n    }\n  }\n  debug(\"OK? %j (%j %j %j)\", ok, k, val, types[i])\n\n  if (!ok) delete data[k]\n  return ok\n}\n\nfunction parse (args, data, remain, types, shorthands) {\n  debug(\"parse\", args, data, remain)\n\n  var key = null\n    , abbrevs = abbrev(Object.keys(types))\n    , shortAbbr = abbrev(Object.keys(shorthands))\n\n  for (var i = 0; i < args.length; i ++) {\n    var arg = args[i]\n    debug(\"arg\", arg)\n\n    if (arg.match(/^-{2,}$/)) {\n      // done with keys.\n      // the rest are args.\n      remain.push.apply(remain, args.slice(i + 1))\n      args[i] = \"--\"\n      break\n    }\n    var hadEq = false\n    if (arg.charAt(0) === \"-\" && arg.length > 1) {\n      var at = arg.indexOf('=')\n      if (at > -1) {\n        hadEq = true\n        var v = arg.substr(at + 1)\n        arg = arg.substr(0, at)\n        args.splice(i, 1, arg, v)\n      }\n\n      // see if it's a shorthand\n      // if so, splice and back up to re-parse it.\n      var shRes = resolveShort(arg, shorthands, shortAbbr, abbrevs)\n      debug(\"arg=%j shRes=%j\", arg, shRes)\n      if (shRes) {\n        debug(arg, shRes)\n        args.splice.apply(args, [i, 1].concat(shRes))\n        if (arg !== shRes[0]) {\n          i --\n          continue\n        }\n      }\n      arg = arg.replace(/^-+/, \"\")\n      var no = null\n      while (arg.toLowerCase().indexOf(\"no-\") === 0) {\n        no = !no\n        arg = arg.substr(3)\n      }\n\n      if (abbrevs[arg]) arg = abbrevs[arg]\n\n      var argType = types[arg]\n      var isTypeArray = Array.isArray(argType)\n      if (isTypeArray && argType.length === 1) {\n        isTypeArray = false\n        argType = argType[0]\n      }\n\n      var isArray = argType === Array ||\n        isTypeArray && argType.indexOf(Array) !== -1\n\n      // allow unknown things to be arrays if specified multiple times.\n      if (!types.hasOwnProperty(arg) && data.hasOwnProperty(arg)) {\n        if (!Array.isArray(data[arg]))\n          data[arg] = [data[arg]]\n        isArray = true\n      }\n\n      var val\n        , la = args[i + 1]\n\n      var isBool = typeof no === 'boolean' ||\n        argType === Boolean ||\n        isTypeArray && argType.indexOf(Boolean) !== -1 ||\n        (typeof argType === 'undefined' && !hadEq) ||\n        (la === \"false\" &&\n         (argType === null ||\n          isTypeArray && ~argType.indexOf(null)))\n\n      if (isBool) {\n        // just set and move along\n        val = !no\n        // however, also support --bool true or --bool false\n        if (la === \"true\" || la === \"false\") {\n          val = JSON.parse(la)\n          la = null\n          if (no) val = !val\n          i ++\n        }\n\n        // also support \"foo\":[Boolean, \"bar\"] and \"--foo bar\"\n        if (isTypeArray && la) {\n          if (~argType.indexOf(la)) {\n            // an explicit type\n            val = la\n            i ++\n          } else if ( la === \"null\" && ~argType.indexOf(null) ) {\n            // null allowed\n            val = null\n            i ++\n          } else if ( !la.match(/^-{2,}[^-]/) &&\n                      !isNaN(la) &&\n                      ~argType.indexOf(Number) ) {\n            // number\n            val = +la\n            i ++\n          } else if ( !la.match(/^-[^-]/) && ~argType.indexOf(String) ) {\n            // string\n            val = la\n            i ++\n          }\n        }\n\n        if (isArray) (data[arg] = data[arg] || []).push(val)\n        else data[arg] = val\n\n        continue\n      }\n\n      if (argType === String) {\n        if (la === undefined) {\n          la = \"\"\n        } else if (la.match(/^-{1,2}[^-]+/)) {\n          la = \"\"\n          i --\n        }\n      }\n\n      if (la && la.match(/^-{2,}$/)) {\n        la = undefined\n        i --\n      }\n\n      val = la === undefined ? true : la\n      if (isArray) (data[arg] = data[arg] || []).push(val)\n      else data[arg] = val\n\n      i ++\n      continue\n    }\n    remain.push(arg)\n  }\n}\n\nfunction resolveShort (arg, shorthands, shortAbbr, abbrevs) {\n  // handle single-char shorthands glommed together, like\n  // npm ls -glp, but only if there is one dash, and only if\n  // all of the chars are single-char shorthands, and it's\n  // not a match to some other abbrev.\n  arg = arg.replace(/^-+/, '')\n\n  // if it's an exact known option, then don't go any further\n  if (abbrevs[arg] === arg)\n    return null\n\n  // if it's an exact known shortopt, same deal\n  if (shorthands[arg]) {\n    // make it an array, if it's a list of words\n    if (shorthands[arg] && !Array.isArray(shorthands[arg]))\n      shorthands[arg] = shorthands[arg].split(/\\s+/)\n\n    return shorthands[arg]\n  }\n\n  // first check to see if this arg is a set of single-char shorthands\n  var singles = shorthands.___singles\n  if (!singles) {\n    singles = Object.keys(shorthands).filter(function (s) {\n      return s.length === 1\n    }).reduce(function (l,r) {\n      l[r] = true\n      return l\n    }, {})\n    shorthands.___singles = singles\n    debug('shorthand singles', singles)\n  }\n\n  var chrs = arg.split(\"\").filter(function (c) {\n    return singles[c]\n  })\n\n  if (chrs.join(\"\") === arg) return chrs.map(function (c) {\n    return shorthands[c]\n  }).reduce(function (l, r) {\n    return l.concat(r)\n  }, [])\n\n\n  // if it's an arg abbrev, and not a literal shorthand, then prefer the arg\n  if (abbrevs[arg] && !shorthands[arg])\n    return null\n\n  // if it's an abbr for a shorthand, then use that\n  if (shortAbbr[arg])\n    arg = shortAbbr[arg]\n\n  // make it an array, if it's a list of words\n  if (shorthands[arg] && !Array.isArray(shorthands[arg]))\n    shorthands[arg] = shorthands[arg].split(/\\s+/)\n\n  return shorthands[arg]\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/abbrev/abbrev.js":"module.exports = exports = abbrev.abbrev = abbrev\n\nabbrev.monkeyPatch = monkeyPatch\n\nfunction monkeyPatch () {\n  Object.defineProperty(Array.prototype, 'abbrev', {\n    value: function () { return abbrev(this) },\n    enumerable: false, configurable: true, writable: true\n  })\n\n  Object.defineProperty(Object.prototype, 'abbrev', {\n    value: function () { return abbrev(Object.keys(this)) },\n    enumerable: false, configurable: true, writable: true\n  })\n}\n\nfunction abbrev (list) {\n  if (arguments.length !== 1 || !Array.isArray(list)) {\n    list = Array.prototype.slice.call(arguments, 0)\n  }\n  for (var i = 0, l = list.length, args = [] ; i < l ; i ++) {\n    args[i] = typeof list[i] === \"string\" ? list[i] : String(list[i])\n  }\n\n  // sort them lexicographically, so that they're next to their nearest kin\n  args = args.sort(lexSort)\n\n  // walk through each, seeing how much it has in common with the next and previous\n  var abbrevs = {}\n    , prev = \"\"\n  for (var i = 0, l = args.length ; i < l ; i ++) {\n    var current = args[i]\n      , next = args[i + 1] || \"\"\n      , nextMatches = true\n      , prevMatches = true\n    if (current === next) continue\n    for (var j = 0, cl = current.length ; j < cl ; j ++) {\n      var curChar = current.charAt(j)\n      nextMatches = nextMatches && curChar === next.charAt(j)\n      prevMatches = prevMatches && curChar === prev.charAt(j)\n      if (!nextMatches && !prevMatches) {\n        j ++\n        break\n      }\n    }\n    prev = current\n    if (j === cl) {\n      abbrevs[current] = current\n      continue\n    }\n    for (var a = current.substr(0, j) ; j <= cl ; j ++) {\n      abbrevs[a] = current\n      a += current.charAt(j)\n    }\n  }\n  return abbrevs\n}\n\nfunction lexSort (a, b) {\n  return a === b ? 0 : a > b ? 1 : -1\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/nopt/node_modules/osenv/osenv.js":"var isWindows = process.platform === 'win32'\nvar path = require('path')\nvar exec = require('child_process').exec\nvar osTmpdir = require('os-tmpdir')\nvar osHomedir = require('os-homedir')\n\n// looking up envs is a bit costly.\n// Also, sometimes we want to have a fallback\n// Pass in a callback to wait for the fallback on failures\n// After the first lookup, always returns the same thing.\nfunction memo (key, lookup, fallback) {\n  var fell = false\n  var falling = false\n  exports[key] = function (cb) {\n    var val = lookup()\n    if (!val && !fell && !falling && fallback) {\n      fell = true\n      falling = true\n      exec(fallback, function (er, output, stderr) {\n        falling = false\n        if (er) return // oh well, we tried\n        val = output.trim()\n      })\n    }\n    exports[key] = function (cb) {\n      if (cb) process.nextTick(cb.bind(null, null, val))\n      return val\n    }\n    if (cb && !falling) process.nextTick(cb.bind(null, null, val))\n    return val\n  }\n}\n\nmemo('user', function () {\n  return ( isWindows\n         ? process.env.USERDOMAIN + '\\\\' + process.env.USERNAME\n         : process.env.USER\n         )\n}, 'whoami')\n\nmemo('prompt', function () {\n  return isWindows ? process.env.PROMPT : process.env.PS1\n})\n\nmemo('hostname', function () {\n  return isWindows ? process.env.COMPUTERNAME : process.env.HOSTNAME\n}, 'hostname')\n\nmemo('tmpdir', function () {\n  return osTmpdir()\n})\n\nmemo('home', function () {\n  return osHomedir()\n})\n\nmemo('path', function () {\n  return (process.env.PATH ||\n          process.env.Path ||\n          process.env.path).split(isWindows ? ';' : ':')\n})\n\nmemo('editor', function () {\n  return process.env.EDITOR ||\n         process.env.VISUAL ||\n         (isWindows ? 'notepad.exe' : 'vi')\n})\n\nmemo('shell', function () {\n  return isWindows ? process.env.ComSpec || 'cmd'\n         : process.env.SHELL || 'bash'\n})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/nopt/node_modules/osenv/node_modules/os-tmpdir/index.js":"'use strict';\nvar isWindows = process.platform === 'win32';\nvar trailingSlashRe = isWindows ? /[^:]\\\\$/ : /.\\/$/;\n\n// https://github.com/nodejs/node/blob/3e7a14381497a3b73dda68d05b5130563cdab420/lib/os.js#L25-L43\nmodule.exports = function () {\n\tvar path;\n\n\tif (isWindows) {\n\t\tpath = process.env.TEMP ||\n\t\t\tprocess.env.TMP ||\n\t\t\t(process.env.SystemRoot || process.env.windir) + '\\\\temp';\n\t} else {\n\t\tpath = process.env.TMPDIR ||\n\t\t\tprocess.env.TMP ||\n\t\t\tprocess.env.TEMP ||\n\t\t\t'/tmp';\n\t}\n\n\tif (trailingSlashRe.test(path)) {\n\t\tpath = path.slice(0, -1);\n\t}\n\n\treturn path;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/nopt/node_modules/osenv/node_modules/os-homedir/index.js":"'use strict';\nvar os = require('os');\n\nfunction homedir() {\n\tvar env = process.env;\n\tvar home = env.HOME;\n\tvar user = env.LOGNAME || env.USER || env.LNAME || env.USERNAME;\n\n\tif (process.platform === 'win32') {\n\t\treturn env.USERPROFILE || env.HOMEDRIVE + env.HOMEPATH || home || null;\n\t}\n\n\tif (process.platform === 'darwin') {\n\t\treturn home || (user ? '/Users/' + user : null);\n\t}\n\n\tif (process.platform === 'linux') {\n\t\treturn home || (process.getuid() === 0 ? '/root' : (user ? '/home/' + user : null));\n\t}\n\n\treturn home || null;\n}\n\nmodule.exports = typeof os.homedir === 'function' ? os.homedir : homedir;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/osenv/osenv.js":"var isWindows = process.platform === 'win32'\nvar path = require('path')\nvar exec = require('child_process').exec\nvar osTmpdir = require('os-tmpdir')\nvar osHomedir = require('os-homedir')\n\n// looking up envs is a bit costly.\n// Also, sometimes we want to have a fallback\n// Pass in a callback to wait for the fallback on failures\n// After the first lookup, always returns the same thing.\nfunction memo (key, lookup, fallback) {\n  var fell = false\n  var falling = false\n  exports[key] = function (cb) {\n    var val = lookup()\n    if (!val && !fell && !falling && fallback) {\n      fell = true\n      falling = true\n      exec(fallback, function (er, output, stderr) {\n        falling = false\n        if (er) return // oh well, we tried\n        val = output.trim()\n      })\n    }\n    exports[key] = function (cb) {\n      if (cb) process.nextTick(cb.bind(null, null, val))\n      return val\n    }\n    if (cb && !falling) process.nextTick(cb.bind(null, null, val))\n    return val\n  }\n}\n\nmemo('user', function () {\n  return ( isWindows\n         ? process.env.USERDOMAIN + '\\\\' + process.env.USERNAME\n         : process.env.USER\n         )\n}, 'whoami')\n\nmemo('prompt', function () {\n  return isWindows ? process.env.PROMPT : process.env.PS1\n})\n\nmemo('hostname', function () {\n  return isWindows ? process.env.COMPUTERNAME : process.env.HOSTNAME\n}, 'hostname')\n\nmemo('tmpdir', function () {\n  return osTmpdir()\n})\n\nmemo('home', function () {\n  return osHomedir()\n})\n\nmemo('path', function () {\n  return (process.env.PATH ||\n          process.env.Path ||\n          process.env.path).split(isWindows ? ';' : ':')\n})\n\nmemo('editor', function () {\n  return process.env.EDITOR ||\n         process.env.VISUAL ||\n         (isWindows ? 'notepad.exe' : 'vi')\n})\n\nmemo('shell', function () {\n  return isWindows ? process.env.ComSpec || 'cmd'\n         : process.env.SHELL || 'bash'\n})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/osenv/node_modules/os-tmpdir/index.js":"'use strict';\nvar isWindows = process.platform === 'win32';\nvar trailingSlashRe = isWindows ? /[^:]\\\\$/ : /.\\/$/;\n\n// https://github.com/nodejs/node/blob/3e7a14381497a3b73dda68d05b5130563cdab420/lib/os.js#L25-L43\nmodule.exports = function () {\n\tvar path;\n\n\tif (isWindows) {\n\t\tpath = process.env.TEMP ||\n\t\t\tprocess.env.TMP ||\n\t\t\t(process.env.SystemRoot || process.env.windir) + '\\\\temp';\n\t} else {\n\t\tpath = process.env.TMPDIR ||\n\t\t\tprocess.env.TMP ||\n\t\t\tprocess.env.TEMP ||\n\t\t\t'/tmp';\n\t}\n\n\tif (trailingSlashRe.test(path)) {\n\t\tpath = path.slice(0, -1);\n\t}\n\n\treturn path;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/osenv/node_modules/os-homedir/index.js":"'use strict';\nvar os = require('os');\n\nfunction homedir() {\n\tvar env = process.env;\n\tvar home = env.HOME;\n\tvar user = env.LOGNAME || env.USER || env.LNAME || env.USERNAME;\n\n\tif (process.platform === 'win32') {\n\t\treturn env.USERPROFILE || env.HOMEDRIVE + env.HOMEPATH || home || null;\n\t}\n\n\tif (process.platform === 'darwin') {\n\t\treturn home || (user ? '/Users/' + user : null);\n\t}\n\n\tif (process.platform === 'linux') {\n\t\treturn home || (process.getuid() === 0 ? '/root' : (user ? '/home/' + user : null));\n\t}\n\n\treturn home || null;\n}\n\nmodule.exports = typeof os.homedir === 'function' ? os.homedir : homedir;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/umask.js":"var umask = require('umask')\nvar npmlog = require('npmlog')\nvar _fromString = umask.fromString\n\nmodule.exports = umask\n\n// fromString with logging callback\numask.fromString = function (val) {\n  _fromString(val, function (err, result) {\n    if (err) {\n      npmlog.warn('invalid umask', err.message)\n    }\n    val = result\n  })\n\n  return val\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/umask/index.js":"'use strict';\n\nvar util = require(\"util\");\n\nfunction toString(val) {\n    val = val.toString(8);\n    while (val.length < 4) {\n        val = \"0\" + val;\n    }\n    return val;\n}\n\nvar defaultUmask = 18; // 0022;\nvar defaultUmaskString = toString(defaultUmask);\n\nfunction validate(data, k, val) {\n    // must be either an integer or an octal string.\n    if (typeof val === \"number\" && !isNaN(val)) {\n        data[k] = val;\n        return true;\n    }\n\n    if (typeof val === \"string\") {\n        if (val.charAt(0) !== \"0\") {\n            return false;\n        }\n        data[k] = parseInt(val, 8);\n        return true;\n    }\n\n    return false;\n}\n\nfunction convert_fromString(val, cb) {\n    if (typeof val === \"string\") {\n        // check for octal string first\n        if (val.charAt(0) === '0' && /^[0-7]+$/.test(val)) {\n            val = parseInt(val, 8);\n        } else if (val.charAt(0) !== '0' && /^[0-9]+$/.test(val)) {\n            // legacy support for decimal strings\n            val = parseInt(val, 10);\n        } else {\n            return cb(new Error(util.format(\"Expected octal string, got %j, defaulting to %j\",\n                                            val, defaultUmaskString)),\n                      defaultUmask);\n        }\n    } else if (typeof val !== \"number\") {\n        return cb(new Error(util.format(\"Expected number or octal string, got %j, defaulting to %j\",\n                                        val, defaultUmaskString)),\n                  defaultUmask);\n    }\n\n    val = Math.floor(val);\n\n    if ((val < 0) || (val > 511)) {\n        return cb(new Error(util.format(\"Must be in range 0..511 (0000..0777), got %j\", val)),\n                  defaultUmask);\n    }\n\n    cb(null, val);\n}\n\nfunction fromString(val, cb) {\n\n    // synchronous callback, no zalgo\n    convert_fromString(val, cb || function (err, result) {\n        /*jslint unparam:true*/\n        val = result;\n    });\n\n    return val;\n}\n\nexports.toString = toString;\nexports.fromString = fromString;\nexports.validate = validate;\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/log.js":"'use strict'\nvar Progress = require('are-we-there-yet')\nvar Gauge = require('gauge')\nvar EE = require('events').EventEmitter\nvar log = exports = module.exports = new EE()\nvar util = require('util')\n\nvar setBlocking = require('set-blocking')\nvar consoleControl = require('console-control-strings')\n\nsetBlocking(true)\nvar stream = process.stderr\nObject.defineProperty(log, 'stream', {\n  set: function (newStream) {\n    stream = newStream\n    if (this.gauge) this.gauge.setWriteTo(stream, stream)\n  },\n  get: function () {\n    return stream\n  }\n})\n\n// by default, decide based on tty-ness.\nvar colorEnabled\nlog.useColor = function () {\n  return colorEnabled != null ? colorEnabled : stream.isTTY\n}\n\nlog.enableColor = function () {\n  colorEnabled = true\n  this.gauge.setTheme({hasColor: colorEnabled, hasUnicode: unicodeEnabled})\n}\nlog.disableColor = function () {\n  colorEnabled = false\n  this.gauge.setTheme({hasColor: colorEnabled, hasUnicode: unicodeEnabled})\n}\n\n// default level\nlog.level = 'info'\n\nlog.gauge = new Gauge(stream, {\n  enabled: false, // no progress bars unless asked\n  theme: {hasColor: log.useColor()},\n  template: [\n    {type: 'progressbar', length: 20},\n    {type: 'activityIndicator', kerning: 1, length: 1},\n    {type: 'section', default: ''},\n    ':',\n    {type: 'logline', kerning: 1, default: ''}\n  ]\n})\n\nlog.tracker = new Progress.TrackerGroup()\n\n// we track this separately as we may need to temporarily disable the\n// display of the status bar for our own loggy purposes.\nlog.progressEnabled = log.gauge.isEnabled()\n\nvar unicodeEnabled\n\nlog.enableUnicode = function () {\n  unicodeEnabled = true\n  this.gauge.setTheme({hasColor: this.useColor(), hasUnicode: unicodeEnabled})\n}\n\nlog.disableUnicode = function () {\n  unicodeEnabled = false\n  this.gauge.setTheme({hasColor: this.useColor(), hasUnicode: unicodeEnabled})\n}\n\nlog.setGaugeThemeset = function (themes) {\n  this.gauge.setThemeset(themes)\n}\n\nlog.setGaugeTemplate = function (template) {\n  this.gauge.setTemplate(template)\n}\n\nlog.enableProgress = function () {\n  if (this.progressEnabled) return\n  this.progressEnabled = true\n  this.tracker.on('change', this.showProgress)\n  if (this._pause) return\n  this.gauge.enable()\n}\n\nlog.disableProgress = function () {\n  if (!this.progressEnabled) return\n  this.progressEnabled = false\n  this.tracker.removeListener('change', this.showProgress)\n  this.gauge.disable()\n}\n\nvar trackerConstructors = ['newGroup', 'newItem', 'newStream']\n\nvar mixinLog = function (tracker) {\n  // mixin the public methods from log into the tracker\n  // (except: conflicts and one's we handle specially)\n  Object.keys(log).forEach(function (P) {\n    if (P[0] === '_') return\n    if (trackerConstructors.filter(function (C) { return C === P }).length) return\n    if (tracker[P]) return\n    if (typeof log[P] !== 'function') return\n    var func = log[P]\n    tracker[P] = function () {\n      return func.apply(log, arguments)\n    }\n  })\n  // if the new tracker is a group, make sure any subtrackers get\n  // mixed in too\n  if (tracker instanceof Progress.TrackerGroup) {\n    trackerConstructors.forEach(function (C) {\n      var func = tracker[C]\n      tracker[C] = function () { return mixinLog(func.apply(tracker, arguments)) }\n    })\n  }\n  return tracker\n}\n\n// Add tracker constructors to the top level log object\ntrackerConstructors.forEach(function (C) {\n  log[C] = function () { return mixinLog(this.tracker[C].apply(this.tracker, arguments)) }\n})\n\nlog.clearProgress = function (cb) {\n  if (!this.progressEnabled) return cb && process.nextTick(cb)\n  this.gauge.hide(cb)\n}\n\nlog.showProgress = function (name, completed) {\n  if (!this.progressEnabled) return\n  var values = {}\n  if (name) values.section = name\n  var last = log.record[log.record.length - 1]\n  if (last) {\n    values.subsection = last.prefix\n    var disp = log.disp[last.level] || last.level\n    var logline = this._format(disp, log.style[last.level])\n    if (last.prefix) logline += ' ' + this._format(last.prefix, this.prefixStyle)\n    logline += ' ' + last.message.split(/\\r?\\n/)[0]\n    values.logline = logline\n  }\n  values.completed = completed || this.tracker.completed()\n  this.gauge.show(values)\n}.bind(log) // bind for use in tracker's on-change listener\n\n// temporarily stop emitting, but don't drop\nlog.pause = function () {\n  this._paused = true\n  if (this.progressEnabled) this.gauge.disable()\n}\n\nlog.resume = function () {\n  if (!this._paused) return\n  this._paused = false\n\n  var b = this._buffer\n  this._buffer = []\n  b.forEach(function (m) {\n    this.emitLog(m)\n  }, this)\n  if (this.progressEnabled) this.gauge.enable()\n}\n\nlog._buffer = []\n\nvar id = 0\nlog.record = []\nlog.maxRecordSize = 10000\nlog.log = function (lvl, prefix, message) {\n  var l = this.levels[lvl]\n  if (l === undefined) {\n    return this.emit('error', new Error(util.format(\n      'Undefined log level: %j', lvl)))\n  }\n\n  var a = new Array(arguments.length - 2)\n  var stack = null\n  for (var i = 2; i < arguments.length; i++) {\n    var arg = a[i - 2] = arguments[i]\n\n    // resolve stack traces to a plain string.\n    if (typeof arg === 'object' && arg &&\n        (arg instanceof Error) && arg.stack) {\n      arg.stack = stack = arg.stack + ''\n    }\n  }\n  if (stack) a.unshift(stack + '\\n')\n  message = util.format.apply(util, a)\n\n  var m = { id: id++,\n            level: lvl,\n            prefix: String(prefix || ''),\n            message: message,\n            messageRaw: a }\n\n  this.emit('log', m)\n  this.emit('log.' + lvl, m)\n  if (m.prefix) this.emit(m.prefix, m)\n\n  this.record.push(m)\n  var mrs = this.maxRecordSize\n  var n = this.record.length - mrs\n  if (n > mrs / 10) {\n    var newSize = Math.floor(mrs * 0.9)\n    this.record = this.record.slice(-1 * newSize)\n  }\n\n  this.emitLog(m)\n}.bind(log)\n\nlog.emitLog = function (m) {\n  if (this._paused) {\n    this._buffer.push(m)\n    return\n  }\n  if (this.progressEnabled) this.gauge.pulse(m.prefix)\n  var l = this.levels[m.level]\n  if (l === undefined) return\n  if (l < this.levels[this.level]) return\n  if (l > 0 && !isFinite(l)) return\n\n  // If 'disp' is null or undefined, use the lvl as a default\n  // Allows: '', 0 as valid disp\n  var disp = log.disp[m.level] != null ? log.disp[m.level] : m.level\n  this.clearProgress()\n  m.message.split(/\\r?\\n/).forEach(function (line) {\n    if (this.heading) {\n      this.write(this.heading, this.headingStyle)\n      this.write(' ')\n    }\n    this.write(disp, log.style[m.level])\n    var p = m.prefix || ''\n    if (p) this.write(' ')\n    this.write(p, this.prefixStyle)\n    this.write(' ' + line + '\\n')\n  }, this)\n  this.showProgress()\n}\n\nlog._format = function (msg, style) {\n  if (!stream) return\n\n  var output = ''\n  if (this.useColor()) {\n    style = style || {}\n    var settings = []\n    if (style.fg) settings.push(style.fg)\n    if (style.bg) settings.push('bg' + style.bg[0].toUpperCase() + style.bg.slice(1))\n    if (style.bold) settings.push('bold')\n    if (style.underline) settings.push('underline')\n    if (style.inverse) settings.push('inverse')\n    if (settings.length) output += consoleControl.color(settings)\n    if (style.beep) output += consoleControl.beep()\n  }\n  output += msg\n  if (this.useColor()) {\n    output += consoleControl.color('reset')\n  }\n  return output\n}\n\nlog.write = function (msg, style) {\n  if (!stream) return\n\n  stream.write(this._format(msg, style))\n}\n\nlog.addLevel = function (lvl, n, style, disp) {\n  // If 'disp' is null or undefined, use the lvl as a default\n  if (disp == null) disp = lvl\n  this.levels[lvl] = n\n  this.style[lvl] = style\n  if (!this[lvl]) {\n    this[lvl] = function () {\n      var a = new Array(arguments.length + 1)\n      a[0] = lvl\n      for (var i = 0; i < arguments.length; i++) {\n        a[i + 1] = arguments[i]\n      }\n      return this.log.apply(this, a)\n    }.bind(this)\n  }\n  this.disp[lvl] = disp\n}\n\nlog.prefixStyle = { fg: 'magenta' }\nlog.headingStyle = { fg: 'white', bg: 'black' }\n\nlog.style = {}\nlog.levels = {}\nlog.disp = {}\nlog.addLevel('silly', -Infinity, { inverse: true }, 'sill')\nlog.addLevel('verbose', 1000, { fg: 'blue', bg: 'black' }, 'verb')\nlog.addLevel('info', 2000, { fg: 'green' })\nlog.addLevel('http', 3000, { fg: 'green', bg: 'black' })\nlog.addLevel('warn', 4000, { fg: 'black', bg: 'yellow' }, 'WARN')\nlog.addLevel('error', 5000, { fg: 'red', bg: 'black' }, 'ERR!')\nlog.addLevel('silent', Infinity)\n\n// allow 'error' prefix\nlog.on('error', function () {})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/are-we-there-yet/index.js":"'use strict'\nexports.TrackerGroup = require('./tracker-group.js')\nexports.Tracker = require('./tracker.js')\nexports.TrackerStream = require('./tracker-stream.js')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/are-we-there-yet/tracker-group.js":"'use strict'\nvar util = require('util')\nvar TrackerBase = require('./tracker-base.js')\nvar Tracker = require('./tracker.js')\nvar TrackerStream = require('./tracker-stream.js')\n\nvar TrackerGroup = module.exports = function (name) {\n  TrackerBase.call(this, name)\n  this.parentGroup = null\n  this.trackers = []\n  this.completion = {}\n  this.weight = {}\n  this.totalWeight = 0\n  this.finished = false\n  this.bubbleChange = bubbleChange(this)\n}\nutil.inherits(TrackerGroup, TrackerBase)\n\nfunction bubbleChange (trackerGroup) {\n  return function (name, completed, tracker) {\n    trackerGroup.completion[tracker.id] = completed\n    if (trackerGroup.finished) return\n    trackerGroup.emit('change', name || trackerGroup.name, trackerGroup.completed(), trackerGroup)\n  }\n}\n\nTrackerGroup.prototype.nameInTree = function () {\n  var names = []\n  var from = this\n  while (from) {\n    names.unshift(from.name)\n    from = from.parentGroup\n  }\n  return names.join('/')\n}\n\nTrackerGroup.prototype.addUnit = function (unit, weight) {\n  if (unit.addUnit) {\n    var toTest = this\n    while (toTest) {\n      if (unit === toTest) {\n        throw new Error(\n          'Attempted to add tracker group ' +\n          unit.name + ' to tree that already includes it ' +\n          this.nameInTree(this))\n      }\n      toTest = toTest.parentGroup\n    }\n    unit.parentGroup = this\n  }\n  this.weight[unit.id] = weight || 1\n  this.totalWeight += this.weight[unit.id]\n  this.trackers.push(unit)\n  this.completion[unit.id] = unit.completed()\n  unit.on('change', this.bubbleChange)\n  if (!this.finished) this.emit('change', unit.name, this.completion[unit.id], unit)\n  return unit\n}\n\nTrackerGroup.prototype.completed = function () {\n  if (this.trackers.length === 0) return 0\n  var valPerWeight = 1 / this.totalWeight\n  var completed = 0\n  for (var ii = 0; ii < this.trackers.length; ii++) {\n    var trackerId = this.trackers[ii].id\n    completed += valPerWeight * this.weight[trackerId] * this.completion[trackerId]\n  }\n  return completed\n}\n\nTrackerGroup.prototype.newGroup = function (name, weight) {\n  return this.addUnit(new TrackerGroup(name), weight)\n}\n\nTrackerGroup.prototype.newItem = function (name, todo, weight) {\n  return this.addUnit(new Tracker(name, todo), weight)\n}\n\nTrackerGroup.prototype.newStream = function (name, todo, weight) {\n  return this.addUnit(new TrackerStream(name, todo), weight)\n}\n\nTrackerGroup.prototype.finish = function () {\n  this.finished = true\n  if (!this.trackers.length) this.addUnit(new Tracker(), 1, true)\n  for (var ii = 0; ii < this.trackers.length; ii++) {\n    var tracker = this.trackers[ii]\n    tracker.finish()\n    tracker.removeListener('change', this.bubbleChange)\n  }\n  this.emit('change', this.name, 1, this)\n}\n\nvar buffer = '                                  '\nTrackerGroup.prototype.debug = function (depth) {\n  depth = depth || 0\n  var indent = depth ? buffer.substr(0, depth) : ''\n  var output = indent + (this.name || 'top') + ': ' + this.completed() + '\\n'\n  this.trackers.forEach(function (tracker) {\n    if (tracker instanceof TrackerGroup) {\n      output += tracker.debug(depth + 1)\n    } else {\n      output += indent + ' ' + tracker.name + ': ' + tracker.completed() + '\\n'\n    }\n  })\n  return output\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/are-we-there-yet/tracker-base.js":"'use strict'\nvar EventEmitter = require('events').EventEmitter\nvar util = require('util')\n\nvar trackerId = 0\nvar TrackerBase = module.exports = function (name) {\n  EventEmitter.call(this)\n  this.id = ++trackerId\n  this.name = name\n}\nutil.inherits(TrackerBase, EventEmitter)\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/are-we-there-yet/tracker.js":"'use strict'\nvar util = require('util')\nvar TrackerBase = require('./tracker-base.js')\n\nvar Tracker = module.exports = function (name, todo) {\n  TrackerBase.call(this, name)\n  this.workDone = 0\n  this.workTodo = todo || 0\n}\nutil.inherits(Tracker, TrackerBase)\n\nTracker.prototype.completed = function () {\n  return this.workTodo === 0 ? 0 : this.workDone / this.workTodo\n}\n\nTracker.prototype.addWork = function (work) {\n  this.workTodo += work\n  this.emit('change', this.name, this.completed(), this)\n}\n\nTracker.prototype.completeWork = function (work) {\n  this.workDone += work\n  if (this.workDone > this.workTodo) this.workDone = this.workTodo\n  this.emit('change', this.name, this.completed(), this)\n}\n\nTracker.prototype.finish = function () {\n  this.workTodo = this.workDone = 1\n  this.emit('change', this.name, 1, this)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/are-we-there-yet/tracker-stream.js":"'use strict'\nvar util = require('util')\nvar stream = require('readable-stream')\nvar delegate = require('delegates')\nvar Tracker = require('./tracker.js')\n\nvar TrackerStream = module.exports = function (name, size, options) {\n  stream.Transform.call(this, options)\n  this.tracker = new Tracker(name, size)\n  this.name = name\n  this.id = this.tracker.id\n  this.tracker.on('change', delegateChange(this))\n}\nutil.inherits(TrackerStream, stream.Transform)\n\nfunction delegateChange (trackerStream) {\n  return function (name, completion, tracker) {\n    trackerStream.emit('change', name, completion, trackerStream)\n  }\n}\n\nTrackerStream.prototype._transform = function (data, encoding, cb) {\n  this.tracker.completeWork(data.length ? data.length : 1)\n  this.push(data)\n  cb()\n}\n\nTrackerStream.prototype._flush = function (cb) {\n  this.tracker.finish()\n  cb()\n}\n\ndelegate(TrackerStream.prototype, 'tracker')\n  .method('completed')\n  .method('addWork')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/readable.js":"var Stream = (function (){\n  try {\n    return require('st' + 'ream'); // hack to fix a circular dependency issue when used with browserify\n  } catch(_){}\n}());\nexports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = Stream || exports;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\n\nif (!process.browser && process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/lib/_stream_readable.js":"'use strict';\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar processNextTick = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream;\n(function () {\n  try {\n    Stream = require('st' + 'ream');\n  } catch (_) {} finally {\n    if (!Stream) Stream = require('events').EventEmitter;\n  }\n})();\n/*</replacement>*/\n\nvar Buffer = require('buffer').Buffer;\n/*<replacement>*/\nvar bufferShim = require('buffer-shims');\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') {\n    return emitter.prependListener(event, fn);\n  } else {\n    // This is a hack to make sure that our error handler is attached before any\n    // userland ones.  NEVER DO THIS. This is here only because this code needs\n    // to continue to work with older versions of Node.js that do not include\n    // the prependListener() method. The goal is to eventually remove this hack.\n    if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n  }\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = hwm || hwm === 0 ? hwm : defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // when piping, we only care about 'readable' events that happen\n  // after read()ing all the bytes and not getting any pushback.\n  this.ranOut = false;\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options && typeof options.read === 'function') this._read = options.read;\n\n  Stream.call(this);\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n\n  if (!state.objectMode && typeof chunk === 'string') {\n    encoding = encoding || state.defaultEncoding;\n    if (encoding !== state.encoding) {\n      chunk = bufferShim.from(chunk, encoding);\n      encoding = '';\n    }\n  }\n\n  return readableAddChunk(this, state, chunk, encoding, false);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  var state = this._readableState;\n  return readableAddChunk(this, state, chunk, '', true);\n};\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\nfunction readableAddChunk(stream, state, chunk, encoding, addToFront) {\n  var er = chunkInvalid(state, chunk);\n  if (er) {\n    stream.emit('error', er);\n  } else if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else if (state.objectMode || chunk && chunk.length > 0) {\n    if (state.ended && !addToFront) {\n      var e = new Error('stream.push() after EOF');\n      stream.emit('error', e);\n    } else if (state.endEmitted && addToFront) {\n      var _e = new Error('stream.unshift() after end event');\n      stream.emit('error', _e);\n    } else {\n      var skipAdd;\n      if (state.decoder && !addToFront && !encoding) {\n        chunk = state.decoder.write(chunk);\n        skipAdd = !state.objectMode && chunk.length === 0;\n      }\n\n      if (!addToFront) state.reading = false;\n\n      // Don't add to the buffer if we've decoded to an empty string chunk and\n      // we're not in object mode\n      if (!skipAdd) {\n        // if we want the data now, just emit it.\n        if (state.flowing && state.length === 0 && !state.sync) {\n          stream.emit('data', chunk);\n          stream.read(0);\n        } else {\n          // update the buffer info.\n          state.length += state.objectMode ? 1 : chunk.length;\n          if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n          if (state.needReadable) emitReadable(stream);\n        }\n      }\n\n      maybeReadMore(stream, state);\n    }\n  } else if (!addToFront) {\n    state.reading = false;\n  }\n\n  return needMoreData(state);\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction chunkInvalid(state, chunk) {\n  var er = null;\n  if (!Buffer.isBuffer(chunk) && typeof chunk !== 'string' && chunk !== null && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) processNextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    processNextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : cleanup;\n  if (state.endEmitted) processNextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable) {\n    debug('onunpipe');\n    if (readable === src) {\n      cleanup();\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', cleanup);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        processNextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this, state);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    processNextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var state = this._readableState;\n  var paused = false;\n\n  var self = this;\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) self.push(chunk);\n    }\n\n    self.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = self.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  var events = ['error', 'close', 'destroy', 'pause', 'resume'];\n  forEach(events, function (ev) {\n    stream.on(ev, self.emit.bind(self, ev));\n  });\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  self._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return self;\n};\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = bufferShim.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    processNextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction forEach(xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/node_modules/process-nextick-args/index.js":"'use strict';\n\nif (!process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = nextTick;\n} else {\n  module.exports = process.nextTick;\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/node_modules/isarray/index.js":"var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/node_modules/buffer-shims/index.js":"'use strict';\n\nvar buffer = require('buffer');\nvar Buffer = buffer.Buffer;\nvar SlowBuffer = buffer.SlowBuffer;\nvar MAX_LEN = buffer.kMaxLength || 2147483647;\nexports.alloc = function alloc(size, fill, encoding) {\n  if (typeof Buffer.alloc === 'function') {\n    return Buffer.alloc(size, fill, encoding);\n  }\n  if (typeof encoding === 'number') {\n    throw new TypeError('encoding must not be number');\n  }\n  if (typeof size !== 'number') {\n    throw new TypeError('size must be a number');\n  }\n  if (size > MAX_LEN) {\n    throw new RangeError('size is too large');\n  }\n  var enc = encoding;\n  var _fill = fill;\n  if (_fill === undefined) {\n    enc = undefined;\n    _fill = 0;\n  }\n  var buf = new Buffer(size);\n  if (typeof _fill === 'string') {\n    var fillBuf = new Buffer(_fill, enc);\n    var flen = fillBuf.length;\n    var i = -1;\n    while (++i < size) {\n      buf[i] = fillBuf[i % flen];\n    }\n  } else {\n    buf.fill(_fill);\n  }\n  return buf;\n}\nexports.allocUnsafe = function allocUnsafe(size) {\n  if (typeof Buffer.allocUnsafe === 'function') {\n    return Buffer.allocUnsafe(size);\n  }\n  if (typeof size !== 'number') {\n    throw new TypeError('size must be a number');\n  }\n  if (size > MAX_LEN) {\n    throw new RangeError('size is too large');\n  }\n  return new Buffer(size);\n}\nexports.from = function from(value, encodingOrOffset, length) {\n  if (typeof Buffer.from === 'function' && (!global.Uint8Array || Uint8Array.from !== Buffer.from)) {\n    return Buffer.from(value, encodingOrOffset, length);\n  }\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number');\n  }\n  if (typeof value === 'string') {\n    return new Buffer(value, encodingOrOffset);\n  }\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    var offset = encodingOrOffset;\n    if (arguments.length === 1) {\n      return new Buffer(value);\n    }\n    if (typeof offset === 'undefined') {\n      offset = 0;\n    }\n    var len = length;\n    if (typeof len === 'undefined') {\n      len = value.byteLength - offset;\n    }\n    if (offset >= value.byteLength) {\n      throw new RangeError('\\'offset\\' is out of bounds');\n    }\n    if (len > value.byteLength - offset) {\n      throw new RangeError('\\'length\\' is out of bounds');\n    }\n    return new Buffer(value.slice(offset, offset + len));\n  }\n  if (Buffer.isBuffer(value)) {\n    var out = new Buffer(value.length);\n    value.copy(out, 0, 0, value.length);\n    return out;\n  }\n  if (value) {\n    if (Array.isArray(value) || (typeof ArrayBuffer !== 'undefined' && value.buffer instanceof ArrayBuffer) || 'length' in value) {\n      return new Buffer(value);\n    }\n    if (value.type === 'Buffer' && Array.isArray(value.data)) {\n      return new Buffer(value.data);\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ' + 'ArrayBuffer, Array, or array-like object.');\n}\nexports.allocUnsafeSlow = function allocUnsafeSlow(size) {\n  if (typeof Buffer.allocUnsafeSlow === 'function') {\n    return Buffer.allocUnsafeSlow(size);\n  }\n  if (typeof size !== 'number') {\n    throw new TypeError('size must be a number');\n  }\n  if (size >= MAX_LEN) {\n    throw new RangeError('size is too large');\n  }\n  return new SlowBuffer(size);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/node_modules/core-util-is/lib/util.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/lib/internal/streams/BufferList.js":"'use strict';\n\nvar Buffer = require('buffer').Buffer;\n/*<replacement>*/\nvar bufferShim = require('buffer-shims');\n/*</replacement>*/\n\nmodule.exports = BufferList;\n\nfunction BufferList() {\n  this.head = null;\n  this.tail = null;\n  this.length = 0;\n}\n\nBufferList.prototype.push = function (v) {\n  var entry = { data: v, next: null };\n  if (this.length > 0) this.tail.next = entry;else this.head = entry;\n  this.tail = entry;\n  ++this.length;\n};\n\nBufferList.prototype.unshift = function (v) {\n  var entry = { data: v, next: this.head };\n  if (this.length === 0) this.tail = entry;\n  this.head = entry;\n  ++this.length;\n};\n\nBufferList.prototype.shift = function () {\n  if (this.length === 0) return;\n  var ret = this.head.data;\n  if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n  --this.length;\n  return ret;\n};\n\nBufferList.prototype.clear = function () {\n  this.head = this.tail = null;\n  this.length = 0;\n};\n\nBufferList.prototype.join = function (s) {\n  if (this.length === 0) return '';\n  var p = this.head;\n  var ret = '' + p.data;\n  while (p = p.next) {\n    ret += s + p.data;\n  }return ret;\n};\n\nBufferList.prototype.concat = function (n) {\n  if (this.length === 0) return bufferShim.alloc(0);\n  if (this.length === 1) return this.head.data;\n  var ret = bufferShim.allocUnsafe(n >>> 0);\n  var p = this.head;\n  var i = 0;\n  while (p) {\n    p.data.copy(ret, i);\n    i += p.data.length;\n    p = p.next;\n  }\n  return ret;\n};","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/lib/_stream_writable.js":"// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\nmodule.exports = Writable;\n\n/*<replacement>*/\nvar processNextTick = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : processNextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream;\n(function () {\n  try {\n    Stream = require('st' + 'ream');\n  } catch (_) {} finally {\n    if (!Stream) Stream = require('events').EventEmitter;\n  }\n})();\n/*</replacement>*/\n\nvar Buffer = require('buffer').Buffer;\n/*<replacement>*/\nvar bufferShim = require('buffer-shims');\n/*</replacement>*/\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = hwm || hwm === 0 ? hwm : defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  processNextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    processNextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = Buffer.isBuffer(chunk);\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = bufferShim.from(chunk, encoding);\n  }\n  return chunk;\n}\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    chunk = decodeChunk(state, chunk, encoding);\n    if (Buffer.isBuffer(chunk)) encoding = 'buffer';\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = new WriteReq(chunk, encoding, cb);\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n  if (sync) processNextTick(cb, er);else cb(er);\n\n  stream._writableState.errorEmitted = true;\n  stream.emit('error', er);\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    while (entry) {\n      buffer[count] = entry;\n      entry = entry.next;\n      count += 1;\n    }\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequestCount = 0;\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished) {\n    state.prefinished = true;\n    stream.emit('prefinish');\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    if (state.pendingcb === 0) {\n      prefinish(stream, state);\n      state.finished = true;\n      stream.emit('finish');\n    } else {\n      prefinish(stream, state);\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) processNextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function (err) {\n    var entry = _this.entry;\n    _this.entry = null;\n    while (entry) {\n      var cb = entry.callback;\n      state.pendingcb--;\n      cb(err);\n      entry = entry.next;\n    }\n    if (state.corkedRequestsFree) {\n      state.corkedRequestsFree.next = _this;\n    } else {\n      state.corkedRequestsFree = _this;\n    }\n  };\n}","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/node_modules/util-deprecate/node.js":"\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = require('util').deprecate;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/lib/_stream_duplex.js":"// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar processNextTick = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\nvar keys = objectKeys(Writable.prototype);\nfor (var v = 0; v < keys.length; v++) {\n  var method = keys[v];\n  if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  processNextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nfunction forEach(xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/lib/_stream_transform.js":"// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction TransformState(stream) {\n  this.afterTransform = function (er, data) {\n    return afterTransform(stream, er, data);\n  };\n\n  this.needTransform = false;\n  this.transforming = false;\n  this.writecb = null;\n  this.writechunk = null;\n  this.writeencoding = null;\n}\n\nfunction afterTransform(stream, er, data) {\n  var ts = stream._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) return stream.emit('error', new Error('no writecb in Transform class'));\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data !== null && data !== undefined) stream.push(data);\n\n  cb(er);\n\n  var rs = stream._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    stream._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = new TransformState(this);\n\n  var stream = this;\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.once('prefinish', function () {\n    if (typeof this._flush === 'function') this._flush(function (er, data) {\n      done(stream, er, data);\n    });else done(stream);\n  });\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data !== null && data !== undefined) stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  var ws = stream._writableState;\n  var ts = stream._transformState;\n\n  if (ws.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (ts.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/lib/_stream_passthrough.js":"// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/are-we-there-yet/node_modules/delegates/index.js":"\n/**\n * Expose `Delegator`.\n */\n\nmodule.exports = Delegator;\n\n/**\n * Initialize a delegator.\n *\n * @param {Object} proto\n * @param {String} target\n * @api public\n */\n\nfunction Delegator(proto, target) {\n  if (!(this instanceof Delegator)) return new Delegator(proto, target);\n  this.proto = proto;\n  this.target = target;\n  this.methods = [];\n  this.getters = [];\n  this.setters = [];\n  this.fluents = [];\n}\n\n/**\n * Delegate method `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.method = function(name){\n  var proto = this.proto;\n  var target = this.target;\n  this.methods.push(name);\n\n  proto[name] = function(){\n    return this[target][name].apply(this[target], arguments);\n  };\n\n  return this;\n};\n\n/**\n * Delegator accessor `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.access = function(name){\n  return this.getter(name).setter(name);\n};\n\n/**\n * Delegator getter `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.getter = function(name){\n  var proto = this.proto;\n  var target = this.target;\n  this.getters.push(name);\n\n  proto.__defineGetter__(name, function(){\n    return this[target][name];\n  });\n\n  return this;\n};\n\n/**\n * Delegator setter `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.setter = function(name){\n  var proto = this.proto;\n  var target = this.target;\n  this.setters.push(name);\n\n  proto.__defineSetter__(name, function(val){\n    return this[target][name] = val;\n  });\n\n  return this;\n};\n\n/**\n * Delegator fluent accessor\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.fluent = function (name) {\n  var proto = this.proto;\n  var target = this.target;\n  this.fluents.push(name);\n\n  proto[name] = function(val){\n    if ('undefined' != typeof val) {\n      this[target][name] = val;\n      return this;\n    } else {\n      return this[target][name];\n    }\n  };\n\n  return this;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/index.js":"'use strict'\nvar Plumbing = require('./plumbing.js')\nvar hasUnicode = require('has-unicode')\nvar hasColor = require('./has-color.js')\nvar onExit = require('signal-exit')\nvar defaultThemes = require('./themes')\nvar setInterval = require('./set-interval.js')\nvar process = require('./process.js')\nvar setImmediate = require('./set-immediate')\n\nmodule.exports = Gauge\n\nfunction callWith (obj, method) {\n  return function () {\n    return method.call(obj)\n  }\n}\n\nfunction Gauge (arg1, arg2) {\n  var options, writeTo\n  if (arg1 && arg1.write) {\n    writeTo = arg1\n    options = arg2 || {}\n  } else if (arg2 && arg2.write) {\n    writeTo = arg2\n    options = arg1 || {}\n  } else {\n    writeTo = process.stderr\n    options = arg1 || arg2 || {}\n  }\n\n  this._status = {\n    spun: 0,\n    section: '',\n    subsection: ''\n  }\n  this._paused = false // are we paused for back pressure?\n  this._disabled = true // are all progress bar updates disabled?\n  this._showing = false // do we WANT the progress bar on screen\n  this._onScreen = false // IS the progress bar on screen\n  this._needsRedraw = false // should we print something at next tick?\n  this._hideCursor = options.hideCursor == null ? true : options.hideCursor\n  this._fixedFramerate = options.fixedFramerate == null\n    ? !(/^v0\\.8\\./.test(process.version))\n    : options.fixedFramerate\n  this._lastUpdateAt = null\n  this._updateInterval = options.updateInterval == null ? 50 : options.updateInterval\n\n  this._themes = options.themes || defaultThemes\n  this._theme = options.theme\n  var theme = this._computeTheme(options.theme)\n  var template = options.template || [\n    {type: 'progressbar', length: 20},\n    {type: 'activityIndicator', kerning: 1, length: 1},\n    {type: 'section', kerning: 1, default: ''},\n    {type: 'subsection', kerning: 1, default: ''}\n  ]\n  this.setWriteTo(writeTo, options.tty)\n  var PlumbingClass = options.Plumbing || Plumbing\n  this._gauge = new PlumbingClass(theme, template, this.getWidth())\n\n  this._$$doRedraw = callWith(this, this._doRedraw)\n  this._$$handleSizeChange = callWith(this, this._handleSizeChange)\n\n  if (options.cleanupOnExit == null || options.cleanupOnExit) {\n    onExit(callWith(this, this.disable))\n  }\n\n  if (options.enabled || (options.enabled == null && this._tty && this._tty.isTTY)) {\n    this.enable()\n  } else {\n    this.disable()\n  }\n}\nGauge.prototype = {}\n\nGauge.prototype.isEnabled = function () {\n  return !this._disabled\n}\n\nGauge.prototype.setTemplate = function (template) {\n  this._gauge.setTemplate(template)\n  if (this._showing) this._requestRedraw()\n}\n\nGauge.prototype._computeTheme = function (theme) {\n  if (!theme) theme = {}\n  if (theme && (Object.keys(theme).length === 0 || theme.hasUnicode != null || theme.hasColor != null)) {\n    var useUnicode = theme.hasUnicode == null ? hasUnicode() : theme.hasUnicode\n    var useColor = theme.hasColor == null ? hasColor : theme.hasColor\n    theme = this._themes.getDefault({hasUnicode: useUnicode, hasColor: useColor, platform: theme.platform})\n  } else if (typeof theme === 'string') {\n    theme = this._themes.getTheme(theme)\n  }\n  return theme\n}\n\nGauge.prototype.setThemeset = function (themes) {\n  this._themes = themes\n  this.setTheme(this._theme)\n}\n\nGauge.prototype.setTheme = function (theme) {\n  this._gauge.setTheme(this._computeTheme(theme))\n  if (this._showing) this._requestRedraw()\n  this._theme = theme\n}\n\nGauge.prototype._requestRedraw = function () {\n  this._needsRedraw = true\n  if (!this._fixedFramerate) this._doRedraw()\n}\n\nGauge.prototype.getWidth = function () {\n  return ((this._tty && this._tty.columns) || 80) - 1\n}\n\nGauge.prototype.setWriteTo = function (writeTo, tty) {\n  var enabled = !this._disabled\n  if (enabled) this.disable()\n  this._writeTo = writeTo\n  this._tty = tty ||\n    (writeTo === process.stderr && process.stdout.isTTY && process.stdout) ||\n    (writeTo.isTTY && writeTo) ||\n    this._tty\n  if (this._gauge) this._gauge.setWidth(this.getWidth())\n  if (enabled) this.enable()\n}\n\nGauge.prototype.enable = function () {\n  if (!this._disabled) return\n  this._disabled = false\n  if (this._tty) this._enableEvents()\n  if (this._showing) this.show()\n}\n\nGauge.prototype.disable = function () {\n  if (this._disabled) return\n  if (this._showing) {\n    this._lastUpdateAt = null\n    this._showing = false\n    this._doRedraw()\n    this._showing = true\n  }\n  this._disabled = true\n  if (this._tty) this._disableEvents()\n}\n\nGauge.prototype._enableEvents = function () {\n  this._tty.on('resize', this._$$handleSizeChange)\n  if (this._fixedFramerate) {\n    this.redrawTracker = setInterval(this._$$doRedraw, this._updateInterval)\n    if (this.redrawTracker.unref) this.redrawTracker.unref()\n  }\n}\n\nGauge.prototype._disableEvents = function () {\n  this._tty.removeListener('resize', this._$$handleSizeChange)\n  if (this._fixedFramerate) clearInterval(this.redrawTracker)\n}\n\nGauge.prototype.hide = function (cb) {\n  if (this._disabled) return cb && process.nextTick(cb)\n  if (!this._showing) return cb && process.nextTick(cb)\n  this._showing = false\n  this._doRedraw()\n  cb && setImmediate(cb)\n}\n\nGauge.prototype.show = function (section, completed) {\n  this._showing = true\n  if (typeof section === 'string') {\n    this._status.section = section\n  } else if (typeof section === 'object') {\n    var sectionKeys = Object.keys(section)\n    for (var ii = 0; ii < sectionKeys.length; ++ii) {\n      var key = sectionKeys[ii]\n      this._status[key] = section[key]\n    }\n  }\n  if (completed != null) this._status.completed = completed\n  if (this._disabled) return\n  this._requestRedraw()\n}\n\nGauge.prototype.pulse = function (subsection) {\n  this._status.subsection = subsection || ''\n  this._status.spun ++\n  if (this._disabled) return\n  if (!this._showing) return\n  this._requestRedraw()\n}\n\nGauge.prototype._handleSizeChange = function () {\n  this._gauge.setWidth(this._tty.columns - 1)\n  this._requestRedraw()\n}\n\nGauge.prototype._doRedraw = function () {\n  if (this._disabled || this._paused) return\n  if (!this._fixedFramerate) {\n    var now = Date.now()\n    if (this._lastUpdateAt && now - this._lastUpdateAt < this._updateInterval) return\n    this._lastUpdateAt = now\n  }\n  if (!this._showing && this._onScreen) {\n    this._onScreen = false\n    var result = this._gauge.hide()\n    if (this._hideCursor) {\n      result += this._gauge.showCursor()\n    }\n    return this._writeTo.write(result)\n  }\n  if (!this._showing && !this._onScreen) return\n  if (this._showing && !this._onScreen) {\n    this._onScreen = true\n    this._needsRedraw = true\n    if (this._hideCursor) {\n      this._writeTo.write(this._gauge.hideCursor())\n    }\n  }\n  if (!this._needsRedraw) return\n  if (!this._writeTo.write(this._gauge.show(this._status))) {\n    this._paused = true\n    this._writeTo.on('drain', callWith(this, function () {\n      this._paused = false\n      this._doRedraw()\n    }))\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/plumbing.js":"'use strict'\nvar consoleControl = require('console-control-strings')\nvar renderTemplate = require('./render-template.js')\nvar validate = require('aproba')\n\nvar Plumbing = module.exports = function (theme, template, width) {\n  if (!width) width = 80\n  validate('OAN', [theme, template, width])\n  this.showing = false\n  this.theme = theme\n  this.width = width\n  this.template = template\n}\nPlumbing.prototype = {}\n\nPlumbing.prototype.setTheme = function (theme) {\n  validate('O', [theme])\n  this.theme = theme\n}\n\nPlumbing.prototype.setTemplate = function (template) {\n  validate('A', [template])\n  this.template = template\n}\n\nPlumbing.prototype.setWidth = function (width) {\n  validate('N', [width])\n  this.width = width\n}\n\nPlumbing.prototype.hide = function () {\n  return consoleControl.gotoSOL() + consoleControl.eraseLine()\n}\n\nPlumbing.prototype.hideCursor = consoleControl.hideCursor\n\nPlumbing.prototype.showCursor = consoleControl.showCursor\n\nPlumbing.prototype.show = function (status) {\n  var values = Object.create(this.theme)\n  for (var key in status) {\n    values[key] = status[key]\n  }\n\n  return renderTemplate(this.width, this.template, values).trim() +\n         consoleControl.eraseLine() + consoleControl.gotoSOL()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/console-control-strings/index.js":"'use strict'\n\n// These tables borrowed from `ansi`\n\nvar prefix = '\\x1b['\n\nexports.up = function up (num) {\n  return prefix + (num || '') + 'A'\n}\n\nexports.down = function down (num) {\n  return prefix + (num || '') + 'B'\n}\n\nexports.forward = function forward (num) {\n  return prefix + (num || '') + 'C'\n}\n\nexports.back = function back (num) {\n  return prefix + (num || '') + 'D'\n}\n\nexports.nextLine = function nextLine (num) {\n  return prefix + (num || '') + 'E'\n}\n\nexports.previousLine = function previousLine (num) {\n  return prefix + (num || '') + 'F'\n}\n\nexports.horizontalAbsolute = function horizontalAbsolute (num) {\n  if (num == null) throw new Error('horizontalAboslute requires a column to position to')\n  return prefix + num + 'G'\n}\n\nexports.eraseData = function eraseData () {\n  return prefix + 'J'\n}\n\nexports.eraseLine = function eraseLine () {\n  return prefix + 'K'\n}\n\nexports.goto = function (x, y) {\n  return prefix + y + ';' + x + 'H'\n}\n\nexports.gotoSOL = function () {\n  return '\\r'\n}\n\nexports.beep = function () {\n  return '\\x07'\n}\n\nexports.hideCursor = function hideCursor () {\n  return prefix + '?25l'\n}\n\nexports.showCursor = function showCursor () {\n  return prefix + '?25h'\n}\n\nvar colors = {\n  reset: 0,\n// styles\n  bold: 1,\n  italic: 3,\n  underline: 4,\n  inverse: 7,\n// resets\n  stopBold: 22,\n  stopItalic: 23,\n  stopUnderline: 24,\n  stopInverse: 27,\n// colors\n  white: 37,\n  black: 30,\n  blue: 34,\n  cyan: 36,\n  green: 32,\n  magenta: 35,\n  red: 31,\n  yellow: 33,\n  bgWhite: 47,\n  bgBlack: 40,\n  bgBlue: 44,\n  bgCyan: 46,\n  bgGreen: 42,\n  bgMagenta: 45,\n  bgRed: 41,\n  bgYellow: 43,\n\n  grey: 90,\n  brightBlack: 90,\n  brightRed: 91,\n  brightGreen: 92,\n  brightYellow: 93,\n  brightBlue: 94,\n  brightMagenta: 95,\n  brightCyan: 96,\n  brightWhite: 97,\n\n  bgGrey: 100,\n  bgBrightBlack: 100,\n  bgBrightRed: 101,\n  bgBrightGreen: 102,\n  bgBrightYellow: 103,\n  bgBrightBlue: 104,\n  bgBrightMagenta: 105,\n  bgBrightCyan: 106,\n  bgBrightWhite: 107\n}\n\nexports.color = function color (colorWith) {\n  if (arguments.length !== 1 || !Array.isArray(colorWith)) {\n    colorWith = Array.prototype.slice.call(arguments)\n  }\n  return prefix + colorWith.map(colorNameToCode).join(';') + 'm'\n}\n\nfunction colorNameToCode (color) {\n  if (colors[color] != null) return colors[color]\n  throw new Error('Unknown color or style name: ' + color)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/render-template.js":"'use strict'\nvar align = require('wide-align')\nvar validate = require('aproba')\nvar objectAssign = require('object-assign')\nvar wideTruncate = require('./wide-truncate')\nvar error = require('./error')\nvar TemplateItem = require('./template-item')\n\nfunction renderValueWithValues (values) {\n  return function (item) {\n    return renderValue(item, values)\n  }\n}\n\nvar renderTemplate = module.exports = function (width, template, values) {\n  var items = prepareItems(width, template, values)\n  var rendered = items.map(renderValueWithValues(values)).join('')\n  return align.left(wideTruncate(rendered, width), width)\n}\n\nfunction preType (item) {\n  var cappedTypeName = item.type[0].toUpperCase() + item.type.slice(1)\n  return 'pre' + cappedTypeName\n}\n\nfunction postType (item) {\n  var cappedTypeName = item.type[0].toUpperCase() + item.type.slice(1)\n  return 'post' + cappedTypeName\n}\n\nfunction hasPreOrPost (item, values) {\n  if (!item.type) return\n  return values[preType(item)] || values[postType(item)]\n}\n\nfunction generatePreAndPost (baseItem, parentValues) {\n  var item = objectAssign({}, baseItem)\n  var values = Object.create(parentValues)\n  var template = []\n  var pre = preType(item)\n  var post = postType(item)\n  if (values[pre]) {\n    template.push({value: values[pre]})\n    values[pre] = null\n  }\n  item.minLength = null\n  item.length = null\n  item.maxLength = null\n  template.push(item)\n  values[item.type] = values[item.type]\n  if (values[post]) {\n    template.push({value: values[post]})\n    values[post] = null\n  }\n  return function ($1, $2, length) {\n    return renderTemplate(length, template, values)\n  }\n}\n\nfunction prepareItems (width, template, values) {\n  function cloneAndObjectify (item, index, arr) {\n    var cloned = new TemplateItem(item, width)\n    var type = cloned.type\n    if (cloned.value == null) {\n      if (!(type in values)) {\n        if (cloned.default == null) {\n          throw new error.MissingTemplateValue(cloned, values)\n        } else {\n          cloned.value = cloned.default\n        }\n      } else {\n        cloned.value = values[type]\n      }\n    }\n    if (cloned.value == null || cloned.value === '') return null\n    cloned.index = index\n    cloned.first = index === 0\n    cloned.last = index === arr.length - 1\n    if (hasPreOrPost(cloned, values)) cloned.value = generatePreAndPost(cloned, values)\n    return cloned\n  }\n\n  var output = template.map(cloneAndObjectify).filter(function (item) { return item != null })\n\n  var outputLength = 0\n  var remainingSpace = width\n  var variableCount = output.length\n\n  function consumeSpace (length) {\n    if (length > remainingSpace) length = remainingSpace\n    outputLength += length\n    remainingSpace -= length\n  }\n\n  function finishSizing (item, length) {\n    if (item.finished) throw new error.Internal('Tried to finish template item that was already finished')\n    if (length === Infinity) throw new error.Internal('Length of template item cannot be infinity')\n    if (length != null) item.length = length\n    item.minLength = null\n    item.maxLength = null\n    --variableCount\n    item.finished = true\n    if (item.length == null) item.length = item.getBaseLength()\n    if (item.length == null) throw new error.Internal('Finished template items must have a length')\n    consumeSpace(item.getLength())\n  }\n\n  output.forEach(function (item) {\n    if (!item.kerning) return\n    var prevPadRight = item.first ? 0 : output[item.index - 1].padRight\n    if (!item.first && prevPadRight < item.kerning) item.padLeft = item.kerning - prevPadRight\n    if (!item.last) item.padRight = item.kerning\n  })\n\n  // Finish any that have a fixed (literal or intuited) length\n  output.forEach(function (item) {\n    if (item.getBaseLength() == null) return\n    finishSizing(item)\n  })\n\n  var resized = 0\n  var resizing\n  var hunkSize\n  do {\n    resizing = false\n    hunkSize = Math.round(remainingSpace / variableCount)\n    output.forEach(function (item) {\n      if (item.finished) return\n      if (!item.maxLength) return\n      if (item.getMaxLength() < hunkSize) {\n        finishSizing(item, item.maxLength)\n        resizing = true\n      }\n    })\n  } while (resizing && resized++ < output.length)\n  if (resizing) throw new error.Internal('Resize loop iterated too many times while determining maxLength')\n\n  resized = 0\n  do {\n    resizing = false\n    hunkSize = Math.round(remainingSpace / variableCount)\n    output.forEach(function (item) {\n      if (item.finished) return\n      if (!item.minLength) return\n      if (item.getMinLength() >= hunkSize) {\n        finishSizing(item, item.minLength)\n        resizing = true\n      }\n    })\n  } while (resizing && resized++ < output.length)\n  if (resizing) throw new error.Internal('Resize loop iterated too many times while determining minLength')\n\n  hunkSize = Math.round(remainingSpace / variableCount)\n  output.forEach(function (item) {\n    if (item.finished) return\n    finishSizing(item, hunkSize)\n  })\n\n  return output\n}\n\nfunction renderFunction (item, values, length) {\n  validate('OON', arguments)\n  if (item.type) {\n    return item.value(values, values[item.type + 'Theme'] || {}, length)\n  } else {\n    return item.value(values, {}, length)\n  }\n}\n\nfunction renderValue (item, values) {\n  var length = item.getBaseLength()\n  var value = typeof item.value === 'function' ? renderFunction(item, values, length) : item.value\n  if (value == null || value === '') return ''\n  var alignWith = align[item.align] || align.left\n  var leftPadding = item.padLeft ? align.left('', item.padLeft) : ''\n  var rightPadding = item.padRight ? align.right('', item.padRight) : ''\n  var truncated = wideTruncate(String(value), length)\n  var aligned = alignWith(truncated, length)\n  return leftPadding + aligned + rightPadding\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/wide-align/align.js":"'use strict'\nvar stringWidth = require('string-width')\n\nexports.center = alignCenter\nexports.left = alignLeft\nexports.right = alignRight\n\n// lodash's way of generating pad characters.\n\nfunction createPadding (width) {\n  var result = ''\n  var string = ' '\n  var n = width\n  do {\n    if (n % 2) {\n      result += string;\n    }\n    n = Math.floor(n / 2);\n    string += string;\n  } while (n);\n\n  return result;\n}\n\nfunction alignLeft (str, width) {\n  var trimmed = str.trimRight()\n  if (trimmed.length === 0 && str.length >= width) return str\n  var padding = ''\n  var strWidth = stringWidth(trimmed)\n\n  if (strWidth < width) {\n    padding = createPadding(width - strWidth)\n  }\n\n  return trimmed + padding\n}\n\nfunction alignRight (str, width) {\n  var trimmed = str.trimLeft()\n  if (trimmed.length === 0 && str.length >= width) return str\n  var padding = ''\n  var strWidth = stringWidth(trimmed)\n\n  if (strWidth < width) {\n    padding = createPadding(width - strWidth)\n  }\n\n  return padding + trimmed\n}\n\nfunction alignCenter (str, width) {\n  var trimmed = str.trim()\n  if (trimmed.length === 0 && str.length >= width) return str\n  var padLeft = ''\n  var padRight = ''\n  var strWidth = stringWidth(trimmed)\n\n  if (strWidth < width) {\n    var padLeftBy = parseInt((width - strWidth) / 2, 10)\n    padLeft = createPadding(padLeftBy)\n    padRight = createPadding(width - (strWidth + padLeftBy))\n  }\n\n  return padLeft + trimmed + padRight\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/string-width/index.js":"'use strict';\nvar stripAnsi = require('strip-ansi');\nvar codePointAt = require('code-point-at');\nvar isFullwidthCodePoint = require('is-fullwidth-code-point');\n\n// https://github.com/nodejs/io.js/blob/cff7300a578be1b10001f2d967aaedc88aee6402/lib/readline.js#L1345\nmodule.exports = function (str) {\n\tif (typeof str !== 'string' || str.length === 0) {\n\t\treturn 0;\n\t}\n\n\tvar width = 0;\n\n\tstr = stripAnsi(str);\n\n\tfor (var i = 0; i < str.length; i++) {\n\t\tvar code = codePointAt(str, i);\n\n\t\t// ignore control characters\n\t\tif (code <= 0x1f || (code >= 0x7f && code <= 0x9f)) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// surrogates\n\t\tif (code >= 0x10000) {\n\t\t\ti++;\n\t\t}\n\n\t\tif (isFullwidthCodePoint(code)) {\n\t\t\twidth += 2;\n\t\t} else {\n\t\t\twidth++;\n\t\t}\n\t}\n\n\treturn width;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/strip-ansi/index.js":"'use strict';\nvar ansiRegex = require('ansi-regex')();\n\nmodule.exports = function (str) {\n\treturn typeof str === 'string' ? str.replace(ansiRegex, '') : str;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/ansi-regex/index.js":"'use strict';\nmodule.exports = function () {\n\treturn /[\\u001b\\u009b][[()#;?]*(?:[0-9]{1,4}(?:;[0-9]{0,4})*)?[0-9A-PRZcf-nqry=><]/g;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/string-width/node_modules/code-point-at/index.js":"/* eslint-disable babel/new-cap, xo/throw-new-error */\n'use strict';\nmodule.exports = function (str, pos) {\n\tif (str === null || str === undefined) {\n\t\tthrow TypeError();\n\t}\n\n\tstr = String(str);\n\n\tvar size = str.length;\n\tvar i = pos ? Number(pos) : 0;\n\n\tif (Number.isNaN(i)) {\n\t\ti = 0;\n\t}\n\n\tif (i < 0 || i >= size) {\n\t\treturn undefined;\n\t}\n\n\tvar first = str.charCodeAt(i);\n\n\tif (first >= 0xD800 && first <= 0xDBFF && size > i + 1) {\n\t\tvar second = str.charCodeAt(i + 1);\n\n\t\tif (second >= 0xDC00 && second <= 0xDFFF) {\n\t\t\treturn ((first - 0xD800) * 0x400) + second - 0xDC00 + 0x10000;\n\t\t}\n\t}\n\n\treturn first;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/string-width/node_modules/is-fullwidth-code-point/index.js":"'use strict';\nvar numberIsNan = require('number-is-nan');\n\nmodule.exports = function (x) {\n\tif (numberIsNan(x)) {\n\t\treturn false;\n\t}\n\n\t// https://github.com/nodejs/io.js/blob/cff7300a578be1b10001f2d967aaedc88aee6402/lib/readline.js#L1369\n\n\t// code points are derived from:\n\t// http://www.unix.org/Public/UNIDATA/EastAsianWidth.txt\n\tif (x >= 0x1100 && (\n\t\tx <= 0x115f ||  // Hangul Jamo\n\t\t0x2329 === x || // LEFT-POINTING ANGLE BRACKET\n\t\t0x232a === x || // RIGHT-POINTING ANGLE BRACKET\n\t\t// CJK Radicals Supplement .. Enclosed CJK Letters and Months\n\t\t(0x2e80 <= x && x <= 0x3247 && x !== 0x303f) ||\n\t\t// Enclosed CJK Letters and Months .. CJK Unified Ideographs Extension A\n\t\t0x3250 <= x && x <= 0x4dbf ||\n\t\t// CJK Unified Ideographs .. Yi Radicals\n\t\t0x4e00 <= x && x <= 0xa4c6 ||\n\t\t// Hangul Jamo Extended-A\n\t\t0xa960 <= x && x <= 0xa97c ||\n\t\t// Hangul Syllables\n\t\t0xac00 <= x && x <= 0xd7a3 ||\n\t\t// CJK Compatibility Ideographs\n\t\t0xf900 <= x && x <= 0xfaff ||\n\t\t// Vertical Forms\n\t\t0xfe10 <= x && x <= 0xfe19 ||\n\t\t// CJK Compatibility Forms .. Small Form Variants\n\t\t0xfe30 <= x && x <= 0xfe6b ||\n\t\t// Halfwidth and Fullwidth Forms\n\t\t0xff01 <= x && x <= 0xff60 ||\n\t\t0xffe0 <= x && x <= 0xffe6 ||\n\t\t// Kana Supplement\n\t\t0x1b000 <= x && x <= 0x1b001 ||\n\t\t// Enclosed Ideographic Supplement\n\t\t0x1f200 <= x && x <= 0x1f251 ||\n\t\t// CJK Unified Ideographs Extension B .. Tertiary Ideographic Plane\n\t\t0x20000 <= x && x <= 0x3fffd)) {\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/string-width/node_modules/is-fullwidth-code-point/node_modules/number-is-nan/index.js":"'use strict';\nmodule.exports = Number.isNaN || function (x) {\n\treturn x !== x;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/aproba/index.js":"'use strict'\n\nfunction isArguments (thingy) {\n  return thingy != null && typeof thingy === 'object' && thingy.hasOwnProperty('callee')\n}\n\nvar types = {\n  '*': {label: 'any', check: function () { return true }},\n  A: {label: 'array', check: function (thingy) { return Array.isArray(thingy) || isArguments(thingy) }},\n  S: {label: 'string', check: function (thingy) { return typeof thingy === 'string' }},\n  N: {label: 'number', check: function (thingy) { return typeof thingy === 'number' }},\n  F: {label: 'function', check: function (thingy) { return typeof thingy === 'function' }},\n  O: {label: 'object', check: function (thingy) { return typeof thingy === 'object' && thingy != null && !types.A.check(thingy) && !types.E.check(thingy) }},\n  B: {label: 'boolean', check: function (thingy) { return typeof thingy === 'boolean' }},\n  E: {label: 'error', check: function (thingy) { return thingy instanceof Error }},\n  Z: {label: 'null', check: function (thingy) { return thingy == null }}\n}\n\nvar validate = module.exports = function (rawSchemas, args) {\n  if (arguments.length !== 2) throw wrongNumberOfArgs(['SA'], arguments.length)\n  if (!rawSchemas) throw missingRequiredArg(0, 'rawSchemas')\n  if (!args) throw missingRequiredArg(1, 'args')\n  if (!types.S.check(rawSchemas)) throw invalidType(0, ['string'], rawSchemas)\n  if (!types.A.check(args)) throw invalidType(1, ['array'], args)\n  var schemas = rawSchemas.split('|')\n  var arity = {}\n  function addSchema (schema) {\n    var group = arity[schema.length] = arity[schema.length] || []\n    if (group.indexOf(schema) === -1) group.push(schema)\n  }\n  schemas.forEach(function (schema) {\n    for (var ii = 0; ii < schema.length; ++ii) {\n      var type = schema[ii]\n      if (!types[type]) throw unknownType(ii, type)\n    }\n    if (/E.*E/.test(schema)) throw moreThanOneError(schema)\n    addSchema(schema)\n    if (/E/.test(schema)) {\n      addSchema(schema.replace(/E.*$/, 'E'))\n      addSchema(schema.replace(/E/, 'Z'))\n      if (schema.length === 1) addSchema('')\n    }\n  })\n  var matching = arity[args.length]\n  if (!matching) {\n    throw wrongNumberOfArgs(Object.keys(arity), args.length)\n  }\n  for (var ii = 0; ii < args.length; ++ii) {\n    var newMatching = matching.filter(function (schema) {\n      var type = schema[ii]\n      var typeCheck = types[type].check\n      return typeCheck(args[ii])\n    })\n    if (!newMatching.length) {\n      var labels = matching.map(function (schema) {\n        return types[schema[ii]].label\n      }).filter(function (schema) { return schema != null })\n      throw invalidType(ii, labels, args[ii])\n    }\n    matching = newMatching\n  }\n}\n\nfunction missingRequiredArg (num) {\n  return newException('EMISSINGARG', 'Missing required argument #' + (num + 1))\n}\n\nfunction unknownType (num, type) {\n  return newException('EUNKNOWNTYPE', 'Unknown type ' + type + ' in argument #' + (num + 1))\n}\n\nfunction invalidType (num, expectedTypes, value) {\n  var valueType\n  Object.keys(types).forEach(function (typeCode) {\n    if (types[typeCode].check(value)) valueType = types[typeCode].label\n  })\n  return newException('EINVALIDTYPE', 'Argument #' + (num + 1) + ': Expected ' +\n    englishList(expectedTypes) + ' but got ' + valueType)\n}\n\nfunction englishList (list) {\n  return list.join(', ').replace(/, ([^,]+)$/, ' or $1')\n}\n\nfunction wrongNumberOfArgs (expected, got) {\n  var english = englishList(expected)\n  var args = expected.every(function (ex) { return ex.length === 1 })\n    ? 'argument'\n    : 'arguments'\n  return newException('EWRONGARGCOUNT', 'Expected ' + english + ' ' + args + ' but got ' + got)\n}\n\nfunction moreThanOneError (schema) {\n  return newException('ETOOMANYERRORTYPES',\n    'Only one error type per argument signature is allowed, more than one found in \"' + schema + '\"')\n}\n\nfunction newException (code, msg) {\n  var e = new Error(msg)\n  e.code = code\n  Error.captureStackTrace(e, validate)\n  return e\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/object-assign/index.js":"'use strict';\n/* eslint-disable no-unused-vars */\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\nfunction toObject(val) {\n\tif (val === null || val === undefined) {\n\t\tthrow new TypeError('Object.assign cannot be called with null or undefined');\n\t}\n\n\treturn Object(val);\n}\n\nfunction shouldUseNative() {\n\ttry {\n\t\tif (!Object.assign) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Detect buggy property enumeration order in older V8 versions.\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=4118\n\t\tvar test1 = new String('abc');  // eslint-disable-line\n\t\ttest1[5] = 'de';\n\t\tif (Object.getOwnPropertyNames(test1)[0] === '5') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test2 = {};\n\t\tfor (var i = 0; i < 10; i++) {\n\t\t\ttest2['_' + String.fromCharCode(i)] = i;\n\t\t}\n\t\tvar order2 = Object.getOwnPropertyNames(test2).map(function (n) {\n\t\t\treturn test2[n];\n\t\t});\n\t\tif (order2.join('') !== '0123456789') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test3 = {};\n\t\t'abcdefghijklmnopqrst'.split('').forEach(function (letter) {\n\t\t\ttest3[letter] = letter;\n\t\t});\n\t\tif (Object.keys(Object.assign({}, test3)).join('') !==\n\t\t\t\t'abcdefghijklmnopqrst') {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t} catch (e) {\n\t\t// We don't expect any of the above to throw, but better to be safe.\n\t\treturn false;\n\t}\n}\n\nmodule.exports = shouldUseNative() ? Object.assign : function (target, source) {\n\tvar from;\n\tvar to = toObject(target);\n\tvar symbols;\n\n\tfor (var s = 1; s < arguments.length; s++) {\n\t\tfrom = Object(arguments[s]);\n\n\t\tfor (var key in from) {\n\t\t\tif (hasOwnProperty.call(from, key)) {\n\t\t\t\tto[key] = from[key];\n\t\t\t}\n\t\t}\n\n\t\tif (Object.getOwnPropertySymbols) {\n\t\t\tsymbols = Object.getOwnPropertySymbols(from);\n\t\t\tfor (var i = 0; i < symbols.length; i++) {\n\t\t\t\tif (propIsEnumerable.call(from, symbols[i])) {\n\t\t\t\t\tto[symbols[i]] = from[symbols[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn to;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/wide-truncate.js":"'use strict'\nvar stringWidth = require('string-width')\nvar stripAnsi = require('strip-ansi')\n\nmodule.exports = wideTruncate\n\nfunction wideTruncate (str, target) {\n  if (stringWidth(str) === 0) return str\n  if (target <= 0) return ''\n  if (stringWidth(str) <= target) return str\n\n  // We compute the number of bytes of ansi sequences here and add\n  // that to our initial truncation to ensure that we don't slice one\n  // that we want to keep in half.\n  var noAnsi = stripAnsi(str)\n  var ansiSize = str.length + noAnsi.length\n  var truncated = str.slice(0, target + ansiSize)\n\n  // we have to shrink the result to account for our ansi sequence buffer\n  // (if an ansi sequence was truncated) and double width characters.\n  while (stringWidth(truncated) > target) {\n    truncated = truncated.slice(0, -1)\n  }\n  return truncated\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/error.js":"'use strict'\nvar util = require('util')\n\nvar User = exports.User = function User (msg) {\n  var err = new Error(msg)\n  Error.captureStackTrace(err, User)\n  err.code = 'EGAUGE'\n  return err\n}\n\nexports.MissingTemplateValue = function MissingTemplateValue (item, values) {\n  var err = new User(util.format('Missing template value \"%s\"', item.type))\n  Error.captureStackTrace(err, MissingTemplateValue)\n  err.template = item\n  err.values = values\n  return err\n}\n\nexports.Internal = function Internal (msg) {\n  var err = new Error(msg)\n  Error.captureStackTrace(err, Internal)\n  err.code = 'EGAUGEINTERNAL'\n  return err\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/template-item.js":"'use strict'\nvar stringWidth = require('string-width')\n\nmodule.exports = TemplateItem\n\nfunction isPercent (num) {\n  if (typeof num !== 'string') return false\n  return num.slice(-1) === '%'\n}\n\nfunction percent (num) {\n  return Number(num.slice(0, -1)) / 100\n}\n\nfunction TemplateItem (values, outputLength) {\n  this.overallOutputLength = outputLength\n  this.finished = false\n  this.type = null\n  this.value = null\n  this.length = null\n  this.maxLength = null\n  this.minLength = null\n  this.kerning = null\n  this.align = 'left'\n  this.padLeft = 0\n  this.padRight = 0\n  this.index = null\n  this.first = null\n  this.last = null\n  if (typeof values === 'string') {\n    this.value = values\n  } else {\n    for (var prop in values) this[prop] = values[prop]\n  }\n  // Realize percents\n  if (isPercent(this.length)) {\n    this.length = Math.round(this.overallOutputLength * percent(this.length))\n  }\n  if (isPercent(this.minLength)) {\n    this.minLength = Math.round(this.overallOutputLength * percent(this.minLength))\n  }\n  if (isPercent(this.maxLength)) {\n    this.maxLength = Math.round(this.overallOutputLength * percent(this.maxLength))\n  }\n  return this\n}\n\nTemplateItem.prototype = {}\n\nTemplateItem.prototype.getBaseLength = function () {\n  var length = this.length\n  if (length == null && typeof this.value === 'string' && this.maxLength == null && this.minLength == null) {\n    length = stringWidth(this.value)\n  }\n  return length\n}\n\nTemplateItem.prototype.getLength = function () {\n  var length = this.getBaseLength()\n  if (length == null) return null\n  return length + this.padLeft + this.padRight\n}\n\nTemplateItem.prototype.getMaxLength = function () {\n  if (this.maxLength == null) return null\n  return this.maxLength + this.padLeft + this.padRight\n}\n\nTemplateItem.prototype.getMinLength = function () {\n  if (this.minLength == null) return null\n  return this.minLength + this.padLeft + this.padRight\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/has-unicode/index.js":"\"use strict\"\nvar os = require(\"os\")\n\nvar hasUnicode = module.exports = function () {\n  // Recent Win32 platforms (>XP) CAN support unicode in the console but\n  // don't have to, and in non-english locales often use traditional local\n  // code pages. There's no way, short of windows system calls or execing\n  // the chcp command line program to figure this out. As such, we default\n  // this to false and encourage your users to override it via config if\n  // appropriate.\n  if (os.type() == \"Windows_NT\") { return false }\n\n  var isUTF8 = /UTF-?8$/i\n  var ctype = process.env.LC_ALL || process.env.LC_CTYPE || process.env.LANG\n  return isUTF8.test(ctype)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/has-color.js":"'use strict'\n\nmodule.exports = isWin32() || isColorTerm()\n\nfunction isWin32 () {\n  return process.platform === 'win32'\n}\n\nfunction isColorTerm () {\n  var termHasColor = /^screen|^xterm|^vt100|color|ansi|cygwin|linux/i\n  return !!process.env.COLORTERM || termHasColor.test(process.env.TERM)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/signal-exit/index.js":"// Note: since nyc uses this module to output coverage, any lines\n// that are in the direct sync flow of nyc's outputCoverage are\n// ignored, since we can never get coverage for them.\nvar assert = require('assert')\nvar signals = require('./signals.js')\n\nvar EE = require('events')\n/* istanbul ignore if */\nif (typeof EE !== 'function') {\n  EE = EE.EventEmitter\n}\n\nvar emitter\nif (process.__signal_exit_emitter__) {\n  emitter = process.__signal_exit_emitter__\n} else {\n  emitter = process.__signal_exit_emitter__ = new EE()\n  emitter.count = 0\n  emitter.emitted = {}\n}\n\n// Because this emitter is a global, we have to check to see if a\n// previous version of this library failed to enable infinite listeners.\n// I know what you're about to say.  But literally everything about\n// signal-exit is a compromise with evil.  Get used to it.\nif (!emitter.infinite) {\n  emitter.setMaxListeners(Infinity)\n  emitter.infinite = true\n}\n\nmodule.exports = function (cb, opts) {\n  assert.equal(typeof cb, 'function', 'a callback must be provided for exit handler')\n\n  if (loaded === false) {\n    load()\n  }\n\n  var ev = 'exit'\n  if (opts && opts.alwaysLast) {\n    ev = 'afterexit'\n  }\n\n  var remove = function () {\n    emitter.removeListener(ev, cb)\n    if (emitter.listeners('exit').length === 0 &&\n        emitter.listeners('afterexit').length === 0) {\n      unload()\n    }\n  }\n  emitter.on(ev, cb)\n\n  return remove\n}\n\nmodule.exports.unload = unload\nfunction unload () {\n  if (!loaded) {\n    return\n  }\n  loaded = false\n\n  signals.forEach(function (sig) {\n    try {\n      process.removeListener(sig, sigListeners[sig])\n    } catch (er) {}\n  })\n  process.emit = originalProcessEmit\n  process.reallyExit = originalProcessReallyExit\n  emitter.count -= 1\n}\n\nfunction emit (event, code, signal) {\n  if (emitter.emitted[event]) {\n    return\n  }\n  emitter.emitted[event] = true\n  emitter.emit(event, code, signal)\n}\n\n// { <signal>: <listener fn>, ... }\nvar sigListeners = {}\nsignals.forEach(function (sig) {\n  sigListeners[sig] = function listener () {\n    // If there are no other listeners, an exit is coming!\n    // Simplest way: remove us and then re-send the signal.\n    // We know that this will kill the process, so we can\n    // safely emit now.\n    var listeners = process.listeners(sig)\n    if (listeners.length === emitter.count) {\n      unload()\n      emit('exit', null, sig)\n      /* istanbul ignore next */\n      emit('afterexit', null, sig)\n      /* istanbul ignore next */\n      process.kill(process.pid, sig)\n    }\n  }\n})\n\nmodule.exports.signals = function () {\n  return signals\n}\n\nmodule.exports.load = load\n\nvar loaded = false\n\nfunction load () {\n  if (loaded) {\n    return\n  }\n  loaded = true\n\n  // This is the number of onSignalExit's that are in play.\n  // It's important so that we can count the correct number of\n  // listeners on signals, and don't wait for the other one to\n  // handle it instead of us.\n  emitter.count += 1\n\n  signals = signals.filter(function (sig) {\n    try {\n      process.on(sig, sigListeners[sig])\n      return true\n    } catch (er) {\n      return false\n    }\n  })\n\n  process.emit = processEmit\n  process.reallyExit = processReallyExit\n}\n\nvar originalProcessReallyExit = process.reallyExit\nfunction processReallyExit (code) {\n  process.exitCode = code || 0\n  emit('exit', process.exitCode, null)\n  /* istanbul ignore next */\n  emit('afterexit', process.exitCode, null)\n  /* istanbul ignore next */\n  originalProcessReallyExit.call(process, process.exitCode)\n}\n\nvar originalProcessEmit = process.emit\nfunction processEmit (ev, arg) {\n  if (ev === 'exit') {\n    if (arg !== undefined) {\n      process.exitCode = arg\n    }\n    var ret = originalProcessEmit.apply(this, arguments)\n    emit('exit', process.exitCode, null)\n    /* istanbul ignore next */\n    emit('afterexit', process.exitCode, null)\n    return ret\n  } else {\n    return originalProcessEmit.apply(this, arguments)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/node_modules/signal-exit/signals.js":"// This is not the set of all possible signals.\n//\n// It IS, however, the set of all signals that trigger\n// an exit on either Linux or BSD systems.  Linux is a\n// superset of the signal names supported on BSD, and\n// the unknown signals just fail to register, so we can\n// catch that easily enough.\n//\n// Don't bother with SIGKILL.  It's uncatchable, which\n// means that we can't fire any callbacks anyway.\n//\n// If a user does happen to register a handler on a non-\n// fatal signal like SIGWINCH or something, and then\n// exit, it'll end up firing `process.emit('exit')`, so\n// the handler will be fired anyway.\n//\n// SIGBUS, SIGFPE, SIGSEGV and SIGILL, when not raised\n// artificially, inherently leave the process in a\n// state from which it is not safe to try and enter JS\n// listeners.\nmodule.exports = [\n  'SIGABRT',\n  'SIGALRM',\n  'SIGHUP',\n  'SIGINT',\n  'SIGTERM'\n]\n\nif (process.platform !== 'win32') {\n  module.exports.push(\n    'SIGVTALRM',\n    'SIGXCPU',\n    'SIGXFSZ',\n    'SIGUSR2',\n    'SIGTRAP',\n    'SIGSYS',\n    'SIGQUIT',\n    'SIGIOT'\n    // should detect profiler and enable/disable accordingly.\n    // see #21\n    // 'SIGPROF'\n  )\n}\n\nif (process.platform === 'linux') {\n  module.exports.push(\n    'SIGIO',\n    'SIGPOLL',\n    'SIGPWR',\n    'SIGSTKFLT',\n    'SIGUNUSED'\n  )\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/themes.js":"'use strict'\nvar consoleControl = require('console-control-strings')\nvar ThemeSet = require('./theme-set.js')\n\nvar themes = module.exports = new ThemeSet()\n\nthemes.addTheme('ASCII', {\n  preProgressbar: '[',\n  postProgressbar: ']',\n  progressbarTheme: {\n    complete: '#',\n    remaining: '.'\n  },\n  activityIndicatorTheme: '-\\\\|/',\n  preSubsection: '>'\n})\n\nthemes.addTheme('colorASCII', themes.getTheme('ASCII'), {\n  progressbarTheme: {\n    preComplete: consoleControl.color('inverse'),\n    complete: ' ',\n    postComplete: consoleControl.color('stopInverse'),\n    preRemaining: consoleControl.color('brightBlack'),\n    remaining: '.',\n    postRemaining: consoleControl.color('reset')\n  }\n})\n\nthemes.addTheme('brailleSpinner', {\n  preProgressbar: '',\n  postProgressbar: '',\n  progressbarTheme: {\n    complete: '',\n    remaining: ''\n  },\n  activityIndicatorTheme: '',\n  preSubsection: '>'\n})\n\nthemes.addTheme('colorBrailleSpinner', themes.getTheme('brailleSpinner'), {\n  progressbarTheme: {\n    preComplete: consoleControl.color('inverse'),\n    complete: ' ',\n    postComplete: consoleControl.color('stopInverse'),\n    preRemaining: consoleControl.color('brightBlack'),\n    remaining: '',\n    postRemaining: consoleControl.color('reset')\n  }\n})\n\nthemes.setDefault({}, 'ASCII')\nthemes.setDefault({hasColor: true}, 'colorASCII')\nthemes.setDefault({platform: 'darwin', hasUnicode: true}, 'brailleSpinner')\nthemes.setDefault({platform: 'darwin', hasUnicode: true, hasColor: true}, 'colorBrailleSpinner')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/theme-set.js":"'use strict'\nvar objectAssign = require('object-assign')\n\nmodule.exports = function () {\n  return ThemeSetProto.newThemeSet()\n}\n\nvar ThemeSetProto = {}\n\nThemeSetProto.baseTheme = require('./base-theme.js')\n\nThemeSetProto.newTheme = function (parent, theme) {\n  if (!theme) {\n    theme = parent\n    parent = this.baseTheme\n  }\n  return objectAssign({}, parent, theme)\n}\n\nThemeSetProto.getThemeNames = function () {\n  return Object.keys(this.themes)\n}\n\nThemeSetProto.addTheme = function (name, parent, theme) {\n  this.themes[name] = this.newTheme(parent, theme)\n}\n\nThemeSetProto.addToAllThemes = function (theme) {\n  var themes = this.themes\n  Object.keys(themes).forEach(function (name) {\n    objectAssign(themes[name], theme)\n  })\n  objectAssign(this.baseTheme, theme)\n}\n\nThemeSetProto.getTheme = function (name) {\n  if (!this.themes[name]) throw this.newMissingThemeError(name)\n  return this.themes[name]\n}\n\nThemeSetProto.setDefault = function (opts, name) {\n  if (name == null) {\n    name = opts\n    opts = {}\n  }\n  var platform = opts.platform == null ? 'fallback' : opts.platform\n  var hasUnicode = !!opts.hasUnicode\n  var hasColor = !!opts.hasColor\n  if (!this.defaults[platform]) this.defaults[platform] = {true: {}, false: {}}\n  this.defaults[platform][hasUnicode][hasColor] = name\n}\n\nThemeSetProto.getDefault = function (opts) {\n  if (!opts) opts = {}\n  var platformName = opts.platform || process.platform\n  var platform = this.defaults[platformName] || this.defaults.fallback\n  var hasUnicode = !!opts.hasUnicode\n  var hasColor = !!opts.hasColor\n  if (!platform) throw this.newMissingDefaultThemeError(platformName, hasUnicode, hasColor)\n  if (!platform[hasUnicode][hasColor]) {\n    if (hasUnicode && hasColor && platform[!hasUnicode][hasColor]) {\n      hasUnicode = false\n    } else if (hasUnicode && hasColor && platform[hasUnicode][!hasColor]) {\n      hasColor = false\n    } else if (hasUnicode && hasColor && platform[!hasUnicode][!hasColor]) {\n      hasUnicode = false\n      hasColor = false\n    } else if (hasUnicode && !hasColor && platform[!hasUnicode][hasColor]) {\n      hasUnicode = false\n    } else if (!hasUnicode && hasColor && platform[hasUnicode][!hasColor]) {\n      hasColor = false\n    } else if (platform === this.defaults.fallback) {\n      throw this.newMissingDefaultThemeError(platformName, hasUnicode, hasColor)\n    }\n  }\n  if (platform[hasUnicode][hasColor]) {\n    return this.getTheme(platform[hasUnicode][hasColor])\n  } else {\n    return this.getDefault(objectAssign({}, opts, {platform: 'fallback'}))\n  }\n}\n\nThemeSetProto.newMissingThemeError = function newMissingThemeError (name) {\n  var err = new Error('Could not find a gauge theme named \"' + name + '\"')\n  Error.captureStackTrace.call(err, newMissingThemeError)\n  err.theme = name\n  err.code = 'EMISSINGTHEME'\n  return err\n}\n\nThemeSetProto.newMissingDefaultThemeError = function newMissingDefaultThemeError (platformName, hasUnicode, hasColor) {\n  var err = new Error(\n    'Could not find a gauge theme for your platform/unicode/color use combo:\\n' +\n    '    platform = ' + platformName + '\\n' +\n    '    hasUnicode = ' + hasUnicode + '\\n' +\n    '    hasColor = ' + hasColor)\n  Error.captureStackTrace.call(err, newMissingDefaultThemeError)\n  err.platform = platformName\n  err.hasUnicode = hasUnicode\n  err.hasColor = hasColor\n  err.code = 'EMISSINGTHEME'\n  return err\n}\n\nThemeSetProto.newThemeSet = function () {\n  var themeset = function (opts) {\n    return themeset.getDefault(opts)\n  }\n  return objectAssign(themeset, ThemeSetProto, {\n    themes: objectAssign({}, this.themes),\n    baseTheme: objectAssign({}, this.baseTheme),\n    defaults: JSON.parse(JSON.stringify(this.defaults || {}))\n  })\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/base-theme.js":"'use strict'\nvar spin = require('./spin.js')\nvar progressBar = require('./progress-bar.js')\n\nmodule.exports = {\n  activityIndicator: function (values, theme, width) {\n    if (values.spun == null) return\n    return spin(theme, values.spun)\n  },\n  progressbar: function (values, theme, width) {\n    if (values.completed == null) return\n    return progressBar(theme, width, values.completed)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/spin.js":"'use strict'\n\nmodule.exports = function spin (spinstr, spun) {\n  return spinstr[spun % spinstr.length]\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/progress-bar.js":"'use strict'\nvar validate = require('aproba')\nvar renderTemplate = require('./render-template.js')\nvar wideTruncate = require('./wide-truncate')\nvar stringWidth = require('string-width')\n\nmodule.exports = function (theme, width, completed) {\n  validate('ONN', [theme, width, completed])\n  if (completed < 0) completed = 0\n  if (completed > 1) completed = 1\n  if (width <= 0) return ''\n  var sofar = Math.round(width * completed)\n  var rest = width - sofar\n  var template = [\n    {type: 'complete', value: repeat(theme.complete, sofar), length: sofar},\n    {type: 'remaining', value: repeat(theme.remaining, rest), length: rest}\n  ]\n  return renderTemplate(width, template, theme)\n}\n\n// lodash's way of repeating\nfunction repeat (string, width) {\n  var result = ''\n  var n = width\n  do {\n    if (n % 2) {\n      result += string\n    }\n    n = Math.floor(n / 2)\n    /*eslint no-self-assign: 0*/\n    string += string\n  } while (n && stringWidth(result) < width)\n\n  return wideTruncate(result, width)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/set-interval.js":"'use strict'\n// this exists so we can replace it during testing\nmodule.exports = setInterval\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/process.js":"'use strict'\n// this exists so we can replace it during testing\nmodule.exports = process\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/gauge/set-immediate.js":"'use strict'\nvar process = require('./process')\ntry {\n  module.exports = setImmediate\n} catch (ex) {\n  module.exports = process.nextTick\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npmlog/node_modules/set-blocking/index.js":"module.exports = function (blocking) {\n  [process.stdout, process.stderr].forEach(function (stream) {\n    if (stream._handle && stream.isTTY && typeof stream._handle.setBlocking === 'function') {\n      stream._handle.setBlocking(blocking)\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/once/once.js":"var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/wrappy/wrappy.js":"// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mkdirp/index.js":"var path = require('path');\nvar fs = require('fs');\nvar _0777 = parseInt('0777', 8);\n\nmodule.exports = mkdirP.mkdirp = mkdirP.mkdirP = mkdirP;\n\nfunction mkdirP (p, opts, f, made) {\n    if (typeof opts === 'function') {\n        f = opts;\n        opts = {};\n    }\n    else if (!opts || typeof opts !== 'object') {\n        opts = { mode: opts };\n    }\n    \n    var mode = opts.mode;\n    var xfs = opts.fs || fs;\n    \n    if (mode === undefined) {\n        mode = _0777 & (~process.umask());\n    }\n    if (!made) made = null;\n    \n    var cb = f || function () {};\n    p = path.resolve(p);\n    \n    xfs.mkdir(p, mode, function (er) {\n        if (!er) {\n            made = made || p;\n            return cb(null, made);\n        }\n        switch (er.code) {\n            case 'ENOENT':\n                mkdirP(path.dirname(p), opts, function (er, made) {\n                    if (er) cb(er, made);\n                    else mkdirP(p, opts, cb, made);\n                });\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                xfs.stat(p, function (er2, stat) {\n                    // if the stat fails, then that's super weird.\n                    // let the original error be the failure reason.\n                    if (er2 || !stat.isDirectory()) cb(er, made)\n                    else cb(null, made);\n                });\n                break;\n        }\n    });\n}\n\nmkdirP.sync = function sync (p, opts, made) {\n    if (!opts || typeof opts !== 'object') {\n        opts = { mode: opts };\n    }\n    \n    var mode = opts.mode;\n    var xfs = opts.fs || fs;\n    \n    if (mode === undefined) {\n        mode = _0777 & (~process.umask());\n    }\n    if (!made) made = null;\n\n    p = path.resolve(p);\n\n    try {\n        xfs.mkdirSync(p, mode);\n        made = made || p;\n    }\n    catch (err0) {\n        switch (err0.code) {\n            case 'ENOENT' :\n                made = sync(path.dirname(p), opts, made);\n                sync(p, opts, made);\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                var stat;\n                try {\n                    stat = xfs.statSync(p);\n                }\n                catch (err1) {\n                    throw err0;\n                }\n                if (!stat.isDirectory()) throw err0;\n                break;\n        }\n    }\n\n    return made;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/is-windows.js":"'use strict'\nmodule.exports = process.platform === 'win32'\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/load-prefix.js":"module.exports = loadPrefix\n\nvar findPrefix = require('./find-prefix.js')\nvar path = require('path')\n\nfunction loadPrefix (cb) {\n  var cli = this.list[0]\n\n  Object.defineProperty(this, 'prefix',\n    {\n      set: function (prefix) {\n        var g = this.get('global')\n        this[g ? 'globalPrefix' : 'localPrefix'] = prefix\n      }.bind(this),\n      get: function () {\n        var g = this.get('global')\n        return g ? this.globalPrefix : this.localPrefix\n      }.bind(this),\n      enumerable: true\n    })\n\n  Object.defineProperty(this, 'globalPrefix',\n    {\n      set: function (prefix) {\n        this.set('prefix', prefix)\n      }.bind(this),\n      get: function () {\n        return path.resolve(this.get('prefix'))\n      }.bind(this),\n      enumerable: true\n    })\n\n  var p\n  Object.defineProperty(this, 'localPrefix',\n    { set: function (prefix) { p = prefix },\n      get: function () { return p },\n    enumerable: true })\n\n  // try to guess at a good node_modules location.\n  // If we are *explicitly* given a prefix on the cli, then\n  // always use that.  otherwise, infer local prefix from cwd.\n  if (Object.prototype.hasOwnProperty.call(cli, 'prefix')) {\n    p = path.resolve(cli.prefix)\n    process.nextTick(cb)\n  } else {\n    findPrefix(process.cwd(), function (er, found) {\n      p = found\n      cb(er)\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/find-prefix.js":"// try to find the most reasonable prefix to use\n\nmodule.exports = findPrefix\n\nvar fs = require('fs')\nvar path = require('path')\n\nfunction findPrefix (p, cb_) {\n  function cb (er, p) {\n    process.nextTick(function () {\n      cb_(er, p)\n    })\n  }\n\n  p = path.resolve(p)\n  // if there's no node_modules folder, then\n  // walk up until we hopefully find one.\n  // if none anywhere, then use cwd.\n  var walkedUp = false\n  while (path.basename(p) === 'node_modules') {\n    p = path.dirname(p)\n    walkedUp = true\n  }\n  if (walkedUp) return cb(null, p)\n\n  findPrefix_(p, p, cb)\n}\n\nfunction findPrefix_ (p, original, cb) {\n  if (p === '/' ||\n      (process.platform === 'win32' && p.match(/^[a-zA-Z]:(\\\\|\\/)?$/))) {\n    return cb(null, original)\n  }\n  fs.readdir(p, function (er, files) {\n    // an error right away is a bad sign.\n    // unless the prefix was simply a non\n    // existent directory.\n    if (er && p === original) {\n      if (er.code === 'ENOENT') return cb(null, original)\n      return cb(er)\n    }\n\n    // walked up too high or something.\n    if (er) return cb(null, original)\n\n    if (files.indexOf('node_modules') !== -1 ||\n        files.indexOf('package.json') !== -1) {\n      return cb(null, p)\n    }\n\n    var d = path.dirname(p)\n    if (d === p) return cb(null, original)\n\n    return findPrefix_(d, original, cb)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/load-cafile.js":"module.exports = loadCAFile\n\nvar fs = require('fs')\n\nfunction loadCAFile (cafilePath, cb) {\n  if (!cafilePath) return process.nextTick(cb)\n\n  fs.readFile(cafilePath, 'utf8', afterCARead.bind(this))\n\n  function afterCARead (er, cadata) {\n    if (er) {\n      // previous cafile no longer exists, so just continue on gracefully\n      if (er.code === 'ENOENT') return cb()\n      return cb(er)\n    }\n\n    var delim = '-----END CERTIFICATE-----'\n    var output\n\n    output = cadata\n      .split(delim)\n      .filter(function (xs) {\n        return !!xs.trim()\n      })\n      .map(function (xs) {\n        return xs.trimLeft() + delim\n      })\n\n    this.set('ca', output)\n    cb(null)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/load-uid.js":"module.exports = loadUid\n\nvar getUid = require('uid-number')\n\n// Call in the context of a npmconf object\n\nfunction loadUid (cb) {\n  // if we're not in unsafe-perm mode, then figure out who\n  // to run stuff as.  Do this first, to support `npm update npm -g`\n  if (!this.get('unsafe-perm')) {\n    getUid(this.get('user'), this.get('group'), cb)\n  } else {\n    process.nextTick(cb)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/uid-number/uid-number.js":"module.exports = uidNumber\n\n// This module calls into get-uid-gid.js, which sets the\n// uid and gid to the supplied argument, in order to find out their\n// numeric value.  This can't be done in the main node process,\n// because otherwise node would be running as that user from this\n// point on.\n\nvar child_process = require(\"child_process\")\n  , path = require(\"path\")\n  , uidSupport = process.getuid && process.setuid\n  , uidCache = {}\n  , gidCache = {}\n\nfunction uidNumber (uid, gid, cb) {\n  if (!uidSupport) return cb()\n  if (typeof cb !== \"function\") cb = gid, gid = null\n  if (typeof cb !== \"function\") cb = uid, uid = null\n  if (gid == null) gid = process.getgid()\n  if (uid == null) uid = process.getuid()\n  if (!isNaN(gid)) gid = gidCache[gid] = +gid\n  if (!isNaN(uid)) uid = uidCache[uid] = +uid\n\n  if (uidCache.hasOwnProperty(uid)) uid = uidCache[uid]\n  if (gidCache.hasOwnProperty(gid)) gid = gidCache[gid]\n\n  if (typeof gid === \"number\" && typeof uid === \"number\") {\n    return process.nextTick(cb.bind(null, null, uid, gid))\n  }\n\n  var getter = require.resolve(\"./get-uid-gid.js\")\n\n  child_process.execFile( process.execPath\n                        , [getter, uid, gid]\n                        , function (code, out, stderr) {\n    if (code) {\n      var er = new Error(\"could not get uid/gid\\n\" + stderr)\n      er.code = code\n      return cb(er)\n    }\n\n    try {\n      out = JSON.parse(out+\"\")\n    } catch (ex) {\n      return cb(ex)\n    }\n\n    if (out.error) {\n      var er = new Error(out.error)\n      er.errno = out.errno\n      return cb(er)\n    }\n\n    if (isNaN(out.uid) || isNaN(out.gid)) return cb(new Error(\n      \"Could not get uid/gid: \"+JSON.stringify(out)))\n\n    cb(null, uidCache[uid] = +out.uid, gidCache[gid] = +out.gid)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/set-user.js":"module.exports = setUser\n\nvar assert = require('assert')\nvar path = require('path')\nvar fs = require('fs')\nvar mkdirp = require('mkdirp')\n\nfunction setUser (cb) {\n  var defaultConf = this.root\n  assert(defaultConf !== Object.prototype)\n\n  // If global, leave it as-is.\n  // If not global, then set the user to the owner of the prefix folder.\n  // Just set the default, so it can be overridden.\n  if (this.get('global')) return cb()\n  if (process.env.SUDO_UID) {\n    defaultConf.user = +(process.env.SUDO_UID)\n    return cb()\n  }\n\n  var prefix = path.resolve(this.get('prefix'))\n  mkdirp(prefix, function (er) {\n    if (er) return cb(er)\n    fs.stat(prefix, function (er, st) {\n      defaultConf.user = st && st.uid\n      return cb(er)\n    })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/get-credentials-by-uri.js":"var assert = require('assert')\n\nvar toNerfDart = require('./nerf-dart.js')\n\nmodule.exports = getCredentialsByURI\n\nfunction getCredentialsByURI (uri) {\n  assert(uri && typeof uri === 'string', 'registry URL is required')\n  var nerfed = toNerfDart(uri)\n  var defnerf = toNerfDart(this.get('registry'))\n\n  // hidden class micro-optimization\n  var c = {\n    scope: nerfed,\n    token: undefined,\n    password: undefined,\n    username: undefined,\n    email: undefined,\n    auth: undefined,\n    alwaysAuth: undefined\n  }\n\n  // used to override scope matching for tokens as well as legacy auth\n  if (this.get(nerfed + ':always-auth') !== undefined) {\n    var val = this.get(nerfed + ':always-auth')\n    c.alwaysAuth = val === 'false' ? false : !!val\n  } else if (this.get('always-auth') !== undefined) {\n    c.alwaysAuth = this.get('always-auth')\n  }\n\n  if (this.get(nerfed + ':_authToken')) {\n    c.token = this.get(nerfed + ':_authToken')\n    // the bearer token is enough, don't confuse things\n    return c\n  }\n\n  // Handle the old-style _auth=<base64> style for the default\n  // registry, if set.\n  //\n  // XXX(isaacs): Remove when npm 1.4 is no longer relevant\n  var authDef = this.get('_auth')\n  var userDef = this.get('username')\n  var passDef = this.get('_password')\n  if (authDef && !(userDef && passDef)) {\n    authDef = new Buffer(authDef, 'base64').toString()\n    authDef = authDef.split(':')\n    userDef = authDef.shift()\n    passDef = authDef.join(':')\n  }\n\n  if (this.get(nerfed + ':_password')) {\n    c.password = new Buffer(this.get(nerfed + ':_password'), 'base64').toString('utf8')\n  } else if (nerfed === defnerf && passDef) {\n    c.password = passDef\n  }\n\n  if (this.get(nerfed + ':username')) {\n    c.username = this.get(nerfed + ':username')\n  } else if (nerfed === defnerf && userDef) {\n    c.username = userDef\n  }\n\n  if (this.get(nerfed + ':email')) {\n    c.email = this.get(nerfed + ':email')\n  } else if (this.get('email')) {\n    c.email = this.get('email')\n  }\n\n  if (c.username && c.password) {\n    c.auth = new Buffer(c.username + ':' + c.password).toString('base64')\n  }\n\n  return c\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/nerf-dart.js":"var url = require('url')\n\nmodule.exports = toNerfDart\n\n/**\n * Maps a URL to an identifier.\n *\n * Name courtesy schiffertronix media LLC, a New Jersey corporation\n *\n * @param {String} uri The URL to be nerfed.\n *\n * @returns {String} A nerfed URL.\n */\nfunction toNerfDart (uri) {\n  var parsed = url.parse(uri)\n  delete parsed.protocol\n  delete parsed.auth\n  delete parsed.query\n  delete parsed.search\n  delete parsed.hash\n\n  return url.resolve(url.format(parsed), '.')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/set-credentials-by-uri.js":"var assert = require('assert')\n\nvar toNerfDart = require('./nerf-dart.js')\n\nmodule.exports = setCredentialsByURI\n\nfunction setCredentialsByURI (uri, c) {\n  assert(uri && typeof uri === 'string', 'registry URL is required')\n  assert(c && typeof c === 'object', 'credentials are required')\n\n  var nerfed = toNerfDart(uri)\n\n  if (c.token) {\n    this.set(nerfed + ':_authToken', c.token, 'user')\n    this.del(nerfed + ':_password', 'user')\n    this.del(nerfed + ':username', 'user')\n    this.del(nerfed + ':email', 'user')\n    this.del(nerfed + ':always-auth', 'user')\n  } else if (c.username || c.password || c.email) {\n    assert(c.username, 'must include username')\n    assert(c.password, 'must include password')\n    assert(c.email, 'must include email address')\n\n    this.del(nerfed + ':_authToken', 'user')\n\n    var encoded = new Buffer(c.password, 'utf8').toString('base64')\n    this.set(nerfed + ':_password', encoded, 'user')\n    this.set(nerfed + ':username', c.username, 'user')\n    this.set(nerfed + ':email', c.email, 'user')\n\n    if (c.alwaysAuth !== undefined) {\n      this.set(nerfed + ':always-auth', c.alwaysAuth, 'user')\n    } else {\n      this.del(nerfed + ':always-auth', 'user')\n    }\n  } else {\n    throw new Error('No credentials to set.')\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/clear-credentials-by-uri.js":"var assert = require('assert')\n\nvar toNerfDart = require('./nerf-dart.js')\n\nmodule.exports = clearCredentialsByURI\n\nfunction clearCredentialsByURI (uri) {\n  assert(uri && typeof uri === 'string', 'registry URL is required')\n\n  var nerfed = toNerfDart(uri)\n\n  this.del(nerfed + ':_authToken', 'user')\n  this.del(nerfed + ':_password', 'user')\n  this.del(nerfed + ':username', 'user')\n  this.del(nerfed + ':email', 'user')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/which/which.js":"module.exports = which\nwhich.sync = whichSync\n\nvar isWindows = process.platform === 'win32' ||\n    process.env.OSTYPE === 'cygwin' ||\n    process.env.OSTYPE === 'msys'\n\nvar path = require('path')\nvar COLON = isWindows ? ';' : ':'\nvar isexe = require('isexe')\n\nfunction getNotFoundError (cmd) {\n  var er = new Error('not found: ' + cmd)\n  er.code = 'ENOENT'\n\n  return er\n}\n\nfunction getPathInfo (cmd, opt) {\n  var colon = opt.colon || COLON\n  var pathEnv = opt.path || process.env.PATH || ''\n  var pathExt = ['']\n\n  pathEnv = pathEnv.split(colon)\n\n  var pathExtExe = ''\n  if (isWindows) {\n    pathEnv.unshift(process.cwd())\n    pathExtExe = (opt.pathExt || process.env.PATHEXT || '.EXE;.CMD;.BAT;.COM')\n    pathExt = pathExtExe.split(colon)\n\n\n    // Always test the cmd itself first.  isexe will check to make sure\n    // it's found in the pathExt set.\n    if (cmd.indexOf('.') !== -1 && pathExt[0] !== '')\n      pathExt.unshift('')\n  }\n\n  // If it has a slash, then we don't bother searching the pathenv.\n  // just check the file itself, and that's it.\n  if (cmd.match(/\\//) || isWindows && cmd.match(/\\\\/))\n    pathEnv = ['']\n\n  return {\n    env: pathEnv,\n    ext: pathExt,\n    extExe: pathExtExe\n  }\n}\n\nfunction which (cmd, opt, cb) {\n  if (typeof opt === 'function') {\n    cb = opt\n    opt = {}\n  }\n\n  var info = getPathInfo(cmd, opt)\n  var pathEnv = info.env\n  var pathExt = info.ext\n  var pathExtExe = info.extExe\n  var found = []\n\n  ;(function F (i, l) {\n    if (i === l) {\n      if (opt.all && found.length)\n        return cb(null, found)\n      else\n        return cb(getNotFoundError(cmd))\n    }\n\n    var pathPart = pathEnv[i]\n    if (pathPart.charAt(0) === '\"' && pathPart.slice(-1) === '\"')\n      pathPart = pathPart.slice(1, -1)\n\n    var p = path.join(pathPart, cmd)\n    if (!pathPart && (/^\\.[\\\\\\/]/).test(cmd)) {\n      p = cmd.slice(0, 2) + p\n    }\n    ;(function E (ii, ll) {\n      if (ii === ll) return F(i + 1, l)\n      var ext = pathExt[ii]\n      isexe(p + ext, { pathExt: pathExtExe }, function (er, is) {\n        if (!er && is) {\n          if (opt.all)\n            found.push(p + ext)\n          else\n            return cb(null, p + ext)\n        }\n        return E(ii + 1, ll)\n      })\n    })(0, pathExt.length)\n  })(0, pathEnv.length)\n}\n\nfunction whichSync (cmd, opt) {\n  opt = opt || {}\n\n  var info = getPathInfo(cmd, opt)\n  var pathEnv = info.env\n  var pathExt = info.ext\n  var pathExtExe = info.extExe\n  var found = []\n\n  for (var i = 0, l = pathEnv.length; i < l; i ++) {\n    var pathPart = pathEnv[i]\n    if (pathPart.charAt(0) === '\"' && pathPart.slice(-1) === '\"')\n      pathPart = pathPart.slice(1, -1)\n\n    var p = path.join(pathPart, cmd)\n    if (!pathPart && /^\\.[\\\\\\/]/.test(cmd)) {\n      p = cmd.slice(0, 2) + p\n    }\n    for (var j = 0, ll = pathExt.length; j < ll; j ++) {\n      var cur = p + pathExt[j]\n      var is\n      try {\n        is = isexe.sync(cur, { pathExt: pathExtExe })\n        if (is) {\n          if (opt.all)\n            found.push(cur)\n          else\n            return cur\n        }\n      } catch (ex) {}\n    }\n  }\n\n  if (opt.all && found.length)\n    return found\n\n  throw getNotFoundError(cmd)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/which/node_modules/isexe/index.js":"var fs = require('fs')\nvar core\nif (process.platform === 'win32' || global.TESTING_WINDOWS) {\n  core = require('./windows.js')\n} else {\n  core = require('./mode.js')\n}\n\nmodule.exports = isexe\nisexe.sync = sync\n\nfunction isexe (path, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  if (!cb) {\n    if (typeof Promise !== 'function') {\n      throw new TypeError('callback not provided')\n    }\n\n    return new Promise(function (resolve, reject) {\n      isexe(path, options || {}, function (er, is) {\n        if (er) {\n          reject(er)\n        } else {\n          resolve(is)\n        }\n      })\n    })\n  }\n\n  core(path, options || {}, function (er, is) {\n    // ignore EACCES because that just means we aren't allowed to run it\n    if (er) {\n      if (er.code === 'EACCES' || options && options.ignoreErrors) {\n        er = null\n        is = false\n      }\n    }\n    cb(er, is)\n  })\n}\n\nfunction sync (path, options) {\n  // my kingdom for a filtered catch\n  try {\n    return core.sync(path, options || {})\n  } catch (er) {\n    if (options && options.ignoreErrors || er.code === 'EACCES') {\n      return false\n    } else {\n      throw er\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/which/node_modules/isexe/mode.js":"module.exports = isexe\nisexe.sync = sync\n\nvar fs = require('fs')\n\nfunction isexe (path, options, cb) {\n  fs.stat(path, function (er, stat) {\n    cb(er, er ? false : checkStat(stat, options))\n  })\n}\n\nfunction sync (path, options) {\n  return checkStat(fs.statSync(path), options)\n}\n\nfunction checkStat (stat, options) {\n  return stat.isFile() && checkMode(stat, options)\n}\n\nfunction checkMode (stat, options) {\n  var mod = stat.mode\n  var uid = stat.uid\n  var gid = stat.gid\n\n  var myUid = options.uid !== undefined ?\n    options.uid : process.getuid && process.getuid()\n  var myGid = options.gid !== undefined ?\n    options.gid : process.getgid && process.getgid()\n\n  var u = parseInt('100', 8)\n  var g = parseInt('010', 8)\n  var o = parseInt('001', 8)\n  var ug = u | g\n\n  var ret = (mod & o) ||\n    (mod & g) && gid === myGid ||\n    (mod & u) && uid === myUid ||\n    (mod & ug) && myUid === 0\n\n  return ret\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/glob.js":"// Approach:\n//\n// 1. Get the minimatch set\n// 2. For each pattern in the set, PROCESS(pattern, false)\n// 3. Store matches per-set, then uniq them\n//\n// PROCESS(pattern, inGlobStar)\n// Get the first [n] items from pattern that are all strings\n// Join these together.  This is PREFIX.\n//   If there is no more remaining, then stat(PREFIX) and\n//   add to matches if it succeeds.  END.\n//\n// If inGlobStar and PREFIX is symlink and points to dir\n//   set ENTRIES = []\n// else readdir(PREFIX) as ENTRIES\n//   If fail, END\n//\n// with ENTRIES\n//   If pattern[n] is GLOBSTAR\n//     // handle the case where the globstar match is empty\n//     // by pruning it out, and testing the resulting pattern\n//     PROCESS(pattern[0..n] + pattern[n+1 .. $], false)\n//     // handle other cases.\n//     for ENTRY in ENTRIES (not dotfiles)\n//       // attach globstar + tail onto the entry\n//       // Mark that this entry is a globstar match\n//       PROCESS(pattern[0..n] + ENTRY + pattern[n .. $], true)\n//\n//   else // not globstar\n//     for ENTRY in ENTRIES (not dotfiles, unless pattern[n] is dot)\n//       Test ENTRY against pattern[n]\n//       If fails, continue\n//       If passes, PROCESS(pattern[0..n] + item + pattern[n+1 .. $])\n//\n// Caveat:\n//   Cache all stats and readdirs results to minimize syscall.  Since all\n//   we ever care about is existence and directory-ness, we can just keep\n//   `true` for files, and [children,...] for directories, or `false` for\n//   things that don't exist.\n\nmodule.exports = glob\n\nvar fs = require('fs')\nvar rp = require('fs.realpath')\nvar minimatch = require('minimatch')\nvar Minimatch = minimatch.Minimatch\nvar inherits = require('inherits')\nvar EE = require('events').EventEmitter\nvar path = require('path')\nvar assert = require('assert')\nvar isAbsolute = require('path-is-absolute')\nvar globSync = require('./sync.js')\nvar common = require('./common.js')\nvar alphasort = common.alphasort\nvar alphasorti = common.alphasorti\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar inflight = require('inflight')\nvar util = require('util')\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nvar once = require('once')\n\nfunction glob (pattern, options, cb) {\n  if (typeof options === 'function') cb = options, options = {}\n  if (!options) options = {}\n\n  if (options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return globSync(pattern, options)\n  }\n\n  return new Glob(pattern, options, cb)\n}\n\nglob.sync = globSync\nvar GlobSync = glob.GlobSync = globSync.GlobSync\n\n// old api surface\nglob.glob = glob\n\nfunction extend (origin, add) {\n  if (add === null || typeof add !== 'object') {\n    return origin\n  }\n\n  var keys = Object.keys(add)\n  var i = keys.length\n  while (i--) {\n    origin[keys[i]] = add[keys[i]]\n  }\n  return origin\n}\n\nglob.hasMagic = function (pattern, options_) {\n  var options = extend({}, options_)\n  options.noprocess = true\n\n  var g = new Glob(pattern, options)\n  var set = g.minimatch.set\n\n  if (!pattern)\n    return false\n\n  if (set.length > 1)\n    return true\n\n  for (var j = 0; j < set[0].length; j++) {\n    if (typeof set[0][j] !== 'string')\n      return true\n  }\n\n  return false\n}\n\nglob.Glob = Glob\ninherits(Glob, EE)\nfunction Glob (pattern, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = null\n  }\n\n  if (options && options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return new GlobSync(pattern, options)\n  }\n\n  if (!(this instanceof Glob))\n    return new Glob(pattern, options, cb)\n\n  setopts(this, pattern, options)\n  this._didRealPath = false\n\n  // process each pattern in the minimatch set\n  var n = this.minimatch.set.length\n\n  // The matches are stored as {<filename>: true,...} so that\n  // duplicates are automagically pruned.\n  // Later, we do an Object.keys() on these.\n  // Keep them as a list so we can fill in when nonull is set.\n  this.matches = new Array(n)\n\n  if (typeof cb === 'function') {\n    cb = once(cb)\n    this.on('error', cb)\n    this.on('end', function (matches) {\n      cb(null, matches)\n    })\n  }\n\n  var self = this\n  var n = this.minimatch.set.length\n  this._processing = 0\n  this.matches = new Array(n)\n\n  this._emitQueue = []\n  this._processQueue = []\n  this.paused = false\n\n  if (this.noprocess)\n    return this\n\n  if (n === 0)\n    return done()\n\n  var sync = true\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false, done)\n  }\n  sync = false\n\n  function done () {\n    --self._processing\n    if (self._processing <= 0) {\n      if (sync) {\n        process.nextTick(function () {\n          self._finish()\n        })\n      } else {\n        self._finish()\n      }\n    }\n  }\n}\n\nGlob.prototype._finish = function () {\n  assert(this instanceof Glob)\n  if (this.aborted)\n    return\n\n  if (this.realpath && !this._didRealpath)\n    return this._realpath()\n\n  common.finish(this)\n  this.emit('end', this.found)\n}\n\nGlob.prototype._realpath = function () {\n  if (this._didRealpath)\n    return\n\n  this._didRealpath = true\n\n  var n = this.matches.length\n  if (n === 0)\n    return this._finish()\n\n  var self = this\n  for (var i = 0; i < this.matches.length; i++)\n    this._realpathSet(i, next)\n\n  function next () {\n    if (--n === 0)\n      self._finish()\n  }\n}\n\nGlob.prototype._realpathSet = function (index, cb) {\n  var matchset = this.matches[index]\n  if (!matchset)\n    return cb()\n\n  var found = Object.keys(matchset)\n  var self = this\n  var n = found.length\n\n  if (n === 0)\n    return cb()\n\n  var set = this.matches[index] = Object.create(null)\n  found.forEach(function (p, i) {\n    // If there's a problem with the stat, then it means that\n    // one or more of the links in the realpath couldn't be\n    // resolved.  just return the abs value in that case.\n    p = self._makeAbs(p)\n    rp.realpath(p, self.realpathCache, function (er, real) {\n      if (!er)\n        set[real] = true\n      else if (er.syscall === 'stat')\n        set[p] = true\n      else\n        self.emit('error', er) // srsly wtf right here\n\n      if (--n === 0) {\n        self.matches[index] = set\n        cb()\n      }\n    })\n  })\n}\n\nGlob.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlob.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n\nGlob.prototype.abort = function () {\n  this.aborted = true\n  this.emit('abort')\n}\n\nGlob.prototype.pause = function () {\n  if (!this.paused) {\n    this.paused = true\n    this.emit('pause')\n  }\n}\n\nGlob.prototype.resume = function () {\n  if (this.paused) {\n    this.emit('resume')\n    this.paused = false\n    if (this._emitQueue.length) {\n      var eq = this._emitQueue.slice(0)\n      this._emitQueue.length = 0\n      for (var i = 0; i < eq.length; i ++) {\n        var e = eq[i]\n        this._emitMatch(e[0], e[1])\n      }\n    }\n    if (this._processQueue.length) {\n      var pq = this._processQueue.slice(0)\n      this._processQueue.length = 0\n      for (var i = 0; i < pq.length; i ++) {\n        var p = pq[i]\n        this._processing--\n        this._process(p[0], p[1], p[2], p[3])\n      }\n    }\n  }\n}\n\nGlob.prototype._process = function (pattern, index, inGlobStar, cb) {\n  assert(this instanceof Glob)\n  assert(typeof cb === 'function')\n\n  if (this.aborted)\n    return\n\n  this._processing++\n  if (this.paused) {\n    this._processQueue.push([pattern, index, inGlobStar, cb])\n    return\n  }\n\n  //console.error('PROCESS %d', this._processing, pattern)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // see if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index, cb)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip _processing\n  if (childrenIgnored(this, read))\n    return cb()\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar, cb)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar, cb)\n}\n\nGlob.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    return self._processReaddir2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\nGlob.prototype._processReaddir2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return cb()\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  //console.error('prd2', prefix, entries, remain[0]._glob, matchedEntries)\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return cb()\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return cb()\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix) {\n      if (prefix !== '/')\n        e = prefix + '/' + e\n      else\n        e = prefix + e\n    }\n    this._process([e].concat(remain), index, inGlobStar, cb)\n  }\n  cb()\n}\n\nGlob.prototype._emitMatch = function (index, e) {\n  if (this.aborted)\n    return\n\n  if (isIgnored(this, e))\n    return\n\n  if (this.paused) {\n    this._emitQueue.push([index, e])\n    return\n  }\n\n  var abs = isAbsolute(e) ? e : this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute)\n    e = abs\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  var st = this.statCache[abs]\n  if (st)\n    this.emit('stat', e, st)\n\n  this.emit('match', e)\n}\n\nGlob.prototype._readdirInGlobStar = function (abs, cb) {\n  if (this.aborted)\n    return\n\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false, cb)\n\n  var lstatkey = 'lstat\\0' + abs\n  var self = this\n  var lstatcb = inflight(lstatkey, lstatcb_)\n\n  if (lstatcb)\n    fs.lstat(abs, lstatcb)\n\n  function lstatcb_ (er, lstat) {\n    if (er && er.code === 'ENOENT')\n      return cb()\n\n    var isSym = lstat && lstat.isSymbolicLink()\n    self.symlinks[abs] = isSym\n\n    // If it's not a symlink or a dir, then it's definitely a regular file.\n    // don't bother doing a readdir in that case.\n    if (!isSym && lstat && !lstat.isDirectory()) {\n      self.cache[abs] = 'FILE'\n      cb()\n    } else\n      self._readdir(abs, false, cb)\n  }\n}\n\nGlob.prototype._readdir = function (abs, inGlobStar, cb) {\n  if (this.aborted)\n    return\n\n  cb = inflight('readdir\\0'+abs+'\\0'+inGlobStar, cb)\n  if (!cb)\n    return\n\n  //console.error('RD %j %j', +inGlobStar, abs)\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs, cb)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return cb()\n\n    if (Array.isArray(c))\n      return cb(null, c)\n  }\n\n  var self = this\n  fs.readdir(abs, readdirCb(this, abs, cb))\n}\n\nfunction readdirCb (self, abs, cb) {\n  return function (er, entries) {\n    if (er)\n      self._readdirError(abs, er, cb)\n    else\n      self._readdirEntries(abs, entries, cb)\n  }\n}\n\nGlob.prototype._readdirEntries = function (abs, entries, cb) {\n  if (this.aborted)\n    return\n\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n  return cb(null, entries)\n}\n\nGlob.prototype._readdirError = function (f, er, cb) {\n  if (this.aborted)\n    return\n\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        this.emit('error', error)\n        this.abort()\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict) {\n        this.emit('error', er)\n        // If the error is handled, then we abort\n        // if not, we threw out of here\n        this.abort()\n      }\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n\n  return cb()\n}\n\nGlob.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    self._processGlobStar2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\n\nGlob.prototype._processGlobStar2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n  //console.error('pgs2', prefix, remain[0], entries)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return cb()\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false, cb)\n\n  var isSym = this.symlinks[abs]\n  var len = entries.length\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return cb()\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true, cb)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true, cb)\n  }\n\n  cb()\n}\n\nGlob.prototype._processSimple = function (prefix, index, cb) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var self = this\n  this._stat(prefix, function (er, exists) {\n    self._processSimple2(prefix, index, er, exists, cb)\n  })\n}\nGlob.prototype._processSimple2 = function (prefix, index, er, exists, cb) {\n\n  //console.error('ps2', prefix, exists)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return cb()\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n  cb()\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlob.prototype._stat = function (f, cb) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return cb()\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return cb(null, c)\n\n    if (needDir && c === 'FILE')\n      return cb()\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (stat !== undefined) {\n    if (stat === false)\n      return cb(null, stat)\n    else {\n      var type = stat.isDirectory() ? 'DIR' : 'FILE'\n      if (needDir && type === 'FILE')\n        return cb()\n      else\n        return cb(null, type, stat)\n    }\n  }\n\n  var self = this\n  var statcb = inflight('stat\\0' + abs, lstatcb_)\n  if (statcb)\n    fs.lstat(abs, statcb)\n\n  function lstatcb_ (er, lstat) {\n    if (lstat && lstat.isSymbolicLink()) {\n      // If it's a symlink, then treat it as the target, unless\n      // the target does not exist, then treat it as a file.\n      return fs.stat(abs, function (er, stat) {\n        if (er)\n          self._stat2(f, abs, null, lstat, cb)\n        else\n          self._stat2(f, abs, er, stat, cb)\n      })\n    } else {\n      self._stat2(f, abs, er, lstat, cb)\n    }\n  }\n}\n\nGlob.prototype._stat2 = function (f, abs, er, stat, cb) {\n  if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n    this.statCache[abs] = false\n    return cb()\n  }\n\n  var needDir = f.slice(-1) === '/'\n  this.statCache[abs] = stat\n\n  if (abs.slice(-1) === '/' && stat && !stat.isDirectory())\n    return cb(null, false, stat)\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return cb()\n\n  return cb(null, c, stat)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/node_modules/fs.realpath/index.js":"module.exports = realpath\nrealpath.realpath = realpath\nrealpath.sync = realpathSync\nrealpath.realpathSync = realpathSync\nrealpath.monkeypatch = monkeypatch\nrealpath.unmonkeypatch = unmonkeypatch\n\nvar fs = require('fs')\nvar origRealpath = fs.realpath\nvar origRealpathSync = fs.realpathSync\n\nvar version = process.version\nvar ok = /^v[0-5]\\./.test(version)\nvar old = require('./old.js')\n\nfunction newError (er) {\n  return er && er.syscall === 'realpath' && (\n    er.code === 'ELOOP' ||\n    er.code === 'ENOMEM' ||\n    er.code === 'ENAMETOOLONG'\n  )\n}\n\nfunction realpath (p, cache, cb) {\n  if (ok) {\n    return origRealpath(p, cache, cb)\n  }\n\n  if (typeof cache === 'function') {\n    cb = cache\n    cache = null\n  }\n  origRealpath(p, cache, function (er, result) {\n    if (newError(er)) {\n      old.realpath(p, cache, cb)\n    } else {\n      cb(er, result)\n    }\n  })\n}\n\nfunction realpathSync (p, cache) {\n  if (ok) {\n    return origRealpathSync(p, cache)\n  }\n\n  try {\n    return origRealpathSync(p, cache)\n  } catch (er) {\n    if (newError(er)) {\n      return old.realpathSync(p, cache)\n    } else {\n      throw er\n    }\n  }\n}\n\nfunction monkeypatch () {\n  fs.realpath = realpath\n  fs.realpathSync = realpathSync\n}\n\nfunction unmonkeypatch () {\n  fs.realpath = origRealpath\n  fs.realpathSync = origRealpathSync\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/node_modules/fs.realpath/old.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar pathModule = require('path');\nvar isWindows = process.platform === 'win32';\nvar fs = require('fs');\n\n// JavaScript implementation of realpath, ported from node pre-v6\n\nvar DEBUG = process.env.NODE_DEBUG && /fs/.test(process.env.NODE_DEBUG);\n\nfunction rethrow() {\n  // Only enable in debug mode. A backtrace uses ~1000 bytes of heap space and\n  // is fairly slow to generate.\n  var callback;\n  if (DEBUG) {\n    var backtrace = new Error;\n    callback = debugCallback;\n  } else\n    callback = missingCallback;\n\n  return callback;\n\n  function debugCallback(err) {\n    if (err) {\n      backtrace.message = err.message;\n      err = backtrace;\n      missingCallback(err);\n    }\n  }\n\n  function missingCallback(err) {\n    if (err) {\n      if (process.throwDeprecation)\n        throw err;  // Forgot a callback but don't know where? Use NODE_DEBUG=fs\n      else if (!process.noDeprecation) {\n        var msg = 'fs: missing callback ' + (err.stack || err.message);\n        if (process.traceDeprecation)\n          console.trace(msg);\n        else\n          console.error(msg);\n      }\n    }\n  }\n}\n\nfunction maybeCallback(cb) {\n  return typeof cb === 'function' ? cb : rethrow();\n}\n\nvar normalize = pathModule.normalize;\n\n// Regexp that finds the next partion of a (partial) path\n// result is [base_with_slash, base], e.g. ['somedir/', 'somedir']\nif (isWindows) {\n  var nextPartRe = /(.*?)(?:[\\/\\\\]+|$)/g;\n} else {\n  var nextPartRe = /(.*?)(?:[\\/]+|$)/g;\n}\n\n// Regex to find the device root, including trailing slash. E.g. 'c:\\\\'.\nif (isWindows) {\n  var splitRootRe = /^(?:[a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/][^\\\\\\/]+)?[\\\\\\/]*/;\n} else {\n  var splitRootRe = /^[\\/]*/;\n}\n\nexports.realpathSync = function realpathSync(p, cache) {\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return cache[p];\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstatSync(base);\n      knownHard[base] = true;\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  // NB: p.length changes.\n  while (pos < p.length) {\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      continue;\n    }\n\n    var resolvedLink;\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // some known symbolic link.  no need to stat again.\n      resolvedLink = cache[base];\n    } else {\n      var stat = fs.lstatSync(base);\n      if (!stat.isSymbolicLink()) {\n        knownHard[base] = true;\n        if (cache) cache[base] = base;\n        continue;\n      }\n\n      // read the link if it wasn't read before\n      // dev/ino always return 0 on windows, so skip the check.\n      var linkTarget = null;\n      if (!isWindows) {\n        var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n        if (seenLinks.hasOwnProperty(id)) {\n          linkTarget = seenLinks[id];\n        }\n      }\n      if (linkTarget === null) {\n        fs.statSync(base);\n        linkTarget = fs.readlinkSync(base);\n      }\n      resolvedLink = pathModule.resolve(previous, linkTarget);\n      // track this, if given a cache.\n      if (cache) cache[base] = resolvedLink;\n      if (!isWindows) seenLinks[id] = linkTarget;\n    }\n\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n\n  if (cache) cache[original] = p;\n\n  return p;\n};\n\n\nexports.realpath = function realpath(p, cache, cb) {\n  if (typeof cb !== 'function') {\n    cb = maybeCallback(cache);\n    cache = null;\n  }\n\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return process.nextTick(cb.bind(null, null, cache[p]));\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstat(base, function(err) {\n        if (err) return cb(err);\n        knownHard[base] = true;\n        LOOP();\n      });\n    } else {\n      process.nextTick(LOOP);\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  function LOOP() {\n    // stop if scanned past end of path\n    if (pos >= p.length) {\n      if (cache) cache[original] = p;\n      return cb(null, p);\n    }\n\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      return process.nextTick(LOOP);\n    }\n\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // known symbolic link.  no need to stat again.\n      return gotResolvedLink(cache[base]);\n    }\n\n    return fs.lstat(base, gotStat);\n  }\n\n  function gotStat(err, stat) {\n    if (err) return cb(err);\n\n    // if not a symlink, skip to the next path part\n    if (!stat.isSymbolicLink()) {\n      knownHard[base] = true;\n      if (cache) cache[base] = base;\n      return process.nextTick(LOOP);\n    }\n\n    // stat & read the link if not read before\n    // call gotTarget as soon as the link target is known\n    // dev/ino always return 0 on windows, so skip the check.\n    if (!isWindows) {\n      var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n      if (seenLinks.hasOwnProperty(id)) {\n        return gotTarget(null, seenLinks[id], base);\n      }\n    }\n    fs.stat(base, function(err) {\n      if (err) return cb(err);\n\n      fs.readlink(base, function(err, target) {\n        if (!isWindows) seenLinks[id] = target;\n        gotTarget(err, target);\n      });\n    });\n  }\n\n  function gotTarget(err, target, base) {\n    if (err) return cb(err);\n\n    var resolvedLink = pathModule.resolve(previous, target);\n    if (cache) cache[base] = resolvedLink;\n    gotResolvedLink(resolvedLink);\n  }\n\n  function gotResolvedLink(resolvedLink) {\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/node_modules/minimatch/minimatch.js":"module.exports = minimatch\nminimatch.Minimatch = Minimatch\n\nvar path = { sep: '/' }\ntry {\n  path = require('path')\n} catch (er) {}\n\nvar GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {}\nvar expand = require('brace-expansion')\n\nvar plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n}\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nvar qmark = '[^/]'\n\n// * => any number of characters\nvar star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nvar twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nvar twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'\n\n// characters that need to be escaped in RegExp.\nvar reSpecials = charSet('().*{}+?[]^$\\\\!')\n\n// \"abc\" -> { a:true, b:true, c:true }\nfunction charSet (s) {\n  return s.split('').reduce(function (set, c) {\n    set[c] = true\n    return set\n  }, {})\n}\n\n// normalizes slashes.\nvar slashSplit = /\\/+/\n\nminimatch.filter = filter\nfunction filter (pattern, options) {\n  options = options || {}\n  return function (p, i, list) {\n    return minimatch(p, pattern, options)\n  }\n}\n\nfunction ext (a, b) {\n  a = a || {}\n  b = b || {}\n  var t = {}\n  Object.keys(b).forEach(function (k) {\n    t[k] = b[k]\n  })\n  Object.keys(a).forEach(function (k) {\n    t[k] = a[k]\n  })\n  return t\n}\n\nminimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return minimatch\n\n  var orig = minimatch\n\n  var m = function minimatch (p, pattern, options) {\n    return orig.minimatch(p, pattern, ext(def, options))\n  }\n\n  m.Minimatch = function Minimatch (pattern, options) {\n    return new orig.Minimatch(pattern, ext(def, options))\n  }\n\n  return m\n}\n\nMinimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return Minimatch\n  return minimatch.defaults(def).Minimatch\n}\n\nfunction minimatch (p, pattern, options) {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  // \"\" only matches \"\"\n  if (pattern.trim() === '') return p === ''\n\n  return new Minimatch(pattern, options).match(p)\n}\n\nfunction Minimatch (pattern, options) {\n  if (!(this instanceof Minimatch)) {\n    return new Minimatch(pattern, options)\n  }\n\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n  pattern = pattern.trim()\n\n  // windows support: need to use /, not \\\n  if (path.sep !== '/') {\n    pattern = pattern.split(path.sep).join('/')\n  }\n\n  this.options = options\n  this.set = []\n  this.pattern = pattern\n  this.regexp = null\n  this.negate = false\n  this.comment = false\n  this.empty = false\n\n  // make the set of regexps etc.\n  this.make()\n}\n\nMinimatch.prototype.debug = function () {}\n\nMinimatch.prototype.make = make\nfunction make () {\n  // don't do it more than once.\n  if (this._made) return\n\n  var pattern = this.pattern\n  var options = this.options\n\n  // empty patterns and comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    this.comment = true\n    return\n  }\n  if (!pattern) {\n    this.empty = true\n    return\n  }\n\n  // step 1: figure out negation, etc.\n  this.parseNegate()\n\n  // step 2: expand braces\n  var set = this.globSet = this.braceExpand()\n\n  if (options.debug) this.debug = console.error\n\n  this.debug(this.pattern, set)\n\n  // step 3: now we have a set, so turn each one into a series of path-portion\n  // matching patterns.\n  // These will be regexps, except in the case of \"**\", which is\n  // set to the GLOBSTAR object for globstar behavior,\n  // and will not contain any / characters\n  set = this.globParts = set.map(function (s) {\n    return s.split(slashSplit)\n  })\n\n  this.debug(this.pattern, set)\n\n  // glob --> regexps\n  set = set.map(function (s, si, set) {\n    return s.map(this.parse, this)\n  }, this)\n\n  this.debug(this.pattern, set)\n\n  // filter out everything that didn't compile properly.\n  set = set.filter(function (s) {\n    return s.indexOf(false) === -1\n  })\n\n  this.debug(this.pattern, set)\n\n  this.set = set\n}\n\nMinimatch.prototype.parseNegate = parseNegate\nfunction parseNegate () {\n  var pattern = this.pattern\n  var negate = false\n  var options = this.options\n  var negateOffset = 0\n\n  if (options.nonegate) return\n\n  for (var i = 0, l = pattern.length\n    ; i < l && pattern.charAt(i) === '!'\n    ; i++) {\n    negate = !negate\n    negateOffset++\n  }\n\n  if (negateOffset) this.pattern = pattern.substr(negateOffset)\n  this.negate = negate\n}\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch.braceExpand = function (pattern, options) {\n  return braceExpand(pattern, options)\n}\n\nMinimatch.prototype.braceExpand = braceExpand\n\nfunction braceExpand (pattern, options) {\n  if (!options) {\n    if (this instanceof Minimatch) {\n      options = this.options\n    } else {\n      options = {}\n    }\n  }\n\n  pattern = typeof pattern === 'undefined'\n    ? this.pattern : pattern\n\n  if (typeof pattern === 'undefined') {\n    throw new TypeError('undefined pattern')\n  }\n\n  if (options.nobrace ||\n    !pattern.match(/\\{.*\\}/)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nMinimatch.prototype.parse = parse\nvar SUBPARSE = {}\nfunction parse (pattern, isSub) {\n  if (pattern.length > 1024 * 64) {\n    throw new TypeError('pattern is too long')\n  }\n\n  var options = this.options\n\n  // shortcuts\n  if (!options.noglobstar && pattern === '**') return GLOBSTAR\n  if (pattern === '') return ''\n\n  var re = ''\n  var hasMagic = !!options.nocase\n  var escaping = false\n  // ? => one single character\n  var patternListStack = []\n  var negativeLists = []\n  var stateChar\n  var inClass = false\n  var reClassStart = -1\n  var classStart = -1\n  // . and .. never match anything that doesn't start with .,\n  // even when options.dot is set.\n  var patternStart = pattern.charAt(0) === '.' ? '' // anything\n  // not (start or / followed by . or .. followed by / or end)\n  : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))'\n  : '(?!\\\\.)'\n  var self = this\n\n  function clearStateChar () {\n    if (stateChar) {\n      // we had some state-tracking character\n      // that wasn't consumed by this pass.\n      switch (stateChar) {\n        case '*':\n          re += star\n          hasMagic = true\n        break\n        case '?':\n          re += qmark\n          hasMagic = true\n        break\n        default:\n          re += '\\\\' + stateChar\n        break\n      }\n      self.debug('clearStateChar %j %j', stateChar, re)\n      stateChar = false\n    }\n  }\n\n  for (var i = 0, len = pattern.length, c\n    ; (i < len) && (c = pattern.charAt(i))\n    ; i++) {\n    this.debug('%s\\t%s %s %j', pattern, i, re, c)\n\n    // skip over any that are escaped.\n    if (escaping && reSpecials[c]) {\n      re += '\\\\' + c\n      escaping = false\n      continue\n    }\n\n    switch (c) {\n      case '/':\n        // completely not allowed, even escaped.\n        // Should already be path-split by now.\n        return false\n\n      case '\\\\':\n        clearStateChar()\n        escaping = true\n      continue\n\n      // the various stateChar values\n      // for the \"extglob\" stuff.\n      case '?':\n      case '*':\n      case '+':\n      case '@':\n      case '!':\n        this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c)\n\n        // all of those are literals inside a class, except that\n        // the glob [!a] means [^a] in regexp\n        if (inClass) {\n          this.debug('  in class')\n          if (c === '!' && i === classStart + 1) c = '^'\n          re += c\n          continue\n        }\n\n        // if we already have a stateChar, then it means\n        // that there was something like ** or +? in there.\n        // Handle the stateChar, then proceed with this one.\n        self.debug('call clearStateChar %j', stateChar)\n        clearStateChar()\n        stateChar = c\n        // if extglob is disabled, then +(asdf|foo) isn't a thing.\n        // just clear the statechar *now*, rather than even diving into\n        // the patternList stuff.\n        if (options.noext) clearStateChar()\n      continue\n\n      case '(':\n        if (inClass) {\n          re += '('\n          continue\n        }\n\n        if (!stateChar) {\n          re += '\\\\('\n          continue\n        }\n\n        patternListStack.push({\n          type: stateChar,\n          start: i - 1,\n          reStart: re.length,\n          open: plTypes[stateChar].open,\n          close: plTypes[stateChar].close\n        })\n        // negation is (?:(?!js)[^/]*)\n        re += stateChar === '!' ? '(?:(?!(?:' : '(?:'\n        this.debug('plType %j %j', stateChar, re)\n        stateChar = false\n      continue\n\n      case ')':\n        if (inClass || !patternListStack.length) {\n          re += '\\\\)'\n          continue\n        }\n\n        clearStateChar()\n        hasMagic = true\n        var pl = patternListStack.pop()\n        // negation is (?:(?!js)[^/]*)\n        // The others are (?:<pattern>)<type>\n        re += pl.close\n        if (pl.type === '!') {\n          negativeLists.push(pl)\n        }\n        pl.reEnd = re.length\n      continue\n\n      case '|':\n        if (inClass || !patternListStack.length || escaping) {\n          re += '\\\\|'\n          escaping = false\n          continue\n        }\n\n        clearStateChar()\n        re += '|'\n      continue\n\n      // these are mostly the same in regexp and glob\n      case '[':\n        // swallow any state-tracking char before the [\n        clearStateChar()\n\n        if (inClass) {\n          re += '\\\\' + c\n          continue\n        }\n\n        inClass = true\n        classStart = i\n        reClassStart = re.length\n        re += c\n      continue\n\n      case ']':\n        //  a right bracket shall lose its special\n        //  meaning and represent itself in\n        //  a bracket expression if it occurs\n        //  first in the list.  -- POSIX.2 2.8.3.2\n        if (i === classStart + 1 || !inClass) {\n          re += '\\\\' + c\n          escaping = false\n          continue\n        }\n\n        // handle the case where we left a class open.\n        // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n        if (inClass) {\n          // split where the last [ was, make sure we don't have\n          // an invalid re. if so, re-walk the contents of the\n          // would-be class to re-translate any characters that\n          // were passed through as-is\n          // TODO: It would probably be faster to determine this\n          // without a try/catch and a new RegExp, but it's tricky\n          // to do safely.  For now, this is safe and works.\n          var cs = pattern.substring(classStart + 1, i)\n          try {\n            RegExp('[' + cs + ']')\n          } catch (er) {\n            // not a valid class!\n            var sp = this.parse(cs, SUBPARSE)\n            re = re.substr(0, reClassStart) + '\\\\[' + sp[0] + '\\\\]'\n            hasMagic = hasMagic || sp[1]\n            inClass = false\n            continue\n          }\n        }\n\n        // finish up the class.\n        hasMagic = true\n        inClass = false\n        re += c\n      continue\n\n      default:\n        // swallow any state char that wasn't consumed\n        clearStateChar()\n\n        if (escaping) {\n          // no need\n          escaping = false\n        } else if (reSpecials[c]\n          && !(c === '^' && inClass)) {\n          re += '\\\\'\n        }\n\n        re += c\n\n    } // switch\n  } // for\n\n  // handle the case where we left a class open.\n  // \"[abc\" is valid, equivalent to \"\\[abc\"\n  if (inClass) {\n    // split where the last [ was, and escape it\n    // this is a huge pita.  We now have to re-walk\n    // the contents of the would-be class to re-translate\n    // any characters that were passed through as-is\n    cs = pattern.substr(classStart + 1)\n    sp = this.parse(cs, SUBPARSE)\n    re = re.substr(0, reClassStart) + '\\\\[' + sp[0]\n    hasMagic = hasMagic || sp[1]\n  }\n\n  // handle the case where we had a +( thing at the *end*\n  // of the pattern.\n  // each pattern list stack adds 3 chars, and we need to go through\n  // and escape any | chars that were passed through as-is for the regexp.\n  // Go through and escape them, taking care not to double-escape any\n  // | chars that were already escaped.\n  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n    var tail = re.slice(pl.reStart + pl.open.length)\n    this.debug('setting tail', re, pl)\n    // maybe some even number of \\, then maybe 1 \\, followed by a |\n    tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, function (_, $1, $2) {\n      if (!$2) {\n        // the | isn't already escaped, so escape it.\n        $2 = '\\\\'\n      }\n\n      // need to escape all those slashes *again*, without escaping the\n      // one that we need for escaping the | character.  As it works out,\n      // escaping an even number of slashes can be done by simply repeating\n      // it exactly after itself.  That's why this trick works.\n      //\n      // I am sorry that you have to see this.\n      return $1 + $1 + $2 + '|'\n    })\n\n    this.debug('tail=%j\\n   %s', tail, tail, pl, re)\n    var t = pl.type === '*' ? star\n      : pl.type === '?' ? qmark\n      : '\\\\' + pl.type\n\n    hasMagic = true\n    re = re.slice(0, pl.reStart) + t + '\\\\(' + tail\n  }\n\n  // handle trailing things that only matter at the very end.\n  clearStateChar()\n  if (escaping) {\n    // trailing \\\\\n    re += '\\\\\\\\'\n  }\n\n  // only need to apply the nodot start if the re starts with\n  // something that could conceivably capture a dot\n  var addPatternStart = false\n  switch (re.charAt(0)) {\n    case '.':\n    case '[':\n    case '(': addPatternStart = true\n  }\n\n  // Hack to work around lack of negative lookbehind in JS\n  // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n  // like 'a.xyz.yz' doesn't match.  So, the first negative\n  // lookahead, has to look ALL the way ahead, to the end of\n  // the pattern.\n  for (var n = negativeLists.length - 1; n > -1; n--) {\n    var nl = negativeLists[n]\n\n    var nlBefore = re.slice(0, nl.reStart)\n    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8)\n    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd)\n    var nlAfter = re.slice(nl.reEnd)\n\n    nlLast += nlAfter\n\n    // Handle nested stuff like *(*.js|!(*.json)), where open parens\n    // mean that we should *not* include the ) in the bit that is considered\n    // \"after\" the negated section.\n    var openParensBefore = nlBefore.split('(').length - 1\n    var cleanAfter = nlAfter\n    for (i = 0; i < openParensBefore; i++) {\n      cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '')\n    }\n    nlAfter = cleanAfter\n\n    var dollar = ''\n    if (nlAfter === '' && isSub !== SUBPARSE) {\n      dollar = '$'\n    }\n    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast\n    re = newRe\n  }\n\n  // if the re is not \"\" at this point, then we need to make sure\n  // it doesn't match against an empty path part.\n  // Otherwise a/* will match a/, which it should not.\n  if (re !== '' && hasMagic) {\n    re = '(?=.)' + re\n  }\n\n  if (addPatternStart) {\n    re = patternStart + re\n  }\n\n  // parsing just a piece of a larger pattern.\n  if (isSub === SUBPARSE) {\n    return [re, hasMagic]\n  }\n\n  // skip the regexp for non-magical patterns\n  // unescape anything in it, though, so that it'll be\n  // an exact match against a file etc.\n  if (!hasMagic) {\n    return globUnescape(pattern)\n  }\n\n  var flags = options.nocase ? 'i' : ''\n  try {\n    var regExp = new RegExp('^' + re + '$', flags)\n  } catch (er) {\n    // If it was an invalid regular expression, then it can't match\n    // anything.  This trick looks for a character after the end of\n    // the string, which is of course impossible, except in multi-line\n    // mode, but it's not a /m regex.\n    return new RegExp('$.')\n  }\n\n  regExp._glob = pattern\n  regExp._src = re\n\n  return regExp\n}\n\nminimatch.makeRe = function (pattern, options) {\n  return new Minimatch(pattern, options || {}).makeRe()\n}\n\nMinimatch.prototype.makeRe = makeRe\nfunction makeRe () {\n  if (this.regexp || this.regexp === false) return this.regexp\n\n  // at this point, this.set is a 2d array of partial\n  // pattern strings, or \"**\".\n  //\n  // It's better to use .match().  This function shouldn't\n  // be used, really, but it's pretty convenient sometimes,\n  // when you just want to work with a regex.\n  var set = this.set\n\n  if (!set.length) {\n    this.regexp = false\n    return this.regexp\n  }\n  var options = this.options\n\n  var twoStar = options.noglobstar ? star\n    : options.dot ? twoStarDot\n    : twoStarNoDot\n  var flags = options.nocase ? 'i' : ''\n\n  var re = set.map(function (pattern) {\n    return pattern.map(function (p) {\n      return (p === GLOBSTAR) ? twoStar\n      : (typeof p === 'string') ? regExpEscape(p)\n      : p._src\n    }).join('\\\\\\/')\n  }).join('|')\n\n  // must match entire pattern\n  // ending in a * or ** will make it less strict.\n  re = '^(?:' + re + ')$'\n\n  // can match anything, as long as it's not this.\n  if (this.negate) re = '^(?!' + re + ').*$'\n\n  try {\n    this.regexp = new RegExp(re, flags)\n  } catch (ex) {\n    this.regexp = false\n  }\n  return this.regexp\n}\n\nminimatch.match = function (list, pattern, options) {\n  options = options || {}\n  var mm = new Minimatch(pattern, options)\n  list = list.filter(function (f) {\n    return mm.match(f)\n  })\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\n\nMinimatch.prototype.match = match\nfunction match (f, partial) {\n  this.debug('match', f, this.pattern)\n  // short-circuit in the case of busted things.\n  // comments, etc.\n  if (this.comment) return false\n  if (this.empty) return f === ''\n\n  if (f === '/' && partial) return true\n\n  var options = this.options\n\n  // windows: need to use /, not \\\n  if (path.sep !== '/') {\n    f = f.split(path.sep).join('/')\n  }\n\n  // treat the test path as a set of pathparts.\n  f = f.split(slashSplit)\n  this.debug(this.pattern, 'split', f)\n\n  // just ONE of the pattern sets in this.set needs to match\n  // in order for it to be valid.  If negating, then just one\n  // match means that we have failed.\n  // Either way, return on the first hit.\n\n  var set = this.set\n  this.debug(this.pattern, 'set', set)\n\n  // Find the basename of the path by looking for the last non-empty segment\n  var filename\n  var i\n  for (i = f.length - 1; i >= 0; i--) {\n    filename = f[i]\n    if (filename) break\n  }\n\n  for (i = 0; i < set.length; i++) {\n    var pattern = set[i]\n    var file = f\n    if (options.matchBase && pattern.length === 1) {\n      file = [filename]\n    }\n    var hit = this.matchOne(file, pattern, partial)\n    if (hit) {\n      if (options.flipNegate) return true\n      return !this.negate\n    }\n  }\n\n  // didn't get any hits.  this is success if it's a negative\n  // pattern, failure otherwise.\n  if (options.flipNegate) return false\n  return this.negate\n}\n\n// set partial to true to test if, for example,\n// \"/a/b\" matches the start of \"/*/b/*/d\"\n// Partial means, if you run out of file before you run\n// out of pattern, then that's fine, as long as all\n// the parts match.\nMinimatch.prototype.matchOne = function (file, pattern, partial) {\n  var options = this.options\n\n  this.debug('matchOne',\n    { 'this': this, file: file, pattern: pattern })\n\n  this.debug('matchOne', file.length, pattern.length)\n\n  for (var fi = 0,\n      pi = 0,\n      fl = file.length,\n      pl = pattern.length\n      ; (fi < fl) && (pi < pl)\n      ; fi++, pi++) {\n    this.debug('matchOne loop')\n    var p = pattern[pi]\n    var f = file[fi]\n\n    this.debug(pattern, p, f)\n\n    // should be impossible.\n    // some invalid regexp stuff in the set.\n    if (p === false) return false\n\n    if (p === GLOBSTAR) {\n      this.debug('GLOBSTAR', [pattern, p, f])\n\n      // \"**\"\n      // a/**/b/**/c would match the following:\n      // a/b/x/y/z/c\n      // a/x/y/z/b/c\n      // a/b/x/b/x/c\n      // a/b/c\n      // To do this, take the rest of the pattern after\n      // the **, and see if it would match the file remainder.\n      // If so, return success.\n      // If not, the ** \"swallows\" a segment, and try again.\n      // This is recursively awful.\n      //\n      // a/**/b/**/c matching a/b/x/y/z/c\n      // - a matches a\n      // - doublestar\n      //   - matchOne(b/x/y/z/c, b/**/c)\n      //     - b matches b\n      //     - doublestar\n      //       - matchOne(x/y/z/c, c) -> no\n      //       - matchOne(y/z/c, c) -> no\n      //       - matchOne(z/c, c) -> no\n      //       - matchOne(c, c) yes, hit\n      var fr = fi\n      var pr = pi + 1\n      if (pr === pl) {\n        this.debug('** at the end')\n        // a ** at the end will just swallow the rest.\n        // We have found a match.\n        // however, it will not swallow /.x, unless\n        // options.dot is set.\n        // . and .. are *never* matched by **, for explosively\n        // exponential reasons.\n        for (; fi < fl; fi++) {\n          if (file[fi] === '.' || file[fi] === '..' ||\n            (!options.dot && file[fi].charAt(0) === '.')) return false\n        }\n        return true\n      }\n\n      // ok, let's see if we can swallow whatever we can.\n      while (fr < fl) {\n        var swallowee = file[fr]\n\n        this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n        // XXX remove this slice.  Just pass the start index.\n        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n          this.debug('globstar found match!', fr, fl, swallowee)\n          // found a match.\n          return true\n        } else {\n          // can't swallow \".\" or \"..\" ever.\n          // can only swallow \".foo\" when explicitly asked.\n          if (swallowee === '.' || swallowee === '..' ||\n            (!options.dot && swallowee.charAt(0) === '.')) {\n            this.debug('dot detected!', file, fr, pattern, pr)\n            break\n          }\n\n          // ** swallows a segment, and continue.\n          this.debug('globstar swallow a segment, and continue')\n          fr++\n        }\n      }\n\n      // no match was found.\n      // However, in partial mode, we can't say this is necessarily over.\n      // If there's more *pattern* left, then\n      if (partial) {\n        // ran out of file\n        this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n        if (fr === fl) return true\n      }\n      return false\n    }\n\n    // something other than **\n    // non-magic patterns just have to match exactly\n    // patterns with magic have been turned into regexps.\n    var hit\n    if (typeof p === 'string') {\n      if (options.nocase) {\n        hit = f.toLowerCase() === p.toLowerCase()\n      } else {\n        hit = f === p\n      }\n      this.debug('string match', p, f, hit)\n    } else {\n      hit = f.match(p)\n      this.debug('pattern match', p, f, hit)\n    }\n\n    if (!hit) return false\n  }\n\n  // Note: ending in / means that we'll get a final \"\"\n  // at the end of the pattern.  This can only match a\n  // corresponding \"\" at the end of the file.\n  // If the file ends in /, then it can only match a\n  // a pattern that ends in /, unless the pattern just\n  // doesn't have any more for it. But, a/b/ should *not*\n  // match \"a/b/*\", even though \"\" matches against the\n  // [^/]*? pattern, except in partial mode, where it might\n  // simply not be reached yet.\n  // However, a/b/ should still satisfy a/*\n\n  // now either we fell off the end of the pattern, or we're done.\n  if (fi === fl && pi === pl) {\n    // ran out of pattern and filename at the same time.\n    // an exact hit!\n    return true\n  } else if (fi === fl) {\n    // ran out of file, but still had pattern left.\n    // this is ok if we're doing the match as part of\n    // a glob fs traversal.\n    return partial\n  } else if (pi === pl) {\n    // ran out of pattern, still have file left.\n    // this is only acceptable if we're on the very last\n    // empty segment of a file with a trailing slash.\n    // a/* should match a/b/\n    var emptyFileEnd = (fi === fl - 1) && (file[fi] === '')\n    return emptyFileEnd\n  }\n\n  // should be unreachable.\n  throw new Error('wtf?')\n}\n\n// replace stuff like \\* with *\nfunction globUnescape (s) {\n  return s.replace(/\\\\(.)/g, '$1')\n}\n\nfunction regExpEscape (s) {\n  return s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/node_modules/minimatch/node_modules/brace-expansion/index.js":"var concatMap = require('concat-map');\nvar balanced = require('balanced-match');\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction identity(e) {\n  return e;\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m || /\\$$/.test(m.pre)) return [str];\n\n  var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isSequence = isNumericSequence || isAlphaSequence;\n  var isOptions = /^(.*,)+(.+)?$/.test(m.body);\n  if (!isSequence && !isOptions) {\n    // {a},b}\n    if (m.post.match(/,.*\\}/)) {\n      str = m.pre + '{' + m.body + escClose + m.post;\n      return expand(str);\n    }\n    return [str];\n  }\n\n  var n;\n  if (isSequence) {\n    n = m.body.split(/\\.\\./);\n  } else {\n    n = parseCommaParts(m.body);\n    if (n.length === 1) {\n      // x{{a,b}}y ==> x{a}y x{b}y\n      n = expand(n[0], false).map(embrace);\n      if (n.length === 1) {\n        var post = m.post.length\n          ? expand(m.post, false)\n          : [''];\n        return post.map(function(p) {\n          return m.pre + n[0] + p;\n        });\n      }\n    }\n  }\n\n  // at this point, n is the parts, and we know it's not a comma set\n  // with a single entry.\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  var N;\n\n  if (isSequence) {\n    var x = numeric(n[0]);\n    var y = numeric(n[1]);\n    var width = Math.max(n[0].length, n[1].length)\n    var incr = n.length == 3\n      ? Math.abs(numeric(n[2]))\n      : 1;\n    var test = lte;\n    var reverse = y < x;\n    if (reverse) {\n      incr *= -1;\n      test = gte;\n    }\n    var pad = n.some(isPadded);\n\n    N = [];\n\n    for (var i = x; test(i, y); i += incr) {\n      var c;\n      if (isAlphaSequence) {\n        c = String.fromCharCode(i);\n        if (c === '\\\\')\n          c = '';\n      } else {\n        c = String(i);\n        if (pad) {\n          var need = width - c.length;\n          if (need > 0) {\n            var z = new Array(need + 1).join('0');\n            if (i < 0)\n              c = '-' + z + c.slice(1);\n            else\n              c = z + c;\n          }\n        }\n      }\n      N.push(c);\n    }\n  } else {\n    N = concatMap(n, function(el) { return expand(el, false) });\n  }\n\n  for (var j = 0; j < N.length; j++) {\n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre + N[j] + post[k];\n      if (!isTop || isSequence || expansion)\n        expansions.push(expansion);\n    }\n  }\n\n  return expansions;\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/node_modules/minimatch/node_modules/brace-expansion/node_modules/concat-map/index.js":"module.exports = function (xs, fn) {\n    var res = [];\n    for (var i = 0; i < xs.length; i++) {\n        var x = fn(xs[i], i);\n        if (isArray(x)) res.push.apply(res, x);\n        else res.push(x);\n    }\n    return res;\n};\n\nvar isArray = Array.isArray || function (xs) {\n    return Object.prototype.toString.call(xs) === '[object Array]';\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/node_modules/minimatch/node_modules/brace-expansion/node_modules/balanced-match/index.js":"module.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/node_modules/path-is-absolute/index.js":"'use strict';\n\nfunction posix(path) {\n\treturn path.charAt(0) === '/';\n}\n\nfunction win32(path) {\n\t// https://github.com/nodejs/node/blob/b3fcc245fb25539909ef1d5eaa01dbf92e168633/lib/path.js#L56\n\tvar splitDeviceRe = /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\tvar result = splitDeviceRe.exec(path);\n\tvar device = result[1] || '';\n\tvar isUnc = Boolean(device && device.charAt(1) !== ':');\n\n\t// UNC paths are always absolute\n\treturn Boolean(result[2] || isUnc);\n}\n\nmodule.exports = process.platform === 'win32' ? win32 : posix;\nmodule.exports.posix = posix;\nmodule.exports.win32 = win32;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/sync.js":"module.exports = globSync\nglobSync.GlobSync = GlobSync\n\nvar fs = require('fs')\nvar rp = require('fs.realpath')\nvar minimatch = require('minimatch')\nvar Minimatch = minimatch.Minimatch\nvar Glob = require('./glob.js').Glob\nvar util = require('util')\nvar path = require('path')\nvar assert = require('assert')\nvar isAbsolute = require('path-is-absolute')\nvar common = require('./common.js')\nvar alphasort = common.alphasort\nvar alphasorti = common.alphasorti\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nfunction globSync (pattern, options) {\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  return new GlobSync(pattern, options).found\n}\n\nfunction GlobSync (pattern, options) {\n  if (!pattern)\n    throw new Error('must provide pattern')\n\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  if (!(this instanceof GlobSync))\n    return new GlobSync(pattern, options)\n\n  setopts(this, pattern, options)\n\n  if (this.noprocess)\n    return this\n\n  var n = this.minimatch.set.length\n  this.matches = new Array(n)\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false)\n  }\n  this._finish()\n}\n\nGlobSync.prototype._finish = function () {\n  assert(this instanceof GlobSync)\n  if (this.realpath) {\n    var self = this\n    this.matches.forEach(function (matchset, index) {\n      var set = self.matches[index] = Object.create(null)\n      for (var p in matchset) {\n        try {\n          p = self._makeAbs(p)\n          var real = rp.realpathSync(p, self.realpathCache)\n          set[real] = true\n        } catch (er) {\n          if (er.syscall === 'stat')\n            set[self._makeAbs(p)] = true\n          else\n            throw er\n        }\n      }\n    })\n  }\n  common.finish(this)\n}\n\n\nGlobSync.prototype._process = function (pattern, index, inGlobStar) {\n  assert(this instanceof GlobSync)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // See if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip processing\n  if (childrenIgnored(this, read))\n    return\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar)\n}\n\n\nGlobSync.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar) {\n  var entries = this._readdir(abs, inGlobStar)\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix.slice(-1) !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix)\n      newPattern = [prefix, e]\n    else\n      newPattern = [e]\n    this._process(newPattern.concat(remain), index, inGlobStar)\n  }\n}\n\n\nGlobSync.prototype._emitMatch = function (index, e) {\n  if (isIgnored(this, e))\n    return\n\n  var abs = this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute) {\n    e = abs\n  }\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  if (this.stat)\n    this._stat(e)\n}\n\n\nGlobSync.prototype._readdirInGlobStar = function (abs) {\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false)\n\n  var entries\n  var lstat\n  var stat\n  try {\n    lstat = fs.lstatSync(abs)\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      // lstat failed, doesn't exist\n      return null\n    }\n  }\n\n  var isSym = lstat && lstat.isSymbolicLink()\n  this.symlinks[abs] = isSym\n\n  // If it's not a symlink or a dir, then it's definitely a regular file.\n  // don't bother doing a readdir in that case.\n  if (!isSym && lstat && !lstat.isDirectory())\n    this.cache[abs] = 'FILE'\n  else\n    entries = this._readdir(abs, false)\n\n  return entries\n}\n\nGlobSync.prototype._readdir = function (abs, inGlobStar) {\n  var entries\n\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return null\n\n    if (Array.isArray(c))\n      return c\n  }\n\n  try {\n    return this._readdirEntries(abs, fs.readdirSync(abs))\n  } catch (er) {\n    this._readdirError(abs, er)\n    return null\n  }\n}\n\nGlobSync.prototype._readdirEntries = function (abs, entries) {\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n\n  // mark and cache dir-ness\n  return entries\n}\n\nGlobSync.prototype._readdirError = function (f, er) {\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        throw error\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict)\n        throw er\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n}\n\nGlobSync.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar) {\n\n  var entries = this._readdir(abs, inGlobStar)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false)\n\n  var len = entries.length\n  var isSym = this.symlinks[abs]\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true)\n  }\n}\n\nGlobSync.prototype._processSimple = function (prefix, index) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var exists = this._stat(prefix)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlobSync.prototype._stat = function (f) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return false\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return c\n\n    if (needDir && c === 'FILE')\n      return false\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (!stat) {\n    var lstat\n    try {\n      lstat = fs.lstatSync(abs)\n    } catch (er) {\n      if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n        this.statCache[abs] = false\n        return false\n      }\n    }\n\n    if (lstat && lstat.isSymbolicLink()) {\n      try {\n        stat = fs.statSync(abs)\n      } catch (er) {\n        stat = lstat\n      }\n    } else {\n      stat = lstat\n    }\n  }\n\n  this.statCache[abs] = stat\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return false\n\n  return c\n}\n\nGlobSync.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlobSync.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/glob/common.js":"exports.alphasort = alphasort\nexports.alphasorti = alphasorti\nexports.setopts = setopts\nexports.ownProp = ownProp\nexports.makeAbs = makeAbs\nexports.finish = finish\nexports.mark = mark\nexports.isIgnored = isIgnored\nexports.childrenIgnored = childrenIgnored\n\nfunction ownProp (obj, field) {\n  return Object.prototype.hasOwnProperty.call(obj, field)\n}\n\nvar path = require(\"path\")\nvar minimatch = require(\"minimatch\")\nvar isAbsolute = require(\"path-is-absolute\")\nvar Minimatch = minimatch.Minimatch\n\nfunction alphasorti (a, b) {\n  return a.toLowerCase().localeCompare(b.toLowerCase())\n}\n\nfunction alphasort (a, b) {\n  return a.localeCompare(b)\n}\n\nfunction setupIgnores (self, options) {\n  self.ignore = options.ignore || []\n\n  if (!Array.isArray(self.ignore))\n    self.ignore = [self.ignore]\n\n  if (self.ignore.length) {\n    self.ignore = self.ignore.map(ignoreMap)\n  }\n}\n\n// ignore patterns are always in dot:true mode.\nfunction ignoreMap (pattern) {\n  var gmatcher = null\n  if (pattern.slice(-3) === '/**') {\n    var gpattern = pattern.replace(/(\\/\\*\\*)+$/, '')\n    gmatcher = new Minimatch(gpattern, { dot: true })\n  }\n\n  return {\n    matcher: new Minimatch(pattern, { dot: true }),\n    gmatcher: gmatcher\n  }\n}\n\nfunction setopts (self, pattern, options) {\n  if (!options)\n    options = {}\n\n  // base-matching: just use globstar for that.\n  if (options.matchBase && -1 === pattern.indexOf(\"/\")) {\n    if (options.noglobstar) {\n      throw new Error(\"base matching requires globstar\")\n    }\n    pattern = \"**/\" + pattern\n  }\n\n  self.silent = !!options.silent\n  self.pattern = pattern\n  self.strict = options.strict !== false\n  self.realpath = !!options.realpath\n  self.realpathCache = options.realpathCache || Object.create(null)\n  self.follow = !!options.follow\n  self.dot = !!options.dot\n  self.mark = !!options.mark\n  self.nodir = !!options.nodir\n  if (self.nodir)\n    self.mark = true\n  self.sync = !!options.sync\n  self.nounique = !!options.nounique\n  self.nonull = !!options.nonull\n  self.nosort = !!options.nosort\n  self.nocase = !!options.nocase\n  self.stat = !!options.stat\n  self.noprocess = !!options.noprocess\n  self.absolute = !!options.absolute\n\n  self.maxLength = options.maxLength || Infinity\n  self.cache = options.cache || Object.create(null)\n  self.statCache = options.statCache || Object.create(null)\n  self.symlinks = options.symlinks || Object.create(null)\n\n  setupIgnores(self, options)\n\n  self.changedCwd = false\n  var cwd = process.cwd()\n  if (!ownProp(options, \"cwd\"))\n    self.cwd = cwd\n  else {\n    self.cwd = path.resolve(options.cwd)\n    self.changedCwd = self.cwd !== cwd\n  }\n\n  self.root = options.root || path.resolve(self.cwd, \"/\")\n  self.root = path.resolve(self.root)\n  if (process.platform === \"win32\")\n    self.root = self.root.replace(/\\\\/g, \"/\")\n\n  // TODO: is an absolute `cwd` supposed to be resolved against `root`?\n  // e.g. { cwd: '/test', root: __dirname } === path.join(__dirname, '/test')\n  self.cwdAbs = isAbsolute(self.cwd) ? self.cwd : makeAbs(self, self.cwd)\n  if (process.platform === \"win32\")\n    self.cwdAbs = self.cwdAbs.replace(/\\\\/g, \"/\")\n  self.nomount = !!options.nomount\n\n  // disable comments and negation in Minimatch.\n  // Note that they are not supported in Glob itself anyway.\n  options.nonegate = true\n  options.nocomment = true\n\n  self.minimatch = new Minimatch(pattern, options)\n  self.options = self.minimatch.options\n}\n\nfunction finish (self) {\n  var nou = self.nounique\n  var all = nou ? [] : Object.create(null)\n\n  for (var i = 0, l = self.matches.length; i < l; i ++) {\n    var matches = self.matches[i]\n    if (!matches || Object.keys(matches).length === 0) {\n      if (self.nonull) {\n        // do like the shell, and spit out the literal glob\n        var literal = self.minimatch.globSet[i]\n        if (nou)\n          all.push(literal)\n        else\n          all[literal] = true\n      }\n    } else {\n      // had matches\n      var m = Object.keys(matches)\n      if (nou)\n        all.push.apply(all, m)\n      else\n        m.forEach(function (m) {\n          all[m] = true\n        })\n    }\n  }\n\n  if (!nou)\n    all = Object.keys(all)\n\n  if (!self.nosort)\n    all = all.sort(self.nocase ? alphasorti : alphasort)\n\n  // at *some* point we statted all of these\n  if (self.mark) {\n    for (var i = 0; i < all.length; i++) {\n      all[i] = self._mark(all[i])\n    }\n    if (self.nodir) {\n      all = all.filter(function (e) {\n        var notDir = !(/\\/$/.test(e))\n        var c = self.cache[e] || self.cache[makeAbs(self, e)]\n        if (notDir && c)\n          notDir = c !== 'DIR' && !Array.isArray(c)\n        return notDir\n      })\n    }\n  }\n\n  if (self.ignore.length)\n    all = all.filter(function(m) {\n      return !isIgnored(self, m)\n    })\n\n  self.found = all\n}\n\nfunction mark (self, p) {\n  var abs = makeAbs(self, p)\n  var c = self.cache[abs]\n  var m = p\n  if (c) {\n    var isDir = c === 'DIR' || Array.isArray(c)\n    var slash = p.slice(-1) === '/'\n\n    if (isDir && !slash)\n      m += '/'\n    else if (!isDir && slash)\n      m = m.slice(0, -1)\n\n    if (m !== p) {\n      var mabs = makeAbs(self, m)\n      self.statCache[mabs] = self.statCache[abs]\n      self.cache[mabs] = self.cache[abs]\n    }\n  }\n\n  return m\n}\n\n// lotta situps...\nfunction makeAbs (self, f) {\n  var abs = f\n  if (f.charAt(0) === '/') {\n    abs = path.join(self.root, f)\n  } else if (isAbsolute(f) || f === '') {\n    abs = f\n  } else if (self.changedCwd) {\n    abs = path.resolve(self.cwd, f)\n  } else {\n    abs = path.resolve(f)\n  }\n\n  if (process.platform === 'win32')\n    abs = abs.replace(/\\\\/g, '/')\n\n  return abs\n}\n\n\n// Return true, if pattern ends with globstar '**', for the accompanying parent directory.\n// Ex:- If node_modules/** is the pattern, add 'node_modules' to ignore list along with it's contents\nfunction isIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return item.matcher.match(path) || !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\nfunction childrenIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/inflight/inflight.js":"var wrappy = require('wrappy')\nvar reqs = Object.create(null)\nvar once = require('once')\n\nmodule.exports = wrappy(inflight)\n\nfunction inflight (key, cb) {\n  if (reqs[key]) {\n    reqs[key].push(cb)\n    return null\n  } else {\n    reqs[key] = [cb]\n    return makeres(key)\n  }\n}\n\nfunction makeres (key) {\n  return once(function RES () {\n    var cbs = reqs[key]\n    var len = cbs.length\n    var args = slice(arguments)\n\n    // XXX It's somewhat ambiguous whether a new callback added in this\n    // pass should be queued for later execution if something in the\n    // list of callbacks throws, or if it should just be discarded.\n    // However, it's such an edge case that it hardly matters, and either\n    // choice is likely as surprising as the other.\n    // As it happens, we do go ahead and schedule it for later execution.\n    try {\n      for (var i = 0; i < len; i++) {\n        cbs[i].apply(null, args)\n      }\n    } finally {\n      if (cbs.length > len) {\n        // added more in the interim.\n        // de-zalgo, just in case, but don't call again.\n        cbs.splice(0, len)\n        process.nextTick(function () {\n          RES.apply(null, args)\n        })\n      } else {\n        delete reqs[key]\n      }\n    }\n  })\n}\n\nfunction slice (args) {\n  var length = args.length\n  var array = []\n\n  for (var i = 0; i < length; i++) array[i] = args[i]\n  return array\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/rimraf/rimraf.js":"module.exports = rimraf\nrimraf.sync = rimrafSync\n\nvar assert = require(\"assert\")\nvar path = require(\"path\")\nvar fs = require(\"fs\")\nvar glob = require(\"glob\")\n\nvar defaultGlobOpts = {\n  nosort: true,\n  silent: true\n}\n\n// for EMFILE handling\nvar timeout = 0\n\nvar isWindows = (process.platform === \"win32\")\n\nfunction defaults (options) {\n  var methods = [\n    'unlink',\n    'chmod',\n    'stat',\n    'lstat',\n    'rmdir',\n    'readdir'\n  ]\n  methods.forEach(function(m) {\n    options[m] = options[m] || fs[m]\n    m = m + 'Sync'\n    options[m] = options[m] || fs[m]\n  })\n\n  options.maxBusyTries = options.maxBusyTries || 3\n  options.emfileWait = options.emfileWait || 1000\n  if (options.glob === false) {\n    options.disableGlob = true\n  }\n  options.disableGlob = options.disableGlob || false\n  options.glob = options.glob || defaultGlobOpts\n}\n\nfunction rimraf (p, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert.equal(typeof cb, 'function', 'rimraf: callback function required')\n  assert(options, 'rimraf: invalid options argument provided')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  defaults(options)\n\n  var busyTries = 0\n  var errState = null\n  var n = 0\n\n  if (options.disableGlob || !glob.hasMagic(p))\n    return afterGlob(null, [p])\n\n  options.lstat(p, function (er, stat) {\n    if (!er)\n      return afterGlob(null, [p])\n\n    glob(p, options.glob, afterGlob)\n  })\n\n  function next (er) {\n    errState = errState || er\n    if (--n === 0)\n      cb(errState)\n  }\n\n  function afterGlob (er, results) {\n    if (er)\n      return cb(er)\n\n    n = results.length\n    if (n === 0)\n      return cb()\n\n    results.forEach(function (p) {\n      rimraf_(p, options, function CB (er) {\n        if (er) {\n          if ((er.code === \"EBUSY\" || er.code === \"ENOTEMPTY\" || er.code === \"EPERM\") &&\n              busyTries < options.maxBusyTries) {\n            busyTries ++\n            var time = busyTries * 100\n            // try again, with the same exact callback as this one.\n            return setTimeout(function () {\n              rimraf_(p, options, CB)\n            }, time)\n          }\n\n          // this one won't happen if graceful-fs is used.\n          if (er.code === \"EMFILE\" && timeout < options.emfileWait) {\n            return setTimeout(function () {\n              rimraf_(p, options, CB)\n            }, timeout ++)\n          }\n\n          // already gone\n          if (er.code === \"ENOENT\") er = null\n        }\n\n        timeout = 0\n        next(er)\n      })\n    })\n  }\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // sunos lets the root user unlink directories, which is... weird.\n  // so we have to lstat here and make sure it's not a dir.\n  options.lstat(p, function (er, st) {\n    if (er && er.code === \"ENOENT\")\n      return cb(null)\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er && er.code === \"EPERM\" && isWindows)\n      fixWinEPERM(p, options, er, cb)\n\n    if (st && st.isDirectory())\n      return rmdir(p, options, er, cb)\n\n    options.unlink(p, function (er) {\n      if (er) {\n        if (er.code === \"ENOENT\")\n          return cb(null)\n        if (er.code === \"EPERM\")\n          return (isWindows)\n            ? fixWinEPERM(p, options, er, cb)\n            : rmdir(p, options, er, cb)\n        if (er.code === \"EISDIR\")\n          return rmdir(p, options, er, cb)\n      }\n      return cb(er)\n    })\n  })\n}\n\nfunction fixWinEPERM (p, options, er, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n  if (er)\n    assert(er instanceof Error)\n\n  options.chmod(p, 666, function (er2) {\n    if (er2)\n      cb(er2.code === \"ENOENT\" ? null : er)\n    else\n      options.stat(p, function(er3, stats) {\n        if (er3)\n          cb(er3.code === \"ENOENT\" ? null : er)\n        else if (stats.isDirectory())\n          rmdir(p, options, er, cb)\n        else\n          options.unlink(p, cb)\n      })\n  })\n}\n\nfunction fixWinEPERMSync (p, options, er) {\n  assert(p)\n  assert(options)\n  if (er)\n    assert(er instanceof Error)\n\n  try {\n    options.chmodSync(p, 666)\n  } catch (er2) {\n    if (er2.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  try {\n    var stats = options.statSync(p)\n  } catch (er3) {\n    if (er3.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  if (stats.isDirectory())\n    rmdirSync(p, options, er)\n  else\n    options.unlinkSync(p)\n}\n\nfunction rmdir (p, options, originalEr, cb) {\n  assert(p)\n  assert(options)\n  if (originalEr)\n    assert(originalEr instanceof Error)\n  assert(typeof cb === 'function')\n\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  options.rmdir(p, function (er) {\n    if (er && (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\"))\n      rmkids(p, options, cb)\n    else if (er && er.code === \"ENOTDIR\")\n      cb(originalEr)\n    else\n      cb(er)\n  })\n}\n\nfunction rmkids(p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.readdir(p, function (er, files) {\n    if (er)\n      return cb(er)\n    var n = files.length\n    if (n === 0)\n      return options.rmdir(p, cb)\n    var errState\n    files.forEach(function (f) {\n      rimraf(path.join(p, f), options, function (er) {\n        if (errState)\n          return\n        if (er)\n          return cb(errState = er)\n        if (--n === 0)\n          options.rmdir(p, cb)\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p, options) {\n  options = options || {}\n  defaults(options)\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert(options, 'rimraf: missing options')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  var results\n\n  if (options.disableGlob || !glob.hasMagic(p)) {\n    results = [p]\n  } else {\n    try {\n      options.lstatSync(p)\n      results = [p]\n    } catch (er) {\n      results = glob.sync(p, options.glob)\n    }\n  }\n\n  if (!results.length)\n    return\n\n  for (var i = 0; i < results.length; i++) {\n    var p = results[i]\n\n    try {\n      var st = options.lstatSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n\n      // Windows can EPERM on stat.  Life is suffering.\n      if (er.code === \"EPERM\" && isWindows)\n        fixWinEPERMSync(p, options, er)\n    }\n\n    try {\n      // sunos lets the root user unlink directories, which is... weird.\n      if (st && st.isDirectory())\n        rmdirSync(p, options, null)\n      else\n        options.unlinkSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n      if (er.code === \"EPERM\")\n        return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)\n      if (er.code !== \"EISDIR\")\n        throw er\n\n      rmdirSync(p, options, er)\n    }\n  }\n}\n\nfunction rmdirSync (p, options, originalEr) {\n  assert(p)\n  assert(options)\n  if (originalEr)\n    assert(originalEr instanceof Error)\n\n  try {\n    options.rmdirSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"ENOTDIR\")\n      throw originalEr\n    if (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\")\n      rmkidsSync(p, options)\n  }\n}\n\nfunction rmkidsSync (p, options) {\n  assert(p)\n  assert(options)\n  options.readdirSync(p).forEach(function (f) {\n    rimrafSync(path.join(p, f), options)\n  })\n\n  // We only end up here once we got ENOTEMPTY at least once, and\n  // at this point, we are guaranteed to have removed all the kids.\n  // So, we know that it won't be ENOENT or ENOTDIR or anything else.\n  // try really hard to delete stuff on windows, because it has a\n  // PROFOUNDLY annoying habit of not closing handles promptly when\n  // files are deleted, resulting in spurious ENOTEMPTY errors.\n  var retries = isWindows ? 100 : 1\n  var i = 0\n  do {\n    var threw = true\n    try {\n      var ret = options.rmdirSync(p, options)\n      threw = false\n      return ret\n    } finally {\n      if (++i < retries && threw)\n        continue\n    }\n  } while (true)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/lazy-property/lazyProperty.js":"\"use strict\"\n\nfunction addLazyProperty(object, name, initializer, enumerable) {\n  Object.defineProperty(object, name, {\n    get: function() {\n      var v = initializer.call(this)\n      Object.defineProperty(this, name, { value: v, enumerable: !!enumerable, writable: true })\n      return v\n    },\n    set: function(v) {\n      Object.defineProperty(this, name, { value: v, enumerable: !!enumerable, writable: true })\n      return v\n    },\n    enumerable: !!enumerable,\n    configurable: true\n  })\n}\n\nmodule.exports = addLazyProperty\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/parse-json.js":"'use strict'\nvar parseJSON = module.exports = function (content) {\n  return JSON.parse(stripBOM(content))\n}\n\nparseJSON.noExceptions = function (content) {\n  try {\n    return parseJSON(content)\n  } catch (ex) {\n    return\n  }\n}\n\n// from read-package-json\nfunction stripBOM (content) {\n  content = content.toString()\n  // Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)\n  // because the buffer-to-string conversion in `fs.readFileSync()`\n  // translates it to FEFF, the UTF-16 BOM.\n  if (content.charCodeAt(0) === 0xFEFF) {\n    content = content.slice(1)\n  }\n  return content\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config/cmd-list.js":"var extend = Object.assign || require('util')._extend\n\n// short names for common things\nvar shorthands = {\n  'un': 'uninstall',\n  'rb': 'rebuild',\n  'list': 'ls',\n  'ln': 'link',\n  'i': 'install',\n  'it': 'install-test',\n  'up': 'update',\n  'c': 'config',\n  's': 'search',\n  'se': 'search',\n  'unstar': 'star', // same function\n  'tst': 'test',\n  't': 'test',\n  'ddp': 'dedupe',\n  'v': 'view',\n  'run': 'run-script'\n}\n\nvar affordances = {\n  'la': 'ls',\n  'll': 'ls',\n  'verison': 'version',\n  'isntall': 'install',\n  'dist-tags': 'dist-tag',\n  'apihelp': 'help',\n  'find-dupes': 'dedupe',\n  'upgrade': 'update',\n  'login': 'adduser',\n  'add-user': 'adduser',\n  'author': 'owner',\n  'home': 'docs',\n  'issues': 'bugs',\n  'info': 'view',\n  'show': 'view',\n  'find': 'search',\n  'unlink': 'uninstall',\n  'remove': 'uninstall',\n  'rm': 'uninstall',\n  'r': 'uninstall'\n}\n\n// these are filenames in .\nvar cmdList = [\n  'install',\n  'install-test',\n  'uninstall',\n  'cache',\n  'config',\n  'set',\n  'get',\n  'update',\n  'outdated',\n  'prune',\n  'pack',\n  'dedupe',\n\n  'rebuild',\n  'link',\n\n  'publish',\n  'star',\n  'stars',\n  'adduser',\n  'login', // This is an alias for `adduser` but it can be confusing\n  'logout',\n  'unpublish',\n  'owner',\n  'access',\n  'team',\n  'deprecate',\n  'shrinkwrap',\n\n  'help',\n  'help-search',\n  'ls',\n  'search',\n  'view',\n  'init',\n  'version',\n  'edit',\n  'explore',\n  'docs',\n  'repo',\n  'bugs',\n  'root',\n  'prefix',\n  'bin',\n  'whoami',\n  'dist-tag',\n  'ping',\n\n  'test',\n  'stop',\n  'start',\n  'restart',\n  'run-script',\n  'completion',\n  'doctor'\n]\n\nvar plumbing = [\n  'build',\n  'unbuild',\n  'xmas',\n  'substack',\n  'visnup'\n]\nmodule.exports.aliases = extend(extend({}, shorthands), affordances)\nmodule.exports.shorthands = shorthands\nmodule.exports.affordances = affordances\nmodule.exports.cmdList = cmdList\nmodule.exports.plumbing = plumbing\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/output.js":"'use strict'\nvar log = require('npmlog')\n// output to stdout in a progress bar compatible way\nmodule.exports = function () {\n  log.clearProgress()\n  console.log.apply(console, arguments)\n  log.showProgress()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/metrics.js":"'use strict'\nexports.start = startMetrics\nexports.stop = stopMetrics\nexports.save = saveMetrics\nexports.send = sendMetrics\n\nvar fs = require('fs')\nvar path = require('path')\nvar npm = require('../npm.js')\nvar uuid = require('uuid')\n\nvar inMetrics = false\n\nfunction startMetrics () {\n  if (inMetrics) return\n  // loaded on demand to avoid any recursive deps when `./metrics-launch` requires us.\n  var metricsLaunch = require('./metrics-launch.js')\n  npm.metricsProcess = metricsLaunch()\n}\n\nfunction stopMetrics () {\n  if (inMetrics) return\n  if (npm.metricsProcess) npm.metricsProcess.kill('SIGKILL')\n}\n\nfunction saveMetrics (itWorked) {\n  if (inMetrics) return\n  // If the metrics reporter hasn't managed to PUT yet then kill it so that it doesn't\n  // step on our updating the anonymous-cli-metrics json\n  stopMetrics()\n  var metricsFile = path.join(npm.config.get('cache'), 'anonymous-cli-metrics.json')\n  var metrics\n  try {\n    metrics = JSON.parse(fs.readFileSync(metricsFile))\n    metrics.metrics.to = new Date().toISOString()\n    if (itWorked) {\n      ++metrics.metrics.successfulInstalls\n    } else {\n      ++metrics.metrics.failedInstalls\n    }\n  } catch (ex) {\n    metrics = {\n      metricId: uuid.v4(),\n      metrics: {\n        from: new Date().toISOString(),\n        to: new Date().toISOString(),\n        successfulInstalls: itWorked ? 1 : 0,\n        failedInstalls: itWorked ? 0 : 1\n      }\n    }\n  }\n  try {\n    fs.writeFileSync(metricsFile, JSON.stringify(metrics))\n  } catch (ex) {\n    // we couldn't write the error metrics file, um, well, oh well.\n  }\n}\n\nfunction sendMetrics (metricsFile, metricsRegistry) {\n  inMetrics = true\n  var cliMetrics = JSON.parse(fs.readFileSync(metricsFile))\n  npm.load({}, function (err) {\n    if (err) return\n    npm.registry.config.retry.retries = 0\n    npm.registry.sendAnonymousCLIMetrics(metricsRegistry, cliMetrics, function (err) {\n      if (err) {\n        fs.writeFileSync(path.join(path.dirname(metricsFile), 'last-send-metrics-error.txt'), err.stack)\n      } else {\n        fs.unlinkSync(metricsFile)\n      }\n    })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/uuid/index.js":"var v1 = require('./v1');\nvar v4 = require('./v4');\n\nvar uuid = v4;\nuuid.v1 = v1;\nuuid.v4 = v4;\n\nmodule.exports = uuid;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/uuid/v1.js":"// Unique ID creation requires a high quality random # generator.  We feature\n// detect to determine the best RNG source, normalizing to a function that\n// returns 128-bits of randomness, since that's what's usually required\nvar rng = require('./lib/rng');\nvar bytesToUuid = require('./lib/bytesToUuid');\n\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\n// random #'s we need to init node and clockseq\nvar _seedBytes = rng();\n\n// Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\nvar _nodeId = [\n  _seedBytes[0] | 0x01,\n  _seedBytes[1], _seedBytes[2], _seedBytes[3], _seedBytes[4], _seedBytes[5]\n];\n\n// Per 4.2.2, randomize (14 bit) clockseq\nvar _clockseq = (_seedBytes[6] << 8 | _seedBytes[7]) & 0x3fff;\n\n// Previous uuid creation time\nvar _lastMSecs = 0, _lastNSecs = 0;\n\n// See https://github.com/broofa/node-uuid for API details\nfunction v1(options, buf, offset) {\n  var i = buf && offset || 0;\n  var b = buf || [];\n\n  options = options || {};\n\n  var clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq;\n\n  // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  var msecs = options.msecs !== undefined ? options.msecs : new Date().getTime();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  var nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  var dt = (msecs - _lastMSecs) + (nsecs - _lastNSecs)/10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error('uuid.v1(): Can\\'t create more than 10M uuids/sec');\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  var tmh = (msecs / 0x100000000 * 10000) & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  var node = options.node || _nodeId;\n  for (var n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf ? buf : bytesToUuid(b);\n}\n\nmodule.exports = v1;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/uuid/lib/rng.js":"// Unique ID creation requires a high quality random # generator.  In node.js\n// this is prett straight-forward - we use the crypto API.\n\nvar rb = require('crypto').randomBytes;\n\nfunction rng() {\n  return rb(16);\n};\n\nmodule.exports = rng;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/uuid/lib/bytesToUuid.js":"/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nvar byteToHex = [];\nfor (var i = 0; i < 256; ++i) {\n  byteToHex[i] = (i + 0x100).toString(16).substr(1);\n}\n\nfunction bytesToUuid(buf, offset) {\n  var i = offset || 0;\n  var bth = byteToHex;\n  return  bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]];\n}\n\nmodule.exports = bytesToUuid;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/uuid/v4.js":"var rng = require('./lib/rng');\nvar bytesToUuid = require('./lib/bytesToUuid');\n\nfunction v4(options, buf, offset) {\n  var i = buf && offset || 0;\n\n  if (typeof(options) == 'string') {\n    buf = options == 'binary' ? new Array(16) : null;\n    options = null;\n  }\n  options = options || {};\n\n  var rnds = options.random || (options.rng || rng)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = (rnds[6] & 0x0f) | 0x40;\n  rnds[8] = (rnds[8] & 0x3f) | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    for (var ii = 0; ii < 16; ++ii) {\n      buf[i + ii] = rnds[ii];\n    }\n  }\n\n  return buf || bytesToUuid(rnds);\n}\n\nmodule.exports = v4;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/access.js":"'use strict'\n\nvar resolve = require('path').resolve\n\nvar readPackageJson = require('read-package-json')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar npm = require('./npm.js')\nvar output = require('./utils/output.js')\n\nvar whoami = require('./whoami')\n\nmodule.exports = access\n\naccess.usage =\n  'npm access public [<package>]\\n' +\n  'npm access restricted [<package>]\\n' +\n  'npm access grant <read-only|read-write> <scope:team> [<package>]\\n' +\n  'npm access revoke <scope:team> [<package>]\\n' +\n  'npm access ls-packages [<user>|<scope>|<scope:team>]\\n' +\n  'npm access ls-collaborators [<package> [<user>]]\\n' +\n  'npm access edit [<package>]'\n\naccess.subcommands = ['public', 'restricted', 'grant', 'revoke',\n                      'ls-packages', 'ls-collaborators', 'edit']\n\naccess.completion = function (opts, cb) {\n  var argv = opts.conf.argv.remain\n  if (argv.length === 2) {\n    return cb(null, access.subcommands)\n  }\n\n  switch (argv[2]) {\n    case 'grant':\n      if (argv.length === 3) {\n        return cb(null, ['read-only', 'read-write'])\n      } else {\n        return cb(null, [])\n      }\n    case 'public':\n    case 'restricted':\n    case 'ls-packages':\n    case 'ls-collaborators':\n    case 'edit':\n      return cb(null, [])\n    case 'revoke':\n      return cb(null, [])\n    default:\n      return cb(new Error(argv[2] + ' not recognized'))\n  }\n}\n\nfunction access (args, cb) {\n  var cmd = args.shift()\n  var params\n  return parseParams(cmd, args, function (err, p) {\n    if (err) { return cb(err) }\n    params = p\n    return mapToRegistry(params.package, npm.config, invokeCmd)\n  })\n\n  function invokeCmd (err, uri, auth, base) {\n    if (err) { return cb(err) }\n    params.auth = auth\n    try {\n      return npm.registry.access(cmd, uri, params, function (err, data) {\n        if (!err && data) {\n          output(JSON.stringify(data, undefined, 2))\n        }\n        cb(err, data)\n      })\n    } catch (e) {\n      cb(e.message + '\\n\\nUsage:\\n' + access.usage)\n    }\n  }\n}\n\nfunction parseParams (cmd, args, cb) {\n  // mapToRegistry will complain if package is undefined,\n  // but it's not needed for ls-packages\n  var params = { 'package': '' }\n  if (cmd === 'grant') {\n    params.permissions = args.shift()\n  }\n  if (['grant', 'revoke', 'ls-packages'].indexOf(cmd) !== -1) {\n    var entity = (args.shift() || '').split(':')\n    params.scope = entity[0]\n    params.team = entity[1]\n  }\n\n  if (cmd === 'ls-packages') {\n    if (!params.scope) {\n      whoami([], true, function (err, scope) {\n        params.scope = scope\n        cb(err, params)\n      })\n    } else {\n      cb(null, params)\n    }\n  } else {\n    getPackage(args.shift(), function (err, pkg) {\n      if (err) return cb(err)\n      params.package = pkg\n\n      if (cmd === 'ls-collaborators') params.user = args.shift()\n      cb(null, params)\n    })\n  }\n}\n\nfunction getPackage (name, cb) {\n  if (name && name.trim()) {\n    cb(null, name.trim())\n  } else {\n    readPackageJson(\n      resolve(npm.prefix, 'package.json'),\n      function (err, data) {\n        if (err) {\n          if (err.code === 'ENOENT') {\n            cb(new Error('no package name passed to command and no package.json found'))\n          } else {\n            cb(err)\n          }\n        } else {\n          cb(null, data.name)\n        }\n      }\n    )\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read-package-json/read-json.js":"var fs\ntry {\n  fs = require('graceful-fs')\n} catch (er) {\n  fs = require('fs')\n}\n\nvar path = require('path')\n\nvar glob = require('glob')\nvar normalizeData = require('normalize-package-data')\nvar safeJSON = require('json-parse-helpfulerror')\n\nmodule.exports = readJson\n\n// put more stuff on here to customize.\nreadJson.extraSet = [\n  gypfile,\n  serverjs,\n  scriptpath,\n  authors,\n  readme,\n  mans,\n  bins,\n  githead\n]\n\nvar typoWarned = {}\n\nfunction readJson (file, log_, strict_, cb_) {\n  var log, strict, cb\n  for (var i = 1; i < arguments.length - 1; i++) {\n    if (typeof arguments[i] === 'boolean') {\n      strict = arguments[i]\n    } else if (typeof arguments[i] === 'function') {\n      log = arguments[i]\n    }\n  }\n\n  if (!log) log = function () {}\n  cb = arguments[ arguments.length - 1 ]\n\n  readJson_(file, log, strict, cb)\n}\n\nfunction readJson_ (file, log, strict, cb) {\n  fs.readFile(file, 'utf8', function (er, d) {\n    parseJson(file, er, d, log, strict, cb)\n  })\n}\n\nfunction stripBOM (content) {\n  // Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)\n  // because the buffer-to-string conversion in `fs.readFileSync()`\n  // translates it to FEFF, the UTF-16 BOM.\n  if (content.charCodeAt(0) === 0xFEFF) content = content.slice(1)\n  return content\n}\n\nfunction parseJson (file, er, d, log, strict, cb) {\n  if (er && er.code === 'ENOENT') {\n    return fs.stat(path.dirname(file), function (err, stat) {\n      if (!err && stat && !stat.isDirectory()) {\n        // ENOTDIR isn't used on Windows, but npm expects it.\n        er = Object.create(er)\n        er.code = 'ENOTDIR'\n        return cb(er)\n      } else {\n        return indexjs(file, er, log, strict, cb)\n      }\n    })\n  }\n  if (er) return cb(er)\n\n  try {\n    d = safeJSON.parse(stripBOM(d))\n  } catch (er) {\n    d = parseIndex(d)\n    if (!d) return cb(parseError(er, file))\n  }\n\n  extras(file, d, log, strict, cb)\n}\n\nfunction indexjs (file, er, log, strict, cb) {\n  if (path.basename(file) === 'index.js') return cb(er)\n\n  var index = path.resolve(path.dirname(file), 'index.js')\n  fs.readFile(index, 'utf8', function (er2, d) {\n    if (er2) return cb(er)\n\n    d = parseIndex(d)\n    if (!d) return cb(er)\n\n    extras(file, d, log, strict, cb)\n  })\n}\n\nreadJson.extras = extras\nfunction extras (file, data, log_, strict_, cb_) {\n  var log, strict, cb\n  for (var i = 2; i < arguments.length - 1; i++) {\n    if (typeof arguments[i] === 'boolean') {\n      strict = arguments[i]\n    } else if (typeof arguments[i] === 'function') {\n      log = arguments[i]\n    }\n  }\n\n  if (!log) log = function () {}\n  cb = arguments[i]\n\n  var set = readJson.extraSet\n  var n = set.length\n  var errState = null\n  set.forEach(function (fn) {\n    fn(file, data, then)\n  })\n\n  function then (er) {\n    if (errState) return\n    if (er) return cb(errState = er)\n    if (--n > 0) return\n    final(file, data, log, strict, cb)\n  }\n}\n\nfunction scriptpath (file, data, cb) {\n  if (!data.scripts) return cb(null, data)\n  var k = Object.keys(data.scripts)\n  k.forEach(scriptpath_, data.scripts)\n  cb(null, data)\n}\n\nfunction scriptpath_ (key) {\n  var s = this[key]\n  // This is never allowed, and only causes problems\n  if (typeof s !== 'string') return delete this[key]\n\n  var spre = /^(\\.[/\\\\])?node_modules[/\\\\].bin[\\\\/]/\n  if (s.match(spre)) {\n    this[key] = this[key].replace(spre, '')\n  }\n}\n\nfunction gypfile (file, data, cb) {\n  var dir = path.dirname(file)\n  var s = data.scripts || {}\n  if (s.install || s.preinstall) return cb(null, data)\n\n  glob('*.gyp', { cwd: dir }, function (er, files) {\n    if (er) return cb(er)\n    gypfile_(file, data, files, cb)\n  })\n}\n\nfunction gypfile_ (file, data, files, cb) {\n  if (!files.length) return cb(null, data)\n  var s = data.scripts || {}\n  s.install = 'node-gyp rebuild'\n  data.scripts = s\n  data.gypfile = true\n  return cb(null, data)\n}\n\nfunction serverjs (file, data, cb) {\n  var dir = path.dirname(file)\n  var s = data.scripts || {}\n  if (s.start) return cb(null, data)\n  glob('server.js', { cwd: dir }, function (er, files) {\n    if (er) return cb(er)\n    serverjs_(file, data, files, cb)\n  })\n}\n\nfunction serverjs_ (file, data, files, cb) {\n  if (!files.length) return cb(null, data)\n  var s = data.scripts || {}\n  s.start = 'node server.js'\n  data.scripts = s\n  return cb(null, data)\n}\n\nfunction authors (file, data, cb) {\n  if (data.contributors) return cb(null, data)\n  var af = path.resolve(path.dirname(file), 'AUTHORS')\n  fs.readFile(af, 'utf8', function (er, ad) {\n    // ignore error.  just checking it.\n    if (er) return cb(null, data)\n    authors_(file, data, ad, cb)\n  })\n}\n\nfunction authors_ (file, data, ad, cb) {\n  ad = ad.split(/\\r?\\n/g).map(function (line) {\n    return line.replace(/^\\s*#.*$/, '').trim()\n  }).filter(function (line) {\n    return line\n  })\n  data.contributors = ad\n  return cb(null, data)\n}\n\nfunction readme (file, data, cb) {\n  if (data.readme) return cb(null, data)\n  var dir = path.dirname(file)\n  var globOpts = { cwd: dir, nocase: true, mark: true }\n  glob('{README,README.*}', globOpts, function (er, files) {\n    if (er) return cb(er)\n    // don't accept directories.\n    files = files.filter(function (file) {\n      return !file.match(/\\/$/)\n    })\n    if (!files.length) return cb()\n    var fn = preferMarkdownReadme(files)\n    var rm = path.resolve(dir, fn)\n    readme_(file, data, rm, cb)\n  })\n}\n\nfunction preferMarkdownReadme (files) {\n  var fallback = 0\n  var re = /\\.m?a?r?k?d?o?w?n?$/i\n  for (var i = 0; i < files.length; i++) {\n    if (files[i].match(re)) {\n      return files[i]\n    } else if (files[i].match(/README$/)) {\n      fallback = i\n    }\n  }\n  // prefer README.md, followed by README; otherwise, return\n  // the first filename (which could be README)\n  return files[fallback]\n}\n\nfunction readme_ (file, data, rm, cb) {\n  var rmfn = path.basename(rm)\n  fs.readFile(rm, 'utf8', function (er, rm) {\n    // maybe not readable, or something.\n    if (er) return cb()\n    data.readme = rm\n    data.readmeFilename = rmfn\n    return cb(er, data)\n  })\n}\n\nfunction mans (file, data, cb) {\n  var m = data.directories && data.directories.man\n  if (data.man || !m) return cb(null, data)\n  m = path.resolve(path.dirname(file), m)\n  glob('**/*.[0-9]', { cwd: m }, function (er, mans) {\n    if (er) return cb(er)\n    mans_(file, data, mans, cb)\n  })\n}\n\nfunction mans_ (file, data, mans, cb) {\n  var m = data.directories && data.directories.man\n  data.man = mans.map(function (mf) {\n    return path.resolve(path.dirname(file), m, mf)\n  })\n  return cb(null, data)\n}\n\nfunction bins (file, data, cb) {\n  if (Array.isArray(data.bin)) return bins_(file, data, data.bin, cb)\n\n  var m = data.directories && data.directories.bin\n  if (data.bin || !m) return cb(null, data)\n\n  m = path.resolve(path.dirname(file), m)\n  glob('**', { cwd: m }, function (er, bins) {\n    if (er) return cb(er)\n    bins_(file, data, bins, cb)\n  })\n}\n\nfunction bins_ (file, data, bins, cb) {\n  var m = (data.directories && data.directories.bin) || '.'\n  data.bin = bins.reduce(function (acc, mf) {\n    if (mf && mf.charAt(0) !== '.') {\n      var f = path.basename(mf)\n      acc[f] = path.join(m, mf)\n    }\n    return acc\n  }, {})\n  return cb(null, data)\n}\n\nfunction githead (file, data, cb) {\n  if (data.gitHead) return cb(null, data)\n  var dir = path.dirname(file)\n  var head = path.resolve(dir, '.git/HEAD')\n  fs.readFile(head, 'utf8', function (er, head) {\n    if (er) return cb(null, data)\n    githead_(file, data, dir, head, cb)\n  })\n}\n\nfunction githead_ (file, data, dir, head, cb) {\n  if (!head.match(/^ref: /)) {\n    data.gitHead = head.trim()\n    return cb(null, data)\n  }\n  var headFile = head.replace(/^ref: /, '').trim()\n  headFile = path.resolve(dir, '.git', headFile)\n  fs.readFile(headFile, 'utf8', function (er, head) {\n    if (er || !head) return cb(null, data)\n    head = head.replace(/^ref: /, '').trim()\n    data.gitHead = head\n    return cb(null, data)\n  })\n}\n\n/**\n * Warn if the bin references don't point to anything.  This might be better in\n * normalize-package-data if it had access to the file path.\n */\nfunction checkBinReferences_ (file, data, warn, cb) {\n  if (!(data.bin instanceof Object)) return cb()\n\n  var keys = Object.keys(data.bin)\n  var keysLeft = keys.length\n  if (!keysLeft) return cb()\n\n  function handleExists (relName, result) {\n    keysLeft--\n    if (!result) warn('No bin file found at ' + relName)\n    if (!keysLeft) cb()\n  }\n\n  keys.forEach(function (key) {\n    var dirName = path.dirname(file)\n    var relName = data.bin[key]\n    var binPath = path.resolve(dirName, relName)\n    fs.exists(binPath, handleExists.bind(null, relName))\n  })\n}\n\nfunction final (file, data, log, strict, cb) {\n  var pId = makePackageId(data)\n\n  function warn (msg) {\n    if (typoWarned[pId]) return\n    if (log) log('package.json', pId, msg)\n  }\n\n  try {\n    normalizeData(data, warn, strict)\n  } catch (error) {\n    return cb(error)\n  }\n\n  checkBinReferences_(file, data, warn, function () {\n    typoWarned[pId] = true\n    cb(null, data)\n  })\n}\n\nfunction makePackageId (data) {\n  var name = cleanString(data.name)\n  var ver = cleanString(data.version)\n  return name + '@' + ver\n}\n\nfunction cleanString (str) {\n  return (!str || typeof (str) !== 'string') ? '' : str.trim()\n}\n\n// /**package { \"name\": \"foo\", \"version\": \"1.2.3\", ... } **/\nfunction parseIndex (data) {\n  data = data.split(/^\\/\\*\\*package(?:\\s|$)/m)\n\n  if (data.length < 2) return null\n  data = data[1]\n  data = data.split(/\\*\\*\\/$/m)\n\n  if (data.length < 2) return null\n  data = data[0]\n  data = data.replace(/^\\s*\\*/mg, '')\n\n  try {\n    return safeJSON.parse(data)\n  } catch (er) {\n    return null\n  }\n}\n\nfunction parseError (ex, file) {\n  var e = new Error('Failed to parse json\\n' + ex.message)\n  e.code = 'EJSONPARSE'\n  e.file = file\n  return e\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/normalize-package-data/lib/normalize.js":"module.exports = normalize\n\nvar fixer = require(\"./fixer\")\nnormalize.fixer = fixer\n\nvar makeWarning = require(\"./make_warning\")\n\nvar fieldsToFix = ['name','version','description','repository','modules','scripts'\n                  ,'files','bin','man','bugs','keywords','readme','homepage','license']\nvar otherThingsToFix = ['dependencies','people', 'typos']\n\nvar thingsToFix = fieldsToFix.map(function(fieldName) {\n  return ucFirst(fieldName) + \"Field\"\n})\n// two ways to do this in CoffeeScript on only one line, sub-70 chars:\n// thingsToFix = fieldsToFix.map (name) -> ucFirst(name) + \"Field\"\n// thingsToFix = (ucFirst(name) + \"Field\" for name in fieldsToFix)\nthingsToFix = thingsToFix.concat(otherThingsToFix)\n\nfunction normalize (data, warn, strict) {\n  if(warn === true) warn = null, strict = true\n  if(!strict) strict = false\n  if(!warn || data.private) warn = function(msg) { /* noop */ }\n\n  if (data.scripts &&\n      data.scripts.install === \"node-gyp rebuild\" &&\n      !data.scripts.preinstall) {\n    data.gypfile = true\n  }\n  fixer.warn = function() { warn(makeWarning.apply(null, arguments)) }\n  thingsToFix.forEach(function(thingName) {\n    fixer[\"fix\" + ucFirst(thingName)](data, strict)\n  })\n  data._id = data.name + \"@\" + data.version\n}\n\nfunction ucFirst (string) {\n  return string.charAt(0).toUpperCase() + string.slice(1);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/normalize-package-data/lib/fixer.js":"var semver = require(\"semver\")\nvar validateLicense = require('validate-npm-package-license');\nvar hostedGitInfo = require(\"hosted-git-info\")\nvar isBuiltinModule = require(\"is-builtin-module\")\nvar depTypes = [\"dependencies\",\"devDependencies\",\"optionalDependencies\"]\nvar extractDescription = require(\"./extract_description\")\nvar url = require(\"url\")\nvar typos = require(\"./typos\")\n\nvar fixer = module.exports = {\n  // default warning function\n  warn: function() {},\n\n  fixRepositoryField: function(data) {\n    if (data.repositories) {\n      this.warn(\"repositories\");\n      data.repository = data.repositories[0]\n    }\n    if (!data.repository) return this.warn(\"missingRepository\")\n    if (typeof data.repository === \"string\") {\n      data.repository = {\n        type: \"git\",\n        url: data.repository\n      }\n    }\n    var r = data.repository.url || \"\"\n    if (r) {\n      var hosted = hostedGitInfo.fromUrl(r)\n      if (hosted) {\n        r = data.repository.url\n          = hosted.getDefaultRepresentation() == \"shortcut\" ? hosted.https() : hosted.toString()\n      }\n    }\n\n    if (r.match(/github.com\\/[^\\/]+\\/[^\\/]+\\.git\\.git$/)) {\n      this.warn(\"brokenGitUrl\", r)\n    }\n  }\n\n, fixTypos: function(data) {\n    Object.keys(typos.topLevel).forEach(function (d) {\n      if (data.hasOwnProperty(d)) {\n        this.warn(\"typo\", d, typos.topLevel[d])\n      }\n    }, this)\n  }\n\n, fixScriptsField: function(data) {\n    if (!data.scripts) return\n    if (typeof data.scripts !== \"object\") {\n      this.warn(\"nonObjectScripts\")\n      delete data.scripts\n      return\n    }\n    Object.keys(data.scripts).forEach(function (k) {\n      if (typeof data.scripts[k] !== \"string\") {\n        this.warn(\"nonStringScript\")\n        delete data.scripts[k]\n      } else if (typos.script[k] && !data.scripts[typos.script[k]]) {\n        this.warn(\"typo\", k, typos.script[k], \"scripts\")\n      }\n    }, this)\n  }\n\n, fixFilesField: function(data) {\n    var files = data.files\n    if (files && !Array.isArray(files)) {\n      this.warn(\"nonArrayFiles\")\n      delete data.files\n    } else if (data.files) {\n      data.files = data.files.filter(function(file) {\n        if (!file || typeof file !== \"string\") {\n          this.warn(\"invalidFilename\", file)\n          return false\n        } else {\n          return true\n        }\n      }, this)\n    }\n  }\n\n, fixBinField: function(data) {\n    if (!data.bin) return;\n    if (typeof data.bin === \"string\") {\n      var b = {}\n      var match\n      if (match = data.name.match(/^@[^/]+[/](.*)$/)) {\n        b[match[1]] = data.bin\n      } else {\n        b[data.name] = data.bin\n      }\n      data.bin = b\n    }\n  }\n\n, fixManField: function(data) {\n    if (!data.man) return;\n    if (typeof data.man === \"string\") {\n      data.man = [ data.man ]\n    }\n  }\n, fixBundleDependenciesField: function(data) {\n    var bdd = \"bundledDependencies\"\n    var bd = \"bundleDependencies\"\n    if (data[bdd] && !data[bd]) {\n      data[bd] = data[bdd]\n      delete data[bdd]\n    }\n    if (data[bd] && !Array.isArray(data[bd])) {\n      this.warn(\"nonArrayBundleDependencies\")\n      delete data[bd]\n    } else if (data[bd]) {\n      data[bd] = data[bd].filter(function(bd) {\n        if (!bd || typeof bd !== 'string') {\n          this.warn(\"nonStringBundleDependency\", bd)\n          return false\n        } else {\n          if (!data.dependencies) {\n            data.dependencies = {}\n          }\n          if (!data.dependencies.hasOwnProperty(bd)) {\n            this.warn(\"nonDependencyBundleDependency\", bd)\n            data.dependencies[bd] = \"*\"\n          }\n          return true\n        }\n      }, this)\n    }\n  }\n\n, fixDependencies: function(data, strict) {\n    var loose = !strict\n    objectifyDeps(data, this.warn)\n    addOptionalDepsToDeps(data, this.warn)\n    this.fixBundleDependenciesField(data)\n\n    ;['dependencies','devDependencies'].forEach(function(deps) {\n      if (!(deps in data)) return\n      if (!data[deps] || typeof data[deps] !== \"object\") {\n        this.warn(\"nonObjectDependencies\", deps)\n        delete data[deps]\n        return\n      }\n      Object.keys(data[deps]).forEach(function (d) {\n        var r = data[deps][d]\n        if (typeof r !== 'string') {\n          this.warn(\"nonStringDependency\", d, JSON.stringify(r))\n          delete data[deps][d]\n        }\n        var hosted = hostedGitInfo.fromUrl(data[deps][d])\n        if (hosted) data[deps][d] = hosted.toString()\n      }, this)\n    }, this)\n  }\n\n, fixModulesField: function (data) {\n    if (data.modules) {\n      this.warn(\"deprecatedModules\")\n      delete data.modules\n    }\n  }\n\n, fixKeywordsField: function (data) {\n    if (typeof data.keywords === \"string\") {\n      data.keywords = data.keywords.split(/,\\s+/)\n    }\n    if (data.keywords && !Array.isArray(data.keywords)) {\n      delete data.keywords\n      this.warn(\"nonArrayKeywords\")\n    } else if (data.keywords) {\n      data.keywords = data.keywords.filter(function(kw) {\n        if (typeof kw !== \"string\" || !kw) {\n          this.warn(\"nonStringKeyword\");\n          return false\n        } else {\n          return true\n        }\n      }, this)\n    }\n  }\n\n, fixVersionField: function(data, strict) {\n    // allow \"loose\" semver 1.0 versions in non-strict mode\n    // enforce strict semver 2.0 compliance in strict mode\n    var loose = !strict\n    if (!data.version) {\n      data.version = \"\"\n      return true\n    }\n    if (!semver.valid(data.version, loose)) {\n      throw new Error('Invalid version: \"'+ data.version + '\"')\n    }\n    data.version = semver.clean(data.version, loose)\n    return true\n  }\n\n, fixPeople: function(data) {\n    modifyPeople(data, unParsePerson)\n    modifyPeople(data, parsePerson)\n  }\n\n, fixNameField: function(data, options) {\n    if (typeof options === \"boolean\") options = {strict: options}\n    else if (typeof options === \"undefined\") options = {}\n    var strict = options.strict\n    if (!data.name && !strict) {\n      data.name = \"\"\n      return\n    }\n    if (typeof data.name !== \"string\") {\n      throw new Error(\"name field must be a string.\")\n    }\n    if (!strict)\n      data.name = data.name.trim()\n    ensureValidName(data.name, strict, options.allowLegacyCase)\n    if (isBuiltinModule(data.name))\n      this.warn(\"conflictingName\", data.name)\n  }\n\n\n, fixDescriptionField: function (data) {\n    if (data.description && typeof data.description !== 'string') {\n      this.warn(\"nonStringDescription\")\n      delete data.description\n    }\n    if (data.readme && !data.description)\n      data.description = extractDescription(data.readme)\n      if(data.description === undefined) delete data.description;\n    if (!data.description) this.warn(\"missingDescription\")\n  }\n\n, fixReadmeField: function (data) {\n    if (!data.readme) {\n      this.warn(\"missingReadme\")\n      data.readme = \"ERROR: No README data found!\"\n    }\n  }\n\n, fixBugsField: function(data) {\n    if (!data.bugs && data.repository && data.repository.url) {\n      var hosted = hostedGitInfo.fromUrl(data.repository.url)\n      if(hosted && hosted.bugs()) {\n        data.bugs = {url: hosted.bugs()}\n      }\n    }\n    else if(data.bugs) {\n      var emailRe = /^.+@.*\\..+$/\n      if(typeof data.bugs == \"string\") {\n        if(emailRe.test(data.bugs))\n          data.bugs = {email:data.bugs}\n        else if(url.parse(data.bugs).protocol)\n          data.bugs = {url: data.bugs}\n        else\n          this.warn(\"nonEmailUrlBugsString\")\n      }\n      else {\n        bugsTypos(data.bugs, this.warn)\n        var oldBugs = data.bugs\n        data.bugs = {}\n        if(oldBugs.url) {\n          if(typeof(oldBugs.url) == \"string\" && url.parse(oldBugs.url).protocol)\n            data.bugs.url = oldBugs.url\n          else\n            this.warn(\"nonUrlBugsUrlField\")\n        }\n        if(oldBugs.email) {\n          if(typeof(oldBugs.email) == \"string\" && emailRe.test(oldBugs.email))\n            data.bugs.email = oldBugs.email\n          else\n            this.warn(\"nonEmailBugsEmailField\")\n        }\n      }\n      if(!data.bugs.email && !data.bugs.url) {\n        delete data.bugs\n        this.warn(\"emptyNormalizedBugs\")\n      }\n    }\n  }\n\n, fixHomepageField: function(data) {\n    if (!data.homepage && data.repository && data.repository.url) {\n      var hosted = hostedGitInfo.fromUrl(data.repository.url)\n      if (hosted && hosted.docs()) data.homepage = hosted.docs()\n    }\n    if (!data.homepage) return\n\n    if(typeof data.homepage !== \"string\") {\n      this.warn(\"nonUrlHomepage\")\n      return delete data.homepage\n    }\n    if(!url.parse(data.homepage).protocol) {\n      this.warn(\"missingProtocolHomepage\")\n      data.homepage = \"http://\" + data.homepage\n    }\n  }\n\n, fixLicenseField: function(data) {\n    if (!data.license) {\n      return this.warn(\"missingLicense\")\n    } else{\n      if (\n        typeof(data.license) !== 'string' ||\n        data.license.length < 1\n      ) {\n        this.warn(\"invalidLicense\")\n      } else {\n        if (!validateLicense(data.license).validForNewPackages)\n          this.warn(\"invalidLicense\")\n      }\n    }\n  }\n}\n\nfunction isValidScopedPackageName(spec) {\n  if (spec.charAt(0) !== '@') return false\n\n  var rest = spec.slice(1).split('/')\n  if (rest.length !== 2) return false\n\n  return rest[0] && rest[1] &&\n    rest[0] === encodeURIComponent(rest[0]) &&\n    rest[1] === encodeURIComponent(rest[1])\n}\n\nfunction isCorrectlyEncodedName(spec) {\n  return !spec.match(/[\\/@\\s\\+%:]/) &&\n    spec === encodeURIComponent(spec)\n}\n\nfunction ensureValidName (name, strict, allowLegacyCase) {\n  if (name.charAt(0) === \".\" ||\n      !(isValidScopedPackageName(name) || isCorrectlyEncodedName(name)) ||\n      (strict && (!allowLegacyCase) && name !== name.toLowerCase()) ||\n      name.toLowerCase() === \"node_modules\" ||\n      name.toLowerCase() === \"favicon.ico\") {\n        throw new Error(\"Invalid name: \" + JSON.stringify(name))\n  }\n}\n\nfunction modifyPeople (data, fn) {\n  if (data.author) data.author = fn(data.author)\n  ;[\"maintainers\", \"contributors\"].forEach(function (set) {\n    if (!Array.isArray(data[set])) return;\n    data[set] = data[set].map(fn)\n  })\n  return data\n}\n\nfunction unParsePerson (person) {\n  if (typeof person === \"string\") return person\n  var name = person.name || \"\"\n  var u = person.url || person.web\n  var url = u ? (\" (\"+u+\")\") : \"\"\n  var e = person.email || person.mail\n  var email = e ? (\" <\"+e+\">\") : \"\"\n  return name+email+url\n}\n\nfunction parsePerson (person) {\n  if (typeof person !== \"string\") return person\n  var name = person.match(/^([^\\(<]+)/)\n  var url = person.match(/\\(([^\\)]+)\\)/)\n  var email = person.match(/<([^>]+)>/)\n  var obj = {}\n  if (name && name[0].trim()) obj.name = name[0].trim()\n  if (email) obj.email = email[1];\n  if (url) obj.url = url[1];\n  return obj\n}\n\nfunction addOptionalDepsToDeps (data, warn) {\n  var o = data.optionalDependencies\n  if (!o) return;\n  var d = data.dependencies || {}\n  Object.keys(o).forEach(function (k) {\n    d[k] = o[k]\n  })\n  data.dependencies = d\n}\n\nfunction depObjectify (deps, type, warn) {\n  if (!deps) return {}\n  if (typeof deps === \"string\") {\n    deps = deps.trim().split(/[\\n\\r\\s\\t ,]+/)\n  }\n  if (!Array.isArray(deps)) return deps\n  warn(\"deprecatedArrayDependencies\", type)\n  var o = {}\n  deps.filter(function (d) {\n    return typeof d === \"string\"\n  }).forEach(function(d) {\n    d = d.trim().split(/(:?[@\\s><=])/)\n    var dn = d.shift()\n    var dv = d.join(\"\")\n    dv = dv.trim()\n    dv = dv.replace(/^@/, \"\")\n    o[dn] = dv\n  })\n  return o\n}\n\nfunction objectifyDeps (data, warn) {\n  depTypes.forEach(function (type) {\n    if (!data[type]) return;\n    data[type] = depObjectify(data[type], type, warn)\n  })\n}\n\nfunction bugsTypos(bugs, warn) {\n  if (!bugs) return\n  Object.keys(bugs).forEach(function (k) {\n    if (typos.bugs[k]) {\n      warn(\"typo\", k, typos.bugs[k], \"bugs\")\n      bugs[typos.bugs[k]] = bugs[k]\n      delete bugs[k]\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/validate-npm-package-license/index.js":"var parse = require('spdx-expression-parse');\nvar correct = require('spdx-correct');\n\nvar genericWarning = (\n  'license should be ' +\n  'a valid SPDX license expression (without \"LicenseRef\"), ' +\n  '\"UNLICENSED\", or ' +\n  '\"SEE LICENSE IN <filename>\"'\n);\n\nvar fileReferenceRE = /^SEE LICEN[CS]E IN (.+)$/;\n\nfunction startsWith(prefix, string) {\n  return string.slice(0, prefix.length) === prefix;\n}\n\nfunction usesLicenseRef(ast) {\n  if (ast.hasOwnProperty('license')) {\n    var license = ast.license;\n    return (\n      startsWith('LicenseRef', license) ||\n      startsWith('DocumentRef', license)\n    );\n  } else {\n    return (\n      usesLicenseRef(ast.left) ||\n      usesLicenseRef(ast.right)\n    );\n  }\n}\n\nmodule.exports = function(argument) {\n  var ast;\n\n  try {\n    ast = parse(argument);\n  } catch (e) {\n    var match\n    if (\n      argument === 'UNLICENSED' ||\n      argument === 'UNLICENCED'\n    ) {\n      return {\n        validForOldPackages: true,\n        validForNewPackages: true,\n        unlicensed: true\n      };\n    } else if (match = fileReferenceRE.exec(argument)) {\n      return {\n        validForOldPackages: true,\n        validForNewPackages: true,\n        inFile: match[1]\n      };\n    } else {\n      var result = {\n        validForOldPackages: false,\n        validForNewPackages: false,\n        warnings: [genericWarning]\n      };\n      var corrected = correct(argument);\n      if (corrected) {\n        result.warnings.push(\n          'license is similar to the valid expression \"' + corrected + '\"'\n        );\n      }\n      return result;\n    }\n  }\n\n  if (usesLicenseRef(ast)) {\n    return {\n      validForNewPackages: false,\n      validForOldPackages: false,\n      spdx: true,\n      warnings: [genericWarning]\n    };\n  } else {\n    return {\n      validForNewPackages: true,\n      validForOldPackages: true,\n      spdx: true\n    };\n  }\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/validate-npm-package-license/node_modules/spdx-expression-parse/index.js":"var parser = require('./parser.generated.js').parser\n\nmodule.exports = function(argument) {\n  return parser.parse(argument) }\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/validate-npm-package-license/node_modules/spdx-expression-parse/parser.generated.js":"var spdxparse=function(){var o=function(k,v,o,l){for(o=o||{},l=k.length;l--;o[k[l]]=v);return o},$V0=[1,5],$V1=[1,6],$V2=[1,7],$V3=[1,4],$V4=[1,9],$V5=[1,10],$V6=[5,14,15,17],$V7=[5,12,14,15,17];var parser={trace:function trace(){},yy:{},symbols_:{error:2,start:3,expression:4,EOS:5,simpleExpression:6,LICENSE:7,PLUS:8,LICENSEREF:9,DOCUMENTREF:10,COLON:11,WITH:12,EXCEPTION:13,AND:14,OR:15,OPEN:16,CLOSE:17,$accept:0,$end:1},terminals_:{2:\"error\",5:\"EOS\",7:\"LICENSE\",8:\"PLUS\",9:\"LICENSEREF\",10:\"DOCUMENTREF\",11:\"COLON\",12:\"WITH\",13:\"EXCEPTION\",14:\"AND\",15:\"OR\",16:\"OPEN\",17:\"CLOSE\"},productions_:[0,[3,2],[6,1],[6,2],[6,1],[6,3],[4,1],[4,3],[4,3],[4,3],[4,3]],performAction:function anonymous(yytext,yyleng,yylineno,yy,yystate,$$,_$){var $0=$$.length-1;switch(yystate){case 1:return this.$=$$[$0-1];break;case 2:case 4:case 5:this.$={license:yytext};break;case 3:this.$={license:$$[$0-1],plus:true};break;case 6:this.$=$$[$0];break;case 7:this.$={exception:$$[$0]};this.$.license=$$[$0-2].license;if($$[$0-2].hasOwnProperty(\"plus\")){this.$.plus=$$[$0-2].plus}break;case 8:this.$={conjunction:\"and\",left:$$[$0-2],right:$$[$0]};break;case 9:this.$={conjunction:\"or\",left:$$[$0-2],right:$$[$0]};break;case 10:this.$=$$[$0-1];break}},table:[{3:1,4:2,6:3,7:$V0,9:$V1,10:$V2,16:$V3},{1:[3]},{5:[1,8],14:$V4,15:$V5},o($V6,[2,6],{12:[1,11]}),{4:12,6:3,7:$V0,9:$V1,10:$V2,16:$V3},o($V7,[2,2],{8:[1,13]}),o($V7,[2,4]),{11:[1,14]},{1:[2,1]},{4:15,6:3,7:$V0,9:$V1,10:$V2,16:$V3},{4:16,6:3,7:$V0,9:$V1,10:$V2,16:$V3},{13:[1,17]},{14:$V4,15:$V5,17:[1,18]},o($V7,[2,3]),{9:[1,19]},o($V6,[2,8]),o([5,15,17],[2,9],{14:$V4}),o($V6,[2,7]),o($V6,[2,10]),o($V7,[2,5])],defaultActions:{8:[2,1]},parseError:function parseError(str,hash){if(hash.recoverable){this.trace(str)}else{throw new Error(str)}},parse:function parse(input){var self=this,stack=[0],tstack=[],vstack=[null],lstack=[],table=this.table,yytext=\"\",yylineno=0,yyleng=0,recovering=0,TERROR=2,EOF=1;var args=lstack.slice.call(arguments,1);var lexer=Object.create(this.lexer);var sharedState={yy:{}};for(var k in this.yy){if(Object.prototype.hasOwnProperty.call(this.yy,k)){sharedState.yy[k]=this.yy[k]}}lexer.setInput(input,sharedState.yy);sharedState.yy.lexer=lexer;sharedState.yy.parser=this;if(typeof lexer.yylloc==\"undefined\"){lexer.yylloc={}}var yyloc=lexer.yylloc;lstack.push(yyloc);var ranges=lexer.options&&lexer.options.ranges;if(typeof sharedState.yy.parseError===\"function\"){this.parseError=sharedState.yy.parseError}else{this.parseError=Object.getPrototypeOf(this).parseError}function popStack(n){stack.length=stack.length-2*n;vstack.length=vstack.length-n;lstack.length=lstack.length-n}_token_stack:function lex(){var token;token=lexer.lex()||EOF;if(typeof token!==\"number\"){token=self.symbols_[token]||token}return token}var symbol,preErrorSymbol,state,action,a,r,yyval={},p,len,newState,expected;while(true){state=stack[stack.length-1];if(this.defaultActions[state]){action=this.defaultActions[state]}else{if(symbol===null||typeof symbol==\"undefined\"){symbol=lex()}action=table[state]&&table[state][symbol]}if(typeof action===\"undefined\"||!action.length||!action[0]){var errStr=\"\";expected=[];for(p in table[state]){if(this.terminals_[p]&&p>TERROR){expected.push(\"'\"+this.terminals_[p]+\"'\")}}if(lexer.showPosition){errStr=\"Parse error on line \"+(yylineno+1)+\":\\n\"+lexer.showPosition()+\"\\nExpecting \"+expected.join(\", \")+\", got '\"+(this.terminals_[symbol]||symbol)+\"'\"}else{errStr=\"Parse error on line \"+(yylineno+1)+\": Unexpected \"+(symbol==EOF?\"end of input\":\"'\"+(this.terminals_[symbol]||symbol)+\"'\")}this.parseError(errStr,{text:lexer.match,token:this.terminals_[symbol]||symbol,line:lexer.yylineno,loc:yyloc,expected:expected})}if(action[0]instanceof Array&&action.length>1){throw new Error(\"Parse Error: multiple actions possible at state: \"+state+\", token: \"+symbol)}switch(action[0]){case 1:stack.push(symbol);vstack.push(lexer.yytext);lstack.push(lexer.yylloc);stack.push(action[1]);symbol=null;if(!preErrorSymbol){yyleng=lexer.yyleng;yytext=lexer.yytext;yylineno=lexer.yylineno;yyloc=lexer.yylloc;if(recovering>0){recovering--}}else{symbol=preErrorSymbol;preErrorSymbol=null}break;case 2:len=this.productions_[action[1]][1];yyval.$=vstack[vstack.length-len];yyval._$={first_line:lstack[lstack.length-(len||1)].first_line,last_line:lstack[lstack.length-1].last_line,first_column:lstack[lstack.length-(len||1)].first_column,last_column:lstack[lstack.length-1].last_column};if(ranges){yyval._$.range=[lstack[lstack.length-(len||1)].range[0],lstack[lstack.length-1].range[1]]}r=this.performAction.apply(yyval,[yytext,yyleng,yylineno,sharedState.yy,action[1],vstack,lstack].concat(args));if(typeof r!==\"undefined\"){return r}if(len){stack=stack.slice(0,-1*len*2);vstack=vstack.slice(0,-1*len);lstack=lstack.slice(0,-1*len)}stack.push(this.productions_[action[1]][0]);vstack.push(yyval.$);lstack.push(yyval._$);newState=table[stack[stack.length-2]][stack[stack.length-1]];stack.push(newState);break;case 3:return true}}return true}};var lexer=function(){var lexer={EOF:1,parseError:function parseError(str,hash){if(this.yy.parser){this.yy.parser.parseError(str,hash)}else{throw new Error(str)}},setInput:function(input,yy){this.yy=yy||this.yy||{};this._input=input;this._more=this._backtrack=this.done=false;this.yylineno=this.yyleng=0;this.yytext=this.matched=this.match=\"\";this.conditionStack=[\"INITIAL\"];this.yylloc={first_line:1,first_column:0,last_line:1,last_column:0};if(this.options.ranges){this.yylloc.range=[0,0]}this.offset=0;return this},input:function(){var ch=this._input[0];this.yytext+=ch;this.yyleng++;this.offset++;this.match+=ch;this.matched+=ch;var lines=ch.match(/(?:\\r\\n?|\\n).*/g);if(lines){this.yylineno++;this.yylloc.last_line++}else{this.yylloc.last_column++}if(this.options.ranges){this.yylloc.range[1]++}this._input=this._input.slice(1);return ch},unput:function(ch){var len=ch.length;var lines=ch.split(/(?:\\r\\n?|\\n)/g);this._input=ch+this._input;this.yytext=this.yytext.substr(0,this.yytext.length-len);this.offset-=len;var oldLines=this.match.split(/(?:\\r\\n?|\\n)/g);this.match=this.match.substr(0,this.match.length-1);this.matched=this.matched.substr(0,this.matched.length-1);if(lines.length-1){this.yylineno-=lines.length-1}var r=this.yylloc.range;this.yylloc={first_line:this.yylloc.first_line,last_line:this.yylineno+1,first_column:this.yylloc.first_column,last_column:lines?(lines.length===oldLines.length?this.yylloc.first_column:0)+oldLines[oldLines.length-lines.length].length-lines[0].length:this.yylloc.first_column-len};if(this.options.ranges){this.yylloc.range=[r[0],r[0]+this.yyleng-len]}this.yyleng=this.yytext.length;return this},more:function(){this._more=true;return this},reject:function(){if(this.options.backtrack_lexer){this._backtrack=true}else{return this.parseError(\"Lexical error on line \"+(this.yylineno+1)+\". You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).\\n\"+this.showPosition(),{text:\"\",token:null,line:this.yylineno})}return this},less:function(n){this.unput(this.match.slice(n))},pastInput:function(){var past=this.matched.substr(0,this.matched.length-this.match.length);return(past.length>20?\"...\":\"\")+past.substr(-20).replace(/\\n/g,\"\")},upcomingInput:function(){var next=this.match;if(next.length<20){next+=this._input.substr(0,20-next.length)}return(next.substr(0,20)+(next.length>20?\"...\":\"\")).replace(/\\n/g,\"\")},showPosition:function(){var pre=this.pastInput();var c=new Array(pre.length+1).join(\"-\");return pre+this.upcomingInput()+\"\\n\"+c+\"^\"},test_match:function(match,indexed_rule){var token,lines,backup;if(this.options.backtrack_lexer){backup={yylineno:this.yylineno,yylloc:{first_line:this.yylloc.first_line,last_line:this.last_line,first_column:this.yylloc.first_column,last_column:this.yylloc.last_column},yytext:this.yytext,match:this.match,matches:this.matches,matched:this.matched,yyleng:this.yyleng,offset:this.offset,_more:this._more,_input:this._input,yy:this.yy,conditionStack:this.conditionStack.slice(0),done:this.done};if(this.options.ranges){backup.yylloc.range=this.yylloc.range.slice(0)}}lines=match[0].match(/(?:\\r\\n?|\\n).*/g);if(lines){this.yylineno+=lines.length}this.yylloc={first_line:this.yylloc.last_line,last_line:this.yylineno+1,first_column:this.yylloc.last_column,last_column:lines?lines[lines.length-1].length-lines[lines.length-1].match(/\\r?\\n?/)[0].length:this.yylloc.last_column+match[0].length};this.yytext+=match[0];this.match+=match[0];this.matches=match;this.yyleng=this.yytext.length;if(this.options.ranges){this.yylloc.range=[this.offset,this.offset+=this.yyleng]}this._more=false;this._backtrack=false;this._input=this._input.slice(match[0].length);this.matched+=match[0];token=this.performAction.call(this,this.yy,this,indexed_rule,this.conditionStack[this.conditionStack.length-1]);if(this.done&&this._input){this.done=false}if(token){return token}else if(this._backtrack){for(var k in backup){this[k]=backup[k]}return false}return false},next:function(){if(this.done){return this.EOF}if(!this._input){this.done=true}var token,match,tempMatch,index;if(!this._more){this.yytext=\"\";this.match=\"\"}var rules=this._currentRules();for(var i=0;i<rules.length;i++){tempMatch=this._input.match(this.rules[rules[i]]);if(tempMatch&&(!match||tempMatch[0].length>match[0].length)){match=tempMatch;index=i;if(this.options.backtrack_lexer){token=this.test_match(tempMatch,rules[i]);if(token!==false){return token}else if(this._backtrack){match=false;continue}else{return false}}else if(!this.options.flex){break}}}if(match){token=this.test_match(match,rules[index]);if(token!==false){return token}return false}if(this._input===\"\"){return this.EOF}else{return this.parseError(\"Lexical error on line \"+(this.yylineno+1)+\". Unrecognized text.\\n\"+this.showPosition(),{text:\"\",token:null,line:this.yylineno})}},lex:function lex(){var r=this.next();if(r){return r}else{return this.lex()}},begin:function begin(condition){this.conditionStack.push(condition)},popState:function popState(){var n=this.conditionStack.length-1;if(n>0){return this.conditionStack.pop()}else{return this.conditionStack[0]}},_currentRules:function _currentRules(){if(this.conditionStack.length&&this.conditionStack[this.conditionStack.length-1]){return this.conditions[this.conditionStack[this.conditionStack.length-1]].rules}else{return this.conditions[\"INITIAL\"].rules}},topState:function topState(n){n=this.conditionStack.length-1-Math.abs(n||0);if(n>=0){return this.conditionStack[n]}else{return\"INITIAL\"}},pushState:function pushState(condition){this.begin(condition)},stateStackSize:function stateStackSize(){return this.conditionStack.length},options:{},performAction:function anonymous(yy,yy_,$avoiding_name_collisions,YY_START){var YYSTATE=YY_START;switch($avoiding_name_collisions){case 0:return 5;break;case 1:break;case 2:return 8;break;case 3:return 16;break;case 4:return 17;break;case 5:return 11;break;case 6:return 10;break;case 7:return 9;break;case 8:return 14;break;case 9:return 15;break;case 10:return 12;break;case 11:return 7;break;case 12:return 7;break;case 13:return 7;break;case 14:return 13;break;case 15:return 13;break;case 16:return 13;break;case 17:return 13;break;case 18:return 13;break;case 19:return 13;break;case 20:return 13;break;case 21:return 13;break;case 22:return 7;break;case 23:return 7;break;case 24:return 13;break;case 25:return 13;break;case 26:return 13;break;case 27:return 7;break;case 28:return 13;break;case 29:return 13;break;case 30:return 13;break;case 31:return 7;break;case 32:return 7;break;case 33:return 13;break;case 34:return 13;break;case 35:return 13;break;case 36:return 7;break;case 37:return 13;break;case 38:return 7;break;case 39:return 7;break;case 40:return 7;break;case 41:return 7;break;case 42:return 7;break;case 43:return 7;break;case 44:return 7;break;case 45:return 7;break;case 46:return 7;break;case 47:return 7;break;case 48:return 7;break;case 49:return 7;break;case 50:return 7;break;case 51:return 13;break;case 52:return 7;break;case 53:return 7;break;case 54:return 7;break;case 55:return 13;break;case 56:return 7;break;case 57:return 7;break;case 58:return 7;break;case 59:return 13;break;case 60:return 7;break;case 61:return 13;break;case 62:return 7;break;case 63:return 7;break;case 64:return 7;break;case 65:return 7;break;case 66:return 7;break;case 67:return 7;break;case 68:return 7;break;case 69:return 7;break;case 70:return 7;break;case 71:return 7;break;case 72:return 7;break;case 73:return 7;break;case 74:return 7;break;case 75:return 7;break;case 76:return 7;break;case 77:return 7;break;case 78:return 7;break;case 79:return 7;break;case 80:return 7;break;case 81:return 7;break;case 82:return 7;break;case 83:return 7;break;case 84:return 7;break;case 85:return 7;break;case 86:return 7;break;case 87:return 7;break;case 88:return 7;break;case 89:return 7;break;case 90:return 7;break;case 91:return 7;break;case 92:return 7;break;case 93:return 7;break;case 94:return 7;break;case 95:return 7;break;case 96:return 7;break;case 97:return 7;break;case 98:return 7;break;case 99:return 7;break;case 100:return 7;break;case 101:return 7;break;case 102:return 7;break;case 103:return 7;break;case 104:return 7;break;case 105:return 7;break;case 106:return 7;break;case 107:return 7;break;case 108:return 7;break;case 109:return 7;break;case 110:return 7;break;case 111:return 7;break;case 112:return 7;break;case 113:return 7;break;case 114:return 7;break;case 115:return 7;break;case 116:return 7;break;case 117:return 7;break;case 118:return 7;break;case 119:return 7;break;case 120:return 7;break;case 121:return 7;break;case 122:return 7;break;case 123:return 7;break;case 124:return 7;break;case 125:return 7;break;case 126:return 7;break;case 127:return 7;break;case 128:return 7;break;case 129:return 7;break;case 130:return 7;break;case 131:return 7;break;case 132:return 7;break;case 133:return 7;break;case 134:return 7;break;case 135:return 7;break;case 136:return 7;break;case 137:return 7;break;case 138:return 7;break;case 139:return 7;break;case 140:return 7;break;case 141:return 7;break;case 142:return 7;break;case 143:return 7;break;case 144:return 7;break;case 145:return 7;break;case 146:return 7;break;case 147:return 7;break;case 148:return 7;break;case 149:return 7;break;case 150:return 7;break;case 151:return 7;break;case 152:return 7;break;case 153:return 7;break;case 154:return 7;break;case 155:return 7;break;case 156:return 7;break;case 157:return 7;break;case 158:return 7;break;case 159:return 7;break;case 160:return 7;break;case 161:return 7;break;case 162:return 7;break;case 163:return 7;break;case 164:return 7;break;case 165:return 7;break;case 166:return 7;break;case 167:return 7;break;case 168:return 7;break;case 169:return 7;break;case 170:return 7;break;case 171:return 7;break;case 172:return 7;break;case 173:return 7;break;case 174:return 7;break;case 175:return 7;break;case 176:return 7;break;case 177:return 7;break;case 178:return 7;break;case 179:return 7;break;case 180:return 7;break;case 181:return 7;break;case 182:return 7;break;case 183:return 7;break;case 184:return 7;break;case 185:return 7;break;case 186:return 7;break;case 187:return 7;break;case 188:return 7;break;case 189:return 7;break;case 190:return 7;break;case 191:return 7;break;case 192:return 7;break;case 193:return 7;break;case 194:return 7;break;case 195:return 7;break;case 196:return 7;break;case 197:return 7;break;case 198:return 7;break;case 199:return 7;break;case 200:return 7;break;case 201:return 7;break;case 202:return 7;break;case 203:return 7;break;case 204:return 7;break;case 205:return 7;break;case 206:return 7;break;case 207:return 7;break;case 208:return 7;break;case 209:return 7;break;case 210:return 7;break;case 211:return 7;break;case 212:return 7;break;case 213:return 7;break;case 214:return 7;break;case 215:return 7;break;case 216:return 7;break;case 217:return 7;break;case 218:return 7;break;case 219:return 7;break;case 220:return 7;break;case 221:return 7;break;case 222:return 7;break;case 223:return 7;break;case 224:return 7;break;case 225:return 7;break;case 226:return 7;break;case 227:return 7;break;case 228:return 7;break;case 229:return 7;break;case 230:return 7;break;case 231:return 7;break;case 232:return 7;break;case 233:return 7;break;case 234:return 7;break;case 235:return 7;break;case 236:return 7;break;case 237:return 7;break;case 238:return 7;break;case 239:return 7;break;case 240:return 7;break;case 241:return 7;break;case 242:return 7;break;case 243:return 7;break;case 244:return 7;break;case 245:return 7;break;case 246:return 7;break;case 247:return 7;break;case 248:return 7;break;case 249:return 7;break;case 250:return 7;break;case 251:return 7;break;case 252:return 7;break;case 253:return 7;break;case 254:return 7;break;case 255:return 7;break;case 256:return 7;break;case 257:return 7;break;case 258:return 7;break;case 259:return 7;break;case 260:return 7;break;case 261:return 7;break;case 262:return 7;break;case 263:return 7;break;case 264:return 7;break;case 265:return 7;break;case 266:return 7;break;case 267:return 7;break;case 268:return 7;break;case 269:return 7;break;case 270:return 7;break;case 271:return 7;break;case 272:return 7;break;case 273:return 7;break;case 274:return 7;break;case 275:return 7;break;case 276:return 7;break;case 277:return 7;break;case 278:return 7;break;case 279:return 7;break;case 280:return 7;break;case 281:return 7;break;case 282:return 7;break;case 283:return 7;break;case 284:return 7;break;case 285:return 7;break;case 286:return 7;break;case 287:return 7;break;case 288:return 7;break;case 289:return 7;break;case 290:return 7;break;case 291:return 7;break;case 292:return 7;break;case 293:return 7;break;case 294:return 7;break;case 295:return 7;break;case 296:return 7;break;case 297:return 7;break;case 298:return 7;break;case 299:return 7;break;case 300:return 7;break;case 301:return 7;break;case 302:return 7;break;case 303:return 7;break;case 304:return 7;break;case 305:return 7;break;case 306:return 7;break;case 307:return 7;break;case 308:return 7;break;case 309:return 7;break;case 310:return 7;break;case 311:return 7;break;case 312:return 7;break;case 313:return 7;break;case 314:return 7;break;case 315:return 7;break;case 316:return 7;break;case 317:return 7;break;case 318:return 7;break;case 319:return 7;break;case 320:return 7;break;case 321:return 7;break;case 322:return 7;break;case 323:return 7;break;case 324:return 7;break;case 325:return 7;break;case 326:return 7;break;case 327:return 7;break;case 328:return 7;break;case 329:return 7;break;case 330:return 7;break;case 331:return 7;break;case 332:return 7;break;case 333:return 7;break;case 334:return 7;break;case 335:return 7;break;case 336:return 7;break;case 337:return 7;break;case 338:return 7;break}},rules:[/^(?:$)/,/^(?:\\s+)/,/^(?:\\+)/,/^(?:\\()/,/^(?:\\))/,/^(?::)/,/^(?:DocumentRef-([0-9A-Za-z-+.]+))/,/^(?:LicenseRef-([0-9A-Za-z-+.]+))/,/^(?:AND)/,/^(?:OR)/,/^(?:WITH)/,/^(?:MPL-2\\.0-no-copyleft-exception)/,/^(?:CNRI-Python-GPL-Compatible)/,/^(?:BSD-3-Clause-Attribution)/,/^(?:WxWindows-exception-3\\.1)/,/^(?:Classpath-exception-2\\.0)/,/^(?:gnu-javamail-exception)/,/^(?:freertos-exception-2\\.0)/,/^(?:i2p-gpl-java-exception)/,/^(?:Autoconf-exception-2\\.0)/,/^(?:Nokia-Qt-exception-1\\.1)/,/^(?:Autoconf-exception-3\\.0)/,/^(?:zlib-acknowledgement)/,/^(?:BSD-2-Clause-FreeBSD)/,/^(?:u-boot-exception-2\\.0)/,/^(?:Bison-exception-2\\.2)/,/^(?:CLISP-exception-2\\.0)/,/^(?:BSD-2-Clause-NetBSD)/,/^(?:FLTK-exception-2\\.0)/,/^(?:eCos-exception-2\\.0)/,/^(?:Font-exception-2\\.0)/,/^(?:BSD-3-Clause-Clear)/,/^(?:BSD-3-Clause-LBNL)/,/^(?:GCC-exception-3\\.1)/,/^(?:Qwt-exception-1\\.0)/,/^(?:GCC-exception-2\\.0)/,/^(?:Artistic-1\\.0-Perl)/,/^(?:Libtool-exception)/,/^(?:Artistic-1\\.0-cl8)/,/^(?:CC-BY-NC-SA-4\\.0)/,/^(?:CC-BY-NC-SA-1\\.0)/,/^(?:CC-BY-NC-ND-4\\.0)/,/^(?:CC-BY-NC-SA-3\\.0)/,/^(?:CC-BY-NC-ND-3\\.0)/,/^(?:CC-BY-NC-SA-2\\.5)/,/^(?:CC-BY-NC-ND-2\\.0)/,/^(?:CC-BY-NC-ND-1\\.0)/,/^(?:CC-BY-NC-SA-2\\.0)/,/^(?:MIT-advertising)/,/^(?:BSD-4-Clause-UC)/,/^(?:CC-BY-NC-ND-2\\.5)/,/^(?:FLTK-exception)/,/^(?:SugarCRM-1\\.1\\.3)/,/^(?:CrystalStacker)/,/^(?:BSD-Protection)/,/^(?:LZMA-exception)/,/^(?:BitTorrent-1\\.1)/,/^(?:BitTorrent-1\\.0)/,/^(?:Frameworx-1\\.0)/,/^(?:mif-exception)/,/^(?:Interbase-1\\.0)/,/^(?:389-exception)/,/^(?:HaskellReport)/,/^(?:CC-BY-NC-3\\.0)/,/^(?:CC-BY-ND-4\\.0)/,/^(?:CC-BY-NC-1\\.0)/,/^(?:CC-BY-NC-2\\.0)/,/^(?:CC-BY-NC-2\\.5)/,/^(?:CC-BY-SA-4\\.0)/,/^(?:CC-BY-NC-4\\.0)/,/^(?:W3C-19980720)/,/^(?:BSD-4-Clause)/,/^(?:Artistic-1\\.0)/,/^(?:BSD-3-Clause)/,/^(?:CC-BY-ND-1\\.0)/,/^(?:BSD-2-Clause)/,/^(?:CC-BY-ND-2\\.0)/,/^(?:CC-BY-ND-2\\.5)/,/^(?:CC-BY-ND-3\\.0)/,/^(?:Artistic-2\\.0)/,/^(?:CC-BY-SA-1\\.0)/,/^(?:CC-BY-SA-2\\.0)/,/^(?:CC-BY-SA-2\\.5)/,/^(?:CC-BY-SA-3\\.0)/,/^(?:XFree86-1\\.1)/,/^(?:OLDAP-2\\.0\\.1)/,/^(?:bzip2-1\\.0\\.6)/,/^(?:OLDAP-2\\.2\\.1)/,/^(?:ImageMagick)/,/^(?:Unicode-TOU)/,/^(?:Adobe-Glyph)/,/^(?:CUA-OPL-1\\.0)/,/^(?:CNRI-Jython)/,/^(?:CNRI-Python)/,/^(?:bzip2-1\\.0\\.5)/,/^(?:OLDAP-2\\.2\\.2)/,/^(?:PostgreSQL)/,/^(?:Apache-1\\.1)/,/^(?:CECILL-1\\.0)/,/^(?:Apache-2\\.0)/,/^(?:Zimbra-1\\.4)/,/^(?:CECILL-1\\.1)/,/^(?:Zimbra-1\\.3)/,/^(?:Adobe-2006)/,/^(?:JasPer-2\\.0)/,/^(?:CECILL-2\\.0)/,/^(?:TORQUE-1\\.1)/,/^(?:CECILL-2\\.1)/,/^(?:Watcom-1\\.0)/,/^(?:Intel-ACPI)/,/^(?:ClArtistic)/,/^(?:Spencer-99)/,/^(?:Condor-1\\.1)/,/^(?:Spencer-94)/,/^(?:gSOAP-1\\.3b)/,/^(?:EUDatagrid)/,/^(?:Spencer-86)/,/^(?:Python-2\\.0)/,/^(?:RHeCos-1\\.1)/,/^(?:CATOSL-1\\.1)/,/^(?:Apache-1\\.0)/,/^(?:FreeImage)/,/^(?:SGI-B-1\\.1)/,/^(?:SGI-B-1\\.0)/,/^(?:SimPL-2\\.0)/,/^(?:Sleepycat)/,/^(?:Crossword)/,/^(?:ErlPL-1\\.1)/,/^(?:CPOL-1\\.02)/,/^(?:OLDAP-2\\.8)/,/^(?:OLDAP-2\\.7)/,/^(?:OLDAP-2\\.6)/,/^(?:CC-BY-1\\.0)/,/^(?:OLDAP-2\\.5)/,/^(?:OLDAP-2\\.4)/,/^(?:OLDAP-2\\.3)/,/^(?:SISSL-1\\.2)/,/^(?:Unlicense)/,/^(?:SGI-B-2\\.0)/,/^(?:OLDAP-2\\.2)/,/^(?:OLDAP-2\\.1)/,/^(?:CC-BY-2\\.5)/,/^(?:D-FSL-1\\.0)/,/^(?:LPPL-1\\.3a)/,/^(?:LPPL-1\\.3c)/,/^(?:OLDAP-2\\.0)/,/^(?:CC-BY-3\\.0)/,/^(?:Leptonica)/,/^(?:OLDAP-1\\.4)/,/^(?:OLDAP-1\\.3)/,/^(?:OLDAP-1\\.2)/,/^(?:OLDAP-1\\.1)/,/^(?:MakeIndex)/,/^(?:CC-BY-4\\.0)/,/^(?:NPOSL-3\\.0)/,/^(?:CC-BY-2\\.0)/,/^(?:PHP-3\\.01)/,/^(?:ANTLR-PD)/,/^(?:APSL-1\\.0)/,/^(?:MIT-enna)/,/^(?:IBM-pibs)/,/^(?:APSL-1\\.1)/,/^(?:APSL-1\\.2)/,/^(?:Beerware)/,/^(?:EUPL-1\\.0)/,/^(?:EUPL-1\\.1)/,/^(?:diffmark)/,/^(?:CDDL-1\\.0)/,/^(?:Zend-2\\.0)/,/^(?:CDDL-1\\.1)/,/^(?:CPAL-1\\.0)/,/^(?:APSL-2\\.0)/,/^(?:LPPL-1\\.0)/,/^(?:AGPL-1\\.0)/,/^(?:Giftware)/,/^(?:Abstyles)/,/^(?:LPPL-1\\.1)/,/^(?:LPPL-1\\.2)/,/^(?:Sendmail)/,/^(?:CECILL-B)/,/^(?:AGPL-3\\.0)/,/^(?:GFDL-1\\.1)/,/^(?:GFDL-1\\.2)/,/^(?:GFDL-1\\.3)/,/^(?:RPSL-1\\.0)/,/^(?:LPL-1\\.02)/,/^(?:CECILL-C)/,/^(?:Afmparse)/,/^(?:LGPL-2\\.1)/,/^(?:PDDL-1\\.0)/,/^(?:ODbL-1\\.0)/,/^(?:OCLC-2\\.0)/,/^(?:LGPL-3\\.0)/,/^(?:Newsletr)/,/^(?:Motosoto)/,/^(?:NBPL-1\\.0)/,/^(?:NASA-1\\.3)/,/^(?:LGPL-2\\.0)/,/^(?:FSFULLR)/,/^(?:MPL-2\\.0)/,/^(?:Multics)/,/^(?:AFL-1\\.1)/,/^(?:MPL-1\\.1)/,/^(?:AFL-1\\.2)/,/^(?:MPL-1\\.0)/,/^(?:AFL-2\\.0)/,/^(?:AFL-2\\.1)/,/^(?:AFL-3\\.0)/,/^(?:NPL-1\\.0)/,/^(?:NPL-1\\.1)/,/^(?:APL-1\\.0)/,/^(?:Aladdin)/,/^(?:AMDPLPA)/,/^(?:BSL-1\\.0)/,/^(?:Borceux)/,/^(?:Caldera)/,/^(?:MIT-CMU)/,/^(?:CPL-1\\.0)/,/^(?:ZPL-2\\.1)/,/^(?:ZPL-2\\.0)/,/^(?:ZPL-1\\.1)/,/^(?:CC0-1\\.0)/,/^(?:YPL-1\\.1)/,/^(?:LPL-1\\.0)/,/^(?:libtiff)/,/^(?:YPL-1\\.0)/,/^(?:Dotseqn)/,/^(?:Latex2e)/,/^(?:VSL-1\\.0)/,/^(?:VOSTROM)/,/^(?:UPL-1\\.0)/,/^(?:dvipdfm)/,/^(?:EPL-1\\.0)/,/^(?:ECL-1\\.0)/,/^(?:ECL-2\\.0)/,/^(?:SPL-1\\.0)/,/^(?:IPL-1\\.0)/,/^(?:EFL-1\\.0)/,/^(?:EFL-2\\.0)/,/^(?:OPL-1\\.0)/,/^(?:OSL-1\\.0)/,/^(?:OSL-1\\.1)/,/^(?:OSL-2\\.0)/,/^(?:OSL-2\\.1)/,/^(?:OSL-3\\.0)/,/^(?:OpenSSL)/,/^(?:PHP-3\\.0)/,/^(?:gnuplot)/,/^(?:Entessa)/,/^(?:GPL-3\\.0)/,/^(?:Eurosym)/,/^(?:psutils)/,/^(?:GPL-2\\.0)/,/^(?:QPL-1\\.0)/,/^(?:MIT-feh)/,/^(?:OFL-1\\.1)/,/^(?:GPL-1\\.0)/,/^(?:RPL-1\\.1)/,/^(?:RPL-1\\.5)/,/^(?:OFL-1\\.0)/,/^(?:Saxpath)/,/^(?:Bahyph)/,/^(?:RSA-MD)/,/^(?:Naumen)/,/^(?:NetCDF)/,/^(?:mpich2)/,/^(?:Glulxe)/,/^(?:APAFML)/,/^(?:psfrag)/,/^(?:Plexus)/,/^(?:SAX-PD)/,/^(?:MITNFA)/,/^(?:eGenix)/,/^(?:iMatix)/,/^(?:Imlib2)/,/^(?:Libpng)/,/^(?:xinetd)/,/^(?:LGPLLR)/,/^(?:Wsuipa)/,/^(?:SMLNJ)/,/^(?:RSCPL)/,/^(?:SISSL)/,/^(?:Rdisc)/,/^(?:Noweb)/,/^(?:Qhull)/,/^(?:Nunit)/,/^(?:GL2PS)/,/^(?:TMate)/,/^(?:MirOS)/,/^(?:MS-RL)/,/^(?:Intel)/,/^(?:MS-PL)/,/^(?:OGTSL)/,/^(?:WTFPL)/,/^(?:Nokia)/,/^(?:XSkat)/,/^(?:Glide)/,/^(?:FSFUL)/,/^(?:AMPAS)/,/^(?:Xerox)/,/^(?:0BSD)/,/^(?:Ruby)/,/^(?:JSON)/,/^(?:MTLL)/,/^(?:Cube)/,/^(?:Zlib)/,/^(?:NCSA)/,/^(?:TOSL)/,/^(?:Xnet)/,/^(?:DSDP)/,/^(?:HPND)/,/^(?:Barr)/,/^(?:SNIA)/,/^(?:ADSL)/,/^(?:NLPL)/,/^(?:Fair)/,/^(?:NOSL)/,/^(?:NGPL)/,/^(?:SCEA)/,/^(?:Zed)/,/^(?:DOC)/,/^(?:ICU)/,/^(?:Vim)/,/^(?:xpp)/,/^(?:OML)/,/^(?:AAL)/,/^(?:AML)/,/^(?:W3C)/,/^(?:ISC)/,/^(?:IPA)/,/^(?:X11)/,/^(?:MIT)/,/^(?:FTL)/,/^(?:IJG)/,/^(?:TCL)/,/^(?:SWL)/,/^(?:NTP)/,/^(?:Mup)/,/^(?:NRL)/],conditions:{INITIAL:{rules:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338],inclusive:true}}};return lexer}();parser.lexer=lexer;function Parser(){this.yy={}}Parser.prototype=parser;parser.Parser=Parser;return new Parser}();if(typeof require!==\"undefined\"&&typeof exports!==\"undefined\"){exports.parser=spdxparse;exports.Parser=spdxparse.Parser;exports.parse=function(){return spdxparse.parse.apply(spdxparse,arguments)};exports.main=function commonjsMain(args){if(!args[1]){console.log(\"Usage: \"+args[0]+\" FILE\");process.exit(1)}var source=require(\"fs\").readFileSync(require(\"path\").normalize(args[1]),\"utf8\");return exports.parser.parse(source)};if(typeof module!==\"undefined\"&&require.main===module){exports.main(process.argv.slice(1))}}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/validate-npm-package-license/node_modules/spdx-correct/index.js":"var licenseIDs = require('spdx-license-ids');\n\nfunction valid(string) {\n  return licenseIDs.indexOf(string) > -1;\n}\n\n// Common transpositions of license identifier acronyms\nvar transpositions = [\n  ['APGL', 'AGPL'],\n  ['Gpl', 'GPL'],\n  ['GLP', 'GPL'],\n  ['APL', 'Apache'],\n  ['ISD', 'ISC'],\n  ['GLP', 'GPL'],\n  ['IST', 'ISC'],\n  ['Claude', 'Clause'],\n  [' or later', '+'],\n  [' International', ''],\n  ['GNU', 'GPL'],\n  ['GUN', 'GPL'],\n  ['+', ''],\n  ['GNU GPL', 'GPL'],\n  ['GNU/GPL', 'GPL'],\n  ['GNU GLP', 'GPL'],\n  ['GNU General Public License', 'GPL'],\n  ['Gnu public license', 'GPL'],\n  ['GNU Public License', 'GPL'],\n  ['GNU GENERAL PUBLIC LICENSE', 'GPL'],\n  ['MTI', 'MIT'],\n  ['Mozilla Public License', 'MPL'],\n  ['WTH', 'WTF'],\n  ['-License', '']\n];\n\nvar TRANSPOSED = 0;\nvar CORRECT = 1;\n\n// Simple corrections to nearly valid identifiers.\nvar transforms = [\n  // e.g. 'mit'\n  function(argument) {\n    return argument.toUpperCase();\n  },\n  // e.g. 'MIT '\n  function(argument) {\n    return argument.trim();\n  },\n  // e.g. 'M.I.T.'\n  function(argument) {\n    return argument.replace(/\\./g, '');\n  },\n  // e.g. 'Apache- 2.0'\n  function(argument) {\n    return argument.replace(/\\s+/g, '');\n  },\n  // e.g. 'CC BY 4.0''\n  function(argument) {\n    return argument.replace(/\\s+/g, '-');\n  },\n  // e.g. 'LGPLv2.1'\n  function(argument) {\n    return argument.replace('v', '-');\n  },\n  // e.g. 'Apache 2.0'\n  function(argument) {\n    return argument.replace(/,?\\s*(\\d)/, '-$1');\n  },\n  // e.g. 'GPL 2'\n  function(argument) {\n    return argument.replace(/,?\\s*(\\d)/, '-$1.0');\n  },\n  // e.g. 'Apache Version 2.0'\n  function(argument) {\n    return argument.replace(/,?\\s*(V\\.|v\\.|V|v|Version|version)\\s*(\\d)/, '-$2');\n  },\n  // e.g. 'Apache Version 2'\n  function(argument) {\n    return argument.replace(/,?\\s*(V\\.|v\\.|V|v|Version|version)\\s*(\\d)/, '-$2.0');\n  },\n  // e.g. 'ZLIB'\n  function(argument) {\n    return argument[0].toUpperCase() + argument.slice(1);\n  },\n  // e.g. 'MPL/2.0'\n  function(argument) {\n    return argument.replace('/', '-');\n  },\n  // e.g. 'Apache 2'\n  function(argument) {\n    return argument\n      .replace(/\\s*V\\s*(\\d)/, '-$1')\n      .replace(/(\\d)$/, '$1.0');\n  },\n  // e.g. 'GPL-2.0-'\n  function(argument) {\n    return argument.slice(0, argument.length - 1);\n  },\n  // e.g. 'GPL2'\n  function(argument) {\n    return argument.replace(/(\\d)$/, '-$1.0');\n  },\n  // e.g. 'BSD 3'\n  function(argument) {\n    return argument.replace(/(-| )?(\\d)$/, '-$2-Clause');\n  },\n  // e.g. 'BSD clause 3'\n  function(argument) {\n    return argument.replace(/(-| )clause(-| )(\\d)/, '-$3-Clause');\n  },\n  // e.g. 'BY-NC-4.0'\n  function(argument) {\n    return 'CC-' + argument;\n  },\n  // e.g. 'BY-NC'\n  function(argument) {\n    return 'CC-' + argument + '-4.0';\n  },\n  // e.g. 'Attribution-NonCommercial'\n  function(argument) {\n    return argument\n      .replace('Attribution', 'BY')\n      .replace('NonCommercial', 'NC')\n      .replace('NoDerivatives', 'ND')\n      .replace(/ (\\d)/, '-$1')\n      .replace(/ ?International/, '');\n  },\n  // e.g. 'Attribution-NonCommercial'\n  function(argument) {\n    return 'CC-' +\n      argument\n      .replace('Attribution', 'BY')\n      .replace('NonCommercial', 'NC')\n      .replace('NoDerivatives', 'ND')\n      .replace(/ (\\d)/, '-$1')\n      .replace(/ ?International/, '') +\n      '-4.0';\n  }\n];\n\n// If all else fails, guess that strings containing certain substrings\n// meant to identify certain licenses.\nvar lastResorts = [\n  ['UNLI', 'Unlicense'],\n  ['WTF', 'WTFPL'],\n  ['2 CLAUSE', 'BSD-2-Clause'],\n  ['2-CLAUSE', 'BSD-2-Clause'],\n  ['3 CLAUSE', 'BSD-3-Clause'],\n  ['3-CLAUSE', 'BSD-3-Clause'],\n  ['AFFERO', 'AGPL-3.0'],\n  ['AGPL', 'AGPL-3.0'],\n  ['APACHE', 'Apache-2.0'],\n  ['ARTISTIC', 'Artistic-2.0'],\n  ['Affero', 'AGPL-3.0'],\n  ['BEER', 'Beerware'],\n  ['BOOST', 'BSL-1.0'],\n  ['BSD', 'BSD-2-Clause'],\n  ['ECLIPSE', 'EPL-1.0'],\n  ['FUCK', 'WTFPL'],\n  ['GNU', 'GPL-3.0'],\n  ['LGPL', 'LGPL-3.0'],\n  ['GPL', 'GPL-3.0'],\n  ['MIT', 'MIT'],\n  ['MPL', 'MPL-2.0'],\n  ['X11', 'X11'],\n  ['ZLIB', 'Zlib']\n];\n\nvar SUBSTRING = 0;\nvar IDENTIFIER = 1;\n\nvar validTransformation = function(identifier) {\n  for (var i = 0; i < transforms.length; i++) {\n    var transformed = transforms[i](identifier);\n    if (transformed !== identifier && valid(transformed)) {\n      return transformed;\n    }\n  }\n  return null;\n};\n\nvar validLastResort = function(identifier) {\n  var upperCased = identifier.toUpperCase();\n  for (var i = 0; i < lastResorts.length; i++) {\n    var lastResort = lastResorts[i];\n    if (upperCased.indexOf(lastResort[SUBSTRING]) > -1) {\n      return lastResort[IDENTIFIER];\n    }\n  }\n  return null;\n};\n\nvar anyCorrection = function(identifier, check) {\n  for (var i = 0; i < transpositions.length; i++) {\n    var transposition = transpositions[i];\n    var transposed = transposition[TRANSPOSED];\n    if (identifier.indexOf(transposed) > -1) {\n      var corrected = identifier.replace(\n        transposed,\n        transposition[CORRECT]\n      );\n      var checked = check(corrected);\n      if (checked !== null) {\n        return checked;\n      }\n    }\n  }\n  return null;\n};\n\nmodule.exports = function(identifier) {\n  identifier = identifier.replace(/\\+$/, '');\n  if (valid(identifier)) {\n    return identifier;\n  }\n  var transformed = validTransformation(identifier);\n  if (transformed !== null) {\n    return transformed;\n  }\n  transformed = anyCorrection(identifier, function(argument) {\n    if (valid(argument)) {\n      return argument;\n    }\n    return validTransformation(argument);\n  });\n  if (transformed !== null) {\n    return transformed;\n  }\n  transformed = validLastResort(identifier);\n  if (transformed !== null) {\n    return transformed;\n  }\n  transformed = anyCorrection(identifier, validLastResort);\n  if (transformed !== null) {\n    return transformed;\n  }\n  return null;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/hosted-git-info/index.js":"'use strict'\nvar url = require('url')\nvar gitHosts = require('./git-host-info.js')\nvar GitHost = module.exports = require('./git-host.js')\n\nvar protocolToRepresentationMap = {\n  'git+ssh': 'sshurl',\n  'git+https': 'https',\n  'ssh': 'sshurl',\n  'git': 'git'\n}\n\nfunction protocolToRepresentation (protocol) {\n  if (protocol.substr(-1) === ':') protocol = protocol.slice(0, -1)\n  return protocolToRepresentationMap[protocol] || protocol\n}\n\nvar authProtocols = {\n  'git:': true,\n  'https:': true,\n  'git+https:': true,\n  'http:': true,\n  'git+http:': true\n}\n\nmodule.exports.fromUrl = function (giturl, opts) {\n  if (giturl == null || giturl === '') return\n  var url = fixupUnqualifiedGist(\n    isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\n  )\n  var parsed = parseGitUrl(url)\n  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^/]*))[/](.+?)(?:[.]git)?($|#)'))\n  var matches = Object.keys(gitHosts).map(function (gitHostName) {\n    try {\n      var gitHostInfo = gitHosts[gitHostName]\n      var auth = null\n      if (parsed.auth && authProtocols[parsed.protocol]) {\n        auth = decodeURIComponent(parsed.auth)\n      }\n      var committish = parsed.hash ? decodeURIComponent(parsed.hash.substr(1)) : null\n      var user = null\n      var project = null\n      var defaultRepresentation = null\n      if (shortcutMatch && shortcutMatch[1] === gitHostName) {\n        user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\n        project = decodeURIComponent(shortcutMatch[3])\n        defaultRepresentation = 'shortcut'\n      } else {\n        if (parsed.host !== gitHostInfo.domain) return\n        if (!gitHostInfo.protocols_re.test(parsed.protocol)) return\n        if (!parsed.path) return\n        var pathmatch = gitHostInfo.pathmatch\n        var matched = parsed.path.match(pathmatch)\n        if (!matched) return\n        if (matched[1] != null) user = decodeURIComponent(matched[1])\n        if (matched[2] != null) project = decodeURIComponent(matched[2])\n        defaultRepresentation = protocolToRepresentation(parsed.protocol)\n      }\n      return new GitHost(gitHostName, user, auth, project, committish, defaultRepresentation, opts)\n    } catch (ex) {\n      if (!(ex instanceof URIError)) throw ex\n    }\n  }).filter(function (gitHostInfo) { return gitHostInfo })\n  if (matches.length !== 1) return\n  return matches[0]\n}\n\nfunction isGitHubShorthand (arg) {\n  // Note: This does not fully test the git ref format.\n  // See https://www.kernel.org/pub/software/scm/git/docs/git-check-ref-format.html\n  //\n  // The only way to do this properly would be to shell out to\n  // git-check-ref-format, and as this is a fast sync function,\n  // we don't want to do that.  Just let git fail if it turns\n  // out that the commit-ish is invalid.\n  // GH usernames cannot start with . or -\n  return /^[^:@%/\\s.-][^:@%/\\s]*[/][^:@\\s/%]+(?:#.*)?$/.test(arg)\n}\n\nfunction fixupUnqualifiedGist (giturl) {\n  // necessary for round-tripping gists\n  var parsed = url.parse(giturl)\n  if (parsed.protocol === 'gist:' && parsed.host && !parsed.path) {\n    return parsed.protocol + '/' + parsed.host\n  } else {\n    return giturl\n  }\n}\n\nfunction parseGitUrl (giturl) {\n  if (typeof giturl !== 'string') giturl = '' + giturl\n  var matched = giturl.match(/^([^@]+)@([^:/]+):[/]?((?:[^/]+[/])?[^/]+?)(?:[.]git)?(#.*)?$/)\n  if (!matched) return url.parse(giturl)\n  return {\n    protocol: 'git+ssh:',\n    slashes: true,\n    auth: matched[1],\n    host: matched[2],\n    port: null,\n    hostname: matched[2],\n    hash: matched[4],\n    search: null,\n    query: null,\n    pathname: '/' + matched[3],\n    path: '/' + matched[3],\n    href: 'git+ssh://' + matched[1] + '@' + matched[2] +\n          '/' + matched[3] + (matched[4] || '')\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/hosted-git-info/git-host-info.js":"'use strict'\n\nvar gitHosts = module.exports = {\n  github: {\n    // First two are insecure and generally shouldn't be used any more, but\n    // they are still supported.\n    'protocols': [ 'git', 'http', 'git+ssh', 'git+https', 'ssh', 'https' ],\n    'domain': 'github.com',\n    'treepath': 'tree',\n    'filetemplate': 'https://{auth@}raw.githubusercontent.com/{user}/{project}/{committish}/{path}',\n    'bugstemplate': 'https://{domain}/{user}/{project}/issues',\n    'gittemplate': 'git://{auth@}{domain}/{user}/{project}.git{#committish}',\n    'tarballtemplate': 'https://{domain}/{user}/{project}/archive/{committish}.tar.gz'\n  },\n  bitbucket: {\n    'protocols': [ 'git+ssh', 'git+https', 'ssh', 'https' ],\n    'domain': 'bitbucket.org',\n    'treepath': 'src',\n    'tarballtemplate': 'https://{domain}/{user}/{project}/get/{committish}.tar.gz'\n  },\n  gitlab: {\n    'protocols': [ 'git+ssh', 'git+https', 'ssh', 'https' ],\n    'domain': 'gitlab.com',\n    'treepath': 'tree',\n    'docstemplate': 'https://{domain}/{user}/{project}{/tree/committish}#README',\n    'bugstemplate': 'https://{domain}/{user}/{project}/issues',\n    'tarballtemplate': 'https://{domain}/{user}/{project}/repository/archive.tar.gz?ref={committish}'\n  },\n  gist: {\n    'protocols': [ 'git', 'git+ssh', 'git+https', 'ssh', 'https' ],\n    'domain': 'gist.github.com',\n    'pathmatch': /^[/](?:([^/]+)[/])?([a-z0-9]+)(?:[.]git)?$/,\n    'filetemplate': 'https://gist.githubusercontent.com/{user}/{project}/raw{/committish}/{path}',\n    'bugstemplate': 'https://{domain}/{project}',\n    'gittemplate': 'git://{domain}/{project}.git{#committish}',\n    'sshtemplate': 'git@{domain}:/{project}.git{#committish}',\n    'sshurltemplate': 'git+ssh://git@{domain}/{project}.git{#committish}',\n    'browsetemplate': 'https://{domain}/{project}{/committish}',\n    'docstemplate': 'https://{domain}/{project}{/committish}',\n    'httpstemplate': 'git+https://{domain}/{project}.git{#committish}',\n    'shortcuttemplate': '{type}:{project}{#committish}',\n    'pathtemplate': '{project}{#committish}',\n    'tarballtemplate': 'https://{domain}/{user}/{project}/archive/{committish}.tar.gz'\n  }\n}\n\nvar gitHostDefaults = {\n  'sshtemplate': 'git@{domain}:{user}/{project}.git{#committish}',\n  'sshurltemplate': 'git+ssh://git@{domain}/{user}/{project}.git{#committish}',\n  'browsetemplate': 'https://{domain}/{user}/{project}{/tree/committish}',\n  'docstemplate': 'https://{domain}/{user}/{project}{/tree/committish}#readme',\n  'httpstemplate': 'git+https://{auth@}{domain}/{user}/{project}.git{#committish}',\n  'filetemplate': 'https://{domain}/{user}/{project}/raw/{committish}/{path}',\n  'shortcuttemplate': '{type}:{user}/{project}{#committish}',\n  'pathtemplate': '{user}/{project}{#committish}',\n  'pathmatch': /^[/]([^/]+)[/]([^/]+?)(?:[.]git|[/])?$/\n}\n\nObject.keys(gitHosts).forEach(function (name) {\n  Object.keys(gitHostDefaults).forEach(function (key) {\n    if (gitHosts[name][key]) return\n    gitHosts[name][key] = gitHostDefaults[key]\n  })\n  gitHosts[name].protocols_re = RegExp('^(' +\n    gitHosts[name].protocols.map(function (protocol) {\n      return protocol.replace(/([\\\\+*{}()[\\]$^|])/g, '\\\\$1')\n    }).join('|') + '):$')\n})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/hosted-git-info/git-host.js":"'use strict'\nvar gitHosts = require('./git-host-info.js')\nvar extend = Object.assign || require('util')._extend\n\nvar GitHost = module.exports = function (type, user, auth, project, committish, defaultRepresentation, opts) {\n  var gitHostInfo = this\n  gitHostInfo.type = type\n  Object.keys(gitHosts[type]).forEach(function (key) {\n    gitHostInfo[key] = gitHosts[type][key]\n  })\n  gitHostInfo.user = user\n  gitHostInfo.auth = auth\n  gitHostInfo.project = project\n  gitHostInfo.committish = committish\n  gitHostInfo.default = defaultRepresentation\n  gitHostInfo.opts = opts || {}\n}\nGitHost.prototype = {}\n\nGitHost.prototype.hash = function () {\n  return this.committish ? '#' + this.committish : ''\n}\n\nGitHost.prototype._fill = function (template, opts) {\n  if (!template) return\n  var vars = extend({}, opts)\n  opts = extend(extend({}, this.opts), opts)\n  var self = this\n  Object.keys(this).forEach(function (key) {\n    if (self[key] != null && vars[key] == null) vars[key] = self[key]\n  })\n  var rawAuth = vars.auth\n  var rawComittish = vars.committish\n  Object.keys(vars).forEach(function (key) {\n    vars[key] = encodeURIComponent(vars[key])\n  })\n  vars['auth@'] = rawAuth ? rawAuth + '@' : ''\n  if (opts.noCommittish) {\n    vars['#committish'] = ''\n    vars['/tree/committish'] = ''\n    vars['/comittish'] = ''\n    vars.comittish = ''\n  } else {\n    vars['#committish'] = rawComittish ? '#' + rawComittish : ''\n    vars['/tree/committish'] = vars.committish\n                            ? '/' + vars.treepath + '/' + vars.committish\n                            : ''\n    vars['/committish'] = vars.committish ? '/' + vars.committish : ''\n    vars.committish = vars.committish || 'master'\n  }\n  var res = template\n  Object.keys(vars).forEach(function (key) {\n    res = res.replace(new RegExp('[{]' + key + '[}]', 'g'), vars[key])\n  })\n  if (opts.noGitPlus) {\n    return res.replace(/^git[+]/, '')\n  } else {\n    return res\n  }\n}\n\nGitHost.prototype.ssh = function (opts) {\n  return this._fill(this.sshtemplate, opts)\n}\n\nGitHost.prototype.sshurl = function (opts) {\n  return this._fill(this.sshurltemplate, opts)\n}\n\nGitHost.prototype.browse = function (opts) {\n  return this._fill(this.browsetemplate, opts)\n}\n\nGitHost.prototype.docs = function (opts) {\n  return this._fill(this.docstemplate, opts)\n}\n\nGitHost.prototype.bugs = function (opts) {\n  return this._fill(this.bugstemplate, opts)\n}\n\nGitHost.prototype.https = function (opts) {\n  return this._fill(this.httpstemplate, opts)\n}\n\nGitHost.prototype.git = function (opts) {\n  return this._fill(this.gittemplate, opts)\n}\n\nGitHost.prototype.shortcut = function (opts) {\n  return this._fill(this.shortcuttemplate, opts)\n}\n\nGitHost.prototype.path = function (opts) {\n  return this._fill(this.pathtemplate, opts)\n}\n\nGitHost.prototype.tarball = function (opts) {\n  return this._fill(this.tarballtemplate, opts)\n}\n\nGitHost.prototype.file = function (P, opts) {\n  return this._fill(this.filetemplate, extend({\n    path: P.replace(/^[/]+/g, '')\n  }, opts))\n}\n\nGitHost.prototype.getDefaultRepresentation = function () {\n  return this.default\n}\n\nGitHost.prototype.toString = function (opts) {\n  return (this[this.default] || this.sshurl).call(this, opts)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/normalize-package-data/node_modules/is-builtin-module/index.js":"'use strict';\nvar builtinModules = require('builtin-modules');\n\nmodule.exports = function (str) {\n\tif (typeof str !== 'string') {\n\t\tthrow new TypeError('Expected a string');\n\t}\n\n\treturn builtinModules.indexOf(str) !== -1;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/normalize-package-data/node_modules/is-builtin-module/node_modules/builtin-modules/index.js":"'use strict';\n\nvar blacklist = [\n\t'freelist',\n\t'sys'\n];\n\nmodule.exports = Object.keys(process.binding('natives')).filter(function (el) {\n\treturn !/^_|^internal|\\//.test(el) && blacklist.indexOf(el) === -1;\n}).sort();\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/normalize-package-data/lib/extract_description.js":"module.exports = extractDescription\n\n// Extracts description from contents of a readme file in markdown format\nfunction extractDescription (d) {\n  if (!d) return;\n  if (d === \"ERROR: No README data found!\") return;\n  // the first block of text before the first heading\n  // that isn't the first line heading\n  d = d.trim().split('\\n')\n  for (var s = 0; d[s] && d[s].trim().match(/^(#|$)/); s ++);\n  var l = d.length\n  for (var e = s + 1; e < l && d[e].trim(); e ++);\n  return d.slice(s, e).join(' ').trim()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/normalize-package-data/lib/make_warning.js":"var util = require(\"util\")\nvar messages = require(\"./warning_messages.json\")\n\nmodule.exports = function() {\n  var args = Array.prototype.slice.call(arguments, 0)\n  var warningName = args.shift()\n  if (warningName == \"typo\") {\n    return makeTypoWarning.apply(null,args)\n  }\n  else {\n    var msgTemplate = messages[warningName] ? messages[warningName] : warningName + \": '%s'\"\n    args.unshift(msgTemplate)\n    return util.format.apply(null, args)\n  }\n}\n\nfunction makeTypoWarning (providedName, probableName, field) {\n  if (field) {\n    providedName = field + \"['\" + providedName + \"']\"\n    probableName = field + \"['\" + probableName + \"']\"\n  }\n  return util.format(messages.typo, providedName, probableName)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read-package-json/node_modules/json-parse-helpfulerror/index.js":"'use strict';\n\nvar jju = require('jju');\n\nfunction parse(text, reviver) {\n    try {\n        return JSON.parse(text, reviver);\n    } catch (err) {\n        // we expect this to throw with a more informative message\n        jju.parse(text, {\n            mode: 'json',\n            reviver: reviver\n        });\n\n        // backup if jju is not as strict as JSON.parse; re-throw error\n        // data-dependent code path, I do not know how to cover it\n        throw err;\n    }\n}\n\nexports.parse = parse;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read-package-json/node_modules/json-parse-helpfulerror/node_modules/jju/index.js":"\nmodule.exports.__defineGetter__('parse', function() {\n\treturn require('./lib/parse').parse\n})\n\nmodule.exports.__defineGetter__('stringify', function() {\n\treturn require('./lib/stringify').stringify\n})\n\nmodule.exports.__defineGetter__('tokenize', function() {\n\treturn require('./lib/parse').tokenize\n})\n\nmodule.exports.__defineGetter__('update', function() {\n\treturn require('./lib/document').update\n})\n\nmodule.exports.__defineGetter__('analyze', function() {\n\treturn require('./lib/analyze').analyze\n})\n\nmodule.exports.__defineGetter__('utils', function() {\n\treturn require('./lib/utils')\n})\n\n/**package\n{ \"name\": \"jju\",\n  \"version\": \"0.0.0\",\n  \"dependencies\": {\"js-yaml\": \"*\"},\n  \"scripts\": {\"postinstall\": \"js-yaml package.yaml > package.json ; npm install\"}\n}\n**/\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/map-to-registry.js":"var url = require('url')\n\nvar log = require('npmlog')\nvar npa = require('npm-package-arg')\n\nmodule.exports = mapToRegistry\n\nfunction mapToRegistry (name, config, cb) {\n  log.silly('mapToRegistry', 'name', name)\n  var registry\n\n  // the name itself takes precedence\n  var data = npa(name)\n  if (data.scope) {\n    // the name is definitely scoped, so escape now\n    name = name.replace('/', '%2f')\n\n    log.silly('mapToRegistry', 'scope (from package name)', data.scope)\n\n    registry = config.get(data.scope + ':registry')\n    if (!registry) {\n      log.verbose('mapToRegistry', 'no registry URL found in name for scope', data.scope)\n    }\n  }\n\n  // ...then --scope=@scope or --scope=scope\n  var scope = config.get('scope')\n  if (!registry && scope) {\n    // I'm an enabler, sorry\n    if (scope.charAt(0) !== '@') scope = '@' + scope\n\n    log.silly('mapToRegistry', 'scope (from config)', scope)\n\n    registry = config.get(scope + ':registry')\n    if (!registry) {\n      log.verbose('mapToRegistry', 'no registry URL found in config for scope', scope)\n    }\n  }\n\n  // ...and finally use the default registry\n  if (!registry) {\n    log.silly('mapToRegistry', 'using default registry')\n    registry = config.get('registry')\n  }\n\n  log.silly('mapToRegistry', 'registry', registry)\n\n  var auth = config.getCredentialsByURI(registry)\n\n  // normalize registry URL so resolution doesn't drop a piece of registry URL\n  var normalized = registry.slice(-1) !== '/' ? registry + '/' : registry\n  var uri\n  log.silly('mapToRegistry', 'data', data)\n  if (data.type === 'remote') {\n    uri = data.spec\n  } else {\n    uri = url.resolve(normalized, name)\n  }\n\n  log.silly('mapToRegistry', 'uri', uri)\n\n  cb(null, uri, scopeAuth(uri, registry, auth), normalized)\n}\n\nfunction scopeAuth (uri, registry, auth) {\n  var cleaned = {\n    scope: auth.scope,\n    email: auth.email,\n    alwaysAuth: auth.alwaysAuth,\n    token: undefined,\n    username: undefined,\n    password: undefined,\n    auth: undefined\n  }\n\n  var requestHost\n  var registryHost\n\n  if (auth.token || auth.auth || (auth.username && auth.password)) {\n    requestHost = url.parse(uri).hostname\n    registryHost = url.parse(registry).hostname\n\n    if (requestHost === registryHost) {\n      cleaned.token = auth.token\n      cleaned.auth = auth.auth\n      cleaned.username = auth.username\n      cleaned.password = auth.password\n    } else if (auth.alwaysAuth) {\n      log.verbose('scopeAuth', 'alwaysAuth set for', registry)\n      cleaned.token = auth.token\n      cleaned.auth = auth.auth\n      cleaned.username = auth.username\n      cleaned.password = auth.password\n    } else {\n      log.silly('scopeAuth', uri, \"doesn't share host with registry\", registry)\n    }\n  }\n\n  return cleaned\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npm-package-arg/npa.js":"var url = require('url')\nvar assert = require('assert')\nvar util = require('util')\nvar semver = require('semver')\nvar HostedGit = require('hosted-git-info')\n\nmodule.exports = npa\n\nvar isWindows = process.platform === 'win32' || global.FAKE_WINDOWS\nvar slashRe = isWindows ? /\\\\|[/]/ : /[/]/\n\nvar parseName = /^(?:@([^/]+?)[/])?([^/]+?)$/\nvar nameAt = /^(@([^/]+?)[/])?([^/]+?)@/\nvar debug = util.debuglog\n  ? util.debuglog('npa')\n  : /\\bnpa\\b/i.test(process.env.NODE_DEBUG || '')\n    ? function () {\n      console.error('NPA: ' + util.format.apply(util, arguments).split('\\n').join('\\nNPA: '))\n    }\n    : function () {}\n\nfunction validName (name) {\n  if (!name) {\n    debug('not a name %j', name)\n    return false\n  }\n  var n = name.trim()\n  if (!n || n.charAt(0) === '.' ||\n    !n.match(/^[a-zA-Z0-9]/) ||\n    n.match(/[/()&?#|<>@:%\\s\\\\*'\"!~`]/) ||\n    n.toLowerCase() === 'node_modules' ||\n    n !== encodeURIComponent(n) ||\n    n.toLowerCase() === 'favicon.ico') {\n    debug('not a valid name %j', name)\n    return false\n  }\n  return n\n}\n\nfunction npa (arg) {\n  assert.equal(typeof arg, 'string')\n  arg = arg.trim()\n\n  var res = new Result()\n  res.raw = arg\n  res.scope = null\n  res.escapedName = null\n\n  // See if it's something like foo@...\n  var nameparse = arg.match(nameAt)\n  debug('nameparse', nameparse)\n  if (nameparse && validName(nameparse[3]) &&\n    (!nameparse[2] || validName(nameparse[2]))) {\n    res.name = (nameparse[1] || '') + nameparse[3]\n    res.escapedName = escapeName(res.name)\n    if (nameparse[2]) {\n      res.scope = '@' + nameparse[2]\n    }\n    arg = arg.substr(nameparse[0].length)\n  } else {\n    res.name = null\n  }\n\n  res.rawSpec = arg\n  res.spec = arg\n\n  var urlparse = url.parse(arg)\n  debug('urlparse', urlparse)\n\n  // windows paths look like urls\n  // don't be fooled!\n  if (isWindows && urlparse && urlparse.protocol &&\n    urlparse.protocol.match(/^[a-zA-Z]:$/)) {\n    debug('windows url-ish local path', urlparse)\n    urlparse = {}\n  }\n\n  if (urlparse.protocol || HostedGit.fromUrl(arg)) {\n    return parseUrl(res, arg, urlparse)\n  }\n\n  // at this point, it's not a url, and not hosted\n  // If it's a valid name, and doesn't already have a name, then assume\n  // $name@\"\" range\n  //\n  // if it's got / chars in it, then assume that it's local.\n\n  if (res.name) {\n    if (arg === '') arg = 'latest'\n    var version = semver.valid(arg, true)\n    var range = semver.validRange(arg, true)\n    // foo@...\n    if (version) {\n      res.spec = version\n      res.type = 'version'\n    } else if (range) {\n      res.spec = range\n      res.type = 'range'\n    } else if (slashRe.test(arg)) {\n      parseLocal(res, arg)\n    } else {\n      res.type = 'tag'\n      res.spec = arg\n    }\n  } else {\n    var p = arg.match(parseName)\n    if (p && validName(p[2]) &&\n      (!p[1] || validName(p[1]))) {\n      res.type = 'tag'\n      res.spec = 'latest'\n      res.rawSpec = ''\n      res.name = arg\n      res.escapedName = escapeName(res.name)\n      if (p[1]) {\n        res.scope = '@' + p[1]\n      }\n    } else {\n      parseLocal(res, arg)\n    }\n  }\n\n  return res\n}\n\nfunction escapeName (name) {\n  // scoped packages in couch must have slash url-encoded, e.g. @foo%2Fbar\n  return name && name.replace('/', '%2f')\n}\n\nfunction parseLocal (res, arg) {\n  // turns out nearly every character is allowed in fs paths\n  if (/\\0/.test(arg)) {\n    throw new Error('Invalid Path: ' + JSON.stringify(arg))\n  }\n  res.type = 'local'\n  res.spec = arg\n}\n\nfunction parseUrl (res, arg, urlparse) {\n  var gitHost = HostedGit.fromUrl(arg)\n  if (gitHost) {\n    res.type = 'hosted'\n    res.spec = gitHost.toString()\n    res.hosted = {\n      type: gitHost.type,\n      ssh: gitHost.ssh(),\n      sshUrl: gitHost.sshurl(),\n      httpsUrl: gitHost.https(),\n      gitUrl: gitHost.git(),\n      shortcut: gitHost.shortcut(),\n      directUrl: gitHost.file('package.json')\n    }\n    return res\n  }\n  // check the protocol, and then see if it's git or not\n  switch (urlparse.protocol) {\n    case 'git:':\n    case 'git+http:':\n    case 'git+https:':\n    case 'git+rsync:':\n    case 'git+ftp:':\n    case 'git+ssh:':\n    case 'git+file:':\n      res.type = 'git'\n      res.spec = arg.replace(/^git[+]/, '')\n      break\n\n    case 'http:':\n    case 'https:':\n      res.type = 'remote'\n      res.spec = arg\n      break\n\n    case 'file:':\n      res.type = 'local'\n      if (isWindows && arg.match(/^file:\\/\\/\\/?[a-z]:/i)) {\n        // Windows URIs usually parse all wrong, so we just take matters\n        // into our own hands, in this case.\n        res.spec = arg.replace(/^file:\\/\\/\\/?/i, '')\n      } else {\n        res.spec = urlparse.pathname\n      }\n      break\n\n    default:\n      throw new Error('Unsupported URL Type: ' + arg)\n  }\n\n  return res\n}\n\nfunction Result () {\n  if (!(this instanceof Result)) return new Result()\n}\nResult.prototype.name = null\nResult.prototype.type = null\nResult.prototype.spec = null\nResult.prototype.raw = null\nResult.prototype.hosted = null\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/whoami.js":"var npm = require('./npm.js')\nvar output = require('./utils/output.js')\n\nmodule.exports = whoami\n\nwhoami.usage = 'npm whoami [--registry <registry>]\\n(just prints username according to given registry)'\n\nfunction whoami (args, silent, cb) {\n  // FIXME: need tighter checking on this, but is a breaking change\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n\n  var registry = npm.config.get('registry')\n  if (!registry) return cb(new Error('no default registry set'))\n\n  var auth = npm.config.getCredentialsByURI(registry)\n  if (auth) {\n    if (auth.username) {\n      if (!silent) output(auth.username)\n      return process.nextTick(cb.bind(this, null, auth.username))\n    } else if (auth.token) {\n      return npm.registry.whoami(registry, { auth: auth }, function (er, username) {\n        if (er) return cb(er)\n        if (!username) {\n          var needNewSession = new Error(\n            'Your auth token is no longer valid. Please log in again.'\n          )\n          needNewSession.code = 'ENEEDAUTH'\n          return cb(needNewSession)\n        }\n\n        if (!silent) output(username)\n        cb(null, username)\n      })\n    }\n  }\n\n  // At this point, if they have a credentials object, it doesn't have a token\n  // or auth in it.  Probably just the default registry.\n  var needAuth = new Error(\n    'this command requires you to be logged in.'\n  )\n  needAuth.code = 'ENEEDAUTH'\n  process.nextTick(cb.bind(this, needAuth))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/adduser.js":"module.exports = adduser\n\nvar log = require('npmlog')\nvar npm = require('./npm.js')\nvar usage = require('./utils/usage')\nvar crypto\n\ntry {\n  crypto = require('crypto')\n} catch (ex) {}\n\nadduser.usage = usage(\n  'adduser',\n  'npm adduser [--registry=url] [--scope=@orgname] [--auth-type=legacy] [--always-auth]'\n)\n\nfunction adduser (args, cb) {\n  if (!crypto) {\n    return cb(new Error(\n    'You must compile node with ssl support to use the adduser feature'\n    ))\n  }\n\n  var registry = npm.config.get('registry')\n  var scope = npm.config.get('scope')\n  var creds = npm.config.getCredentialsByURI(npm.config.get('registry'))\n\n  if (scope) {\n    var scopedRegistry = npm.config.get(scope + ':registry')\n    var cliRegistry = npm.config.get('registry', 'cli')\n    if (scopedRegistry && !cliRegistry) registry = scopedRegistry\n  }\n\n  log.disableProgress()\n\n  try {\n    var auth = require('./auth/' + npm.config.get('auth-type'))\n  } catch (e) {\n    return cb(new Error('no such auth module'))\n  }\n  auth.login(creds, registry, scope, function (err, newCreds) {\n    if (err) return cb(err)\n\n    npm.config.del('_token', 'user') // prevent legacy pollution\n    if (scope) npm.config.set(scope + ':registry', registry, 'user')\n    npm.config.setCredentialsByURI(registry, newCreds)\n    npm.config.save('user', cb)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/usage.js":"'use strict'\nvar aliases = require('../config/cmd-list').aliases\n\nmodule.exports = function usage (cmd, txt, opt) {\n  var post = Object.keys(aliases).reduce(function (p, c) {\n    var val = aliases[c]\n    if (val !== cmd) return p\n    return p.concat(c)\n  }, [])\n\n  if (opt || post.length > 0) txt += '\\n\\n'\n\n  if (post.length === 1) {\n    txt += 'alias: '\n    txt += post.join(', ')\n  } else if (post.length > 1) {\n    txt += 'aliases: '\n    txt += post.join(', ')\n  }\n\n  if (opt) {\n    if (post.length > 0) txt += '\\n'\n    txt += 'common options: ' + opt\n  }\n\n  return txt\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/bugs.js":"module.exports = bugs\n\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar opener = require('opener')\nvar fetchPackageMetadata = require('./fetch-package-metadata.js')\nvar usage = require('./utils/usage')\n\nbugs.usage = usage(\n  'bugs',\n  'npm bugs [<pkgname>]'\n)\n\nbugs.completion = function (opts, cb) {\n  // FIXME: there used to be registry completion here, but it stopped making\n  // sense somewhere around 50,000 packages on the registry\n  cb()\n}\n\nfunction bugs (args, cb) {\n  var n = args.length ? args[0] : '.'\n  fetchPackageMetadata(n, '.', {fullMetadata: true}, function (er, d) {\n    if (er) return cb(er)\n\n    var url = d.bugs && ((typeof d.bugs === 'string') ? d.bugs : d.bugs.url)\n    if (!url) {\n      url = 'https://www.npmjs.org/package/' + d.name\n    }\n    log.silly('bugs', 'url', url)\n    opener(url, { command: npm.config.get('browser') }, cb)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/opener/opener.js":"#!/usr/bin/env node\n\n\"use strict\";\n\nvar childProcess = require(\"child_process\");\n\nfunction opener(args, options, callback) {\n    // http://stackoverflow.com/q/1480971/3191, but see below for Windows.\n    var command = process.platform === \"win32\" ? \"cmd\" :\n                  process.platform === \"darwin\" ? \"open\" :\n                  \"xdg-open\";\n\n    if (typeof args === \"string\") {\n        args = [args];\n    }\n\n    if (typeof options === \"function\") {\n        callback = options;\n        options = {};\n    }\n\n    if (options && typeof options === \"object\" && options.command) {\n        if (process.platform === \"win32\") {\n            // *always* use cmd on windows\n            args = [options.command].concat(args);\n        } else {\n            command = options.command;\n        }\n    }\n\n    if (process.platform === \"win32\") {\n        // On Windows, we really want to use the \"start\" command. But, the rules regarding arguments with spaces, and\n        // escaping them with quotes, can get really arcane. So the easiest way to deal with this is to pass off the\n        // responsibility to \"cmd /c\", which has that logic built in.\n        //\n        // Furthermore, if \"cmd /c\" double-quoted the first parameter, then \"start\" will interpret it as a window title,\n        // so we need to add a dummy empty-string window title: http://stackoverflow.com/a/154090/3191\n        //\n        // Additionally, on Windows ampersand needs to be escaped when passed to \"start\"\n        args = args.map(function(value) {\n            return value.replace(/&/g, '^&');\n        });\n        args = [\"/c\", \"start\", '\"\"'].concat(args);\n    }\n\n    return childProcess.execFile(command, args, options, callback);\n}\n\n// Export `opener` for programmatic access.\n// You might use this to e.g. open a website: `opener(\"http://google.com\")`\nmodule.exports = opener;\n\n// If we're being called from the command line, just execute, using the command-line arguments.\nif (require.main && require.main.id === module.id) {\n    opener(process.argv.slice(2), function (error) {\n        if (error) {\n            throw error;\n        }\n    });\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/fetch-package-metadata.js":"'use strict'\nvar fs = require('graceful-fs')\nvar path = require('path')\nvar zlib = require('zlib')\n\nvar log = require('npmlog')\nvar realizePackageSpecifier = require('realize-package-specifier')\nvar tar = require('tar')\nvar once = require('once')\nvar semver = require('semver')\nvar readPackageTree = require('read-package-tree')\nvar readPackageJson = require('read-package-json')\nvar iferr = require('iferr')\nvar rimraf = require('rimraf')\nvar clone = require('lodash.clonedeep')\nvar validate = require('aproba')\nvar unpipe = require('unpipe')\nvar normalizePackageData = require('normalize-package-data')\nvar limit = require('call-limit')\n\nvar npm = require('./npm.js')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar cache = require('./cache.js')\nvar cachedPackageRoot = require('./cache/cached-package-root.js')\nvar tempFilename = require('./utils/temp-filename.js')\nvar getCacheStat = require('./cache/get-stat.js')\nvar unpack = require('./utils/tar.js').unpack\nvar pulseTillDone = require('./utils/pulse-till-done.js')\nvar parseJSON = require('./utils/parse-json.js')\nvar pickManifestFromRegistryMetadata = require('./utils/pick-manifest-from-registry-metadata.js')\n\nfunction andLogAndFinish (spec, tracker, done) {\n  validate('SF', [spec, done])\n  return function (er, pkg) {\n    if (er) {\n      log.silly('fetchPackageMetaData', 'error for ' + spec, er)\n      if (tracker) tracker.finish()\n    }\n    return done(er, pkg)\n  }\n}\n\nmodule.exports = limit(fetchPackageMetadata, npm.limit.fetch)\n\nfunction fetchPackageMetadata (spec, where, opts, done) {\n  validate('SSOF|SSFZ|OSOF|OSFZ', [spec, where, opts, done])\n\n  if (!done) {\n    done = opts\n    opts = {}\n  }\n  var tracker = opts.tracker\n  if (typeof spec === 'object') {\n    var dep = spec\n    spec = dep.raw\n  }\n  var logAndFinish = andLogAndFinish(spec, tracker, done)\n  if (!dep) {\n    log.silly('fetchPackageMetaData', spec)\n    return realizePackageSpecifier(spec, where, iferr(logAndFinish, function (dep) {\n      fetchPackageMetadata(dep, where, {tracker: tracker}, done)\n    }))\n  }\n  if (dep.type === 'version' || dep.type === 'range' || dep.type === 'tag') {\n    fetchNamedPackageData(dep, opts, addRequestedAndFinish)\n  } else if (dep.type === 'directory') {\n    fetchDirectoryPackageData(dep, where, addRequestedAndFinish)\n  } else {\n    fetchOtherPackageData(spec, dep, where, addRequestedAndFinish)\n  }\n  function addRequestedAndFinish (er, pkg) {\n    if (pkg) annotateMetadata(pkg, dep, spec, where)\n    logAndFinish(er, pkg)\n  }\n}\n\nvar annotateMetadata = module.exports.annotateMetadata = function (pkg, requested, spec, where) {\n  validate('OOSS', arguments)\n  pkg._requested = requested\n  pkg._spec = spec\n  pkg._where = where\n  if (!pkg._args) pkg._args = []\n  pkg._args.push([requested, where])\n  // non-npm registries can and will return unnormalized data, plus\n  // even the npm registry may have package data normalized with older\n  // normalization rules. This ensures we get package data in a consistent,\n  // stable format.\n  try {\n    normalizePackageData(pkg)\n  } catch (ex) {\n    // don't care\n  }\n}\n\nfunction fetchOtherPackageData (spec, dep, where, next) {\n  validate('SOSF', arguments)\n  log.silly('fetchOtherPackageData', spec)\n  cache.add(spec, null, where, false, iferr(next, function (pkg) {\n    var result = clone(pkg)\n    result._inCache = true\n    next(null, result)\n  }))\n}\n\nfunction fetchDirectoryPackageData (dep, where, next) {\n  validate('OSF', arguments)\n  log.silly('fetchDirectoryPackageData', dep.name || dep.rawSpec)\n  readPackageJson(path.join(dep.spec, 'package.json'), false, next)\n}\n\nvar regCache = {}\n\nfunction fetchNamedPackageData (dep, opts, next) {\n  validate('OOF', arguments)\n  log.silly('fetchNamedPackageData', dep.name || dep.rawSpec)\n  mapToRegistry(dep.name || dep.rawSpec, npm.config, iferr(next, function (url, auth) {\n    if (regCache[url]) {\n      pickVersionFromRegistryDocument(clone(regCache[url]))\n    } else {\n      var fullMetadata = opts.fullMetadata == null ? true : opts.fullMetadata\n      npm.registry.get(url, {auth: auth, fullMetadata: fullMetadata}, pulseTillDone('fetchMetadata', iferr(next, pickVersionFromRegistryDocument)))\n    }\n    function thenAddMetadata (pkg) {\n      pkg._from = dep.raw\n      pkg._resolved = pkg.dist.tarball\n      pkg._shasum = pkg.dist.shasum\n\n      next(null, pkg)\n    }\n    function pickVersionFromRegistryDocument (pkg) {\n      if (!regCache[url]) regCache[url] = pkg\n      var versions = Object.keys(pkg.versions)\n\n      var invalidVersions = versions.filter(function (v) { return !semver.valid(v) })\n      if (invalidVersions.length > 0) {\n        log.warn('pickVersion', 'The package %s has invalid semver-version(s): %s. This usually only happens for unofficial private registries. ' +\n            'You should delete or re-publish the invalid versions.', pkg.name, invalidVersions.join(', '))\n      }\n\n      versions = versions.filter(function (v) { return semver.valid(v) })\n\n      if (dep.type === 'tag') {\n        var tagVersion = pkg['dist-tags'][dep.spec]\n        if (pkg.versions[tagVersion]) return thenAddMetadata(pkg.versions[tagVersion])\n      } else {\n        var picked = pickManifestFromRegistryMetadata(dep.spec, npm.config.get('tag'), versions, pkg)\n        if (picked) return thenAddMetadata(picked.manifest)\n      }\n\n      // We didn't manage to find a compatible version\n      // If this package was requested from cache, force hitting the network\n      if (pkg._cached) {\n        log.silly('fetchNamedPackageData', 'No valid target from cache, forcing network')\n        return npm.registry.get(url, {\n          auth: auth,\n          skipCache: true\n        }, pulseTillDone('fetchMetadata', iferr(next, pickVersionFromRegistryDocument)))\n      }\n\n      // And failing that, we error out\n      var targets = versions.length\n                  ? 'Valid install targets:\\n' + versions.join(', ') + '\\n'\n                  : 'No valid targets found.'\n      var er = new Error('No compatible version found: ' +\n                         dep.raw + '\\n' + targets)\n      er.code = 'ETARGET'\n      return next(er)\n    }\n  }))\n}\n\nfunction retryWithCached (pkg, asserter, next) {\n  if (!pkg._inCache) {\n    cache.add(pkg._spec, null, pkg._where, false, iferr(next, function (newpkg) {\n      Object.keys(newpkg).forEach(function (key) {\n        if (key[0] !== '_') return\n        pkg[key] = newpkg[key]\n      })\n      pkg._inCache = true\n      return asserter(pkg, next)\n    }))\n  }\n  return !pkg._inCache\n}\n\nmodule.exports.addShrinkwrap = function addShrinkwrap (pkg, next) {\n  validate('OF', arguments)\n  if (pkg._shrinkwrap !== undefined) return next(null, pkg)\n  if (pkg._hasShrinkwrap === false) {\n    pkg._shrinkwrap = null\n    return next(null, pkg)\n  }\n  if (retryWithCached(pkg, addShrinkwrap, next)) return\n  pkg._shrinkwrap = null\n  // FIXME: cache the shrinkwrap directly\n  var pkgname = pkg.name\n  var ver = pkg.version\n  var tarball = path.join(cachedPackageRoot({name: pkgname, version: ver}), 'package.tgz')\n  untarStream(tarball, function (er, untar) {\n    if (er) {\n      if (er.code === 'ENOTTARBALL') {\n        pkg._shrinkwrap = null\n        return next()\n      } else {\n        return next(er)\n      }\n    }\n    if (er) return next(er)\n    var foundShrinkwrap = false\n    untar.on('entry', function (entry) {\n      if (!/^(?:[^\\/]+[\\/])npm-shrinkwrap.json$/.test(entry.path)) return\n      log.silly('addShrinkwrap', 'Found shrinkwrap in ' + pkgname + ' ' + entry.path)\n      foundShrinkwrap = true\n      var shrinkwrap = ''\n      entry.on('data', function (chunk) {\n        shrinkwrap += chunk\n      })\n      entry.on('end', function () {\n        untar.close()\n        log.silly('addShrinkwrap', 'Completed reading shrinkwrap in ' + pkgname)\n        try {\n          pkg._shrinkwrap = parseJSON(shrinkwrap)\n        } catch (ex) {\n          var er = new Error('Error parsing ' + pkgname + '@' + ver + \"'s npm-shrinkwrap.json: \" + ex.message)\n          er.type = 'ESHRINKWRAP'\n          return next(er)\n        }\n        next(null, pkg)\n      })\n      entry.resume()\n    })\n    untar.on('end', function () {\n      if (!foundShrinkwrap) {\n        pkg._shrinkwrap = null\n        next(null, pkg)\n      }\n    })\n  })\n}\n\nmodule.exports.addBundled = function addBundled (pkg, next) {\n  validate('OF', arguments)\n  if (pkg._bundled !== undefined) return next(null, pkg)\n  if (!pkg.bundleDependencies) return next(null, pkg)\n  if (retryWithCached(pkg, addBundled, next)) return\n  pkg._bundled = null\n  var pkgname = pkg.name\n  var ver = pkg.version\n  var tarball = path.join(cachedPackageRoot({name: pkgname, version: ver}), 'package.tgz')\n  var target = tempFilename('unpack')\n  getCacheStat(iferr(next, function (cs) {\n    log.verbose('addBundled', 'extract', tarball)\n    unpack(tarball, target, null, null, cs.uid, cs.gid, iferr(next, function () {\n      log.silly('addBundled', 'read tarball')\n      readPackageTree(target, function (er, tree) {\n        log.silly('cleanup', 'remove extracted module')\n        rimraf(target, function () {\n          if (tree) {\n            pkg._bundled = tree.children\n          }\n          next(null, pkg)\n        })\n      })\n    }))\n  }))\n}\n\n// FIXME: hasGzipHeader / hasTarHeader / untarStream duplicate a lot\n// of code from lib/utils/tar.js these should be brought together.\n\nfunction hasGzipHeader (c) {\n  return c[0] === 0x1F && c[1] === 0x8B && c[2] === 0x08\n}\n\nfunction hasTarHeader (c) {\n  return c[257] === 0x75 && // tar archives have 7573746172 at position\n         c[258] === 0x73 && // 257 and 003030 or 202000 at position 262\n         c[259] === 0x74 &&\n         c[260] === 0x61 &&\n         c[261] === 0x72 &&\n\n       ((c[262] === 0x00 &&\n         c[263] === 0x30 &&\n         c[264] === 0x30) ||\n\n        (c[262] === 0x20 &&\n         c[263] === 0x20 &&\n         c[264] === 0x00))\n}\n\nfunction untarStream (tarball, cb) {\n  validate('SF', arguments)\n  cb = once(cb)\n\n  var stream\n  var file = stream = fs.createReadStream(tarball)\n  var tounpipe = [file]\n  file.on('error', function (er) {\n    er = new Error('Error extracting ' + tarball + ' archive: ' + er.message)\n    er.code = 'EREADFILE'\n    cb(er)\n  })\n  file.on('data', function OD (c) {\n    if (hasGzipHeader(c)) {\n      doGunzip()\n    } else if (hasTarHeader(c)) {\n      doUntar()\n    } else {\n      if (file.close) file.close()\n      if (file.destroy) file.destroy()\n      var er = new Error('Non-gzip/tarball ' + tarball)\n      er.code = 'ENOTTARBALL'\n      return cb(er)\n    }\n    file.removeListener('data', OD)\n    file.emit('data', c)\n    cb(null, stream)\n  })\n\n  function doGunzip () {\n    var gunzip = stream.pipe(zlib.createGunzip())\n    gunzip.on('error', function (er) {\n      er = new Error('Error extracting ' + tarball + ' archive: ' + er.message)\n      er.code = 'EGUNZIP'\n      cb(er)\n    })\n    tounpipe.push(gunzip)\n    stream = gunzip\n    doUntar()\n  }\n\n  function doUntar () {\n    var untar = stream.pipe(tar.Parse())\n    untar.on('error', function (er) {\n      er = new Error('Error extracting ' + tarball + ' archive: ' + er.message)\n      er.code = 'EUNTAR'\n      cb(er)\n    })\n    tounpipe.push(untar)\n    stream = untar\n    addClose()\n  }\n\n  function addClose () {\n    stream.close = function () {\n      tounpipe.forEach(function (stream) {\n        unpipe(stream)\n      })\n\n      if (file.close) file.close()\n      if (file.destroy) file.destroy()\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/realize-package-specifier/index.js":"\"use strict\"\nvar fs = require(\"fs\")\nvar path = require(\"path\")\nvar dz = require(\"dezalgo\")\nvar npa = require(\"npm-package-arg\")\n\nmodule.exports = function (spec, where, cb) {\n  if (where instanceof Function) { cb = where; where = null }\n  if (where == null) where = \".\"\n  cb = dz(cb)\n  try {\n    var dep = npa(spec)\n  }\n  catch (e) {\n    return cb(e)\n  }\n  if ((dep.type == \"range\" || dep.type == \"version\") && dep.name != dep.raw) return cb(null, dep)\n  var specpath = dep.type == \"local\"\n               ? path.resolve(where, dep.spec)\n               : path.resolve(where, dep.rawSpec? dep.rawSpec: dep.name)\n  fs.stat(specpath, function (er, s) {\n    if (er) return finalize()\n    if (!s.isDirectory()) return finalize(\"local\")\n    fs.stat(path.join(specpath, \"package.json\"), function (er) {\n      finalize(er ? null : \"directory\")\n    })\n  })\n  function finalize(type) {\n    if (type != null && type != dep.type) {\n      dep.type = type\n      if (! dep.rawSpec) {\n        dep.rawSpec = dep.name\n        dep.name = null\n      }\n    }\n    if (dep.type == \"local\" || dep.type == \"directory\") {\n      dep.spec = path.resolve(specpath)\n    }\n    cb(null, dep)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/dezalgo/dezalgo.js":"var wrappy = require('wrappy')\nmodule.exports = wrappy(dezalgo)\n\nvar asap = require('asap')\n\nfunction dezalgo (cb) {\n  var sync = true\n  asap(function () {\n    sync = false\n  })\n\n  return function zalgoSafe() {\n    var args = arguments\n    var me = this\n    if (sync)\n      asap(function() {\n        cb.apply(me, args)\n      })\n    else\n      cb.apply(me, args)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/asap/asap.js":"\"use strict\";\n\nvar rawAsap = require(\"./raw\");\nvar freeTasks = [];\n\n/**\n * Calls a task as soon as possible after returning, in its own event, with\n * priority over IO events. An exception thrown in a task can be handled by\n * `process.on(\"uncaughtException\") or `domain.on(\"error\")`, but will otherwise\n * crash the process. If the error is handled, all subsequent tasks will\n * resume.\n *\n * @param {{call}} task A callable object, typically a function that takes no\n * arguments.\n */\nmodule.exports = asap;\nfunction asap(task) {\n    var rawTask;\n    if (freeTasks.length) {\n        rawTask = freeTasks.pop();\n    } else {\n        rawTask = new RawTask();\n    }\n    rawTask.task = task;\n    rawTask.domain = process.domain;\n    rawAsap(rawTask);\n}\n\nfunction RawTask() {\n    this.task = null;\n    this.domain = null;\n}\n\nRawTask.prototype.call = function () {\n    if (this.domain) {\n        this.domain.enter();\n    }\n    var threw = true;\n    try {\n        this.task.call();\n        threw = false;\n        // If the task throws an exception (presumably) Node.js restores the\n        // domain stack for the next event.\n        if (this.domain) {\n            this.domain.exit();\n        }\n    } finally {\n        // We use try/finally and a threw flag to avoid messing up stack traces\n        // when we catch and release errors.\n        if (threw) {\n            // In Node.js, uncaught exceptions are considered fatal errors.\n            // Re-throw them to interrupt flushing!\n            // Ensure that flushing continues if an uncaught exception is\n            // suppressed listening process.on(\"uncaughtException\") or\n            // domain.on(\"error\").\n            rawAsap.requestFlush();\n        }\n        // If the task threw an error, we do not want to exit the domain here.\n        // Exiting the domain would prevent the domain from catching the error.\n        this.task = null;\n        this.domain = null;\n        freeTasks.push(this);\n    }\n};\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/asap/raw.js":"\"use strict\";\n\nvar domain; // The domain module is executed on demand\nvar hasSetImmediate = typeof setImmediate === \"function\";\n\n// Use the fastest means possible to execute a task in its own turn, with\n// priority over other events including network IO events in Node.js.\n//\n// An exception thrown by a task will permanently interrupt the processing of\n// subsequent tasks. The higher level `asap` function ensures that if an\n// exception is thrown by a task, that the task queue will continue flushing as\n// soon as possible, but if you use `rawAsap` directly, you are responsible to\n// either ensure that no exceptions are thrown from your task, or to manually\n// call `rawAsap.requestFlush` if an exception is thrown.\nmodule.exports = rawAsap;\nfunction rawAsap(task) {\n    if (!queue.length) {\n        requestFlush();\n        flushing = true;\n    }\n    // Avoids a function call\n    queue[queue.length] = task;\n}\n\nvar queue = [];\n// Once a flush has been requested, no further calls to `requestFlush` are\n// necessary until the next `flush` completes.\nvar flushing = false;\n// The position of the next task to execute in the task queue. This is\n// preserved between calls to `flush` so that it can be resumed if\n// a task throws an exception.\nvar index = 0;\n// If a task schedules additional tasks recursively, the task queue can grow\n// unbounded. To prevent memory excaustion, the task queue will periodically\n// truncate already-completed tasks.\nvar capacity = 1024;\n\n// The flush function processes all tasks that have been scheduled with\n// `rawAsap` unless and until one of those tasks throws an exception.\n// If a task throws an exception, `flush` ensures that its state will remain\n// consistent and will resume where it left off when called again.\n// However, `flush` does not make any arrangements to be called again if an\n// exception is thrown.\nfunction flush() {\n    while (index < queue.length) {\n        var currentIndex = index;\n        // Advance the index before calling the task. This ensures that we will\n        // begin flushing on the next task the task throws an error.\n        index = index + 1;\n        queue[currentIndex].call();\n        // Prevent leaking memory for long chains of recursive calls to `asap`.\n        // If we call `asap` within tasks scheduled by `asap`, the queue will\n        // grow, but to avoid an O(n) walk for every task we execute, we don't\n        // shift tasks off the queue after they have been executed.\n        // Instead, we periodically shift 1024 tasks off the queue.\n        if (index > capacity) {\n            // Manually shift all values starting at the index back to the\n            // beginning of the queue.\n            for (var scan = 0, newLength = queue.length - index; scan < newLength; scan++) {\n                queue[scan] = queue[scan + index];\n            }\n            queue.length -= index;\n            index = 0;\n        }\n    }\n    queue.length = 0;\n    index = 0;\n    flushing = false;\n}\n\nrawAsap.requestFlush = requestFlush;\nfunction requestFlush() {\n    // Ensure flushing is not bound to any domain.\n    // It is not sufficient to exit the domain, because domains exist on a stack.\n    // To execute code outside of any domain, the following dance is necessary.\n    var parentDomain = process.domain;\n    if (parentDomain) {\n        if (!domain) {\n            // Lazy execute the domain module.\n            // Only employed if the user elects to use domains.\n            domain = require(\"domain\");\n        }\n        domain.active = process.domain = null;\n    }\n\n    // `setImmediate` is slower that `process.nextTick`, but `process.nextTick`\n    // cannot handle recursion.\n    // `requestFlush` will only be called recursively from `asap.js`, to resume\n    // flushing after an error is thrown into a domain.\n    // Conveniently, `setImmediate` was introduced in the same version\n    // `process.nextTick` started throwing recursion errors.\n    if (flushing && hasSetImmediate) {\n        setImmediate(flush);\n    } else {\n        process.nextTick(flush);\n    }\n\n    if (parentDomain) {\n        domain.active = process.domain = parentDomain;\n    }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/tar.js":"// field paths that every tar file must have.\n// header is padded to 512 bytes.\nvar f = 0\n  , fields = {}\n  , path = fields.path = f++\n  , mode = fields.mode = f++\n  , uid = fields.uid = f++\n  , gid = fields.gid = f++\n  , size = fields.size = f++\n  , mtime = fields.mtime = f++\n  , cksum = fields.cksum = f++\n  , type = fields.type = f++\n  , linkpath = fields.linkpath = f++\n  , headerSize = 512\n  , blockSize = 512\n  , fieldSize = []\n\nfieldSize[path] = 100\nfieldSize[mode] = 8\nfieldSize[uid] = 8\nfieldSize[gid] = 8\nfieldSize[size] = 12\nfieldSize[mtime] = 12\nfieldSize[cksum] = 8\nfieldSize[type] = 1\nfieldSize[linkpath] = 100\n\n// \"ustar\\0\" may introduce another bunch of headers.\n// these are optional, and will be nulled out if not present.\n\nvar ustar = fields.ustar = f++\n  , ustarver = fields.ustarver = f++\n  , uname = fields.uname = f++\n  , gname = fields.gname = f++\n  , devmaj = fields.devmaj = f++\n  , devmin = fields.devmin = f++\n  , prefix = fields.prefix = f++\n  , fill = fields.fill = f++\n\n// terminate fields.\nfields[f] = null\n\nfieldSize[ustar] = 6\nfieldSize[ustarver] = 2\nfieldSize[uname] = 32\nfieldSize[gname] = 32\nfieldSize[devmaj] = 8\nfieldSize[devmin] = 8\nfieldSize[prefix] = 155\nfieldSize[fill] = 12\n\n// nb: prefix field may in fact be 130 bytes of prefix,\n// a null char, 12 bytes for atime, 12 bytes for ctime.\n//\n// To recognize this format:\n// 1. prefix[130] === ' ' or '\\0'\n// 2. atime and ctime are octal numeric values\n// 3. atime and ctime have ' ' in their last byte\n\nvar fieldEnds = {}\n  , fieldOffs = {}\n  , fe = 0\nfor (var i = 0; i < f; i ++) {\n  fieldOffs[i] = fe\n  fieldEnds[i] = (fe += fieldSize[i])\n}\n\n// build a translation table of field paths.\nObject.keys(fields).forEach(function (f) {\n  if (fields[f] !== null) fields[fields[f]] = f\n})\n\n// different values of the 'type' field\n// paths match the values of Stats.isX() functions, where appropriate\nvar types =\n  { 0: \"File\"\n  , \"\\0\": \"OldFile\" // like 0\n  , \"\": \"OldFile\"\n  , 1: \"Link\"\n  , 2: \"SymbolicLink\"\n  , 3: \"CharacterDevice\"\n  , 4: \"BlockDevice\"\n  , 5: \"Directory\"\n  , 6: \"FIFO\"\n  , 7: \"ContiguousFile\" // like 0\n  // posix headers\n  , g: \"GlobalExtendedHeader\" // k=v for the rest of the archive\n  , x: \"ExtendedHeader\" // k=v for the next file\n  // vendor-specific stuff\n  , A: \"SolarisACL\" // skip\n  , D: \"GNUDumpDir\" // like 5, but with data, which should be skipped\n  , I: \"Inode\" // metadata only, skip\n  , K: \"NextFileHasLongLinkpath\" // data = link path of next file\n  , L: \"NextFileHasLongPath\" // data = path of next file\n  , M: \"ContinuationFile\" // skip\n  , N: \"OldGnuLongPath\" // like L\n  , S: \"SparseFile\" // skip\n  , V: \"TapeVolumeHeader\" // skip\n  , X: \"OldExtendedHeader\" // like x\n  }\n\nObject.keys(types).forEach(function (t) {\n  types[types[t]] = types[types[t]] || t\n})\n\n// values for the mode field\nvar modes =\n  { suid: 04000 // set uid on extraction\n  , sgid: 02000 // set gid on extraction\n  , svtx: 01000 // set restricted deletion flag on dirs on extraction\n  , uread:  0400\n  , uwrite: 0200\n  , uexec:  0100\n  , gread:  040\n  , gwrite: 020\n  , gexec:  010\n  , oread:  4\n  , owrite: 2\n  , oexec:  1\n  , all: 07777\n  }\n\nvar numeric =\n  { mode: true\n  , uid: true\n  , gid: true\n  , size: true\n  , mtime: true\n  , devmaj: true\n  , devmin: true\n  , cksum: true\n  , atime: true\n  , ctime: true\n  , dev: true\n  , ino: true\n  , nlink: true\n  }\n\nObject.keys(modes).forEach(function (t) {\n  modes[modes[t]] = modes[modes[t]] || t\n})\n\nvar knownExtended =\n  { atime: true\n  , charset: true\n  , comment: true\n  , ctime: true\n  , gid: true\n  , gname: true\n  , linkpath: true\n  , mtime: true\n  , path: true\n  , realtime: true\n  , security: true\n  , size: true\n  , uid: true\n  , uname: true }\n\n\nexports.fields = fields\nexports.fieldSize = fieldSize\nexports.fieldOffs = fieldOffs\nexports.fieldEnds = fieldEnds\nexports.types = types\nexports.modes = modes\nexports.numeric = numeric\nexports.headerSize = headerSize\nexports.blockSize = blockSize\nexports.knownExtended = knownExtended\n\nexports.Pack = require(\"./lib/pack.js\")\nexports.Parse = require(\"./lib/parse.js\")\nexports.Extract = require(\"./lib/extract.js\")\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/pack.js":"// pipe in an fstream, and it'll make a tarball.\n// key-value pair argument is global extended header props.\n\nmodule.exports = Pack\n\nvar EntryWriter = require(\"./entry-writer.js\")\n  , Stream = require(\"stream\").Stream\n  , path = require(\"path\")\n  , inherits = require(\"inherits\")\n  , GlobalHeaderWriter = require(\"./global-header-writer.js\")\n  , collect = require(\"fstream\").collect\n  , eof = new Buffer(512)\n\nfor (var i = 0; i < 512; i ++) eof[i] = 0\n\ninherits(Pack, Stream)\n\nfunction Pack (props) {\n  // console.error(\"-- p ctor\")\n  var me = this\n  if (!(me instanceof Pack)) return new Pack(props)\n\n  if (props) me._noProprietary = props.noProprietary\n  else me._noProprietary = false\n\n  me._global = props\n\n  me.readable = true\n  me.writable = true\n  me._buffer = []\n  // console.error(\"-- -- set current to null in ctor\")\n  me._currentEntry = null\n  me._processing = false\n\n  me._pipeRoot = null\n  me.on(\"pipe\", function (src) {\n    if (src.root === me._pipeRoot) return\n    me._pipeRoot = src\n    src.on(\"end\", function () {\n      me._pipeRoot = null\n    })\n    me.add(src)\n  })\n}\n\nPack.prototype.addGlobal = function (props) {\n  // console.error(\"-- p addGlobal\")\n  if (this._didGlobal) return\n  this._didGlobal = true\n\n  var me = this\n  GlobalHeaderWriter(props)\n    .on(\"data\", function (c) {\n      me.emit(\"data\", c)\n    })\n    .end()\n}\n\nPack.prototype.add = function (stream) {\n  if (this._global && !this._didGlobal) this.addGlobal(this._global)\n\n  if (this._ended) return this.emit(\"error\", new Error(\"add after end\"))\n\n  collect(stream)\n  this._buffer.push(stream)\n  this._process()\n  this._needDrain = this._buffer.length > 0\n  return !this._needDrain\n}\n\nPack.prototype.pause = function () {\n  this._paused = true\n  if (this._currentEntry) this._currentEntry.pause()\n  this.emit(\"pause\")\n}\n\nPack.prototype.resume = function () {\n  this._paused = false\n  if (this._currentEntry) this._currentEntry.resume()\n  this.emit(\"resume\")\n  this._process()\n}\n\nPack.prototype.end = function () {\n  this._ended = true\n  this._buffer.push(eof)\n  this._process()\n}\n\nPack.prototype._process = function () {\n  var me = this\n  if (me._paused || me._processing) {\n    return\n  }\n\n  var entry = me._buffer.shift()\n\n  if (!entry) {\n    if (me._needDrain) {\n      me.emit(\"drain\")\n    }\n    return\n  }\n\n  if (entry.ready === false) {\n    // console.error(\"-- entry is not ready\", entry)\n    me._buffer.unshift(entry)\n    entry.on(\"ready\", function () {\n      // console.error(\"-- -- ready!\", entry)\n      me._process()\n    })\n    return\n  }\n\n  me._processing = true\n\n  if (entry === eof) {\n    // need 2 ending null blocks.\n    me.emit(\"data\", eof)\n    me.emit(\"data\", eof)\n    me.emit(\"end\")\n    me.emit(\"close\")\n    return\n  }\n\n  // Change the path to be relative to the root dir that was\n  // added to the tarball.\n  //\n  // XXX This should be more like how -C works, so you can\n  // explicitly set a root dir, and also explicitly set a pathname\n  // in the tarball to use.  That way we can skip a lot of extra\n  // work when resolving symlinks for bundled dependencies in npm.\n\n  var root = path.dirname((entry.root || entry).path);\n  if (me._global && me._global.fromBase && entry.root && entry.root.path) {\n    // user set 'fromBase: true' indicating tar root should be directory itself\n    root = entry.root.path;\n  }\n\n  var wprops = {}\n\n  Object.keys(entry.props || {}).forEach(function (k) {\n    wprops[k] = entry.props[k]\n  })\n\n  if (me._noProprietary) wprops.noProprietary = true\n\n  wprops.path = path.relative(root, entry.path || '')\n\n  // actually not a matter of opinion or taste.\n  if (process.platform === \"win32\") {\n    wprops.path = wprops.path.replace(/\\\\/g, \"/\")\n  }\n\n  if (!wprops.type)\n    wprops.type = 'Directory'\n\n  switch (wprops.type) {\n    // sockets not supported\n    case \"Socket\":\n      return\n\n    case \"Directory\":\n      wprops.path += \"/\"\n      wprops.size = 0\n      break\n\n    case \"Link\":\n      var lp = path.resolve(path.dirname(entry.path), entry.linkpath)\n      wprops.linkpath = path.relative(root, lp) || \".\"\n      wprops.size = 0\n      break\n\n    case \"SymbolicLink\":\n      var lp = path.resolve(path.dirname(entry.path), entry.linkpath)\n      wprops.linkpath = path.relative(path.dirname(entry.path), lp) || \".\"\n      wprops.size = 0\n      break\n  }\n\n  // console.error(\"-- new writer\", wprops)\n  // if (!wprops.type) {\n  //   // console.error(\"-- no type?\", entry.constructor.name, entry)\n  // }\n\n  // console.error(\"-- -- set current to new writer\", wprops.path)\n  var writer = me._currentEntry = EntryWriter(wprops)\n\n  writer.parent = me\n\n  // writer.on(\"end\", function () {\n  //   // console.error(\"-- -- writer end\", writer.path)\n  // })\n\n  writer.on(\"data\", function (c) {\n    me.emit(\"data\", c)\n  })\n\n  writer.on(\"header\", function () {\n    Buffer.prototype.toJSON = function () {\n      return this.toString().split(/\\0/).join(\".\")\n    }\n    // console.error(\"-- -- writer header %j\", writer.props)\n    if (writer.props.size === 0) nextEntry()\n  })\n  writer.on(\"close\", nextEntry)\n\n  var ended = false\n  function nextEntry () {\n    if (ended) return\n    ended = true\n\n    // console.error(\"-- -- writer close\", writer.path)\n    // console.error(\"-- -- set current to null\", wprops.path)\n    me._currentEntry = null\n    me._processing = false\n    me._process()\n  }\n\n  writer.on(\"error\", function (er) {\n    // console.error(\"-- -- writer error\", writer.path)\n    me.emit(\"error\", er)\n  })\n\n  // if it's the root, then there's no need to add its entries,\n  // or data, since they'll be added directly.\n  if (entry === me._pipeRoot) {\n    // console.error(\"-- is the root, don't auto-add\")\n    writer.add = null\n  }\n\n  entry.pipe(writer)\n}\n\nPack.prototype.destroy = function () {}\nPack.prototype.write = function () {}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/entry-writer.js":"module.exports = EntryWriter\n\nvar tar = require(\"../tar.js\")\n  , TarHeader = require(\"./header.js\")\n  , Entry = require(\"./entry.js\")\n  , inherits = require(\"inherits\")\n  , BlockStream = require(\"block-stream\")\n  , ExtendedHeaderWriter\n  , Stream = require(\"stream\").Stream\n  , EOF = {}\n\ninherits(EntryWriter, Stream)\n\nfunction EntryWriter (props) {\n  var me = this\n\n  if (!(me instanceof EntryWriter)) {\n    return new EntryWriter(props)\n  }\n\n  Stream.apply(this)\n\n  me.writable = true\n  me.readable = true\n\n  me._stream = new BlockStream(512)\n\n  me._stream.on(\"data\", function (c) {\n    me.emit(\"data\", c)\n  })\n\n  me._stream.on(\"drain\", function () {\n    me.emit(\"drain\")\n  })\n\n  me._stream.on(\"end\", function () {\n    me.emit(\"end\")\n    me.emit(\"close\")\n  })\n\n  me.props = props\n  if (props.type === \"Directory\") {\n    props.size = 0\n  }\n  props.ustar = \"ustar\\0\"\n  props.ustarver = \"00\"\n  me.path = props.path\n\n  me._buffer = []\n  me._didHeader = false\n  me._meta = false\n\n  me.on(\"pipe\", function () {\n    me._process()\n  })\n}\n\nEntryWriter.prototype.write = function (c) {\n  // console.error(\".. ew write\")\n  if (this._ended) return this.emit(\"error\", new Error(\"write after end\"))\n  this._buffer.push(c)\n  this._process()\n  this._needDrain = this._buffer.length > 0\n  return !this._needDrain\n}\n\nEntryWriter.prototype.end = function (c) {\n  // console.error(\".. ew end\")\n  if (c) this._buffer.push(c)\n  this._buffer.push(EOF)\n  this._ended = true\n  this._process()\n  this._needDrain = this._buffer.length > 0\n}\n\nEntryWriter.prototype.pause = function () {\n  // console.error(\".. ew pause\")\n  this._paused = true\n  this.emit(\"pause\")\n}\n\nEntryWriter.prototype.resume = function () {\n  // console.error(\".. ew resume\")\n  this._paused = false\n  this.emit(\"resume\")\n  this._process()\n}\n\nEntryWriter.prototype.add = function (entry) {\n  // console.error(\".. ew add\")\n  if (!this.parent) return this.emit(\"error\", new Error(\"no parent\"))\n\n  // make sure that the _header and such is emitted, and clear out\n  // the _currentEntry link on the parent.\n  if (!this._ended) this.end()\n\n  return this.parent.add(entry)\n}\n\nEntryWriter.prototype._header = function () {\n  // console.error(\".. ew header\")\n  if (this._didHeader) return\n  this._didHeader = true\n\n  var headerBlock = TarHeader.encode(this.props)\n\n  if (this.props.needExtended && !this._meta) {\n    var me = this\n\n    ExtendedHeaderWriter = ExtendedHeaderWriter ||\n      require(\"./extended-header-writer.js\")\n\n    ExtendedHeaderWriter(this.props)\n      .on(\"data\", function (c) {\n        me.emit(\"data\", c)\n      })\n      .on(\"error\", function (er) {\n        me.emit(\"error\", er)\n      })\n      .end()\n  }\n\n  // console.error(\".. .. ew headerBlock emitting\")\n  this.emit(\"data\", headerBlock)\n  this.emit(\"header\")\n}\n\nEntryWriter.prototype._process = function () {\n  // console.error(\".. .. ew process\")\n  if (!this._didHeader && !this._meta) {\n    this._header()\n  }\n\n  if (this._paused || this._processing) {\n    // console.error(\".. .. .. paused=%j, processing=%j\", this._paused, this._processing)\n    return\n  }\n\n  this._processing = true\n\n  var buf = this._buffer\n  for (var i = 0; i < buf.length; i ++) {\n    // console.error(\".. .. .. i=%d\", i)\n\n    var c = buf[i]\n\n    if (c === EOF) this._stream.end()\n    else this._stream.write(c)\n\n    if (this._paused) {\n      // console.error(\".. .. .. paused mid-emission\")\n      this._processing = false\n      if (i < buf.length) {\n        this._needDrain = true\n        this._buffer = buf.slice(i + 1)\n      }\n      return\n    }\n  }\n\n  // console.error(\".. .. .. emitted\")\n  this._buffer.length = 0\n  this._processing = false\n\n  // console.error(\".. .. .. emitting drain\")\n  this.emit(\"drain\")\n}\n\nEntryWriter.prototype.destroy = function () {}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/header.js":"// parse a 512-byte header block to a data object, or vice-versa\n// If the data won't fit nicely in a simple header, then generate\n// the appropriate extended header file, and return that.\n\nmodule.exports = TarHeader\n\nvar tar = require(\"../tar.js\")\n  , fields = tar.fields\n  , fieldOffs = tar.fieldOffs\n  , fieldEnds = tar.fieldEnds\n  , fieldSize = tar.fieldSize\n  , numeric = tar.numeric\n  , assert = require(\"assert\").ok\n  , space = \" \".charCodeAt(0)\n  , slash = \"/\".charCodeAt(0)\n  , bslash = process.platform === \"win32\" ? \"\\\\\".charCodeAt(0) : null\n\nfunction TarHeader (block) {\n  if (!(this instanceof TarHeader)) return new TarHeader(block)\n  if (block) this.decode(block)\n}\n\nTarHeader.prototype =\n  { decode : decode\n  , encode: encode\n  , calcSum: calcSum\n  , checkSum: checkSum\n  }\n\nTarHeader.parseNumeric = parseNumeric\nTarHeader.encode = encode\nTarHeader.decode = decode\n\n// note that this will only do the normal ustar header, not any kind\n// of extended posix header file.  If something doesn't fit comfortably,\n// then it will set obj.needExtended = true, and set the block to\n// the closest approximation.\nfunction encode (obj) {\n  if (!obj && !(this instanceof TarHeader)) throw new Error(\n    \"encode must be called on a TarHeader, or supplied an object\")\n\n  obj = obj || this\n  var block = obj.block = new Buffer(512)\n\n  // if the object has a \"prefix\", then that's actually an extension of\n  // the path field.\n  if (obj.prefix) {\n    // console.error(\"%% header encoding, got a prefix\", obj.prefix)\n    obj.path = obj.prefix + \"/\" + obj.path\n    // console.error(\"%% header encoding, prefixed path\", obj.path)\n    obj.prefix = \"\"\n  }\n\n  obj.needExtended = false\n\n  if (obj.mode) {\n    if (typeof obj.mode === \"string\") obj.mode = parseInt(obj.mode, 8)\n    obj.mode = obj.mode & 0777\n  }\n\n  for (var f = 0; fields[f] !== null; f ++) {\n    var field = fields[f]\n      , off = fieldOffs[f]\n      , end = fieldEnds[f]\n      , ret\n\n    switch (field) {\n      case \"cksum\":\n        // special, done below, after all the others\n        break\n\n      case \"prefix\":\n        // special, this is an extension of the \"path\" field.\n        // console.error(\"%% header encoding, skip prefix later\")\n        break\n\n      case \"type\":\n        // convert from long name to a single char.\n        var type = obj.type || \"0\"\n        if (type.length > 1) {\n          type = tar.types[obj.type]\n          if (!type) type = \"0\"\n        }\n        writeText(block, off, end, type)\n        break\n\n      case \"path\":\n        // uses the \"prefix\" field if > 100 bytes, but <= 255\n        var pathLen = Buffer.byteLength(obj.path)\n          , pathFSize = fieldSize[fields.path]\n          , prefFSize = fieldSize[fields.prefix]\n\n        // paths between 100 and 255 should use the prefix field.\n        // longer than 255\n        if (pathLen > pathFSize &&\n            pathLen <= pathFSize + prefFSize) {\n          // need to find a slash somewhere in the middle so that\n          // path and prefix both fit in their respective fields\n          var searchStart = pathLen - 1 - pathFSize\n            , searchEnd = prefFSize\n            , found = false\n            , pathBuf = new Buffer(obj.path)\n\n          for ( var s = searchStart\n              ; (s <= searchEnd)\n              ; s ++ ) {\n            if (pathBuf[s] === slash || pathBuf[s] === bslash) {\n              found = s\n              break\n            }\n          }\n\n          if (found !== false) {\n            prefix = pathBuf.slice(0, found).toString(\"utf8\")\n            path = pathBuf.slice(found + 1).toString(\"utf8\")\n\n            ret = writeText(block, off, end, path)\n            off = fieldOffs[fields.prefix]\n            end = fieldEnds[fields.prefix]\n            // console.error(\"%% header writing prefix\", off, end, prefix)\n            ret = writeText(block, off, end, prefix) || ret\n            break\n          }\n        }\n\n        // paths less than 100 chars don't need a prefix\n        // and paths longer than 255 need an extended header and will fail\n        // on old implementations no matter what we do here.\n        // Null out the prefix, and fallthrough to default.\n        // console.error(\"%% header writing no prefix\")\n        var poff = fieldOffs[fields.prefix]\n          , pend = fieldEnds[fields.prefix]\n        writeText(block, poff, pend, \"\")\n        // fallthrough\n\n      // all other fields are numeric or text\n      default:\n        ret = numeric[field]\n            ? writeNumeric(block, off, end, obj[field])\n            : writeText(block, off, end, obj[field] || \"\")\n        break\n    }\n    obj.needExtended = obj.needExtended || ret\n  }\n\n  var off = fieldOffs[fields.cksum]\n    , end = fieldEnds[fields.cksum]\n\n  writeNumeric(block, off, end, calcSum.call(this, block))\n\n  return block\n}\n\n// if it's a negative number, or greater than will fit,\n// then use write256.\nvar MAXNUM = { 12: 077777777777\n             , 11: 07777777777\n             , 8 : 07777777\n             , 7 : 0777777 }\nfunction writeNumeric (block, off, end, num) {\n  var writeLen = end - off\n    , maxNum = MAXNUM[writeLen] || 0\n\n  num = num || 0\n  // console.error(\"  numeric\", num)\n\n  if (num instanceof Date ||\n      Object.prototype.toString.call(num) === \"[object Date]\") {\n    num = num.getTime() / 1000\n  }\n\n  if (num > maxNum || num < 0) {\n    write256(block, off, end, num)\n    // need an extended header if negative or too big.\n    return true\n  }\n\n  // god, tar is so annoying\n  // if the string is small enough, you should put a space\n  // between the octal string and the \\0, but if it doesn't\n  // fit, then don't.\n  var numStr = Math.floor(num).toString(8)\n  if (num < MAXNUM[writeLen - 1]) numStr += \" \"\n\n  // pad with \"0\" chars\n  if (numStr.length < writeLen) {\n    numStr = (new Array(writeLen - numStr.length).join(\"0\")) + numStr\n  }\n\n  if (numStr.length !== writeLen - 1) {\n    throw new Error(\"invalid length: \" + JSON.stringify(numStr) + \"\\n\" +\n                    \"expected: \"+writeLen)\n  }\n  block.write(numStr, off, writeLen, \"utf8\")\n  block[end - 1] = 0\n}\n\nfunction write256 (block, off, end, num) {\n  var buf = block.slice(off, end)\n  var positive = num >= 0\n  buf[0] = positive ? 0x80 : 0xFF\n\n  // get the number as a base-256 tuple\n  if (!positive) num *= -1\n  var tuple = []\n  do {\n    var n = num % 256\n    tuple.push(n)\n    num = (num - n) / 256\n  } while (num)\n\n  var bytes = tuple.length\n\n  var fill = buf.length - bytes\n  for (var i = 1; i < fill; i ++) {\n    buf[i] = positive ? 0 : 0xFF\n  }\n\n  // tuple is a base256 number, with [0] as the *least* significant byte\n  // if it's negative, then we need to flip all the bits once we hit the\n  // first non-zero bit.  The 2's-complement is (0x100 - n), and the 1's-\n  // complement is (0xFF - n).\n  var zero = true\n  for (i = bytes; i > 0; i --) {\n    var byte = tuple[bytes - i]\n    if (positive) buf[fill + i] = byte\n    else if (zero && byte === 0) buf[fill + i] = 0\n    else if (zero) {\n      zero = false\n      buf[fill + i] = 0x100 - byte\n    } else buf[fill + i] = 0xFF - byte\n  }\n}\n\nfunction writeText (block, off, end, str) {\n  // strings are written as utf8, then padded with \\0\n  var strLen = Buffer.byteLength(str)\n    , writeLen = Math.min(strLen, end - off)\n    // non-ascii fields need extended headers\n    // long fields get truncated\n    , needExtended = strLen !== str.length || strLen > writeLen\n\n  // write the string, and null-pad\n  if (writeLen > 0) block.write(str, off, writeLen, \"utf8\")\n  for (var i = off + writeLen; i < end; i ++) block[i] = 0\n\n  return needExtended\n}\n\nfunction calcSum (block) {\n  block = block || this.block\n  assert(Buffer.isBuffer(block) && block.length === 512)\n\n  if (!block) throw new Error(\"Need block to checksum\")\n\n  // now figure out what it would be if the cksum was \"        \"\n  var sum = 0\n    , start = fieldOffs[fields.cksum]\n    , end = fieldEnds[fields.cksum]\n\n  for (var i = 0; i < fieldOffs[fields.cksum]; i ++) {\n    sum += block[i]\n  }\n\n  for (var i = start; i < end; i ++) {\n    sum += space\n  }\n\n  for (var i = end; i < 512; i ++) {\n    sum += block[i]\n  }\n\n  return sum\n}\n\n\nfunction checkSum (block) {\n  var sum = calcSum.call(this, block)\n  block = block || this.block\n\n  var cksum = block.slice(fieldOffs[fields.cksum], fieldEnds[fields.cksum])\n  cksum = parseNumeric(cksum)\n\n  return cksum === sum\n}\n\nfunction decode (block) {\n  block = block || this.block\n  assert(Buffer.isBuffer(block) && block.length === 512)\n\n  this.block = block\n  this.cksumValid = this.checkSum()\n\n  var prefix = null\n\n  // slice off each field.\n  for (var f = 0; fields[f] !== null; f ++) {\n    var field = fields[f]\n      , val = block.slice(fieldOffs[f], fieldEnds[f])\n\n    switch (field) {\n      case \"ustar\":\n        // if not ustar, then everything after that is just padding.\n        if (val.toString() !== \"ustar\\0\") {\n          this.ustar = false\n          return\n        } else {\n          // console.error(\"ustar:\", val, val.toString())\n          this.ustar = val.toString()\n        }\n        break\n\n      // prefix is special, since it might signal the xstar header\n      case \"prefix\":\n        var atime = parseNumeric(val.slice(131, 131 + 12))\n          , ctime = parseNumeric(val.slice(131 + 12, 131 + 12 + 12))\n        if ((val[130] === 0 || val[130] === space) &&\n            typeof atime === \"number\" &&\n            typeof ctime === \"number\" &&\n            val[131 + 12] === space &&\n            val[131 + 12 + 12] === space) {\n          this.atime = atime\n          this.ctime = ctime\n          val = val.slice(0, 130)\n        }\n        prefix = val.toString(\"utf8\").replace(/\\0+$/, \"\")\n        // console.error(\"%% header reading prefix\", prefix)\n        break\n\n      // all other fields are null-padding text\n      // or a number.\n      default:\n        if (numeric[field]) {\n          this[field] = parseNumeric(val)\n        } else {\n          this[field] = val.toString(\"utf8\").replace(/\\0+$/, \"\")\n        }\n        break\n    }\n  }\n\n  // if we got a prefix, then prepend it to the path.\n  if (prefix) {\n    this.path = prefix + \"/\" + this.path\n    // console.error(\"%% header got a prefix\", this.path)\n  }\n}\n\nfunction parse256 (buf) {\n  // first byte MUST be either 80 or FF\n  // 80 for positive, FF for 2's comp\n  var positive\n  if (buf[0] === 0x80) positive = true\n  else if (buf[0] === 0xFF) positive = false\n  else return null\n\n  // build up a base-256 tuple from the least sig to the highest\n  var zero = false\n    , tuple = []\n  for (var i = buf.length - 1; i > 0; i --) {\n    var byte = buf[i]\n    if (positive) tuple.push(byte)\n    else if (zero && byte === 0) tuple.push(0)\n    else if (zero) {\n      zero = false\n      tuple.push(0x100 - byte)\n    } else tuple.push(0xFF - byte)\n  }\n\n  for (var sum = 0, i = 0, l = tuple.length; i < l; i ++) {\n    sum += tuple[i] * Math.pow(256, i)\n  }\n\n  return positive ? sum : -1 * sum\n}\n\nfunction parseNumeric (f) {\n  if (f[0] & 0x80) return parse256(f)\n\n  var str = f.toString(\"utf8\").split(\"\\0\")[0].trim()\n    , res = parseInt(str, 8)\n\n  return isNaN(res) ? null : res\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/entry.js":"// A passthrough read/write stream that sets its properties\n// based on a header, extendedHeader, and globalHeader\n//\n// Can be either a file system object of some sort, or\n// a pax/ustar metadata entry.\n\nmodule.exports = Entry\n\nvar TarHeader = require(\"./header.js\")\n  , tar = require(\"../tar\")\n  , assert = require(\"assert\").ok\n  , Stream = require(\"stream\").Stream\n  , inherits = require(\"inherits\")\n  , fstream = require(\"fstream\").Abstract\n\nfunction Entry (header, extended, global) {\n  Stream.call(this)\n  this.readable = true\n  this.writable = true\n\n  this._needDrain = false\n  this._paused = false\n  this._reading = false\n  this._ending = false\n  this._ended = false\n  this._remaining = 0\n  this._abort = false\n  this._queue = []\n  this._index = 0\n  this._queueLen = 0\n\n  this._read = this._read.bind(this)\n\n  this.props = {}\n  this._header = header\n  this._extended = extended || {}\n\n  // globals can change throughout the course of\n  // a file parse operation.  Freeze it at its current state.\n  this._global = {}\n  var me = this\n  Object.keys(global || {}).forEach(function (g) {\n    me._global[g] = global[g]\n  })\n\n  this._setProps()\n}\n\ninherits(Entry, Stream)\n\nEntry.prototype.write = function (c) {\n  if (this._ending) this.error(\"write() after end()\", null, true)\n  if (this._remaining === 0) {\n    this.error(\"invalid bytes past eof\")\n  }\n\n  // often we'll get a bunch of \\0 at the end of the last write,\n  // since chunks will always be 512 bytes when reading a tarball.\n  if (c.length > this._remaining) {\n    c = c.slice(0, this._remaining)\n  }\n  this._remaining -= c.length\n\n  // put it on the stack.\n  var ql = this._queueLen\n  this._queue.push(c)\n  this._queueLen ++\n\n  this._read()\n\n  // either paused, or buffered\n  if (this._paused || ql > 0) {\n    this._needDrain = true\n    return false\n  }\n\n  return true\n}\n\nEntry.prototype.end = function (c) {\n  if (c) this.write(c)\n  this._ending = true\n  this._read()\n}\n\nEntry.prototype.pause = function () {\n  this._paused = true\n  this.emit(\"pause\")\n}\n\nEntry.prototype.resume = function () {\n  // console.error(\"    Tar Entry resume\", this.path)\n  this.emit(\"resume\")\n  this._paused = false\n  this._read()\n  return this._queueLen - this._index > 1\n}\n\n  // This is bound to the instance\nEntry.prototype._read = function () {\n  // console.error(\"    Tar Entry _read\", this.path)\n\n  if (this._paused || this._reading || this._ended) return\n\n  // set this flag so that event handlers don't inadvertently\n  // get multiple _read() calls running.\n  this._reading = true\n\n  // have any data to emit?\n  while (this._index < this._queueLen && !this._paused) {\n    var chunk = this._queue[this._index ++]\n    this.emit(\"data\", chunk)\n  }\n\n  // check if we're drained\n  if (this._index >= this._queueLen) {\n    this._queue.length = this._queueLen = this._index = 0\n    if (this._needDrain) {\n      this._needDrain = false\n      this.emit(\"drain\")\n    }\n    if (this._ending) {\n      this._ended = true\n      this.emit(\"end\")\n    }\n  }\n\n  // if the queue gets too big, then pluck off whatever we can.\n  // this should be fairly rare.\n  var mql = this._maxQueueLen\n  if (this._queueLen > mql && this._index > 0) {\n    mql = Math.min(this._index, mql)\n    this._index -= mql\n    this._queueLen -= mql\n    this._queue = this._queue.slice(mql)\n  }\n\n  this._reading = false\n}\n\nEntry.prototype._setProps = function () {\n  // props = extended->global->header->{}\n  var header = this._header\n    , extended = this._extended\n    , global = this._global\n    , props = this.props\n\n  // first get the values from the normal header.\n  var fields = tar.fields\n  for (var f = 0; fields[f] !== null; f ++) {\n    var field = fields[f]\n      , val = header[field]\n    if (typeof val !== \"undefined\") props[field] = val\n  }\n\n  // next, the global header for this file.\n  // numeric values, etc, will have already been parsed.\n  ;[global, extended].forEach(function (p) {\n    Object.keys(p).forEach(function (f) {\n      if (typeof p[f] !== \"undefined\") props[f] = p[f]\n    })\n  })\n\n  // no nulls allowed in path or linkpath\n  ;[\"path\", \"linkpath\"].forEach(function (p) {\n    if (props.hasOwnProperty(p)) {\n      props[p] = props[p].split(\"\\0\")[0]\n    }\n  })\n\n\n  // set date fields to be a proper date\n  ;[\"mtime\", \"ctime\", \"atime\"].forEach(function (p) {\n    if (props.hasOwnProperty(p)) {\n      props[p] = new Date(props[p] * 1000)\n    }\n  })\n\n  // set the type so that we know what kind of file to create\n  var type\n  switch (tar.types[props.type]) {\n    case \"OldFile\":\n    case \"ContiguousFile\":\n      type = \"File\"\n      break\n\n    case \"GNUDumpDir\":\n      type = \"Directory\"\n      break\n\n    case undefined:\n      type = \"Unknown\"\n      break\n\n    case \"Link\":\n    case \"SymbolicLink\":\n    case \"CharacterDevice\":\n    case \"BlockDevice\":\n    case \"Directory\":\n    case \"FIFO\":\n    default:\n      type = tar.types[props.type]\n  }\n\n  this.type = type\n  this.path = props.path\n  this.size = props.size\n\n  // size is special, since it signals when the file needs to end.\n  this._remaining = props.size\n}\n\n// the parser may not call write if _abort is true. \n// useful for skipping data from some files quickly.\nEntry.prototype.abort = function(){\n  this._abort = true\n}\n\nEntry.prototype.warn = fstream.warn\nEntry.prototype.error = fstream.error\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/fstream.js":"exports.Abstract = require('./lib/abstract.js')\nexports.Reader = require('./lib/reader.js')\nexports.Writer = require('./lib/writer.js')\n\nexports.File = {\n  Reader: require('./lib/file-reader.js'),\n  Writer: require('./lib/file-writer.js')\n}\n\nexports.Dir = {\n  Reader: require('./lib/dir-reader.js'),\n  Writer: require('./lib/dir-writer.js')\n}\n\nexports.Link = {\n  Reader: require('./lib/link-reader.js'),\n  Writer: require('./lib/link-writer.js')\n}\n\nexports.Proxy = {\n  Reader: require('./lib/proxy-reader.js'),\n  Writer: require('./lib/proxy-writer.js')\n}\n\nexports.Reader.Dir = exports.DirReader = exports.Dir.Reader\nexports.Reader.File = exports.FileReader = exports.File.Reader\nexports.Reader.Link = exports.LinkReader = exports.Link.Reader\nexports.Reader.Proxy = exports.ProxyReader = exports.Proxy.Reader\n\nexports.Writer.Dir = exports.DirWriter = exports.Dir.Writer\nexports.Writer.File = exports.FileWriter = exports.File.Writer\nexports.Writer.Link = exports.LinkWriter = exports.Link.Writer\nexports.Writer.Proxy = exports.ProxyWriter = exports.Proxy.Writer\n\nexports.collect = require('./lib/collect.js')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/abstract.js":"// the parent class for all fstreams.\n\nmodule.exports = Abstract\n\nvar Stream = require('stream').Stream\nvar inherits = require('inherits')\n\nfunction Abstract () {\n  Stream.call(this)\n}\n\ninherits(Abstract, Stream)\n\nAbstract.prototype.on = function (ev, fn) {\n  if (ev === 'ready' && this.ready) {\n    process.nextTick(fn.bind(this))\n  } else {\n    Stream.prototype.on.call(this, ev, fn)\n  }\n  return this\n}\n\nAbstract.prototype.abort = function () {\n  this._aborted = true\n  this.emit('abort')\n}\n\nAbstract.prototype.destroy = function () {}\n\nAbstract.prototype.warn = function (msg, code) {\n  var self = this\n  var er = decorate(msg, code, self)\n  if (!self.listeners('warn')) {\n    console.error('%s %s\\n' +\n    'path = %s\\n' +\n    'syscall = %s\\n' +\n    'fstream_type = %s\\n' +\n    'fstream_path = %s\\n' +\n    'fstream_unc_path = %s\\n' +\n    'fstream_class = %s\\n' +\n    'fstream_stack =\\n%s\\n',\n      code || 'UNKNOWN',\n      er.stack,\n      er.path,\n      er.syscall,\n      er.fstream_type,\n      er.fstream_path,\n      er.fstream_unc_path,\n      er.fstream_class,\n      er.fstream_stack.join('\\n'))\n  } else {\n    self.emit('warn', er)\n  }\n}\n\nAbstract.prototype.info = function (msg, code) {\n  this.emit('info', msg, code)\n}\n\nAbstract.prototype.error = function (msg, code, th) {\n  var er = decorate(msg, code, this)\n  if (th) throw er\n  else this.emit('error', er)\n}\n\nfunction decorate (er, code, self) {\n  if (!(er instanceof Error)) er = new Error(er)\n  er.code = er.code || code\n  er.path = er.path || self.path\n  er.fstream_type = er.fstream_type || self.type\n  er.fstream_path = er.fstream_path || self.path\n  if (self._path !== self.path) {\n    er.fstream_unc_path = er.fstream_unc_path || self._path\n  }\n  if (self.linkpath) {\n    er.fstream_linkpath = er.fstream_linkpath || self.linkpath\n  }\n  er.fstream_class = er.fstream_class || self.constructor.name\n  er.fstream_stack = er.fstream_stack ||\n    new Error().stack.split(/\\n/).slice(3).map(function (s) {\n      return s.replace(/^ {4}at /, '')\n    })\n\n  return er\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/reader.js":"module.exports = Reader\n\nvar fs = require('graceful-fs')\nvar Stream = require('stream').Stream\nvar inherits = require('inherits')\nvar path = require('path')\nvar getType = require('./get-type.js')\nvar hardLinks = Reader.hardLinks = {}\nvar Abstract = require('./abstract.js')\n\n// Must do this *before* loading the child classes\ninherits(Reader, Abstract)\n\nvar LinkReader = require('./link-reader.js')\n\nfunction Reader (props, currentStat) {\n  var self = this\n  if (!(self instanceof Reader)) return new Reader(props, currentStat)\n\n  if (typeof props === 'string') {\n    props = { path: props }\n  }\n\n  // polymorphism.\n  // call fstream.Reader(dir) to get a DirReader object, etc.\n  // Note that, unlike in the Writer case, ProxyReader is going\n  // to be the *normal* state of affairs, since we rarely know\n  // the type of a file prior to reading it.\n\n  var type\n  var ClassType\n\n  if (props.type && typeof props.type === 'function') {\n    type = props.type\n    ClassType = type\n  } else {\n    type = getType(props)\n    ClassType = Reader\n  }\n\n  if (currentStat && !type) {\n    type = getType(currentStat)\n    props[type] = true\n    props.type = type\n  }\n\n  switch (type) {\n    case 'Directory':\n      ClassType = require('./dir-reader.js')\n      break\n\n    case 'Link':\n    // XXX hard links are just files.\n    // However, it would be good to keep track of files' dev+inode\n    // and nlink values, and create a HardLinkReader that emits\n    // a linkpath value of the original copy, so that the tar\n    // writer can preserve them.\n    // ClassType = HardLinkReader\n    // break\n\n    case 'File':\n      ClassType = require('./file-reader.js')\n      break\n\n    case 'SymbolicLink':\n      ClassType = LinkReader\n      break\n\n    case 'Socket':\n      ClassType = require('./socket-reader.js')\n      break\n\n    case null:\n      ClassType = require('./proxy-reader.js')\n      break\n  }\n\n  if (!(self instanceof ClassType)) {\n    return new ClassType(props)\n  }\n\n  Abstract.call(self)\n\n  if (!props.path) {\n    self.error('Must provide a path', null, true)\n  }\n\n  self.readable = true\n  self.writable = false\n\n  self.type = type\n  self.props = props\n  self.depth = props.depth = props.depth || 0\n  self.parent = props.parent || null\n  self.root = props.root || (props.parent && props.parent.root) || self\n\n  self._path = self.path = path.resolve(props.path)\n  if (process.platform === 'win32') {\n    self.path = self._path = self.path.replace(/\\?/g, '_')\n    if (self._path.length >= 260) {\n      // how DOES one create files on the moon?\n      // if the path has spaces in it, then UNC will fail.\n      self._swallowErrors = true\n      // if (self._path.indexOf(\" \") === -1) {\n      self._path = '\\\\\\\\?\\\\' + self.path.replace(/\\//g, '\\\\')\n    // }\n    }\n  }\n  self.basename = props.basename = path.basename(self.path)\n  self.dirname = props.dirname = path.dirname(self.path)\n\n  // these have served their purpose, and are now just noisy clutter\n  props.parent = props.root = null\n\n  // console.error(\"\\n\\n\\n%s setting size to\", props.path, props.size)\n  self.size = props.size\n  self.filter = typeof props.filter === 'function' ? props.filter : null\n  if (props.sort === 'alpha') props.sort = alphasort\n\n  // start the ball rolling.\n  // this will stat the thing, and then call self._read()\n  // to start reading whatever it is.\n  // console.error(\"calling stat\", props.path, currentStat)\n  self._stat(currentStat)\n}\n\nfunction alphasort (a, b) {\n  return a === b ? 0\n    : a.toLowerCase() > b.toLowerCase() ? 1\n      : a.toLowerCase() < b.toLowerCase() ? -1\n        : a > b ? 1\n          : -1\n}\n\nReader.prototype._stat = function (currentStat) {\n  var self = this\n  var props = self.props\n  var stat = props.follow ? 'stat' : 'lstat'\n  // console.error(\"Reader._stat\", self._path, currentStat)\n  if (currentStat) process.nextTick(statCb.bind(null, null, currentStat))\n  else fs[stat](self._path, statCb)\n\n  function statCb (er, props_) {\n    // console.error(\"Reader._stat, statCb\", self._path, props_, props_.nlink)\n    if (er) return self.error(er)\n\n    Object.keys(props_).forEach(function (k) {\n      props[k] = props_[k]\n    })\n\n    // if it's not the expected size, then abort here.\n    if (undefined !== self.size && props.size !== self.size) {\n      return self.error('incorrect size')\n    }\n    self.size = props.size\n\n    var type = getType(props)\n    var handleHardlinks = props.hardlinks !== false\n\n    // special little thing for handling hardlinks.\n    if (handleHardlinks && type !== 'Directory' && props.nlink && props.nlink > 1) {\n      var k = props.dev + ':' + props.ino\n      // console.error(\"Reader has nlink\", self._path, k)\n      if (hardLinks[k] === self._path || !hardLinks[k]) {\n        hardLinks[k] = self._path\n      } else {\n        // switch into hardlink mode.\n        type = self.type = self.props.type = 'Link'\n        self.Link = self.props.Link = true\n        self.linkpath = self.props.linkpath = hardLinks[k]\n        // console.error(\"Hardlink detected, switching mode\", self._path, self.linkpath)\n        // Setting __proto__ would arguably be the \"correct\"\n        // approach here, but that just seems too wrong.\n        self._stat = self._read = LinkReader.prototype._read\n      }\n    }\n\n    if (self.type && self.type !== type) {\n      self.error('Unexpected type: ' + type)\n    }\n\n    // if the filter doesn't pass, then just skip over this one.\n    // still have to emit end so that dir-walking can move on.\n    if (self.filter) {\n      var who = self._proxy || self\n      // special handling for ProxyReaders\n      if (!self.filter.call(who, who, props)) {\n        if (!self._disowned) {\n          self.abort()\n          self.emit('end')\n          self.emit('close')\n        }\n        return\n      }\n    }\n\n    // last chance to abort or disown before the flow starts!\n    var events = ['_stat', 'stat', 'ready']\n    var e = 0\n    ;(function go () {\n      if (self._aborted) {\n        self.emit('end')\n        self.emit('close')\n        return\n      }\n\n      if (self._paused && self.type !== 'Directory') {\n        self.once('resume', go)\n        return\n      }\n\n      var ev = events[e++]\n      if (!ev) {\n        return self._read()\n      }\n      self.emit(ev, props)\n      go()\n    })()\n  }\n}\n\nReader.prototype.pipe = function (dest) {\n  var self = this\n  if (typeof dest.add === 'function') {\n    // piping to a multi-compatible, and we've got directory entries.\n    self.on('entry', function (entry) {\n      var ret = dest.add(entry)\n      if (ret === false) {\n        self.pause()\n      }\n    })\n  }\n\n  // console.error(\"R Pipe apply Stream Pipe\")\n  return Stream.prototype.pipe.apply(this, arguments)\n}\n\nReader.prototype.pause = function (who) {\n  this._paused = true\n  who = who || this\n  this.emit('pause', who)\n  if (this._stream) this._stream.pause(who)\n}\n\nReader.prototype.resume = function (who) {\n  this._paused = false\n  who = who || this\n  this.emit('resume', who)\n  if (this._stream) this._stream.resume(who)\n  this._read()\n}\n\nReader.prototype._read = function () {\n  this.error('Cannot read unknown type: ' + this.type)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/get-type.js":"module.exports = getType\n\nfunction getType (st) {\n  var types = [\n    'Directory',\n    'File',\n    'SymbolicLink',\n    'Link', // special for hardlinks from tarballs\n    'BlockDevice',\n    'CharacterDevice',\n    'FIFO',\n    'Socket'\n  ]\n  var type\n\n  if (st.type && types.indexOf(st.type) !== -1) {\n    st[st.type] = true\n    return st.type\n  }\n\n  for (var i = 0, l = types.length; i < l; i++) {\n    type = types[i]\n    var is = st[type] || st['is' + type]\n    if (typeof is === 'function') is = is.call(st)\n    if (is) {\n      st[type] = true\n      st.type = type\n      return type\n    }\n  }\n\n  return null\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/link-reader.js":"// Basically just a wrapper around an fs.readlink\n//\n// XXX: Enhance this to support the Link type, by keeping\n// a lookup table of {<dev+inode>:<path>}, so that hardlinks\n// can be preserved in tarballs.\n\nmodule.exports = LinkReader\n\nvar fs = require('graceful-fs')\nvar inherits = require('inherits')\nvar Reader = require('./reader.js')\n\ninherits(LinkReader, Reader)\n\nfunction LinkReader (props) {\n  var self = this\n  if (!(self instanceof LinkReader)) {\n    throw new Error('LinkReader must be called as constructor.')\n  }\n\n  if (!((props.type === 'Link' && props.Link) ||\n    (props.type === 'SymbolicLink' && props.SymbolicLink))) {\n    throw new Error('Non-link type ' + props.type)\n  }\n\n  Reader.call(self, props)\n}\n\n// When piping a LinkReader into a LinkWriter, we have to\n// already have the linkpath property set, so that has to\n// happen *before* the \"ready\" event, which means we need to\n// override the _stat method.\nLinkReader.prototype._stat = function (currentStat) {\n  var self = this\n  fs.readlink(self._path, function (er, linkpath) {\n    if (er) return self.error(er)\n    self.linkpath = self.props.linkpath = linkpath\n    self.emit('linkpath', linkpath)\n    Reader.prototype._stat.call(self, currentStat)\n  })\n}\n\nLinkReader.prototype._read = function () {\n  var self = this\n  if (self._paused) return\n  // basically just a no-op, since we got all the info we need\n  // from the _stat method\n  if (!self._ended) {\n    self.emit('end')\n    self.emit('close')\n    self._ended = true\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/writer.js":"module.exports = Writer\n\nvar fs = require('graceful-fs')\nvar inherits = require('inherits')\nvar rimraf = require('rimraf')\nvar mkdir = require('mkdirp')\nvar path = require('path')\nvar umask = process.platform === 'win32' ? 0 : process.umask()\nvar getType = require('./get-type.js')\nvar Abstract = require('./abstract.js')\n\n// Must do this *before* loading the child classes\ninherits(Writer, Abstract)\n\nWriter.dirmode = parseInt('0777', 8) & (~umask)\nWriter.filemode = parseInt('0666', 8) & (~umask)\n\nvar DirWriter = require('./dir-writer.js')\nvar LinkWriter = require('./link-writer.js')\nvar FileWriter = require('./file-writer.js')\nvar ProxyWriter = require('./proxy-writer.js')\n\n// props is the desired state.  current is optionally the current stat,\n// provided here so that subclasses can avoid statting the target\n// more than necessary.\nfunction Writer (props, current) {\n  var self = this\n\n  if (typeof props === 'string') {\n    props = { path: props }\n  }\n\n  // polymorphism.\n  // call fstream.Writer(dir) to get a DirWriter object, etc.\n  var type = getType(props)\n  var ClassType = Writer\n\n  switch (type) {\n    case 'Directory':\n      ClassType = DirWriter\n      break\n    case 'File':\n      ClassType = FileWriter\n      break\n    case 'Link':\n    case 'SymbolicLink':\n      ClassType = LinkWriter\n      break\n    case null:\n    default:\n      // Don't know yet what type to create, so we wrap in a proxy.\n      ClassType = ProxyWriter\n      break\n  }\n\n  if (!(self instanceof ClassType)) return new ClassType(props)\n\n  // now get down to business.\n\n  Abstract.call(self)\n\n  if (!props.path) self.error('Must provide a path', null, true)\n\n  // props is what we want to set.\n  // set some convenience properties as well.\n  self.type = props.type\n  self.props = props\n  self.depth = props.depth || 0\n  self.clobber = props.clobber === false ? props.clobber : true\n  self.parent = props.parent || null\n  self.root = props.root || (props.parent && props.parent.root) || self\n\n  self._path = self.path = path.resolve(props.path)\n  if (process.platform === 'win32') {\n    self.path = self._path = self.path.replace(/\\?/g, '_')\n    if (self._path.length >= 260) {\n      self._swallowErrors = true\n      self._path = '\\\\\\\\?\\\\' + self.path.replace(/\\//g, '\\\\')\n    }\n  }\n  self.basename = path.basename(props.path)\n  self.dirname = path.dirname(props.path)\n  self.linkpath = props.linkpath || null\n\n  props.parent = props.root = null\n\n  // console.error(\"\\n\\n\\n%s setting size to\", props.path, props.size)\n  self.size = props.size\n\n  if (typeof props.mode === 'string') {\n    props.mode = parseInt(props.mode, 8)\n  }\n\n  self.readable = false\n  self.writable = true\n\n  // buffer until ready, or while handling another entry\n  self._buffer = []\n  self.ready = false\n\n  self.filter = typeof props.filter === 'function' ? props.filter : null\n\n  // start the ball rolling.\n  // this checks what's there already, and then calls\n  // self._create() to call the impl-specific creation stuff.\n  self._stat(current)\n}\n\n// Calling this means that it's something we can't create.\n// Just assert that it's already there, otherwise raise a warning.\nWriter.prototype._create = function () {\n  var self = this\n  fs[self.props.follow ? 'stat' : 'lstat'](self._path, function (er) {\n    if (er) {\n      return self.warn('Cannot create ' + self._path + '\\n' +\n        'Unsupported type: ' + self.type, 'ENOTSUP')\n    }\n    self._finish()\n  })\n}\n\nWriter.prototype._stat = function (current) {\n  var self = this\n  var props = self.props\n  var stat = props.follow ? 'stat' : 'lstat'\n  var who = self._proxy || self\n\n  if (current) statCb(null, current)\n  else fs[stat](self._path, statCb)\n\n  function statCb (er, current) {\n    if (self.filter && !self.filter.call(who, who, current)) {\n      self._aborted = true\n      self.emit('end')\n      self.emit('close')\n      return\n    }\n\n    // if it's not there, great.  We'll just create it.\n    // if it is there, then we'll need to change whatever differs\n    if (er || !current) {\n      return create(self)\n    }\n\n    self._old = current\n    var currentType = getType(current)\n\n    // if it's a type change, then we need to clobber or error.\n    // if it's not a type change, then let the impl take care of it.\n    if (currentType !== self.type) {\n      return rimraf(self._path, function (er) {\n        if (er) return self.error(er)\n        self._old = null\n        create(self)\n      })\n    }\n\n    // otherwise, just handle in the app-specific way\n    // this creates a fs.WriteStream, or mkdir's, or whatever\n    create(self)\n  }\n}\n\nfunction create (self) {\n  // console.error(\"W create\", self._path, Writer.dirmode)\n\n  // XXX Need to clobber non-dirs that are in the way,\n  // unless { clobber: false } in the props.\n  mkdir(path.dirname(self._path), Writer.dirmode, function (er, made) {\n    // console.error(\"W created\", path.dirname(self._path), er)\n    if (er) return self.error(er)\n\n    // later on, we have to set the mode and owner for these\n    self._madeDir = made\n    return self._create()\n  })\n}\n\nfunction endChmod (self, want, current, path, cb) {\n  var wantMode = want.mode\n  var chmod = want.follow || self.type !== 'SymbolicLink'\n    ? 'chmod' : 'lchmod'\n\n  if (!fs[chmod]) return cb()\n  if (typeof wantMode !== 'number') return cb()\n\n  var curMode = current.mode & parseInt('0777', 8)\n  wantMode = wantMode & parseInt('0777', 8)\n  if (wantMode === curMode) return cb()\n\n  fs[chmod](path, wantMode, cb)\n}\n\nfunction endChown (self, want, current, path, cb) {\n  // Don't even try it unless root.  Too easy to EPERM.\n  if (process.platform === 'win32') return cb()\n  if (!process.getuid || process.getuid() !== 0) return cb()\n  if (typeof want.uid !== 'number' &&\n    typeof want.gid !== 'number') return cb()\n\n  if (current.uid === want.uid &&\n    current.gid === want.gid) return cb()\n\n  var chown = (self.props.follow || self.type !== 'SymbolicLink')\n    ? 'chown' : 'lchown'\n  if (!fs[chown]) return cb()\n\n  if (typeof want.uid !== 'number') want.uid = current.uid\n  if (typeof want.gid !== 'number') want.gid = current.gid\n\n  fs[chown](path, want.uid, want.gid, cb)\n}\n\nfunction endUtimes (self, want, current, path, cb) {\n  if (!fs.utimes || process.platform === 'win32') return cb()\n\n  var utimes = (want.follow || self.type !== 'SymbolicLink')\n    ? 'utimes' : 'lutimes'\n\n  if (utimes === 'lutimes' && !fs[utimes]) {\n    utimes = 'utimes'\n  }\n\n  if (!fs[utimes]) return cb()\n\n  var curA = current.atime\n  var curM = current.mtime\n  var meA = want.atime\n  var meM = want.mtime\n\n  if (meA === undefined) meA = curA\n  if (meM === undefined) meM = curM\n\n  if (!isDate(meA)) meA = new Date(meA)\n  if (!isDate(meM)) meA = new Date(meM)\n\n  if (meA.getTime() === curA.getTime() &&\n    meM.getTime() === curM.getTime()) return cb()\n\n  fs[utimes](path, meA, meM, cb)\n}\n\n// XXX This function is beastly.  Break it up!\nWriter.prototype._finish = function () {\n  var self = this\n\n  if (self._finishing) return\n  self._finishing = true\n\n  // console.error(\" W Finish\", self._path, self.size)\n\n  // set up all the things.\n  // At this point, we're already done writing whatever we've gotta write,\n  // adding files to the dir, etc.\n  var todo = 0\n  var errState = null\n  var done = false\n\n  if (self._old) {\n    // the times will almost *certainly* have changed.\n    // adds the utimes syscall, but remove another stat.\n    self._old.atime = new Date(0)\n    self._old.mtime = new Date(0)\n    // console.error(\" W Finish Stale Stat\", self._path, self.size)\n    setProps(self._old)\n  } else {\n    var stat = self.props.follow ? 'stat' : 'lstat'\n    // console.error(\" W Finish Stating\", self._path, self.size)\n    fs[stat](self._path, function (er, current) {\n      // console.error(\" W Finish Stated\", self._path, self.size, current)\n      if (er) {\n        // if we're in the process of writing out a\n        // directory, it's very possible that the thing we're linking to\n        // doesn't exist yet (especially if it was intended as a symlink),\n        // so swallow ENOENT errors here and just soldier on.\n        if (er.code === 'ENOENT' &&\n          (self.type === 'Link' || self.type === 'SymbolicLink') &&\n          process.platform === 'win32') {\n          self.ready = true\n          self.emit('ready')\n          self.emit('end')\n          self.emit('close')\n          self.end = self._finish = function () {}\n          return\n        } else return self.error(er)\n      }\n      setProps(self._old = current)\n    })\n  }\n\n  return\n\n  function setProps (current) {\n    todo += 3\n    endChmod(self, self.props, current, self._path, next('chmod'))\n    endChown(self, self.props, current, self._path, next('chown'))\n    endUtimes(self, self.props, current, self._path, next('utimes'))\n  }\n\n  function next (what) {\n    return function (er) {\n      // console.error(\"   W Finish\", what, todo)\n      if (errState) return\n      if (er) {\n        er.fstream_finish_call = what\n        return self.error(errState = er)\n      }\n      if (--todo > 0) return\n      if (done) return\n      done = true\n\n      // we may still need to set the mode/etc. on some parent dirs\n      // that were created previously.  delay end/close until then.\n      if (!self._madeDir) return end()\n      else endMadeDir(self, self._path, end)\n\n      function end (er) {\n        if (er) {\n          er.fstream_finish_call = 'setupMadeDir'\n          return self.error(er)\n        }\n        // all the props have been set, so we're completely done.\n        self.emit('end')\n        self.emit('close')\n      }\n    }\n  }\n}\n\nfunction endMadeDir (self, p, cb) {\n  var made = self._madeDir\n  // everything *between* made and path.dirname(self._path)\n  // needs to be set up.  Note that this may just be one dir.\n  var d = path.dirname(p)\n\n  endMadeDir_(self, d, function (er) {\n    if (er) return cb(er)\n    if (d === made) {\n      return cb()\n    }\n    endMadeDir(self, d, cb)\n  })\n}\n\nfunction endMadeDir_ (self, p, cb) {\n  var dirProps = {}\n  Object.keys(self.props).forEach(function (k) {\n    dirProps[k] = self.props[k]\n\n    // only make non-readable dirs if explicitly requested.\n    if (k === 'mode' && self.type !== 'Directory') {\n      dirProps[k] = dirProps[k] | parseInt('0111', 8)\n    }\n  })\n\n  var todo = 3\n  var errState = null\n  fs.stat(p, function (er, current) {\n    if (er) return cb(errState = er)\n    endChmod(self, dirProps, current, p, next)\n    endChown(self, dirProps, current, p, next)\n    endUtimes(self, dirProps, current, p, next)\n  })\n\n  function next (er) {\n    if (errState) return\n    if (er) return cb(errState = er)\n    if (--todo === 0) return cb()\n  }\n}\n\nWriter.prototype.pipe = function () {\n  this.error(\"Can't pipe from writable stream\")\n}\n\nWriter.prototype.add = function () {\n  this.error(\"Can't add to non-Directory type\")\n}\n\nWriter.prototype.write = function () {\n  return true\n}\n\nfunction objectToString (d) {\n  return Object.prototype.toString.call(d)\n}\n\nfunction isDate (d) {\n  return typeof d === 'object' && objectToString(d) === '[object Date]'\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/dir-writer.js":"// It is expected that, when .add() returns false, the consumer\n// of the DirWriter will pause until a \"drain\" event occurs. Note\n// that this is *almost always going to be the case*, unless the\n// thing being written is some sort of unsupported type, and thus\n// skipped over.\n\nmodule.exports = DirWriter\n\nvar Writer = require('./writer.js')\nvar inherits = require('inherits')\nvar mkdir = require('mkdirp')\nvar path = require('path')\nvar collect = require('./collect.js')\n\ninherits(DirWriter, Writer)\n\nfunction DirWriter (props) {\n  var self = this\n  if (!(self instanceof DirWriter)) {\n    self.error('DirWriter must be called as constructor.', null, true)\n  }\n\n  // should already be established as a Directory type\n  if (props.type !== 'Directory' || !props.Directory) {\n    self.error('Non-directory type ' + props.type + ' ' +\n      JSON.stringify(props), null, true)\n  }\n\n  Writer.call(this, props)\n}\n\nDirWriter.prototype._create = function () {\n  var self = this\n  mkdir(self._path, Writer.dirmode, function (er) {\n    if (er) return self.error(er)\n    // ready to start getting entries!\n    self.ready = true\n    self.emit('ready')\n    self._process()\n  })\n}\n\n// a DirWriter has an add(entry) method, but its .write() doesn't\n// do anything.  Why a no-op rather than a throw?  Because this\n// leaves open the door for writing directory metadata for\n// gnu/solaris style dumpdirs.\nDirWriter.prototype.write = function () {\n  return true\n}\n\nDirWriter.prototype.end = function () {\n  this._ended = true\n  this._process()\n}\n\nDirWriter.prototype.add = function (entry) {\n  var self = this\n\n  // console.error('\\tadd', entry._path, '->', self._path)\n  collect(entry)\n  if (!self.ready || self._currentEntry) {\n    self._buffer.push(entry)\n    return false\n  }\n\n  // create a new writer, and pipe the incoming entry into it.\n  if (self._ended) {\n    return self.error('add after end')\n  }\n\n  self._buffer.push(entry)\n  self._process()\n\n  return this._buffer.length === 0\n}\n\nDirWriter.prototype._process = function () {\n  var self = this\n\n  // console.error('DW Process p=%j', self._processing, self.basename)\n\n  if (self._processing) return\n\n  var entry = self._buffer.shift()\n  if (!entry) {\n    // console.error(\"DW Drain\")\n    self.emit('drain')\n    if (self._ended) self._finish()\n    return\n  }\n\n  self._processing = true\n  // console.error(\"DW Entry\", entry._path)\n\n  self.emit('entry', entry)\n\n  // ok, add this entry\n  //\n  // don't allow recursive copying\n  var p = entry\n  var pp\n  do {\n    pp = p._path || p.path\n    if (pp === self.root._path || pp === self._path ||\n      (pp && pp.indexOf(self._path) === 0)) {\n      // console.error('DW Exit (recursive)', entry.basename, self._path)\n      self._processing = false\n      if (entry._collected) entry.pipe()\n      return self._process()\n    }\n    p = p.parent\n  } while (p)\n\n  // console.error(\"DW not recursive\")\n\n  // chop off the entry's root dir, replace with ours\n  var props = {\n    parent: self,\n    root: self.root || self,\n    type: entry.type,\n    depth: self.depth + 1\n  }\n\n  pp = entry._path || entry.path || entry.props.path\n  if (entry.parent) {\n    pp = pp.substr(entry.parent._path.length + 1)\n  }\n  // get rid of any ../../ shenanigans\n  props.path = path.join(self.path, path.join('/', pp))\n\n  // if i have a filter, the child should inherit it.\n  props.filter = self.filter\n\n  // all the rest of the stuff, copy over from the source.\n  Object.keys(entry.props).forEach(function (k) {\n    if (!props.hasOwnProperty(k)) {\n      props[k] = entry.props[k]\n    }\n  })\n\n  // not sure at this point what kind of writer this is.\n  var child = self._currentChild = new Writer(props)\n  child.on('ready', function () {\n    // console.error(\"DW Child Ready\", child.type, child._path)\n    // console.error(\"  resuming\", entry._path)\n    entry.pipe(child)\n    entry.resume()\n  })\n\n  // XXX Make this work in node.\n  // Long filenames should not break stuff.\n  child.on('error', function (er) {\n    if (child._swallowErrors) {\n      self.warn(er)\n      child.emit('end')\n      child.emit('close')\n    } else {\n      self.emit('error', er)\n    }\n  })\n\n  // we fire _end internally *after* end, so that we don't move on\n  // until any \"end\" listeners have had their chance to do stuff.\n  child.on('close', onend)\n  var ended = false\n  function onend () {\n    if (ended) return\n    ended = true\n    // console.error(\"* DW Child end\", child.basename)\n    self._currentChild = null\n    self._processing = false\n    self._process()\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/collect.js":"module.exports = collect\n\nfunction collect (stream) {\n  if (stream._collected) return\n\n  if (stream._paused) return stream.on('resume', collect.bind(null, stream))\n\n  stream._collected = true\n  stream.pause()\n\n  stream.on('data', save)\n  stream.on('end', save)\n  var buf = []\n  function save (b) {\n    if (typeof b === 'string') b = new Buffer(b)\n    if (Buffer.isBuffer(b) && !b.length) return\n    buf.push(b)\n  }\n\n  stream.on('entry', saveEntry)\n  var entryBuffer = []\n  function saveEntry (e) {\n    collect(e)\n    entryBuffer.push(e)\n  }\n\n  stream.on('proxy', proxyPause)\n  function proxyPause (p) {\n    p.pause()\n  }\n\n  // replace the pipe method with a new version that will\n  // unlock the buffered stuff.  if you just call .pipe()\n  // without a destination, then it'll re-play the events.\n  stream.pipe = (function (orig) {\n    return function (dest) {\n      // console.error(' === open the pipes', dest && dest.path)\n\n      // let the entries flow through one at a time.\n      // Once they're all done, then we can resume completely.\n      var e = 0\n      ;(function unblockEntry () {\n        var entry = entryBuffer[e++]\n        // console.error(\" ==== unblock entry\", entry && entry.path)\n        if (!entry) return resume()\n        entry.on('end', unblockEntry)\n        if (dest) dest.add(entry)\n        else stream.emit('entry', entry)\n      })()\n\n      function resume () {\n        stream.removeListener('entry', saveEntry)\n        stream.removeListener('data', save)\n        stream.removeListener('end', save)\n\n        stream.pipe = orig\n        if (dest) stream.pipe(dest)\n\n        buf.forEach(function (b) {\n          if (b) stream.emit('data', b)\n          else stream.emit('end')\n        })\n\n        stream.resume()\n      }\n\n      return dest\n    }\n  })(stream.pipe)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/link-writer.js":"module.exports = LinkWriter\n\nvar fs = require('graceful-fs')\nvar Writer = require('./writer.js')\nvar inherits = require('inherits')\nvar path = require('path')\nvar rimraf = require('rimraf')\n\ninherits(LinkWriter, Writer)\n\nfunction LinkWriter (props) {\n  var self = this\n  if (!(self instanceof LinkWriter)) {\n    throw new Error('LinkWriter must be called as constructor.')\n  }\n\n  // should already be established as a Link type\n  if (!((props.type === 'Link' && props.Link) ||\n    (props.type === 'SymbolicLink' && props.SymbolicLink))) {\n    throw new Error('Non-link type ' + props.type)\n  }\n\n  if (props.linkpath === '') props.linkpath = '.'\n  if (!props.linkpath) {\n    self.error('Need linkpath property to create ' + props.type)\n  }\n\n  Writer.call(this, props)\n}\n\nLinkWriter.prototype._create = function () {\n  // console.error(\" LW _create\")\n  var self = this\n  var hard = self.type === 'Link' || process.platform === 'win32'\n  var link = hard ? 'link' : 'symlink'\n  var lp = hard ? path.resolve(self.dirname, self.linkpath) : self.linkpath\n\n  // can only change the link path by clobbering\n  // For hard links, let's just assume that's always the case, since\n  // there's no good way to read them if we don't already know.\n  if (hard) return clobber(self, lp, link)\n\n  fs.readlink(self._path, function (er, p) {\n    // only skip creation if it's exactly the same link\n    if (p && p === lp) return finish(self)\n    clobber(self, lp, link)\n  })\n}\n\nfunction clobber (self, lp, link) {\n  rimraf(self._path, function (er) {\n    if (er) return self.error(er)\n    create(self, lp, link)\n  })\n}\n\nfunction create (self, lp, link) {\n  fs[link](lp, self._path, function (er) {\n    // if this is a hard link, and we're in the process of writing out a\n    // directory, it's very possible that the thing we're linking to\n    // doesn't exist yet (especially if it was intended as a symlink),\n    // so swallow ENOENT errors here and just soldier in.\n    // Additionally, an EPERM or EACCES can happen on win32 if it's trying\n    // to make a link to a directory.  Again, just skip it.\n    // A better solution would be to have fs.symlink be supported on\n    // windows in some nice fashion.\n    if (er) {\n      if ((er.code === 'ENOENT' ||\n        er.code === 'EACCES' ||\n        er.code === 'EPERM') && process.platform === 'win32') {\n        self.ready = true\n        self.emit('ready')\n        self.emit('end')\n        self.emit('close')\n        self.end = self._finish = function () {}\n      } else return self.error(er)\n    }\n    finish(self)\n  })\n}\n\nfunction finish (self) {\n  self.ready = true\n  self.emit('ready')\n  if (self._ended && !self._finished) self._finish()\n}\n\nLinkWriter.prototype.end = function () {\n  // console.error(\"LW finish in end\")\n  this._ended = true\n  if (this.ready) {\n    this._finished = true\n    this._finish()\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/file-writer.js":"module.exports = FileWriter\n\nvar fs = require('graceful-fs')\nvar Writer = require('./writer.js')\nvar inherits = require('inherits')\nvar EOF = {}\n\ninherits(FileWriter, Writer)\n\nfunction FileWriter (props) {\n  var self = this\n  if (!(self instanceof FileWriter)) {\n    throw new Error('FileWriter must be called as constructor.')\n  }\n\n  // should already be established as a File type\n  if (props.type !== 'File' || !props.File) {\n    throw new Error('Non-file type ' + props.type)\n  }\n\n  self._buffer = []\n  self._bytesWritten = 0\n\n  Writer.call(this, props)\n}\n\nFileWriter.prototype._create = function () {\n  var self = this\n  if (self._stream) return\n\n  var so = {}\n  if (self.props.flags) so.flags = self.props.flags\n  so.mode = Writer.filemode\n  if (self._old && self._old.blksize) so.bufferSize = self._old.blksize\n\n  self._stream = fs.createWriteStream(self._path, so)\n\n  self._stream.on('open', function () {\n    // console.error(\"FW open\", self._buffer, self._path)\n    self.ready = true\n    self._buffer.forEach(function (c) {\n      if (c === EOF) self._stream.end()\n      else self._stream.write(c)\n    })\n    self.emit('ready')\n    // give this a kick just in case it needs it.\n    self.emit('drain')\n  })\n\n  self._stream.on('error', function (er) { self.emit('error', er) })\n\n  self._stream.on('drain', function () { self.emit('drain') })\n\n  self._stream.on('close', function () {\n    // console.error('\\n\\nFW Stream Close', self._path, self.size)\n    self._finish()\n  })\n}\n\nFileWriter.prototype.write = function (c) {\n  var self = this\n\n  self._bytesWritten += c.length\n\n  if (!self.ready) {\n    if (!Buffer.isBuffer(c) && typeof c !== 'string') {\n      throw new Error('invalid write data')\n    }\n    self._buffer.push(c)\n    return false\n  }\n\n  var ret = self._stream.write(c)\n  // console.error('\\t-- fw wrote, _stream says', ret, self._stream._queue.length)\n\n  // allow 2 buffered writes, because otherwise there's just too\n  // much stop and go bs.\n  if (ret === false && self._stream._queue) {\n    return self._stream._queue.length <= 2\n  } else {\n    return ret\n  }\n}\n\nFileWriter.prototype.end = function (c) {\n  var self = this\n\n  if (c) self.write(c)\n\n  if (!self.ready) {\n    self._buffer.push(EOF)\n    return false\n  }\n\n  return self._stream.end()\n}\n\nFileWriter.prototype._finish = function () {\n  var self = this\n  if (typeof self.size === 'number' && self._bytesWritten !== self.size) {\n    self.error(\n      'Did not get expected byte count.\\n' +\n      'expect: ' + self.size + '\\n' +\n      'actual: ' + self._bytesWritten)\n  }\n  Writer.prototype._finish.call(self)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/proxy-writer.js":"// A writer for when we don't know what kind of thing\n// the thing is.  That is, it's not explicitly set,\n// so we're going to make it whatever the thing already\n// is, or \"File\"\n//\n// Until then, collect all events.\n\nmodule.exports = ProxyWriter\n\nvar Writer = require('./writer.js')\nvar getType = require('./get-type.js')\nvar inherits = require('inherits')\nvar collect = require('./collect.js')\nvar fs = require('fs')\n\ninherits(ProxyWriter, Writer)\n\nfunction ProxyWriter (props) {\n  var self = this\n  if (!(self instanceof ProxyWriter)) {\n    throw new Error('ProxyWriter must be called as constructor.')\n  }\n\n  self.props = props\n  self._needDrain = false\n\n  Writer.call(self, props)\n}\n\nProxyWriter.prototype._stat = function () {\n  var self = this\n  var props = self.props\n  // stat the thing to see what the proxy should be.\n  var stat = props.follow ? 'stat' : 'lstat'\n\n  fs[stat](props.path, function (er, current) {\n    var type\n    if (er || !current) {\n      type = 'File'\n    } else {\n      type = getType(current)\n    }\n\n    props[type] = true\n    props.type = self.type = type\n\n    self._old = current\n    self._addProxy(Writer(props, current))\n  })\n}\n\nProxyWriter.prototype._addProxy = function (proxy) {\n  // console.error(\"~~ set proxy\", this.path)\n  var self = this\n  if (self._proxy) {\n    return self.error('proxy already set')\n  }\n\n  self._proxy = proxy\n  ;[\n    'ready',\n    'error',\n    'close',\n    'pipe',\n    'drain',\n    'warn'\n  ].forEach(function (ev) {\n    proxy.on(ev, self.emit.bind(self, ev))\n  })\n\n  self.emit('proxy', proxy)\n\n  var calls = self._buffer\n  calls.forEach(function (c) {\n    // console.error(\"~~ ~~ proxy buffered call\", c[0], c[1])\n    proxy[c[0]].apply(proxy, c[1])\n  })\n  self._buffer.length = 0\n  if (self._needsDrain) self.emit('drain')\n}\n\nProxyWriter.prototype.add = function (entry) {\n  // console.error(\"~~ proxy add\")\n  collect(entry)\n\n  if (!this._proxy) {\n    this._buffer.push(['add', [entry]])\n    this._needDrain = true\n    return false\n  }\n  return this._proxy.add(entry)\n}\n\nProxyWriter.prototype.write = function (c) {\n  // console.error('~~ proxy write')\n  if (!this._proxy) {\n    this._buffer.push(['write', [c]])\n    this._needDrain = true\n    return false\n  }\n  return this._proxy.write(c)\n}\n\nProxyWriter.prototype.end = function (c) {\n  // console.error('~~ proxy end')\n  if (!this._proxy) {\n    this._buffer.push(['end', [c]])\n    return false\n  }\n  return this._proxy.end(c)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/file-reader.js":"// Basically just a wrapper around an fs.ReadStream\n\nmodule.exports = FileReader\n\nvar fs = require('graceful-fs')\nvar inherits = require('inherits')\nvar Reader = require('./reader.js')\nvar EOF = {EOF: true}\nvar CLOSE = {CLOSE: true}\n\ninherits(FileReader, Reader)\n\nfunction FileReader (props) {\n  // console.error(\"    FR create\", props.path, props.size, new Error().stack)\n  var self = this\n  if (!(self instanceof FileReader)) {\n    throw new Error('FileReader must be called as constructor.')\n  }\n\n  // should already be established as a File type\n  // XXX Todo: preserve hardlinks by tracking dev+inode+nlink,\n  // with a HardLinkReader class.\n  if (!((props.type === 'Link' && props.Link) ||\n    (props.type === 'File' && props.File))) {\n    throw new Error('Non-file type ' + props.type)\n  }\n\n  self._buffer = []\n  self._bytesEmitted = 0\n  Reader.call(self, props)\n}\n\nFileReader.prototype._getStream = function () {\n  var self = this\n  var stream = self._stream = fs.createReadStream(self._path, self.props)\n\n  if (self.props.blksize) {\n    stream.bufferSize = self.props.blksize\n  }\n\n  stream.on('open', self.emit.bind(self, 'open'))\n\n  stream.on('data', function (c) {\n    // console.error('\\t\\t%d %s', c.length, self.basename)\n    self._bytesEmitted += c.length\n    // no point saving empty chunks\n    if (!c.length) {\n      return\n    } else if (self._paused || self._buffer.length) {\n      self._buffer.push(c)\n      self._read()\n    } else self.emit('data', c)\n  })\n\n  stream.on('end', function () {\n    if (self._paused || self._buffer.length) {\n      // console.error('FR Buffering End', self._path)\n      self._buffer.push(EOF)\n      self._read()\n    } else {\n      self.emit('end')\n    }\n\n    if (self._bytesEmitted !== self.props.size) {\n      self.error(\"Didn't get expected byte count\\n\" +\n        'expect: ' + self.props.size + '\\n' +\n        'actual: ' + self._bytesEmitted)\n    }\n  })\n\n  stream.on('close', function () {\n    if (self._paused || self._buffer.length) {\n      // console.error('FR Buffering Close', self._path)\n      self._buffer.push(CLOSE)\n      self._read()\n    } else {\n      // console.error('FR close 1', self._path)\n      self.emit('close')\n    }\n  })\n\n  stream.on('error', function (e) {\n    self.emit('error', e)\n  })\n\n  self._read()\n}\n\nFileReader.prototype._read = function () {\n  var self = this\n  // console.error('FR _read', self._path)\n  if (self._paused) {\n    // console.error('FR _read paused', self._path)\n    return\n  }\n\n  if (!self._stream) {\n    // console.error('FR _getStream calling', self._path)\n    return self._getStream()\n  }\n\n  // clear out the buffer, if there is one.\n  if (self._buffer.length) {\n    // console.error('FR _read has buffer', self._buffer.length, self._path)\n    var buf = self._buffer\n    for (var i = 0, l = buf.length; i < l; i++) {\n      var c = buf[i]\n      if (c === EOF) {\n        // console.error('FR Read emitting buffered end', self._path)\n        self.emit('end')\n      } else if (c === CLOSE) {\n        // console.error('FR Read emitting buffered close', self._path)\n        self.emit('close')\n      } else {\n        // console.error('FR Read emitting buffered data', self._path)\n        self.emit('data', c)\n      }\n\n      if (self._paused) {\n        // console.error('FR Read Re-pausing at '+i, self._path)\n        self._buffer = buf.slice(i)\n        return\n      }\n    }\n    self._buffer.length = 0\n  }\n// console.error(\"FR _read done\")\n// that's about all there is to it.\n}\n\nFileReader.prototype.pause = function (who) {\n  var self = this\n  // console.error('FR Pause', self._path)\n  if (self._paused) return\n  who = who || self\n  self._paused = true\n  if (self._stream) self._stream.pause()\n  self.emit('pause', who)\n}\n\nFileReader.prototype.resume = function (who) {\n  var self = this\n  // console.error('FR Resume', self._path)\n  if (!self._paused) return\n  who = who || self\n  self.emit('resume', who)\n  self._paused = false\n  if (self._stream) self._stream.resume()\n  self._read()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/dir-reader.js":"// A thing that emits \"entry\" events with Reader objects\n// Pausing it causes it to stop emitting entry events, and also\n// pauses the current entry if there is one.\n\nmodule.exports = DirReader\n\nvar fs = require('graceful-fs')\nvar inherits = require('inherits')\nvar path = require('path')\nvar Reader = require('./reader.js')\nvar assert = require('assert').ok\n\ninherits(DirReader, Reader)\n\nfunction DirReader (props) {\n  var self = this\n  if (!(self instanceof DirReader)) {\n    throw new Error('DirReader must be called as constructor.')\n  }\n\n  // should already be established as a Directory type\n  if (props.type !== 'Directory' || !props.Directory) {\n    throw new Error('Non-directory type ' + props.type)\n  }\n\n  self.entries = null\n  self._index = -1\n  self._paused = false\n  self._length = -1\n\n  if (props.sort) {\n    this.sort = props.sort\n  }\n\n  Reader.call(this, props)\n}\n\nDirReader.prototype._getEntries = function () {\n  var self = this\n\n  // race condition.  might pause() before calling _getEntries,\n  // and then resume, and try to get them a second time.\n  if (self._gotEntries) return\n  self._gotEntries = true\n\n  fs.readdir(self._path, function (er, entries) {\n    if (er) return self.error(er)\n\n    self.entries = entries\n\n    self.emit('entries', entries)\n    if (self._paused) self.once('resume', processEntries)\n    else processEntries()\n\n    function processEntries () {\n      self._length = self.entries.length\n      if (typeof self.sort === 'function') {\n        self.entries = self.entries.sort(self.sort.bind(self))\n      }\n      self._read()\n    }\n  })\n}\n\n// start walking the dir, and emit an \"entry\" event for each one.\nDirReader.prototype._read = function () {\n  var self = this\n\n  if (!self.entries) return self._getEntries()\n\n  if (self._paused || self._currentEntry || self._aborted) {\n    // console.error('DR paused=%j, current=%j, aborted=%j', self._paused, !!self._currentEntry, self._aborted)\n    return\n  }\n\n  self._index++\n  if (self._index >= self.entries.length) {\n    if (!self._ended) {\n      self._ended = true\n      self.emit('end')\n      self.emit('close')\n    }\n    return\n  }\n\n  // ok, handle this one, then.\n\n  // save creating a proxy, by stat'ing the thing now.\n  var p = path.resolve(self._path, self.entries[self._index])\n  assert(p !== self._path)\n  assert(self.entries[self._index])\n\n  // set this to prevent trying to _read() again in the stat time.\n  self._currentEntry = p\n  fs[ self.props.follow ? 'stat' : 'lstat' ](p, function (er, stat) {\n    if (er) return self.error(er)\n\n    var who = self._proxy || self\n\n    stat.path = p\n    stat.basename = path.basename(p)\n    stat.dirname = path.dirname(p)\n    var childProps = self.getChildProps.call(who, stat)\n    childProps.path = p\n    childProps.basename = path.basename(p)\n    childProps.dirname = path.dirname(p)\n\n    var entry = Reader(childProps, stat)\n\n    // console.error(\"DR Entry\", p, stat.size)\n\n    self._currentEntry = entry\n\n    // \"entry\" events are for direct entries in a specific dir.\n    // \"child\" events are for any and all children at all levels.\n    // This nomenclature is not completely final.\n\n    entry.on('pause', function (who) {\n      if (!self._paused && !entry._disowned) {\n        self.pause(who)\n      }\n    })\n\n    entry.on('resume', function (who) {\n      if (self._paused && !entry._disowned) {\n        self.resume(who)\n      }\n    })\n\n    entry.on('stat', function (props) {\n      self.emit('_entryStat', entry, props)\n      if (entry._aborted) return\n      if (entry._paused) {\n        entry.once('resume', function () {\n          self.emit('entryStat', entry, props)\n        })\n      } else self.emit('entryStat', entry, props)\n    })\n\n    entry.on('ready', function EMITCHILD () {\n      // console.error(\"DR emit child\", entry._path)\n      if (self._paused) {\n        // console.error(\"  DR emit child - try again later\")\n        // pause the child, and emit the \"entry\" event once we drain.\n        // console.error(\"DR pausing child entry\")\n        entry.pause(self)\n        return self.once('resume', EMITCHILD)\n      }\n\n      // skip over sockets.  they can't be piped around properly,\n      // so there's really no sense even acknowledging them.\n      // if someone really wants to see them, they can listen to\n      // the \"socket\" events.\n      if (entry.type === 'Socket') {\n        self.emit('socket', entry)\n      } else {\n        self.emitEntry(entry)\n      }\n    })\n\n    var ended = false\n    entry.on('close', onend)\n    entry.on('disown', onend)\n    function onend () {\n      if (ended) return\n      ended = true\n      self.emit('childEnd', entry)\n      self.emit('entryEnd', entry)\n      self._currentEntry = null\n      if (!self._paused) {\n        self._read()\n      }\n    }\n\n    // XXX Remove this.  Works in node as of 0.6.2 or so.\n    // Long filenames should not break stuff.\n    entry.on('error', function (er) {\n      if (entry._swallowErrors) {\n        self.warn(er)\n        entry.emit('end')\n        entry.emit('close')\n      } else {\n        self.emit('error', er)\n      }\n    })\n\n    // proxy up some events.\n    ;[\n      'child',\n      'childEnd',\n      'warn'\n    ].forEach(function (ev) {\n      entry.on(ev, self.emit.bind(self, ev))\n    })\n  })\n}\n\nDirReader.prototype.disown = function (entry) {\n  entry.emit('beforeDisown')\n  entry._disowned = true\n  entry.parent = entry.root = null\n  if (entry === this._currentEntry) {\n    this._currentEntry = null\n  }\n  entry.emit('disown')\n}\n\nDirReader.prototype.getChildProps = function () {\n  return {\n    depth: this.depth + 1,\n    root: this.root || this,\n    parent: this,\n    follow: this.follow,\n    filter: this.filter,\n    sort: this.props.sort,\n    hardlinks: this.props.hardlinks\n  }\n}\n\nDirReader.prototype.pause = function (who) {\n  var self = this\n  if (self._paused) return\n  who = who || self\n  self._paused = true\n  if (self._currentEntry && self._currentEntry.pause) {\n    self._currentEntry.pause(who)\n  }\n  self.emit('pause', who)\n}\n\nDirReader.prototype.resume = function (who) {\n  var self = this\n  if (!self._paused) return\n  who = who || self\n\n  self._paused = false\n  // console.error('DR Emit Resume', self._path)\n  self.emit('resume', who)\n  if (self._paused) {\n    // console.error('DR Re-paused', self._path)\n    return\n  }\n\n  if (self._currentEntry) {\n    if (self._currentEntry.resume) self._currentEntry.resume(who)\n  } else self._read()\n}\n\nDirReader.prototype.emitEntry = function (entry) {\n  this.emit('entry', entry)\n  this.emit('child', entry)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream/lib/proxy-reader.js":"// A reader for when we don't yet know what kind of thing\n// the thing is.\n\nmodule.exports = ProxyReader\n\nvar Reader = require('./reader.js')\nvar getType = require('./get-type.js')\nvar inherits = require('inherits')\nvar fs = require('graceful-fs')\n\ninherits(ProxyReader, Reader)\n\nfunction ProxyReader (props) {\n  var self = this\n  if (!(self instanceof ProxyReader)) {\n    throw new Error('ProxyReader must be called as constructor.')\n  }\n\n  self.props = props\n  self._buffer = []\n  self.ready = false\n\n  Reader.call(self, props)\n}\n\nProxyReader.prototype._stat = function () {\n  var self = this\n  var props = self.props\n  // stat the thing to see what the proxy should be.\n  var stat = props.follow ? 'stat' : 'lstat'\n\n  fs[stat](props.path, function (er, current) {\n    var type\n    if (er || !current) {\n      type = 'File'\n    } else {\n      type = getType(current)\n    }\n\n    props[type] = true\n    props.type = self.type = type\n\n    self._old = current\n    self._addProxy(Reader(props, current))\n  })\n}\n\nProxyReader.prototype._addProxy = function (proxy) {\n  var self = this\n  if (self._proxyTarget) {\n    return self.error('proxy already set')\n  }\n\n  self._proxyTarget = proxy\n  proxy._proxy = self\n\n  ;[\n    'error',\n    'data',\n    'end',\n    'close',\n    'linkpath',\n    'entry',\n    'entryEnd',\n    'child',\n    'childEnd',\n    'warn',\n    'stat'\n  ].forEach(function (ev) {\n    // console.error('~~ proxy event', ev, self.path)\n    proxy.on(ev, self.emit.bind(self, ev))\n  })\n\n  self.emit('proxy', proxy)\n\n  proxy.on('ready', function () {\n    // console.error(\"~~ proxy is ready!\", self.path)\n    self.ready = true\n    self.emit('ready')\n  })\n\n  var calls = self._buffer\n  self._buffer.length = 0\n  calls.forEach(function (c) {\n    proxy[c[0]].apply(proxy, c[1])\n  })\n}\n\nProxyReader.prototype.pause = function () {\n  return this._proxyTarget ? this._proxyTarget.pause() : false\n}\n\nProxyReader.prototype.resume = function () {\n  return this._proxyTarget ? this._proxyTarget.resume() : false\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/node_modules/block-stream/block-stream.js":"// write data to it, and it'll emit data in 512 byte blocks.\n// if you .end() or .flush(), it'll emit whatever it's got,\n// padded with nulls to 512 bytes.\n\nmodule.exports = BlockStream\n\nvar Stream = require(\"stream\").Stream\n  , inherits = require(\"inherits\")\n  , assert = require(\"assert\").ok\n  , debug = process.env.DEBUG ? console.error : function () {}\n\nfunction BlockStream (size, opt) {\n  this.writable = this.readable = true\n  this._opt = opt || {}\n  this._chunkSize = size || 512\n  this._offset = 0\n  this._buffer = []\n  this._bufferLength = 0\n  if (this._opt.nopad) this._zeroes = false\n  else {\n    this._zeroes = new Buffer(this._chunkSize)\n    for (var i = 0; i < this._chunkSize; i ++) {\n      this._zeroes[i] = 0\n    }\n  }\n}\n\ninherits(BlockStream, Stream)\n\nBlockStream.prototype.write = function (c) {\n  // debug(\"   BS write\", c)\n  if (this._ended) throw new Error(\"BlockStream: write after end\")\n  if (c && !Buffer.isBuffer(c)) c = new Buffer(c + \"\")\n  if (c.length) {\n    this._buffer.push(c)\n    this._bufferLength += c.length\n  }\n  // debug(\"pushed onto buffer\", this._bufferLength)\n  if (this._bufferLength >= this._chunkSize) {\n    if (this._paused) {\n      // debug(\"   BS paused, return false, need drain\")\n      this._needDrain = true\n      return false\n    }\n    this._emitChunk()\n  }\n  return true\n}\n\nBlockStream.prototype.pause = function () {\n  // debug(\"   BS pausing\")\n  this._paused = true\n}\n\nBlockStream.prototype.resume = function () {\n  // debug(\"   BS resume\")\n  this._paused = false\n  return this._emitChunk()\n}\n\nBlockStream.prototype.end = function (chunk) {\n  // debug(\"end\", chunk)\n  if (typeof chunk === \"function\") cb = chunk, chunk = null\n  if (chunk) this.write(chunk)\n  this._ended = true\n  this.flush()\n}\n\nBlockStream.prototype.flush = function () {\n  this._emitChunk(true)\n}\n\nBlockStream.prototype._emitChunk = function (flush) {\n  // debug(\"emitChunk flush=%j emitting=%j paused=%j\", flush, this._emitting, this._paused)\n\n  // emit a <chunkSize> chunk\n  if (flush && this._zeroes) {\n    // debug(\"    BS push zeroes\", this._bufferLength)\n    // push a chunk of zeroes\n    var padBytes = (this._bufferLength % this._chunkSize)\n    if (padBytes !== 0) padBytes = this._chunkSize - padBytes\n    if (padBytes > 0) {\n      // debug(\"padBytes\", padBytes, this._zeroes.slice(0, padBytes))\n      this._buffer.push(this._zeroes.slice(0, padBytes))\n      this._bufferLength += padBytes\n      // debug(this._buffer[this._buffer.length - 1].length, this._bufferLength)\n    }\n  }\n\n  if (this._emitting || this._paused) return\n  this._emitting = true\n\n  // debug(\"    BS entering loops\")\n  var bufferIndex = 0\n  while (this._bufferLength >= this._chunkSize &&\n         (flush || !this._paused)) {\n    // debug(\"     BS data emission loop\", this._bufferLength)\n\n    var out\n      , outOffset = 0\n      , outHas = this._chunkSize\n\n    while (outHas > 0 && (flush || !this._paused) ) {\n      // debug(\"    BS data inner emit loop\", this._bufferLength)\n      var cur = this._buffer[bufferIndex]\n        , curHas = cur.length - this._offset\n      // debug(\"cur=\", cur)\n      // debug(\"curHas=%j\", curHas)\n      // If it's not big enough to fill the whole thing, then we'll need\n      // to copy multiple buffers into one.  However, if it is big enough,\n      // then just slice out the part we want, to save unnecessary copying.\n      // Also, need to copy if we've already done some copying, since buffers\n      // can't be joined like cons strings.\n      if (out || curHas < outHas) {\n        out = out || new Buffer(this._chunkSize)\n        cur.copy(out, outOffset,\n                 this._offset, this._offset + Math.min(curHas, outHas))\n      } else if (cur.length === outHas && this._offset === 0) {\n        // shortcut -- cur is exactly long enough, and no offset.\n        out = cur\n      } else {\n        // slice out the piece of cur that we need.\n        out = cur.slice(this._offset, this._offset + outHas)\n      }\n\n      if (curHas > outHas) {\n        // means that the current buffer couldn't be completely output\n        // update this._offset to reflect how much WAS written\n        this._offset += outHas\n        outHas = 0\n      } else {\n        // output the entire current chunk.\n        // toss it away\n        outHas -= curHas\n        outOffset += curHas\n        bufferIndex ++\n        this._offset = 0\n      }\n    }\n\n    this._bufferLength -= this._chunkSize\n    assert(out.length === this._chunkSize)\n    // debug(\"emitting data\", out)\n    // debug(\"   BS emitting, paused=%j\", this._paused, this._bufferLength)\n    this.emit(\"data\", out)\n    out = null\n  }\n  // debug(\"    BS out of loops\", this._bufferLength)\n\n  // whatever is left, it's not enough to fill up a block, or we're paused\n  this._buffer = this._buffer.slice(bufferIndex)\n  if (this._paused) {\n    // debug(\"    BS paused, leaving\", this._bufferLength)\n    this._needsDrain = true\n    this._emitting = false\n    return\n  }\n\n  // if flushing, and not using null-padding, then need to emit the last\n  // chunk(s) sitting in the queue.  We know that it's not enough to\n  // fill up a whole block, because otherwise it would have been emitted\n  // above, but there may be some offset.\n  var l = this._buffer.length\n  if (flush && !this._zeroes && l) {\n    if (l === 1) {\n      if (this._offset) {\n        this.emit(\"data\", this._buffer[0].slice(this._offset))\n      } else {\n        this.emit(\"data\", this._buffer[0])\n      }\n    } else {\n      var outHas = this._bufferLength\n        , out = new Buffer(outHas)\n        , outOffset = 0\n      for (var i = 0; i < l; i ++) {\n        var cur = this._buffer[i]\n          , curHas = cur.length - this._offset\n        cur.copy(out, outOffset, this._offset)\n        this._offset = 0\n        outOffset += curHas\n        this._bufferLength -= curHas\n      }\n      this.emit(\"data\", out)\n    }\n    // truncate\n    this._buffer.length = 0\n    this._bufferLength = 0\n    this._offset = 0\n  }\n\n  // now either drained or ended\n  // debug(\"either draining, or ended\", this._bufferLength, this._ended)\n  // means that we've flushed out all that we can so far.\n  if (this._needDrain) {\n    // debug(\"emitting drain\", this._bufferLength)\n    this._needDrain = false\n    this.emit(\"drain\")\n  }\n\n  if ((this._bufferLength === 0) && this._ended && !this._endEmitted) {\n    // debug(\"emitting end\", this._bufferLength)\n    this._endEmitted = true\n    this.emit(\"end\")\n  }\n\n  this._emitting = false\n\n  // debug(\"    BS no longer emitting\", flush, this._paused, this._emitting, this._bufferLength, this._chunkSize)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/global-header-writer.js":"module.exports = GlobalHeaderWriter\n\nvar ExtendedHeaderWriter = require(\"./extended-header-writer.js\")\n  , inherits = require(\"inherits\")\n\ninherits(GlobalHeaderWriter, ExtendedHeaderWriter)\n\nfunction GlobalHeaderWriter (props) {\n  if (!(this instanceof GlobalHeaderWriter)) {\n    return new GlobalHeaderWriter(props)\n  }\n  ExtendedHeaderWriter.call(this, props)\n  this.props.type = \"g\"\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/extended-header-writer.js":"\nmodule.exports = ExtendedHeaderWriter\n\nvar inherits = require(\"inherits\")\n  , EntryWriter = require(\"./entry-writer.js\")\n\ninherits(ExtendedHeaderWriter, EntryWriter)\n\nvar tar = require(\"../tar.js\")\n  , path = require(\"path\")\n  , TarHeader = require(\"./header.js\")\n\n// props is the props of the thing we need to write an\n// extended header for.\n// Don't be shy with it.  Just encode everything.\nfunction ExtendedHeaderWriter (props) {\n  // console.error(\">> ehw ctor\")\n  var me = this\n\n  if (!(me instanceof ExtendedHeaderWriter)) {\n    return new ExtendedHeaderWriter(props)\n  }\n\n  me.fields = props\n\n  var p =\n    { path : (\"PaxHeader\" + path.join(\"/\", props.path || \"\"))\n             .replace(/\\\\/g, \"/\").substr(0, 100)\n    , mode : props.mode || 0666\n    , uid : props.uid || 0\n    , gid : props.gid || 0\n    , size : 0 // will be set later\n    , mtime : props.mtime || Date.now() / 1000\n    , type : \"x\"\n    , linkpath : \"\"\n    , ustar : \"ustar\\0\"\n    , ustarver : \"00\"\n    , uname : props.uname || \"\"\n    , gname : props.gname || \"\"\n    , devmaj : props.devmaj || 0\n    , devmin : props.devmin || 0\n    }\n\n\n  EntryWriter.call(me, p)\n  // console.error(\">> ehw props\", me.props)\n  me.props = p\n\n  me._meta = true\n}\n\nExtendedHeaderWriter.prototype.end = function () {\n  // console.error(\">> ehw end\")\n  var me = this\n\n  if (me._ended) return\n  me._ended = true\n\n  me._encodeFields()\n\n  if (me.props.size === 0) {\n    // nothing to write!\n    me._ready = true\n    me._stream.end()\n    return\n  }\n\n  me._stream.write(TarHeader.encode(me.props))\n  me.body.forEach(function (l) {\n    me._stream.write(l)\n  })\n  me._ready = true\n\n  // console.error(\">> ehw _process calling end()\", me.props)\n  this._stream.end()\n}\n\nExtendedHeaderWriter.prototype._encodeFields = function () {\n  // console.error(\">> ehw _encodeFields\")\n  this.body = []\n  if (this.fields.prefix) {\n    this.fields.path = this.fields.prefix + \"/\" + this.fields.path\n    this.fields.prefix = \"\"\n  }\n  encodeFields(this.fields, \"\", this.body, this.fields.noProprietary)\n  var me = this\n  this.body.forEach(function (l) {\n    me.props.size += l.length\n  })\n}\n\nfunction encodeFields (fields, prefix, body, nop) {\n  // console.error(\">> >> ehw encodeFields\")\n  // \"%d %s=%s\\n\", <length>, <keyword>, <value>\n  // The length is a decimal number, and includes itself and the \\n\n  // Numeric values are decimal strings.\n\n  Object.keys(fields).forEach(function (k) {\n    var val = fields[k]\n      , numeric = tar.numeric[k]\n\n    if (prefix) k = prefix + \".\" + k\n\n    // already including NODETAR.type, don't need File=true also\n    if (k === fields.type && val === true) return\n\n    switch (k) {\n      // don't include anything that's always handled just fine\n      // in the normal header, or only meaningful in the context\n      // of nodetar\n      case \"mode\":\n      case \"cksum\":\n      case \"ustar\":\n      case \"ustarver\":\n      case \"prefix\":\n      case \"basename\":\n      case \"dirname\":\n      case \"needExtended\":\n      case \"block\":\n      case \"filter\":\n        return\n\n      case \"rdev\":\n        if (val === 0) return\n        break\n\n      case \"nlink\":\n      case \"dev\": // Truly a hero among men, Creator of Star!\n      case \"ino\": // Speak his name with reverent awe!  It is:\n        k = \"SCHILY.\" + k\n        break\n\n      default: break\n    }\n\n    if (val && typeof val === \"object\" &&\n        !Buffer.isBuffer(val)) encodeFields(val, k, body, nop)\n    else if (val === null || val === undefined) return\n    else body.push.apply(body, encodeField(k, val, nop))\n  })\n\n  return body\n}\n\nfunction encodeField (k, v, nop) {\n  // lowercase keys must be valid, otherwise prefix with\n  // \"NODETAR.\"\n  if (k.charAt(0) === k.charAt(0).toLowerCase()) {\n    var m = k.split(\".\")[0]\n    if (!tar.knownExtended[m]) k = \"NODETAR.\" + k\n  }\n\n  // no proprietary\n  if (nop && k.charAt(0) !== k.charAt(0).toLowerCase()) {\n    return []\n  }\n\n  if (typeof val === \"number\") val = val.toString(10)\n\n  var s = new Buffer(\" \" + k + \"=\" + v + \"\\n\")\n    , digits = Math.floor(Math.log(s.length) / Math.log(10)) + 1\n\n  // console.error(\"1 s=%j digits=%j s.length=%d\", s.toString(), digits, s.length)\n\n  // if adding that many digits will make it go over that length,\n  // then add one to it. For example, if the string is:\n  // \" foo=bar\\n\"\n  // then that's 9 characters.  With the \"9\", that bumps the length\n  // up to 10.  However, this is invalid:\n  // \"10 foo=bar\\n\"\n  // but, since that's actually 11 characters, since 10 adds another\n  // character to the length, and the length includes the number\n  // itself.  In that case, just bump it up again.\n  if (s.length + digits >= Math.pow(10, digits)) digits += 1\n  // console.error(\"2 s=%j digits=%j s.length=%d\", s.toString(), digits, s.length)\n\n  var len = digits + s.length\n  // console.error(\"3 s=%j digits=%j s.length=%d len=%d\", s.toString(), digits, s.length, len)\n  var lenBuf = new Buffer(\"\" + len)\n  if (lenBuf.length + s.length !== len) {\n    throw new Error(\"Bad length calculation\\n\"+\n                    \"len=\"+len+\"\\n\"+\n                    \"lenBuf=\"+JSON.stringify(lenBuf.toString())+\"\\n\"+\n                    \"lenBuf.length=\"+lenBuf.length+\"\\n\"+\n                    \"digits=\"+digits+\"\\n\"+\n                    \"s=\"+JSON.stringify(s.toString())+\"\\n\"+\n                    \"s.length=\"+s.length)\n  }\n\n  return [lenBuf, s]\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/parse.js":"\n// A writable stream.\n// It emits \"entry\" events, which provide a readable stream that has\n// header info attached.\n\nmodule.exports = Parse.create = Parse\n\nvar stream = require(\"stream\")\n  , Stream = stream.Stream\n  , BlockStream = require(\"block-stream\")\n  , tar = require(\"../tar.js\")\n  , TarHeader = require(\"./header.js\")\n  , Entry = require(\"./entry.js\")\n  , BufferEntry = require(\"./buffer-entry.js\")\n  , ExtendedHeader = require(\"./extended-header.js\")\n  , assert = require(\"assert\").ok\n  , inherits = require(\"inherits\")\n  , fstream = require(\"fstream\")\n\n// reading a tar is a lot like reading a directory\n// However, we're actually not going to run the ctor,\n// since it does a stat and various other stuff.\n// This inheritance gives us the pause/resume/pipe\n// behavior that is desired.\ninherits(Parse, fstream.Reader)\n\nfunction Parse () {\n  var me = this\n  if (!(me instanceof Parse)) return new Parse()\n\n  // doesn't apply fstream.Reader ctor?\n  // no, becasue we don't want to stat/etc, we just\n  // want to get the entry/add logic from .pipe()\n  Stream.apply(me)\n\n  me.writable = true\n  me.readable = true\n  me._stream = new BlockStream(512)\n  me.position = 0\n  me._ended = false\n\n  me._stream.on(\"error\", function (e) {\n    me.emit(\"error\", e)\n  })\n\n  me._stream.on(\"data\", function (c) {\n    me._process(c)\n  })\n\n  me._stream.on(\"end\", function () {\n    me._streamEnd()\n  })\n\n  me._stream.on(\"drain\", function () {\n    me.emit(\"drain\")\n  })\n}\n\n// overridden in Extract class, since it needs to\n// wait for its DirWriter part to finish before\n// emitting \"end\"\nParse.prototype._streamEnd = function () {\n  var me = this\n  if (!me._ended || me._entry) me.error(\"unexpected eof\")\n  me.emit(\"end\")\n}\n\n// a tar reader is actually a filter, not just a readable stream.\n// So, you should pipe a tarball stream into it, and it needs these\n// write/end methods to do that.\nParse.prototype.write = function (c) {\n  if (this._ended) {\n    // gnutar puts a LOT of nulls at the end.\n    // you can keep writing these things forever.\n    // Just ignore them.\n    for (var i = 0, l = c.length; i > l; i ++) {\n      if (c[i] !== 0) return this.error(\"write() after end()\")\n    }\n    return\n  }\n  return this._stream.write(c)\n}\n\nParse.prototype.end = function (c) {\n  this._ended = true\n  return this._stream.end(c)\n}\n\n// don't need to do anything, since we're just\n// proxying the data up from the _stream.\n// Just need to override the parent's \"Not Implemented\"\n// error-thrower.\nParse.prototype._read = function () {}\n\nParse.prototype._process = function (c) {\n  assert(c && c.length === 512, \"block size should be 512\")\n\n  // one of three cases.\n  // 1. A new header\n  // 2. A part of a file/extended header\n  // 3. One of two or more EOF null blocks\n\n  if (this._entry) {\n    var entry = this._entry\n    if(!entry._abort) entry.write(c)\n    else {\n      entry._remaining -= c.length\n      if(entry._remaining < 0) entry._remaining = 0\n    }\n    if (entry._remaining === 0) {\n      entry.end()\n      this._entry = null\n    }\n  } else {\n    // either zeroes or a header\n    var zero = true\n    for (var i = 0; i < 512 && zero; i ++) {\n      zero = c[i] === 0\n    }\n\n    // eof is *at least* 2 blocks of nulls, and then the end of the\n    // file.  you can put blocks of nulls between entries anywhere,\n    // so appending one tarball to another is technically valid.\n    // ending without the eof null blocks is not allowed, however.\n    if (zero) {\n      if (this._eofStarted)\n        this._ended = true\n      this._eofStarted = true\n    } else {\n      this._eofStarted = false\n      this._startEntry(c)\n    }\n  }\n\n  this.position += 512\n}\n\n// take a header chunk, start the right kind of entry.\nParse.prototype._startEntry = function (c) {\n  var header = new TarHeader(c)\n    , self = this\n    , entry\n    , ev\n    , EntryType\n    , onend\n    , meta = false\n\n  if (null === header.size || !header.cksumValid) {\n    var e = new Error(\"invalid tar file\")\n    e.header = header\n    e.tar_file_offset = this.position\n    e.tar_block = this.position / 512\n    return this.emit(\"error\", e)\n  }\n\n  switch (tar.types[header.type]) {\n    case \"File\":\n    case \"OldFile\":\n    case \"Link\":\n    case \"SymbolicLink\":\n    case \"CharacterDevice\":\n    case \"BlockDevice\":\n    case \"Directory\":\n    case \"FIFO\":\n    case \"ContiguousFile\":\n    case \"GNUDumpDir\":\n      // start a file.\n      // pass in any extended headers\n      // These ones consumers are typically most interested in.\n      EntryType = Entry\n      ev = \"entry\"\n      break\n\n    case \"GlobalExtendedHeader\":\n      // extended headers that apply to the rest of the tarball\n      EntryType = ExtendedHeader\n      onend = function () {\n        self._global = self._global || {}\n        Object.keys(entry.fields).forEach(function (k) {\n          self._global[k] = entry.fields[k]\n        })\n      }\n      ev = \"globalExtendedHeader\"\n      meta = true\n      break\n\n    case \"ExtendedHeader\":\n    case \"OldExtendedHeader\":\n      // extended headers that apply to the next entry\n      EntryType = ExtendedHeader\n      onend = function () {\n        self._extended = entry.fields\n      }\n      ev = \"extendedHeader\"\n      meta = true\n      break\n\n    case \"NextFileHasLongLinkpath\":\n      // set linkpath=<contents> in extended header\n      EntryType = BufferEntry\n      onend = function () {\n        self._extended = self._extended || {}\n        self._extended.linkpath = entry.body\n      }\n      ev = \"longLinkpath\"\n      meta = true\n      break\n\n    case \"NextFileHasLongPath\":\n    case \"OldGnuLongPath\":\n      // set path=<contents> in file-extended header\n      EntryType = BufferEntry\n      onend = function () {\n        self._extended = self._extended || {}\n        self._extended.path = entry.body\n      }\n      ev = \"longPath\"\n      meta = true\n      break\n\n    default:\n      // all the rest we skip, but still set the _entry\n      // member, so that we can skip over their data appropriately.\n      // emit an event to say that this is an ignored entry type?\n      EntryType = Entry\n      ev = \"ignoredEntry\"\n      break\n  }\n\n  var global, extended\n  if (meta) {\n    global = extended = null\n  } else {\n    var global = this._global\n    var extended = this._extended\n\n    // extendedHeader only applies to one entry, so once we start\n    // an entry, it's over.\n    this._extended = null\n  }\n  entry = new EntryType(header, extended, global)\n  entry.meta = meta\n\n  // only proxy data events of normal files.\n  if (!meta) {\n    entry.on(\"data\", function (c) {\n      me.emit(\"data\", c)\n    })\n  }\n\n  if (onend) entry.on(\"end\", onend)\n\n  this._entry = entry\n  var me = this\n\n  entry.on(\"pause\", function () {\n    me.pause()\n  })\n\n  entry.on(\"resume\", function () {\n    me.resume()\n  })\n\n  if (this.listeners(\"*\").length) {\n    this.emit(\"*\", ev, entry)\n  }\n\n  this.emit(ev, entry)\n\n  // Zero-byte entry.  End immediately.\n  if (entry.props.size === 0) {\n    entry.end()\n    this._entry = null\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/buffer-entry.js":"// just like the Entry class, but it buffers the contents\n//\n// XXX It would be good to set a maximum BufferEntry filesize,\n// since it eats up memory.  In normal operation,\n// these are only for long filenames or link names, which are\n// rarely very big.\n\nmodule.exports = BufferEntry\n\nvar inherits = require(\"inherits\")\n  , Entry = require(\"./entry.js\")\n\nfunction BufferEntry () {\n  Entry.apply(this, arguments)\n  this._buffer = new Buffer(this.props.size)\n  this._offset = 0\n  this.body = \"\"\n  this.on(\"end\", function () {\n    this.body = this._buffer.toString().slice(0, -1)\n  })\n}\n\ninherits(BufferEntry, Entry)\n\n// collect the bytes as they come in.\nBufferEntry.prototype.write = function (c) {\n  c.copy(this._buffer, this._offset)\n  this._offset += c.length\n  Entry.prototype.write.call(this, c)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/extended-header.js":"// An Entry consisting of:\n//\n// \"%d %s=%s\\n\", <length>, <keyword>, <value>\n//\n// The length is a decimal number, and includes itself and the \\n\n// \\0 does not terminate anything.  Only the length terminates the string.\n// Numeric values are decimal strings.\n\nmodule.exports = ExtendedHeader\n\nvar Entry = require(\"./entry.js\")\n  , inherits = require(\"inherits\")\n  , tar = require(\"../tar.js\")\n  , numeric = tar.numeric\n  , keyTrans = { \"SCHILY.dev\": \"dev\"\n               , \"SCHILY.ino\": \"ino\"\n               , \"SCHILY.nlink\": \"nlink\" }\n\nfunction ExtendedHeader () {\n  Entry.apply(this, arguments)\n  this.on(\"data\", this._parse)\n  this.fields = {}\n  this._position = 0\n  this._fieldPos = 0\n  this._state = SIZE\n  this._sizeBuf = []\n  this._keyBuf = []\n  this._valBuf = []\n  this._size = -1\n  this._key = \"\"\n}\n\ninherits(ExtendedHeader, Entry)\nExtendedHeader.prototype._parse = parse\n\nvar s = 0\n  , states = ExtendedHeader.states = {}\n  , SIZE = states.SIZE = s++\n  , KEY  = states.KEY  = s++\n  , VAL  = states.VAL  = s++\n  , ERR  = states.ERR  = s++\n\nObject.keys(states).forEach(function (s) {\n  states[states[s]] = states[s]\n})\n\nstates[s] = null\n\n// char code values for comparison\nvar _0 = \"0\".charCodeAt(0)\n  , _9 = \"9\".charCodeAt(0)\n  , point = \".\".charCodeAt(0)\n  , a = \"a\".charCodeAt(0)\n  , Z = \"Z\".charCodeAt(0)\n  , a = \"a\".charCodeAt(0)\n  , z = \"z\".charCodeAt(0)\n  , space = \" \".charCodeAt(0)\n  , eq = \"=\".charCodeAt(0)\n  , cr = \"\\n\".charCodeAt(0)\n\nfunction parse (c) {\n  if (this._state === ERR) return\n\n  for ( var i = 0, l = c.length\n      ; i < l\n      ; this._position++, this._fieldPos++, i++) {\n    // console.error(\"top of loop, size=\"+this._size)\n\n    var b = c[i]\n\n    if (this._size >= 0 && this._fieldPos > this._size) {\n      error(this, \"field exceeds length=\"+this._size)\n      return\n    }\n\n    switch (this._state) {\n      case ERR: return\n\n      case SIZE:\n        // console.error(\"parsing size, b=%d, rest=%j\", b, c.slice(i).toString())\n        if (b === space) {\n          this._state = KEY\n          // this._fieldPos = this._sizeBuf.length\n          this._size = parseInt(new Buffer(this._sizeBuf).toString(), 10)\n          this._sizeBuf.length = 0\n          continue\n        }\n        if (b < _0 || b > _9) {\n          error(this, \"expected [\" + _0 + \"..\" + _9 + \"], got \" + b)\n          return\n        }\n        this._sizeBuf.push(b)\n        continue\n\n      case KEY:\n        // can be any char except =, not > size.\n        if (b === eq) {\n          this._state = VAL\n          this._key = new Buffer(this._keyBuf).toString()\n          if (keyTrans[this._key]) this._key = keyTrans[this._key]\n          this._keyBuf.length = 0\n          continue\n        }\n        this._keyBuf.push(b)\n        continue\n\n      case VAL:\n        // field must end with cr\n        if (this._fieldPos === this._size - 1) {\n          // console.error(\"finished with \"+this._key)\n          if (b !== cr) {\n            error(this, \"expected \\\\n at end of field\")\n            return\n          }\n          var val = new Buffer(this._valBuf).toString()\n          if (numeric[this._key]) {\n            val = parseFloat(val)\n          }\n          this.fields[this._key] = val\n\n          this._valBuf.length = 0\n          this._state = SIZE\n          this._size = -1\n          this._fieldPos = -1\n          continue\n        }\n        this._valBuf.push(b)\n        continue\n    }\n  }\n}\n\nfunction error (me, msg) {\n  msg = \"invalid header: \" + msg\n      + \"\\nposition=\" + me._position\n      + \"\\nfield position=\" + me._fieldPos\n\n  me.error(msg)\n  me.state = ERR\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/tar/lib/extract.js":"// give it a tarball and a path, and it'll dump the contents\n\nmodule.exports = Extract\n\nvar tar = require(\"../tar.js\")\n  , fstream = require(\"fstream\")\n  , inherits = require(\"inherits\")\n  , path = require(\"path\")\n\nfunction Extract (opts) {\n  if (!(this instanceof Extract)) return new Extract(opts)\n  tar.Parse.apply(this)\n\n  if (typeof opts !== \"object\") {\n    opts = { path: opts }\n  }\n\n  // better to drop in cwd? seems more standard.\n  opts.path = opts.path || path.resolve(\"node-tar-extract\")\n  opts.type = \"Directory\"\n  opts.Directory = true\n\n  // similar to --strip or --strip-components\n  opts.strip = +opts.strip\n  if (!opts.strip || opts.strip <= 0) opts.strip = 0\n\n  this._fst = fstream.Writer(opts)\n\n  this.pause()\n  var me = this\n\n  // Hardlinks in tarballs are relative to the root\n  // of the tarball.  So, they need to be resolved against\n  // the target directory in order to be created properly.\n  me.on(\"entry\", function (entry) {\n    // if there's a \"strip\" argument, then strip off that many\n    // path components.\n    if (opts.strip) {\n      var p = entry.path.split(\"/\").slice(opts.strip).join(\"/\")\n      entry.path = entry.props.path = p\n      if (entry.linkpath) {\n        var lp = entry.linkpath.split(\"/\").slice(opts.strip).join(\"/\")\n        entry.linkpath = entry.props.linkpath = lp\n      }\n    }\n    if (entry.type === \"Link\") {\n      entry.linkpath = entry.props.linkpath =\n        path.join(opts.path, path.join(\"/\", entry.props.linkpath))\n    }\n\n    if (entry.type === \"SymbolicLink\") {\n      var dn = path.dirname(entry.path) || \"\"\n      var linkpath = entry.props.linkpath\n      var target = path.resolve(opts.path, dn, linkpath)\n      if (target.indexOf(opts.path) !== 0) {\n        linkpath = path.join(opts.path, path.join(\"/\", linkpath))\n      }\n      entry.linkpath = entry.props.linkpath = linkpath\n    }\n  })\n\n  this._fst.on(\"ready\", function () {\n    me.pipe(me._fst, { end: false })\n    me.resume()\n  })\n\n  this._fst.on('error', function(err) {\n    me.emit('error', err)\n  })\n\n  this._fst.on('drain', function() {\n    me.emit('drain')\n  })\n\n  // this._fst.on(\"end\", function () {\n  //   console.error(\"\\nEEEE Extract End\", me._fst.path)\n  // })\n\n  this._fst.on(\"close\", function () {\n    // console.error(\"\\nEEEE Extract End\", me._fst.path)\n    me.emit(\"finish\")\n    me.emit(\"end\")\n    me.emit(\"close\")\n  })\n}\n\ninherits(Extract, tar.Parse)\n\nExtract.prototype._streamEnd = function () {\n  var me = this\n  if (!me._ended || me._entry) me.error(\"unexpected eof\")\n  me._fst.end()\n  // my .end() is coming later.\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read-package-tree/rpt.js":"var fs = require('fs')\nvar rpj = require('read-package-json')\nvar path = require('path')\nvar dz = require('dezalgo')\nvar once = require('once')\nvar readdir = require('readdir-scoped-modules')\nvar debug = require('debuglog')('rpt')\n\nfunction asyncForEach (items, todo, done) {\n  var remaining = items.length\n  if (remaining === 0) return done()\n  var seenErr\n  items.forEach(function (item) {\n    todo(item, handleComplete)\n  })\n  function handleComplete (err) {\n    if (seenErr) return\n    if (err) {\n      seenErr = true\n      return done(err)\n    }\n    if (--remaining === 0) done()\n  }\n}\n\nfunction dpath (p) {\n  if (!p) return ''\n  if (p.indexOf(process.cwd()) === 0) {\n    p = p.substr(process.cwd().length + 1)\n  }\n  return p\n}\n\nmodule.exports = rpt\n\nrpt.Node = Node\nrpt.Link = Link\n\nvar ID = 0\nfunction Node (pkg, logical, physical, er, cache) {\n  if (cache[physical]) return cache[physical]\n\n  if (!(this instanceof Node)) {\n    return new Node(pkg, logical, physical, er, cache)\n  }\n\n  cache[physical] = this\n\n  debug(this.constructor.name, dpath(physical), pkg && pkg._id)\n\n  this.id = ID++\n  this.package = pkg || {}\n  this.path = logical\n  this.realpath = physical\n  this.parent = null\n  this.isLink = false\n  this.children = []\n  this.error = er\n}\n\nNode.prototype.package = null\nNode.prototype.path = ''\nNode.prototype.realpath = ''\nNode.prototype.children = null\nNode.prototype.error = null\n\nfunction Link (pkg, logical, physical, realpath, er, cache) {\n  if (cache[physical]) return cache[physical]\n\n  if (!(this instanceof Link)) {\n    return new Link(pkg, logical, physical, realpath, er, cache)\n  }\n\n  cache[physical] = this\n\n  debug(this.constructor.name, dpath(physical), pkg && pkg._id)\n\n  this.id = ID++\n  this.path = logical\n  this.realpath = realpath\n  this.package = pkg || {}\n  this.parent = null\n  this.target = new Node(this.package, logical, realpath, er, cache)\n  this.isLink = true\n  this.children = this.target.children\n  this.error = er\n}\n\nLink.prototype = Object.create(Node.prototype, {\n  constructor: { value: Link }\n})\nLink.prototype.target = null\nLink.prototype.realpath = ''\n\nfunction loadNode (logical, physical, cache, cb) {\n  debug('loadNode', dpath(logical))\n  return fs.realpath(physical, thenReadPackageJson)\n\n  var realpath\n  function thenReadPackageJson (er, real) {\n    if (er) {\n      var node = new Node(null, logical, physical, er, cache)\n      return cb(null, node)\n    }\n    debug('realpath l=%j p=%j real=%j', dpath(logical), dpath(physical), dpath(real))\n    var pj = path.join(real, 'package.json')\n    realpath = real\n    return rpj(pj, thenCreateNode)\n  }\n  function thenCreateNode (er, pkg) {\n    pkg = pkg || null\n    var node\n    if (physical === realpath) {\n      node = new Node(pkg, logical, physical, er, cache)\n    } else {\n      node = new Link(pkg, logical, physical, realpath, er, cache)\n    }\n\n    cb(null, node)\n  }\n}\n\nfunction loadChildren (node, cache, filterWith, cb) {\n  debug('loadChildren', dpath(node.path))\n  // needed 'cause we process all kids async-like and errors\n  // short circuit, so we have to be sure that after an error\n  // the cbs from other kids don't result in calling cb a second\n  // (or more) time.\n  cb = once(cb)\n  var nm = path.join(node.path, 'node_modules')\n  var rm\n  return fs.realpath(path.join(node.path, 'node_modules'), thenReaddir)\n\n  function thenReaddir (er, real_nm) {\n    if (er) return cb(null, node)\n    rm = real_nm\n    readdir(nm, thenLoadKids)\n  }\n\n  function thenLoadKids (er, kids) {\n    // If there are no children, that's fine, just return\n    if (er) return cb(null, node)\n\n    kids = kids.filter(function (kid) {\n      return kid[0] !== '.' && (!filterWith || filterWith(node, kid))\n    })\n\n    asyncForEach(kids, thenLoadNode, thenSortChildren)\n  }\n  function thenLoadNode (kid, done) {\n    var kidPath = path.join(nm, kid)\n    var kidRealPath = path.join(rm, kid)\n    loadNode(kidPath, kidRealPath, cache, andAddNode(done))\n  }\n  function andAddNode (done) {\n    return function (er, kid) {\n      if (er) return done(er)\n      node.children.push(kid)\n      kid.parent = node\n      done()\n    }\n  }\n  function thenSortChildren (er) {\n    sortChildren(node)\n    cb(er, node)\n  }\n}\n\nfunction sortChildren (node) {\n  node.children = node.children.sort(function (a, b) {\n    a = a.package.name ? a.package.name.toLowerCase() : a.path\n    b = b.package.name ? b.package.name.toLowerCase() : b.path\n    return a > b ? 1 : -1\n  })\n}\n\nfunction loadTree (node, did, cache, filterWith, cb) {\n  debug('loadTree', dpath(node.path), !!cache[node.path])\n\n  if (did[node.realpath]) {\n    return dz(cb)(null, node)\n  }\n\n  did[node.realpath] = true\n\n  // needed 'cause we process all kids async-like and errors\n  // short circuit, so we have to be sure that after an error\n  // the cbs from other kids don't result in calling cb a second\n  // (or more) time.\n  cb = once(cb)\n  return loadChildren(node, cache, filterWith, thenProcessChildren)\n\n  function thenProcessChildren (er, node) {\n    if (er) return cb(er)\n\n    var kids = node.children.filter(function (kid) {\n      return !did[kid.realpath]\n    })\n\n    return asyncForEach(kids, loadTreeForKid, cb)\n  }\n  function loadTreeForKid (kid, done) {\n    loadTree(kid, did, cache, filterWith, done)\n  }\n}\n\nfunction rpt (root, filterWith, cb) {\n  if (!cb) {\n    cb = filterWith\n    filterWith = null\n  }\n  var cache = Object.create(null)\n  var topErr\n  var tree\n  return fs.realpath(root, thenLoadNode)\n\n  function thenLoadNode (er, realRoot) {\n    if (er) return cb(er)\n    debug('rpt', dpath(realRoot))\n    loadNode(root, realRoot, cache, thenLoadTree)\n  }\n  function thenLoadTree(er, node) {\n    // even if there's an error, it's fine, as long as we got a node\n    if (node) {\n      topErr = er\n      tree = node\n      loadTree(node, {}, cache, filterWith, thenHandleErrors)\n    } else {\n      cb(er)\n    }\n  }\n  function thenHandleErrors (er) {\n    cb(topErr && topErr.code !== 'ENOENT' ? topErr : er, tree)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readdir-scoped-modules/readdir.js":"var fs = require ('graceful-fs')\nvar dz = require ('dezalgo')\nvar once = require ('once')\nvar path = require ('path')\nvar debug = require ('debuglog') ('rds')\n\nmodule . exports = readdir\n\nfunction readdir (dir, cb) {\n  fs . readdir (dir, function (er, kids) {\n    if (er)\n      return cb (er)\n\n    debug ('dir=%j, kids=%j', dir, kids)\n    readScopes (dir, kids, function (er, data) {\n      if (er)\n        return cb (er)\n\n      // Sort for bonus consistency points\n      data = data . sort (function (a, b) {\n        return a > b ? 1 : -1\n      })\n\n      return cb (null, data)\n    })\n  })\n}\n\n// Turn [ 'a', '@scope' ] into\n// ['a', '@scope/foo', '@scope/bar']\nfunction readScopes (root, kids, cb) {\n  var scopes = kids . filter (function (kid) {\n    return kid . charAt (0) === '@'\n  })\n\n  kids = kids . filter (function (kid) {\n    return kid . charAt (0) !== '@'\n  })\n\n  debug ('scopes=%j', scopes)\n\n  if (scopes . length === 0)\n    dz (cb) (null, kids) // prevent maybe-sync zalgo release\n\n  cb = once (cb)\n  var l = scopes . length\n  scopes . forEach (function (scope) {\n    var scopedir = path . resolve (root, scope)\n    debug ('root=%j scope=%j scopedir=%j', root, scope, scopedir)\n    fs . readdir (scopedir, then . bind (null, scope))\n  })\n\n  function then (scope, er, scopekids) {\n    if (er)\n      return cb (er)\n\n    // XXX: Not sure how old this node bug is. Maybe superstition?\n    scopekids = scopekids . filter (function (scopekid) {\n      return !(scopekid === '.' || scopekid === '..' || !scopekid)\n    })\n\n    kids . push . apply (kids, scopekids . map (function (scopekid) {\n      return scope + '/' + scopekid\n    }))\n\n    debug ('scope=%j scopekids=%j kids=%j', scope, scopekids, kids)\n\n    if (--l === 0)\n      cb (null, kids)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/debuglog/debuglog.js":"var util = require('util');\n\nmodule.exports = (util && util.debuglog) || debuglog;\n\nvar debugs = {};\nvar debugEnviron = process.env.NODE_DEBUG || '';\n\nfunction debuglog(set) {\n  set = set.toUpperCase();\n  if (!debugs[set]) {\n    if (new RegExp('\\\\b' + set + '\\\\b', 'i').test(debugEnviron)) {\n      var pid = process.pid;\n      debugs[set] = function() {\n        var msg = util.format.apply(exports, arguments);\n        console.error('%s %d: %s', set, pid, msg);\n      };\n    } else {\n      debugs[set] = function() {};\n    }\n  }\n  return debugs[set];\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/iferr/index.js":"// Generated by CoffeeScript 1.7.1\n(function() {\n  var exports, iferr, printerr, throwerr, tiferr,\n    __slice = [].slice;\n\n  iferr = function(fail, succ) {\n    return function() {\n      var a, err;\n      err = arguments[0], a = 2 <= arguments.length ? __slice.call(arguments, 1) : [];\n      if (err != null) {\n        return fail(err);\n      } else {\n        return typeof succ === \"function\" ? succ.apply(null, a) : void 0;\n      }\n    };\n  };\n\n  tiferr = function(fail, succ) {\n    return iferr(fail, function() {\n      var a, err;\n      a = 1 <= arguments.length ? __slice.call(arguments, 0) : [];\n      try {\n        return succ.apply(null, a);\n      } catch (_error) {\n        err = _error;\n        return fail(err);\n      }\n    });\n  };\n\n  throwerr = iferr.bind(null, function(err) {\n    throw err;\n  });\n\n  printerr = iferr(function(err) {\n    return console.error(err.stack || err);\n  });\n\n  module.exports = exports = iferr;\n\n  exports.iferr = iferr;\n\n  exports.tiferr = tiferr;\n\n  exports.throwerr = throwerr;\n\n  exports.printerr = printerr;\n\n}).call(this);\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/lodash.clonedeep/index.js":"/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    promiseTag = '[object Promise]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to match `RegExp` flags from their coerced string values. */\nvar reFlags = /\\w*$/;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Used to detect unsigned integer values. */\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\n\n/** Used to identify `toStringTag` values supported by `_.clone`. */\nvar cloneableTags = {};\ncloneableTags[argsTag] = cloneableTags[arrayTag] =\ncloneableTags[arrayBufferTag] = cloneableTags[dataViewTag] =\ncloneableTags[boolTag] = cloneableTags[dateTag] =\ncloneableTags[float32Tag] = cloneableTags[float64Tag] =\ncloneableTags[int8Tag] = cloneableTags[int16Tag] =\ncloneableTags[int32Tag] = cloneableTags[mapTag] =\ncloneableTags[numberTag] = cloneableTags[objectTag] =\ncloneableTags[regexpTag] = cloneableTags[setTag] =\ncloneableTags[stringTag] = cloneableTags[symbolTag] =\ncloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] =\ncloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;\ncloneableTags[errorTag] = cloneableTags[funcTag] =\ncloneableTags[weakMapTag] = false;\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/**\n * Adds the key-value `pair` to `map`.\n *\n * @private\n * @param {Object} map The map to modify.\n * @param {Array} pair The key-value pair to add.\n * @returns {Object} Returns `map`.\n */\nfunction addMapEntry(map, pair) {\n  // Don't return `map.set` because it's not chainable in IE 11.\n  map.set(pair[0], pair[1]);\n  return map;\n}\n\n/**\n * Adds `value` to `set`.\n *\n * @private\n * @param {Object} set The set to modify.\n * @param {*} value The value to add.\n * @returns {Object} Returns `set`.\n */\nfunction addSetEntry(set, value) {\n  // Don't return `set.add` because it's not chainable in IE 11.\n  set.add(value);\n  return set;\n}\n\n/**\n * A specialized version of `_.forEach` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns `array`.\n */\nfunction arrayEach(array, iteratee) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  while (++index < length) {\n    if (iteratee(array[index], index, array) === false) {\n      break;\n    }\n  }\n  return array;\n}\n\n/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\n/**\n * A specialized version of `_.reduce` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {*} [accumulator] The initial value.\n * @param {boolean} [initAccum] Specify using the first element of `array` as\n *  the initial value.\n * @returns {*} Returns the accumulated value.\n */\nfunction arrayReduce(array, iteratee, accumulator, initAccum) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  if (initAccum && length) {\n    accumulator = array[++index];\n  }\n  while (++index < length) {\n    accumulator = iteratee(accumulator, array[index], index, array);\n  }\n  return accumulator;\n}\n\n/**\n * The base implementation of `_.times` without support for iteratee shorthands\n * or max array length checks.\n *\n * @private\n * @param {number} n The number of times to invoke `iteratee`.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the array of results.\n */\nfunction baseTimes(n, iteratee) {\n  var index = -1,\n      result = Array(n);\n\n  while (++index < n) {\n    result[index] = iteratee(index);\n  }\n  return result;\n}\n\n/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\n/**\n * Checks if `value` is a host object in IE < 9.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a host object, else `false`.\n */\nfunction isHostObject(value) {\n  // Many host objects are `Object` objects that can coerce to strings\n  // despite having improperly defined `toString` methods.\n  var result = false;\n  if (value != null && typeof value.toString != 'function') {\n    try {\n      result = !!(value + '');\n    } catch (e) {}\n  }\n  return result;\n}\n\n/**\n * Converts `map` to its key-value pairs.\n *\n * @private\n * @param {Object} map The map to convert.\n * @returns {Array} Returns the key-value pairs.\n */\nfunction mapToArray(map) {\n  var index = -1,\n      result = Array(map.size);\n\n  map.forEach(function(value, key) {\n    result[++index] = [key, value];\n  });\n  return result;\n}\n\n/**\n * Creates a unary function that invokes `func` with its argument transformed.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {Function} transform The argument transform.\n * @returns {Function} Returns the new function.\n */\nfunction overArg(func, transform) {\n  return function(arg) {\n    return func(transform(arg));\n  };\n}\n\n/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype,\n    funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined,\n    Symbol = root.Symbol,\n    Uint8Array = root.Uint8Array,\n    getPrototype = overArg(Object.getPrototypeOf, Object),\n    objectCreate = Object.create,\n    propertyIsEnumerable = objectProto.propertyIsEnumerable,\n    splice = arrayProto.splice;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols,\n    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,\n    nativeKeys = overArg(Object.keys, Object);\n\n/* Built-in method references that are verified to be native. */\nvar DataView = getNative(root, 'DataView'),\n    Map = getNative(root, 'Map'),\n    Promise = getNative(root, 'Promise'),\n    Set = getNative(root, 'Set'),\n    WeakMap = getNative(root, 'WeakMap'),\n    nativeCreate = getNative(Object, 'create');\n\n/** Used to detect maps, sets, and weakmaps. */\nvar dataViewCtorString = toSource(DataView),\n    mapCtorString = toSource(Map),\n    promiseCtorString = toSource(Promise),\n    setCtorString = toSource(Set),\n    weakMapCtorString = toSource(WeakMap);\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n}\n\n/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  return this.has(key) && delete this.__data__[key];\n}\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);\n}\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n}\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  return true;\n}\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  return getMapData(this, key)['delete'](key);\n}\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  getMapData(this, key).set(key, value);\n  return this;\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\n/**\n * Creates a stack cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Stack(entries) {\n  this.__data__ = new ListCache(entries);\n}\n\n/**\n * Removes all key-value entries from the stack.\n *\n * @private\n * @name clear\n * @memberOf Stack\n */\nfunction stackClear() {\n  this.__data__ = new ListCache;\n}\n\n/**\n * Removes `key` and its value from the stack.\n *\n * @private\n * @name delete\n * @memberOf Stack\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction stackDelete(key) {\n  return this.__data__['delete'](key);\n}\n\n/**\n * Gets the stack value for `key`.\n *\n * @private\n * @name get\n * @memberOf Stack\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction stackGet(key) {\n  return this.__data__.get(key);\n}\n\n/**\n * Checks if a stack value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Stack\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction stackHas(key) {\n  return this.__data__.has(key);\n}\n\n/**\n * Sets the stack `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Stack\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the stack cache instance.\n */\nfunction stackSet(key, value) {\n  var cache = this.__data__;\n  if (cache instanceof ListCache) {\n    var pairs = cache.__data__;\n    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {\n      pairs.push([key, value]);\n      return this;\n    }\n    cache = this.__data__ = new MapCache(pairs);\n  }\n  cache.set(key, value);\n  return this;\n}\n\n// Add methods to `Stack`.\nStack.prototype.clear = stackClear;\nStack.prototype['delete'] = stackDelete;\nStack.prototype.get = stackGet;\nStack.prototype.has = stackHas;\nStack.prototype.set = stackSet;\n\n/**\n * Creates an array of the enumerable property names of the array-like `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @param {boolean} inherited Specify returning inherited property names.\n * @returns {Array} Returns the array of property names.\n */\nfunction arrayLikeKeys(value, inherited) {\n  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.\n  // Safari 9 makes `arguments.length` enumerable in strict mode.\n  var result = (isArray(value) || isArguments(value))\n    ? baseTimes(value.length, String)\n    : [];\n\n  var length = result.length,\n      skipIndexes = !!length;\n\n  for (var key in value) {\n    if ((inherited || hasOwnProperty.call(value, key)) &&\n        !(skipIndexes && (key == 'length' || isIndex(key, length)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * Assigns `value` to `key` of `object` if the existing value is not equivalent\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignValue(object, key, value) {\n  var objValue = object[key];\n  if (!(hasOwnProperty.call(object, key) && eq(objValue, value)) ||\n      (value === undefined && !(key in object))) {\n    object[key] = value;\n  }\n}\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.assign` without support for multiple sources\n * or `customizer` functions.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @returns {Object} Returns `object`.\n */\nfunction baseAssign(object, source) {\n  return object && copyObject(source, keys(source), object);\n}\n\n/**\n * The base implementation of `_.clone` and `_.cloneDeep` which tracks\n * traversed objects.\n *\n * @private\n * @param {*} value The value to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @param {boolean} [isFull] Specify a clone including symbols.\n * @param {Function} [customizer] The function to customize cloning.\n * @param {string} [key] The key of `value`.\n * @param {Object} [object] The parent object of `value`.\n * @param {Object} [stack] Tracks traversed objects and their clone counterparts.\n * @returns {*} Returns the cloned value.\n */\nfunction baseClone(value, isDeep, isFull, customizer, key, object, stack) {\n  var result;\n  if (customizer) {\n    result = object ? customizer(value, key, object, stack) : customizer(value);\n  }\n  if (result !== undefined) {\n    return result;\n  }\n  if (!isObject(value)) {\n    return value;\n  }\n  var isArr = isArray(value);\n  if (isArr) {\n    result = initCloneArray(value);\n    if (!isDeep) {\n      return copyArray(value, result);\n    }\n  } else {\n    var tag = getTag(value),\n        isFunc = tag == funcTag || tag == genTag;\n\n    if (isBuffer(value)) {\n      return cloneBuffer(value, isDeep);\n    }\n    if (tag == objectTag || tag == argsTag || (isFunc && !object)) {\n      if (isHostObject(value)) {\n        return object ? value : {};\n      }\n      result = initCloneObject(isFunc ? {} : value);\n      if (!isDeep) {\n        return copySymbols(value, baseAssign(result, value));\n      }\n    } else {\n      if (!cloneableTags[tag]) {\n        return object ? value : {};\n      }\n      result = initCloneByTag(value, tag, baseClone, isDeep);\n    }\n  }\n  // Check for circular references and return its corresponding clone.\n  stack || (stack = new Stack);\n  var stacked = stack.get(value);\n  if (stacked) {\n    return stacked;\n  }\n  stack.set(value, result);\n\n  if (!isArr) {\n    var props = isFull ? getAllKeys(value) : keys(value);\n  }\n  arrayEach(props || value, function(subValue, key) {\n    if (props) {\n      key = subValue;\n      subValue = value[key];\n    }\n    // Recursively populate clone (susceptible to call stack limits).\n    assignValue(result, key, baseClone(subValue, isDeep, isFull, customizer, key, value, stack));\n  });\n  return result;\n}\n\n/**\n * The base implementation of `_.create` without support for assigning\n * properties to the created object.\n *\n * @private\n * @param {Object} prototype The object to inherit from.\n * @returns {Object} Returns the new object.\n */\nfunction baseCreate(proto) {\n  return isObject(proto) ? objectCreate(proto) : {};\n}\n\n/**\n * The base implementation of `getAllKeys` and `getAllKeysIn` which uses\n * `keysFunc` and `symbolsFunc` to get the enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @param {Function} symbolsFunc The function to get the symbols of `object`.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction baseGetAllKeys(object, keysFunc, symbolsFunc) {\n  var result = keysFunc(object);\n  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));\n}\n\n/**\n * The base implementation of `getTag`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  return objectToString.call(value);\n}\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = (isFunction(value) || isHostObject(value)) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\n/**\n * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeys(object) {\n  if (!isPrototype(object)) {\n    return nativeKeys(object);\n  }\n  var result = [];\n  for (var key in Object(object)) {\n    if (hasOwnProperty.call(object, key) && key != 'constructor') {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * Creates a clone of  `buffer`.\n *\n * @private\n * @param {Buffer} buffer The buffer to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Buffer} Returns the cloned buffer.\n */\nfunction cloneBuffer(buffer, isDeep) {\n  if (isDeep) {\n    return buffer.slice();\n  }\n  var result = new buffer.constructor(buffer.length);\n  buffer.copy(result);\n  return result;\n}\n\n/**\n * Creates a clone of `arrayBuffer`.\n *\n * @private\n * @param {ArrayBuffer} arrayBuffer The array buffer to clone.\n * @returns {ArrayBuffer} Returns the cloned array buffer.\n */\nfunction cloneArrayBuffer(arrayBuffer) {\n  var result = new arrayBuffer.constructor(arrayBuffer.byteLength);\n  new Uint8Array(result).set(new Uint8Array(arrayBuffer));\n  return result;\n}\n\n/**\n * Creates a clone of `dataView`.\n *\n * @private\n * @param {Object} dataView The data view to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned data view.\n */\nfunction cloneDataView(dataView, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;\n  return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);\n}\n\n/**\n * Creates a clone of `map`.\n *\n * @private\n * @param {Object} map The map to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned map.\n */\nfunction cloneMap(map, isDeep, cloneFunc) {\n  var array = isDeep ? cloneFunc(mapToArray(map), true) : mapToArray(map);\n  return arrayReduce(array, addMapEntry, new map.constructor);\n}\n\n/**\n * Creates a clone of `regexp`.\n *\n * @private\n * @param {Object} regexp The regexp to clone.\n * @returns {Object} Returns the cloned regexp.\n */\nfunction cloneRegExp(regexp) {\n  var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));\n  result.lastIndex = regexp.lastIndex;\n  return result;\n}\n\n/**\n * Creates a clone of `set`.\n *\n * @private\n * @param {Object} set The set to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned set.\n */\nfunction cloneSet(set, isDeep, cloneFunc) {\n  var array = isDeep ? cloneFunc(setToArray(set), true) : setToArray(set);\n  return arrayReduce(array, addSetEntry, new set.constructor);\n}\n\n/**\n * Creates a clone of the `symbol` object.\n *\n * @private\n * @param {Object} symbol The symbol object to clone.\n * @returns {Object} Returns the cloned symbol object.\n */\nfunction cloneSymbol(symbol) {\n  return symbolValueOf ? Object(symbolValueOf.call(symbol)) : {};\n}\n\n/**\n * Creates a clone of `typedArray`.\n *\n * @private\n * @param {Object} typedArray The typed array to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned typed array.\n */\nfunction cloneTypedArray(typedArray, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;\n  return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);\n}\n\n/**\n * Copies the values of `source` to `array`.\n *\n * @private\n * @param {Array} source The array to copy values from.\n * @param {Array} [array=[]] The array to copy values to.\n * @returns {Array} Returns `array`.\n */\nfunction copyArray(source, array) {\n  var index = -1,\n      length = source.length;\n\n  array || (array = Array(length));\n  while (++index < length) {\n    array[index] = source[index];\n  }\n  return array;\n}\n\n/**\n * Copies properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy properties from.\n * @param {Array} props The property identifiers to copy.\n * @param {Object} [object={}] The object to copy properties to.\n * @param {Function} [customizer] The function to customize copied values.\n * @returns {Object} Returns `object`.\n */\nfunction copyObject(source, props, object, customizer) {\n  object || (object = {});\n\n  var index = -1,\n      length = props.length;\n\n  while (++index < length) {\n    var key = props[index];\n\n    var newValue = customizer\n      ? customizer(object[key], source[key], key, object, source)\n      : undefined;\n\n    assignValue(object, key, newValue === undefined ? source[key] : newValue);\n  }\n  return object;\n}\n\n/**\n * Copies own symbol properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy symbols from.\n * @param {Object} [object={}] The object to copy symbols to.\n * @returns {Object} Returns `object`.\n */\nfunction copySymbols(source, object) {\n  return copyObject(source, getSymbols(source), object);\n}\n\n/**\n * Creates an array of own enumerable property names and symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeys(object) {\n  return baseGetAllKeys(object, keys, getSymbols);\n}\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\n/**\n * Creates an array of the own enumerable symbol properties of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbols = nativeGetSymbols ? overArg(nativeGetSymbols, Object) : stubArray;\n\n/**\n * Gets the `toStringTag` of `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nvar getTag = baseGetTag;\n\n// Fallback for data views, maps, sets, and weak maps in IE 11,\n// for data views in Edge < 14, and promises in Node.js.\nif ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||\n    (Map && getTag(new Map) != mapTag) ||\n    (Promise && getTag(Promise.resolve()) != promiseTag) ||\n    (Set && getTag(new Set) != setTag) ||\n    (WeakMap && getTag(new WeakMap) != weakMapTag)) {\n  getTag = function(value) {\n    var result = objectToString.call(value),\n        Ctor = result == objectTag ? value.constructor : undefined,\n        ctorString = Ctor ? toSource(Ctor) : undefined;\n\n    if (ctorString) {\n      switch (ctorString) {\n        case dataViewCtorString: return dataViewTag;\n        case mapCtorString: return mapTag;\n        case promiseCtorString: return promiseTag;\n        case setCtorString: return setTag;\n        case weakMapCtorString: return weakMapTag;\n      }\n    }\n    return result;\n  };\n}\n\n/**\n * Initializes an array clone.\n *\n * @private\n * @param {Array} array The array to clone.\n * @returns {Array} Returns the initialized clone.\n */\nfunction initCloneArray(array) {\n  var length = array.length,\n      result = array.constructor(length);\n\n  // Add properties assigned by `RegExp#exec`.\n  if (length && typeof array[0] == 'string' && hasOwnProperty.call(array, 'index')) {\n    result.index = array.index;\n    result.input = array.input;\n  }\n  return result;\n}\n\n/**\n * Initializes an object clone.\n *\n * @private\n * @param {Object} object The object to clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneObject(object) {\n  return (typeof object.constructor == 'function' && !isPrototype(object))\n    ? baseCreate(getPrototype(object))\n    : {};\n}\n\n/**\n * Initializes an object clone based on its `toStringTag`.\n *\n * **Note:** This function only supports cloning values with tags of\n * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.\n *\n * @private\n * @param {Object} object The object to clone.\n * @param {string} tag The `toStringTag` of the object to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneByTag(object, tag, cloneFunc, isDeep) {\n  var Ctor = object.constructor;\n  switch (tag) {\n    case arrayBufferTag:\n      return cloneArrayBuffer(object);\n\n    case boolTag:\n    case dateTag:\n      return new Ctor(+object);\n\n    case dataViewTag:\n      return cloneDataView(object, isDeep);\n\n    case float32Tag: case float64Tag:\n    case int8Tag: case int16Tag: case int32Tag:\n    case uint8Tag: case uint8ClampedTag: case uint16Tag: case uint32Tag:\n      return cloneTypedArray(object, isDeep);\n\n    case mapTag:\n      return cloneMap(object, isDeep, cloneFunc);\n\n    case numberTag:\n    case stringTag:\n      return new Ctor(object);\n\n    case regexpTag:\n      return cloneRegExp(object);\n\n    case setTag:\n      return cloneSet(object, isDeep, cloneFunc);\n\n    case symbolTag:\n      return cloneSymbol(object);\n  }\n}\n\n/**\n * Checks if `value` is a valid array-like index.\n *\n * @private\n * @param {*} value The value to check.\n * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.\n * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.\n */\nfunction isIndex(value, length) {\n  length = length == null ? MAX_SAFE_INTEGER : length;\n  return !!length &&\n    (typeof value == 'number' || reIsUint.test(value)) &&\n    (value > -1 && value % 1 == 0 && value < length);\n}\n\n/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\n/**\n * Checks if `value` is likely a prototype object.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.\n */\nfunction isPrototype(value) {\n  var Ctor = value && value.constructor,\n      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;\n\n  return value === proto;\n}\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to process.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\n/**\n * This method is like `_.clone` except that it recursively clones `value`.\n *\n * @static\n * @memberOf _\n * @since 1.0.0\n * @category Lang\n * @param {*} value The value to recursively clone.\n * @returns {*} Returns the deep cloned value.\n * @see _.clone\n * @example\n *\n * var objects = [{ 'a': 1 }, { 'b': 2 }];\n *\n * var deep = _.cloneDeep(objects);\n * console.log(deep[0] === objects[0]);\n * // => false\n */\nfunction cloneDeep(value) {\n  return baseClone(value, true, true);\n}\n\n/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nfunction isArguments(value) {\n  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.\n  return isArrayLikeObject(value) && hasOwnProperty.call(value, 'callee') &&\n    (!propertyIsEnumerable.call(value, 'callee') || objectToString.call(value) == argsTag);\n}\n\n/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\n/**\n * Checks if `value` is a buffer.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.\n * @example\n *\n * _.isBuffer(new Buffer(2));\n * // => true\n *\n * _.isBuffer(new Uint8Array(2));\n * // => false\n */\nvar isBuffer = nativeIsBuffer || stubFalse;\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 8-9 which returns 'object' for typed array and other constructors.\n  var tag = isObject(value) ? objectToString.call(value) : '';\n  return tag == funcTag || tag == genTag;\n}\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\n/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return !!value && (type == 'object' || type == 'function');\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\n/**\n * Creates an array of the own enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects. See the\n * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * for more details.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keys(new Foo);\n * // => ['a', 'b'] (iteration order is not guaranteed)\n *\n * _.keys('hi');\n * // => ['0', '1']\n */\nfunction keys(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);\n}\n\n/**\n * This method returns a new empty array.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {Array} Returns the new empty array.\n * @example\n *\n * var arrays = _.times(2, _.stubArray);\n *\n * console.log(arrays);\n * // => [[], []]\n *\n * console.log(arrays[0] === arrays[1]);\n * // => false\n */\nfunction stubArray() {\n  return [];\n}\n\n/**\n * This method returns `false`.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {boolean} Returns `false`.\n * @example\n *\n * _.times(2, _.stubFalse);\n * // => [false, false]\n */\nfunction stubFalse() {\n  return false;\n}\n\nmodule.exports = cloneDeep;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/unpipe/index.js":"/*!\n * unpipe\n * Copyright(c) 2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n'use strict'\n\n/**\n * Module exports.\n * @public\n */\n\nmodule.exports = unpipe\n\n/**\n * Determine if there are Node.js pipe-like data listeners.\n * @private\n */\n\nfunction hasPipeDataListeners(stream) {\n  var listeners = stream.listeners('data')\n\n  for (var i = 0; i < listeners.length; i++) {\n    if (listeners[i].name === 'ondata') {\n      return true\n    }\n  }\n\n  return false\n}\n\n/**\n * Unpipe a stream from all destinations.\n *\n * @param {object} stream\n * @public\n */\n\nfunction unpipe(stream) {\n  if (!stream) {\n    throw new TypeError('argument stream is required')\n  }\n\n  if (typeof stream.unpipe === 'function') {\n    // new-style\n    stream.unpipe()\n    return\n  }\n\n  // Node.js 0.8 hack\n  if (!hasPipeDataListeners(stream)) {\n    return\n  }\n\n  var listener\n  var listeners = stream.listeners('close')\n\n  for (var i = 0; i < listeners.length; i++) {\n    listener = listeners[i]\n\n    if (listener.name !== 'cleanup' && listener.name !== 'onclose') {\n      continue\n    }\n\n    // invoke the listener\n    listener.call(stream)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/call-limit/call-limit.js":"\"use strict\"\n\nvar defaultMaxRunning = 50\n\nvar limit = module.exports = function (func, maxRunning) {\n  var running = 0\n  var queue = []\n  if (!maxRunning) maxRunning = defaultMaxRunning\n  return function limited () {\n    var self = this\n    var args = Array.prototype.slice.call(arguments)\n    if (running >= maxRunning) {\n      queue.push({self: this, args: args})\n      return\n    }\n    var cb = typeof args[args.length-1] === 'function' && args.pop()\n    ++ running\n    args.push(function () {\n      var cbargs = arguments\n      -- running\n      cb && process.nextTick(function () {\n        cb.apply(self, cbargs)\n      })\n      if (queue.length) {\n        var next = queue.shift()\n        limited.apply(next.self, next.args)\n      }\n    })\n    func.apply(self, args)\n  }\n}\n\nmodule.exports.method = function (classOrObj, method, maxRunning) {\n  if (typeof classOrObj === 'function') {\n    var func = classOrObj.prototype[method]\n    classOrObj.prototype[method] = limit(func, maxRunning)\n  } else {\n    var func = classOrObj[method]\n    classOrObj[method] = limit(func, maxRunning)\n  }\n}\n\nmodule.exports.promise = function (func, maxRunning) {\n  var running = 0\n  var queue = []\n  if (!maxRunning) maxRunning = defaultMaxRunning\n  return function () {\n    var self = this\n    var args = Array.prototype.slice.call(arguments)\n    return new Promise(function (resolve) {\n      if (running >= maxRunning) {\n        queue.push({self: self, args: args, resolve: resolve})\n        return\n      } else {\n        runNext(self, args, resolve)\n      }\n      function runNext (self, args, resolve) {\n        ++ running\n        resolve(\n          func.apply(self, args)\n          .then(finish, function (err) {\n            finish(err)\n            throw err\n           }))\n      }\n\n      function finish () {\n        -- running\n        if (queue.length) {\n          var next = queue.shift()\n          process.nextTick(runNext, next.self, next.args, next.resolve)\n        }\n      }\n    })\n  }\n}\n\nmodule.exports.promise.method = function (classOrObj, method, maxRunning) {\n  if (typeof classOrObj === 'function') {\n    var func = classOrObj.prototype[method]\n    classOrObj.prototype[method] = limit.promise(func, maxRunning)\n  } else {\n    var func = classOrObj[method]\n    classOrObj[method] = limit.promise(func, maxRunning)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache.js":"// XXX lib/utils/tar.js and this file need to be rewritten.\n\n// URL-to-cache folder mapping:\n// : -> !\n// @ -> _\n// http://registry.npmjs.org/foo/version -> cache/http!/...\n//\n\n/*\nfetching a URL:\n1. Check for URL in inflight URLs.  If present, add cb, and return.\n2. Acquire lock at {cache}/{sha(url)}.lock\n   retries = {cache-lock-retries, def=10}\n   stale = {cache-lock-stale, def=60000}\n   wait = {cache-lock-wait, def=10000}\n3. if lock can't be acquired, then fail\n4. fetch url, clear lock, call cbs\n\ncache folders:\n1. urls: http!/server.com/path/to/thing\n2. c:\\path\\to\\thing: file!/c!/path/to/thing\n3. /path/to/thing: file!/path/to/thing\n4. git@ private: git_github.com!npm/npm\n5. git://public: git!/github.com/npm/npm\n6. git+blah:// git-blah!/server.com/foo/bar\n\nadding a folder:\n1. tar into tmp/random/package.tgz\n2. untar into tmp/random/contents/package, stripping one dir piece\n3. tar tmp/random/contents/package to cache/n/v/package.tgz\n4. untar cache/n/v/package.tgz into cache/n/v/package\n5. rm tmp/random\n\nAdding a url:\n1. fetch to tmp/random/package.tgz\n2. goto folder(2)\n\nadding a name@version:\n1. registry.get(name/version)\n2. if response isn't 304, add url(dist.tarball)\n\nadding a name@range:\n1. registry.get(name)\n2. Find a version that satisfies\n3. add name@version\n\nadding a local tarball:\n1. untar to tmp/random/{blah}\n2. goto folder(2)\n\nadding a namespaced package:\n1. lookup registry for @namespace\n2. namespace_registry.get('name')\n3. add url(namespace/latest.tarball)\n*/\n\nexports = module.exports = cache\n\ncache.unpack = unpack\ncache.clean = clean\ncache.read = read\n\nvar npm = require('./npm.js')\nvar fs = require('graceful-fs')\nvar writeFileAtomic = require('write-file-atomic')\nvar assert = require('assert')\nvar rm = require('./utils/gently-rm.js')\nvar readJson = require('read-package-json')\nvar log = require('npmlog')\nvar path = require('path')\nvar asyncMap = require('slide').asyncMap\nvar tar = require('./utils/tar.js')\nvar fileCompletion = require('./utils/completion/file-completion.js')\nvar deprCheck = require('./utils/depr-check.js')\nvar addNamed = require('./cache/add-named.js')\nvar addLocal = require('./cache/add-local.js')\nvar addRemoteTarball = require('./cache/add-remote-tarball.js')\nvar addRemoteGit = require('./cache/add-remote-git.js')\nvar inflight = require('inflight')\nvar realizePackageSpecifier = require('realize-package-specifier')\nvar npa = require('npm-package-arg')\nvar getStat = require('./cache/get-stat.js')\nvar cachedPackageRoot = require('./cache/cached-package-root.js')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar output = require('./utils/output.js')\n\ncache.usage = 'npm cache add <tarball file>' +\n              '\\nnpm cache add <folder>' +\n              '\\nnpm cache add <tarball url>' +\n              '\\nnpm cache add <git url>' +\n              '\\nnpm cache add <name>@<version>' +\n              '\\nnpm cache ls [<path>]' +\n              '\\nnpm cache clean [<pkg>[@<version>]]'\n\ncache.completion = function (opts, cb) {\n  var argv = opts.conf.argv.remain\n  if (argv.length === 2) {\n    return cb(null, ['add', 'ls', 'clean'])\n  }\n\n  switch (argv[2]) {\n    case 'clean':\n    case 'ls':\n      // cache and ls are easy, because the completion is\n      // what ls_ returns anyway.\n      // just get the partial words, minus the last path part\n      var p = path.dirname(opts.partialWords.slice(3).join('/'))\n      if (p === '.') p = ''\n      return ls_(p, 2, cb)\n    case 'add':\n      // Same semantics as install and publish.\n      return npm.commands.install.completion(opts, cb)\n  }\n}\n\nfunction cache (args, cb) {\n  var cmd = args.shift()\n  switch (cmd) {\n    case 'rm': case 'clear': case 'clean': return clean(args, cb)\n    case 'list': case 'sl': case 'ls': return ls(args, cb)\n    case 'add': return add(args, npm.prefix, cb)\n    default: return cb('Usage: ' + cache.usage)\n  }\n}\n\n// if the pkg and ver are in the cache, then\n// just do a readJson and return.\n// if they're not, then fetch them from the registry.\nfunction read (name, ver, forceBypass, cb) {\n  assert(typeof name === 'string', 'must include name of module to install')\n  assert(typeof cb === 'function', 'must include callback')\n\n  if (forceBypass === undefined || forceBypass === null) forceBypass = true\n\n  var root = cachedPackageRoot({name: name, version: ver})\n  function c (er, data) {\n    if (er) log.verbose('cache', 'addNamed error for', name + '@' + ver, er)\n    if (data) deprCheck(data)\n\n    return cb(er, data)\n  }\n\n  if (forceBypass && npm.config.get('force')) {\n    log.verbose('using force', 'skipping cache')\n    return addNamed(name, ver, null, c)\n  }\n\n  readJson(path.join(root, 'package', 'package.json'), function (er, data) {\n    if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n\n    if (data) {\n      if (!data.name) return cb(new Error('No name provided'))\n      if (!data.version) return cb(new Error('No version provided'))\n    }\n\n    if (er) return addNamed(name, ver, null, c)\n    else c(er, data)\n  })\n}\n\nfunction normalize (args) {\n  var normalized = ''\n  if (args.length > 0) {\n    var a = npa(args[0])\n    if (a.name) normalized = a.name\n    if (a.rawSpec) normalized = [normalized, a.rawSpec].join('/')\n    if (args.length > 1) normalized = [normalized].concat(args.slice(1)).join('/')\n  }\n\n  if (normalized.substr(-1) === '/') {\n    normalized = normalized.substr(0, normalized.length - 1)\n  }\n  normalized = path.normalize(normalized)\n  log.silly('ls', 'normalized', normalized)\n\n  return normalized\n}\n\n// npm cache ls [<path>]\nfunction ls (args, cb) {\n  var prefix = npm.config.get('cache')\n  if (prefix.indexOf(process.env.HOME) === 0) {\n    prefix = '~' + prefix.substr(process.env.HOME.length)\n  }\n  ls_(normalize(args), npm.config.get('depth'), function (er, files) {\n    output(files.map(function (f) {\n      return path.join(prefix, f)\n    }).join('\\n').trim())\n    cb(er, files)\n  })\n}\n\n// Calls cb with list of cached pkgs matching show.\nfunction ls_ (req, depth, cb) {\n  return fileCompletion(npm.cache, req, depth, cb)\n}\n\n// npm cache clean [<path>]\nfunction clean (args, cb) {\n  assert(typeof cb === 'function', 'must include callback')\n\n  if (!args) args = []\n\n  var f = path.join(npm.cache, normalize(args))\n  if (f === npm.cache) {\n    fs.readdir(npm.cache, function (er, files) {\n      if (er) return cb()\n      asyncMap(\n        files.filter(function (f) {\n          return npm.config.get('force') || f !== '-'\n        }).map(function (f) {\n          return path.join(npm.cache, f)\n        }),\n        rm,\n        cb\n      )\n    })\n  } else {\n    rm(f, cb)\n  }\n}\n\n// npm cache add <tarball-url>\n// npm cache add <pkg> <ver>\n// npm cache add <tarball>\n// npm cache add <folder>\ncache.add = function (pkg, ver, where, scrub, cb) {\n  assert(typeof pkg === 'string', 'must include name of package to install')\n  assert(typeof cb === 'function', 'must include callback')\n\n  if (scrub) {\n    return clean([], function (er) {\n      if (er) return cb(er)\n      add([pkg, ver], where, cb)\n    })\n  }\n  return add([pkg, ver], where, cb)\n}\n\nvar adding = 0\nfunction add (args, where, cb) {\n  // this is hot code.  almost everything passes through here.\n  // the args can be any of:\n  // ['url']\n  // ['pkg', 'version']\n  // ['pkg@version']\n  // ['pkg', 'url']\n  // This is tricky, because urls can contain @\n  // Also, in some cases we get [name, null] rather\n  // that just a single argument.\n\n  var usage = 'Usage:\\n' +\n              '    npm cache add <tarball-url>\\n' +\n              '    npm cache add <pkg>@<ver>\\n' +\n              '    npm cache add <tarball>\\n' +\n              '    npm cache add <folder>\\n'\n  var spec\n\n  log.silly('cache add', 'args', args)\n\n  if (args[1] === undefined) args[1] = null\n\n  // at this point the args length must ==2\n  if (args[1] !== null) {\n    spec = args[0] + '@' + args[1]\n  } else if (args.length === 2) {\n    spec = args[0]\n  }\n\n  log.verbose('cache add', 'spec', spec)\n\n  if (!spec) return cb(usage)\n\n  adding++\n  cb = afterAdd(cb)\n\n  realizePackageSpecifier(spec, where, function (err, p) {\n    if (err) return cb(err)\n\n    log.silly('cache add', 'parsed spec', p)\n\n    switch (p.type) {\n      case 'local':\n      case 'directory':\n        addLocal(p, null, cb)\n        break\n      case 'remote':\n        // get auth, if possible\n        mapToRegistry(p.raw, npm.config, function (err, uri, auth) {\n          if (err) return cb(err)\n\n          addRemoteTarball(p.spec, { name: p.name }, null, auth, cb)\n        })\n        break\n      case 'git':\n      case 'hosted':\n        addRemoteGit(p.rawSpec, cb)\n        break\n      default:\n        if (p.name) return addNamed(p.name, p.spec, null, cb)\n\n        cb(new Error(\"couldn't figure out how to install \" + spec))\n    }\n  })\n}\n\nfunction unpack (pkg, ver, unpackTarget, dMode, fMode, uid, gid, cb) {\n  if (typeof cb !== 'function') {\n    cb = gid\n    gid = null\n  }\n  if (typeof cb !== 'function') {\n    cb = uid\n    uid = null\n  }\n  if (typeof cb !== 'function') {\n    cb = fMode\n    fMode = null\n  }\n  if (typeof cb !== 'function') {\n    cb = dMode\n    dMode = null\n  }\n\n  read(pkg, ver, false, function (er) {\n    if (er) {\n      log.error('unpack', 'Could not read data for %s', pkg + '@' + ver)\n      return cb(er)\n    }\n    npm.commands.unbuild([unpackTarget], true, function (er) {\n      if (er) return cb(er)\n      tar.unpack(\n        path.join(cachedPackageRoot({ name: pkg, version: ver }), 'package.tgz'),\n        unpackTarget,\n        dMode, fMode,\n        uid, gid,\n        cb\n      )\n    })\n  })\n}\n\nfunction afterAdd (cb) {\n  return function (er, data) {\n    adding--\n\n    if (er || !data || !data.name || !data.version) return cb(er, data)\n    log.silly('cache', 'afterAdd', data.name + '@' + data.version)\n\n    // Save the resolved, shasum, etc. into the data so that the next\n    // time we load from this cached data, we have all the same info.\n    // Ignore if it fails.\n    var pj = path.join(cachedPackageRoot(data), 'package', 'package.json')\n\n    var done = inflight(pj, cb)\n    if (!done) return log.verbose('afterAdd', pj, 'already in flight; not writing')\n    log.verbose('afterAdd', pj, 'not in flight; writing')\n\n    getStat(function (er, cs) {\n      if (er) return done(er)\n      writeFileAtomic(pj, JSON.stringify(data), { chown: cs }, function (er) {\n        if (!er) log.verbose('afterAdd', pj, 'written')\n        return done(null, data)\n      })\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/write-file-atomic/index.js":"'use strict'\nmodule.exports = writeFile\nmodule.exports.sync = writeFileSync\nmodule.exports._getTmpname = getTmpname // for testing\n\nvar fs = require('graceful-fs')\nvar chain = require('slide').chain\nvar MurmurHash3 = require('imurmurhash')\nvar extend = Object.assign || require('util')._extend\n\nvar invocations = 0\nfunction getTmpname (filename) {\n  return filename + '.' +\n    MurmurHash3(__filename)\n      .hash(String(process.pid))\n      .hash(String(++invocations))\n      .result()\n}\n\nfunction writeFile (filename, data, options, callback) {\n  if (options instanceof Function) {\n    callback = options\n    options = null\n  }\n  if (!options) options = {}\n  fs.realpath(filename, function (_, realname) {\n    _writeFile(realname || filename, data, options, callback)\n  })\n}\nfunction _writeFile (filename, data, options, callback) {\n  var tmpfile = getTmpname(filename)\n\n  if (options.mode && options.chown) {\n    return thenWriteFile()\n  } else {\n    // Either mode or chown is not explicitly set\n    // Default behavior is to copy it from original file\n    return fs.stat(filename, function (err, stats) {\n      if (err || !stats) return thenWriteFile()\n\n      options = extend({}, options)\n      if (!options.mode) {\n        options.mode = stats.mode\n      }\n      if (!options.chown && process.getuid) {\n        options.chown = { uid: stats.uid, gid: stats.gid }\n      }\n      return thenWriteFile()\n    })\n  }\n\n  function thenWriteFile () {\n    chain([\n      [fs, fs.writeFile, tmpfile, data, options.encoding || 'utf8'],\n      options.mode && [fs, fs.chmod, tmpfile, options.mode],\n      options.chown && [fs, fs.chown, tmpfile, options.chown.uid, options.chown.gid],\n      [fs, fs.rename, tmpfile, filename]\n    ], function (err) {\n      err ? fs.unlink(tmpfile, function () { callback(err) })\n        : callback()\n    })\n  }\n}\n\nfunction writeFileSync (filename, data, options) {\n  if (!options) options = {}\n  try {\n    filename = fs.realpathSync(filename)\n  } catch (ex) {\n    // it's ok, it'll happen on a not yet existing file\n  }\n  var tmpfile = getTmpname(filename)\n\n  try {\n    if (!options.mode || !options.chown) {\n      // Either mode or chown is not explicitly set\n      // Default behavior is to copy it from original file\n      try {\n        var stats = fs.statSync(filename)\n        options = extend({}, options)\n        if (!options.mode) {\n          options.mode = stats.mode\n        }\n        if (!options.chown && process.getuid) {\n          options.chown = { uid: stats.uid, gid: stats.gid }\n        }\n      } catch (ex) {\n        // ignore stat errors\n      }\n    }\n\n    fs.writeFileSync(tmpfile, data, options.encoding || 'utf8')\n    if (options.chown) fs.chownSync(tmpfile, options.chown.uid, options.chown.gid)\n    if (options.mode) fs.chmodSync(tmpfile, options.mode)\n    fs.renameSync(tmpfile, filename)\n  } catch (err) {\n    try { fs.unlinkSync(tmpfile) } catch (e) {}\n    throw err\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/slide/lib/slide.js":"exports.asyncMap = require(\"./async-map\")\nexports.bindActor = require(\"./bind-actor\")\nexports.chain = require(\"./chain\")\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/slide/lib/async-map.js":"\n/*\nusage:\n\n// do something to a list of things\nasyncMap(myListOfStuff, function (thing, cb) { doSomething(thing.foo, cb) }, cb)\n// do more than one thing to each item\nasyncMap(list, fooFn, barFn, cb)\n\n*/\n\nmodule.exports = asyncMap\n\nfunction asyncMap () {\n  var steps = Array.prototype.slice.call(arguments)\n    , list = steps.shift() || []\n    , cb_ = steps.pop()\n  if (typeof cb_ !== \"function\") throw new Error(\n    \"No callback provided to asyncMap\")\n  if (!list) return cb_(null, [])\n  if (!Array.isArray(list)) list = [list]\n  var n = steps.length\n    , data = [] // 2d array\n    , errState = null\n    , l = list.length\n    , a = l * n\n  if (!a) return cb_(null, [])\n  function cb (er) {\n    if (er && !errState) errState = er\n\n    var argLen = arguments.length\n    for (var i = 1; i < argLen; i ++) if (arguments[i] !== undefined) {\n      data[i - 1] = (data[i - 1] || []).concat(arguments[i])\n    }\n    // see if any new things have been added.\n    if (list.length > l) {\n      var newList = list.slice(l)\n      a += (list.length - l) * n\n      l = list.length\n      process.nextTick(function () {\n        newList.forEach(function (ar) {\n          steps.forEach(function (fn) { fn(ar, cb) })\n        })\n      })\n    }\n\n    if (--a === 0) cb_.apply(null, [errState].concat(data))\n  }\n  // expect the supplied cb function to be called\n  // \"n\" times for each thing in the array.\n  list.forEach(function (ar) {\n    steps.forEach(function (fn) { fn(ar, cb) })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/slide/lib/bind-actor.js":"module.exports = bindActor\nfunction bindActor () {\n  var args = \n        Array.prototype.slice.call\n        (arguments) // jswtf.\n    , obj = null\n    , fn\n  if (typeof args[0] === \"object\") {\n    obj = args.shift()\n    fn = args.shift()\n    if (typeof fn === \"string\")\n      fn = obj[ fn ]\n  } else fn = args.shift()\n  return function (cb) {\n    fn.apply(obj, args.concat(cb)) }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/slide/lib/chain.js":"module.exports = chain\nvar bindActor = require(\"./bind-actor.js\")\nchain.first = {} ; chain.last = {}\nfunction chain (things, cb) {\n  var res = []\n  ;(function LOOP (i, len) {\n    if (i >= len) return cb(null,res)\n    if (Array.isArray(things[i]))\n      things[i] = bindActor.apply(null,\n        things[i].map(function(i){\n          return (i===chain.first) ? res[0]\n           : (i===chain.last)\n             ? res[res.length - 1] : i }))\n    if (!things[i]) return LOOP(i + 1, len)\n    things[i](function (er, data) {\n      if (er) return cb(er, res)\n      if (data !== undefined) res = res.concat(data)\n      LOOP(i + 1, len)\n    })\n  })(0, things.length) }\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/imurmurhash/imurmurhash.js":"/**\n * @preserve\n * JS Implementation of incremental MurmurHash3 (r150) (as of May 10, 2013)\n *\n * @author <a href=\"mailto:jensyt@gmail.com\">Jens Taylor</a>\n * @see http://github.com/homebrewing/brauhaus-diff\n * @author <a href=\"mailto:gary.court@gmail.com\">Gary Court</a>\n * @see http://github.com/garycourt/murmurhash-js\n * @author <a href=\"mailto:aappleby@gmail.com\">Austin Appleby</a>\n * @see http://sites.google.com/site/murmurhash/\n */\n(function(){\n    var cache;\n\n    // Call this function without `new` to use the cached object (good for\n    // single-threaded environments), or with `new` to create a new object.\n    //\n    // @param {string} key A UTF-16 or ASCII string\n    // @param {number} seed An optional positive integer\n    // @return {object} A MurmurHash3 object for incremental hashing\n    function MurmurHash3(key, seed) {\n        var m = this instanceof MurmurHash3 ? this : cache;\n        m.reset(seed)\n        if (typeof key === 'string' && key.length > 0) {\n            m.hash(key);\n        }\n\n        if (m !== this) {\n            return m;\n        }\n    };\n\n    // Incrementally add a string to this hash\n    //\n    // @param {string} key A UTF-16 or ASCII string\n    // @return {object} this\n    MurmurHash3.prototype.hash = function(key) {\n        var h1, k1, i, top, len;\n\n        len = key.length;\n        this.len += len;\n\n        k1 = this.k1;\n        i = 0;\n        switch (this.rem) {\n            case 0: k1 ^= len > i ? (key.charCodeAt(i++) & 0xffff) : 0;\n            case 1: k1 ^= len > i ? (key.charCodeAt(i++) & 0xffff) << 8 : 0;\n            case 2: k1 ^= len > i ? (key.charCodeAt(i++) & 0xffff) << 16 : 0;\n            case 3:\n                k1 ^= len > i ? (key.charCodeAt(i) & 0xff) << 24 : 0;\n                k1 ^= len > i ? (key.charCodeAt(i++) & 0xff00) >> 8 : 0;\n        }\n\n        this.rem = (len + this.rem) & 3; // & 3 is same as % 4\n        len -= this.rem;\n        if (len > 0) {\n            h1 = this.h1;\n            while (1) {\n                k1 = (k1 * 0x2d51 + (k1 & 0xffff) * 0xcc9e0000) & 0xffffffff;\n                k1 = (k1 << 15) | (k1 >>> 17);\n                k1 = (k1 * 0x3593 + (k1 & 0xffff) * 0x1b870000) & 0xffffffff;\n\n                h1 ^= k1;\n                h1 = (h1 << 13) | (h1 >>> 19);\n                h1 = (h1 * 5 + 0xe6546b64) & 0xffffffff;\n\n                if (i >= len) {\n                    break;\n                }\n\n                k1 = ((key.charCodeAt(i++) & 0xffff)) ^\n                     ((key.charCodeAt(i++) & 0xffff) << 8) ^\n                     ((key.charCodeAt(i++) & 0xffff) << 16);\n                top = key.charCodeAt(i++);\n                k1 ^= ((top & 0xff) << 24) ^\n                      ((top & 0xff00) >> 8);\n            }\n\n            k1 = 0;\n            switch (this.rem) {\n                case 3: k1 ^= (key.charCodeAt(i + 2) & 0xffff) << 16;\n                case 2: k1 ^= (key.charCodeAt(i + 1) & 0xffff) << 8;\n                case 1: k1 ^= (key.charCodeAt(i) & 0xffff);\n            }\n\n            this.h1 = h1;\n        }\n\n        this.k1 = k1;\n        return this;\n    };\n\n    // Get the result of this hash\n    //\n    // @return {number} The 32-bit hash\n    MurmurHash3.prototype.result = function() {\n        var k1, h1;\n        \n        k1 = this.k1;\n        h1 = this.h1;\n\n        if (k1 > 0) {\n            k1 = (k1 * 0x2d51 + (k1 & 0xffff) * 0xcc9e0000) & 0xffffffff;\n            k1 = (k1 << 15) | (k1 >>> 17);\n            k1 = (k1 * 0x3593 + (k1 & 0xffff) * 0x1b870000) & 0xffffffff;\n            h1 ^= k1;\n        }\n\n        h1 ^= this.len;\n\n        h1 ^= h1 >>> 16;\n        h1 = (h1 * 0xca6b + (h1 & 0xffff) * 0x85eb0000) & 0xffffffff;\n        h1 ^= h1 >>> 13;\n        h1 = (h1 * 0xae35 + (h1 & 0xffff) * 0xc2b20000) & 0xffffffff;\n        h1 ^= h1 >>> 16;\n\n        return h1 >>> 0;\n    };\n\n    // Reset the hash object for reuse\n    //\n    // @param {number} seed An optional positive integer\n    MurmurHash3.prototype.reset = function(seed) {\n        this.h1 = typeof seed === 'number' ? seed : 0;\n        this.rem = this.k1 = this.len = 0;\n        return this;\n    };\n\n    // A cached object to use. This can be safely used if you're in a single-\n    // threaded environment, otherwise you need to create new hashes to use.\n    cache = new MurmurHash3();\n\n    if (typeof(module) != 'undefined') {\n        module.exports = MurmurHash3;\n    } else {\n        this.MurmurHash3 = MurmurHash3;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/gently-rm.js":"// only remove the thing if it's a symlink into a specific folder. This is\n// a very common use-case of npm's, but not so common elsewhere.\n\nexports = module.exports = gentlyRm\n\nvar resolve = require('path').resolve\nvar dirname = require('path').dirname\nvar normalize = require('path').normalize\nvar validate = require('aproba')\nvar log = require('npmlog')\nvar lstat = require('graceful-fs').lstat\nvar readlink = require('graceful-fs').readlink\nvar isInside = require('path-is-inside')\nvar vacuum = require('fs-vacuum')\nvar chain = require('slide').chain\nvar asyncMap = require('slide').asyncMap\nvar readCmdShim = require('read-cmd-shim')\nvar iferr = require('iferr')\nvar npm = require('../npm.js')\n\nfunction gentlyRm (target, gently, base, cb) {\n  if (!cb) {\n    cb = base\n    base = undefined\n  }\n\n  if (!cb) {\n    cb = gently\n    gently = false\n  }\n\n  log.silly(\n    'gentlyRm',\n    target,\n    'is being', gently ? 'gently removed' : 'purged',\n    base ? 'from base ' + base : ''\n  )\n\n  // never rm the root, prefix, or bin dirs\n  //\n  // globals included because of `npm link` -- as far as the package\n  // requesting the link is concerned, the linked package is always\n  // installed globally\n  var prefixes = [\n    npm.prefix,\n    npm.globalPrefix,\n    npm.dir,\n    npm.root,\n    npm.globalDir,\n    npm.bin,\n    npm.globalBin\n  ]\n\n  var targetPath = normalize(resolve(npm.prefix, target))\n  if (prefixes.indexOf(targetPath) !== -1) {\n    log.verbose('gentlyRm', targetPath, \"is part of npm and can't be removed\")\n    return cb(new Error('May not delete: ' + targetPath))\n  }\n  var options = { log: log.silly.bind(log, 'vacuum-fs') }\n  if (npm.config.get('force') || !gently) options.purge = true\n  if (base) options.base = normalize(resolve(npm.prefix, base))\n\n  if (!gently) {\n    log.verbose('gentlyRm', \"don't care about contents; nuking\", targetPath)\n    return vacuum(targetPath, options, cb)\n  }\n\n  var parent = options.base = options.base || normalize(npm.prefix)\n\n  // Do all the async work we'll need to do in order to tell if this is a\n  // safe operation\n  chain([\n    [isEverInside, parent, prefixes],\n    [readLinkOrShim, targetPath],\n    [isEverInside, targetPath, prefixes],\n    [isEverInside, targetPath, [parent]]\n  ], function (er, results) {\n    if (er) {\n      if (er.code === 'ENOENT') return cb()\n      return cb(er)\n    }\n    var parentInfo = {\n      path: parent,\n      managed: results[0]\n    }\n    var targetInfo = {\n      path: targetPath,\n      symlink: results[1],\n      managed: results[2],\n      inParent: results[3]\n    }\n\n    isSafeToRm(parentInfo, targetInfo, iferr(cb, thenRemove))\n\n    function thenRemove (toRemove, removeBase) {\n      if (!toRemove) return cb()\n      if (removeBase) options.base = removeBase\n      log.verbose('gentlyRm', options.purge ? 'Purging' : 'Vacuuming',\n        toRemove, 'up to', options.base)\n      return vacuum(toRemove, options, cb)\n    }\n  })\n}\n\nexports._isSafeToRm = isSafeToRm\nfunction isSafeToRm (parent, target, cb) {\n  log.silly('gentlyRm', 'parent.path =', parent.path)\n  log.silly('gentlyRm', 'parent.managed =',\n    parent.managed && parent.managed.target + ' is in ' + parent.managed.path)\n  log.silly('gentlyRm', 'target.path = ', target.path)\n  log.silly('gentlyRm', 'target.symlink =', target.symlink)\n  log.silly('gentlyRm', 'target.managed =',\n    target.managed && target.managed.target + ' is in ' + target.managed.path)\n  log.silly('gentlyRm', 'target.inParent = ', target.inParent)\n\n  // The parent directory or something it symlinks to must eventually be in\n  // a folder that npm maintains.\n  if (!parent.managed) {\n    log.verbose('gentlyRm', parent.path,\n      'is not contained in any diretory npm is known to control or ' +\n      'any place they link to')\n    return cb(clobberFail(target.path, 'containing path ' + parent.path +\n      \" isn't under npm's control\"))\n  }\n\n  // The target or something it symlinks to must eventually be in the parent\n  // or something the parent symlinks to\n  if (target.inParent) {\n    var actualTarget = target.inParent.target\n    var targetsParent = target.inParent.path\n    // if the target.path was what we found in some version of parent, remove\n    // using that parent as the base\n    if (target.path === actualTarget) {\n      return cb(null, target.path, targetsParent)\n    } else {\n      // If something the target.path links to was what was found, just\n      // remove target.path in the location it was found.\n      return cb(null, target.path, dirname(target.path))\n    }\n  }\n\n  // If the target is in a managed directory and is in a symlink, but was\n  // not in our parent that usually means someone else installed a bin file\n  // with the same name as one of our bin files.\n  if (target.managed && target.symlink) {\n    log.warn('gentlyRm', 'not removing', target.path,\n      \"as it wasn't installed by\", parent.path)\n    return cb()\n  }\n\n  if (target.symlink) {\n    return cb(clobberFail(target.path, target.symlink +\n      ' symlink target is not controlled by npm ' + parent.path))\n  } else {\n    return cb(clobberFail(target.path, 'is outside ' + parent.path +\n      ' and not a link'))\n  }\n}\n\nfunction clobberFail (target, msg) {\n  validate('SS', arguments)\n  var er = new Error('Refusing to delete ' + target + ': ' + msg)\n  er.code = 'EEXIST'\n  er.path = target\n  return er\n}\n\nfunction isENOENT (err) {\n  return err && err.code === 'ENOENT'\n}\n\nfunction notENOENT (err) {\n  return !isENOENT(err)\n}\n\nfunction skipENOENT (cb) {\n  return function (err, value) {\n    if (isENOENT(err)) {\n      return cb(null, false)\n    } else {\n      return cb(err, value)\n    }\n  }\n}\n\nfunction errorsToValues (fn) {\n  return function () {\n    var args = Array.prototype.slice.call(arguments)\n    var cb = args.pop()\n    args.push(function (err, value) {\n      if (err) {\n        return cb(null, err)\n      } else {\n        return cb(null, value)\n      }\n    })\n    fn.apply(null, args)\n  }\n}\n\nfunction isNotError (value) {\n  return !(value instanceof Error)\n}\n\nexports._isEverInside = isEverInside\n// return the first of path, where target (or anything it symlinks to)\n// isInside the path (or anything it symlinks to)\nfunction isEverInside (target, paths, cb) {\n  validate('SAF', arguments)\n  asyncMap(paths, errorsToValues(readAllLinks), iferr(cb, function (resolvedPaths) {\n    var errorFree = resolvedPaths.filter(isNotError)\n    if (errorFree.length === 0) {\n      var badErrors = resolvedPaths.filter(notENOENT)\n      if (badErrors.length === 0) {\n        return cb(null, false)\n      } else {\n        return cb(badErrors[0])\n      }\n    }\n    readAllLinks(target, iferr(skipENOENT(cb), function (targets) {\n      cb(null, areAnyInsideAny(targets, errorFree))\n    }))\n  }))\n}\n\nexports._areAnyInsideAny = areAnyInsideAny\n// Return the first path found that any target is inside\nfunction areAnyInsideAny (targets, paths) {\n  validate('AA', arguments)\n  var toCheck = []\n  paths.forEach(function (path) {\n    targets.forEach(function (target) {\n      toCheck.push([target, path])\n    })\n  })\n  for (var ii = 0; ii < toCheck.length; ++ii) {\n    var target = toCheck[ii][0]\n    var path = toCheck[ii][1]\n    var inside = isInside(target, path)\n    if (!inside) log.silly('isEverInside', target, 'is not inside', path)\n    if (inside && path) return inside && path && {target: target, path: path}\n  }\n  return false\n}\n\nexports._readAllLinks = readAllLinks\n// resolves chains of symlinks of unlimited depth, returning a list of paths\n// it's seen in the process when it hits either a symlink cycle or a\n// non-symlink\nfunction readAllLinks (path, cb) {\n  validate('SF', arguments)\n  var seen = {}\n  _readAllLinks(path)\n\n  function _readAllLinks (path) {\n    if (seen[path]) return cb(null, Object.keys(seen))\n    seen[path] = true\n    resolveSymlink(path, iferr(cb, _readAllLinks))\n  }\n}\n\nexports._resolveSymlink = resolveSymlink\nvar resolvedPaths = {}\nfunction resolveSymlink (symlink, cb) {\n  validate('SF', arguments)\n  var cached = resolvedPaths[symlink]\n  if (cached) return cb(null, cached)\n\n  readLinkOrShim(symlink, iferr(cb, function (symlinkTarget) {\n    if (symlinkTarget) {\n      resolvedPaths[symlink] = resolve(dirname(symlink), symlinkTarget)\n    } else {\n      resolvedPaths[symlink] = symlink\n    }\n    return cb(null, resolvedPaths[symlink])\n  }))\n}\n\nexports._readLinkOrShim = readLinkOrShim\nfunction readLinkOrShim (path, cb) {\n  validate('SF', arguments)\n  lstat(path, iferr(cb, function (stat) {\n    if (stat.isSymbolicLink()) {\n      readlink(path, cb)\n    } else {\n      readCmdShim(path, function (er, source) {\n        if (!er) return cb(null, source)\n        // lstat wouldn't return an error on these, so we don't either.\n        if (er.code === 'ENOTASHIM' || er.code === 'EISDIR') {\n          return cb(null, null)\n        } else {\n          return cb(er)\n        }\n      })\n    }\n  }))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/path-is-inside/lib/path-is-inside.js":"\"use strict\";\n\nvar path = require(\"path\");\n\nmodule.exports = function (thePath, potentialParent) {\n    // For inside-directory checking, we want to allow trailing slashes, so normalize.\n    thePath = stripTrailingSep(thePath);\n    potentialParent = stripTrailingSep(potentialParent);\n\n    // Node treats only Windows as case-insensitive in its path module; we follow those conventions.\n    if (process.platform === \"win32\") {\n        thePath = thePath.toLowerCase();\n        potentialParent = potentialParent.toLowerCase();\n    }\n\n    return thePath.lastIndexOf(potentialParent, 0) === 0 &&\n\t\t(\n\t\t\tthePath[potentialParent.length] === path.sep ||\n\t\t\tthePath[potentialParent.length] === undefined\n\t\t);\n};\n\nfunction stripTrailingSep(thePath) {\n    if (thePath[thePath.length - 1] === path.sep) {\n        return thePath.slice(0, -1);\n    }\n    return thePath;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fs-vacuum/vacuum.js":"var assert = require('assert')\nvar dirname = require('path').dirname\nvar resolve = require('path').resolve\nvar isInside = require('path-is-inside')\n\nvar rimraf = require('rimraf')\nvar lstat = require('graceful-fs').lstat\nvar readdir = require('graceful-fs').readdir\nvar rmdir = require('graceful-fs').rmdir\nvar unlink = require('graceful-fs').unlink\n\nmodule.exports = vacuum\n\nfunction vacuum (leaf, options, cb) {\n  assert(typeof leaf === 'string', 'must pass in path to remove')\n  assert(typeof cb === 'function', 'must pass in callback')\n\n  if (!options) options = {}\n  assert(typeof options === 'object', 'options must be an object')\n\n  var log = options.log ? options.log : function () {}\n\n  leaf = leaf && resolve(leaf)\n  var base = options.base && resolve(options.base)\n  if (base && !isInside(leaf, base)) {\n    return cb(new Error(leaf + ' is not a child of ' + base))\n  }\n\n  lstat(leaf, function (error, stat) {\n    if (error) {\n      if (error.code === 'ENOENT') return cb(null)\n\n      log(error.stack)\n      return cb(error)\n    }\n\n    if (!(stat && (stat.isDirectory() || stat.isSymbolicLink() || stat.isFile()))) {\n      log(leaf, 'is not a directory, file, or link')\n      return cb(new Error(leaf + ' is not a directory, file, or link'))\n    }\n\n    if (options.purge) {\n      log('purging', leaf)\n      rimraf(leaf, function (error) {\n        if (error) return cb(error)\n\n        next(dirname(leaf))\n      })\n    } else if (!stat.isDirectory()) {\n      log('removing', leaf)\n      unlink(leaf, function (error) {\n        if (error) return cb(error)\n\n        next(dirname(leaf))\n      })\n    } else {\n      next(leaf)\n    }\n  })\n\n  function next (branch) {\n    branch = branch && resolve(branch)\n    // either we've reached the base or we've reached the root\n    if ((base && branch === base) || branch === dirname(branch)) {\n      log('finished vacuuming up to', branch)\n      return cb(null)\n    }\n\n    readdir(branch, function (error, files) {\n      if (error) {\n        if (error.code === 'ENOENT') return cb(null)\n\n        log('unable to check directory', branch, 'due to', error.message)\n        return cb(error)\n      }\n\n      if (files.length > 0) {\n        log('quitting because other entries in', branch)\n        return cb(null)\n      }\n\n      if (branch === process.env.HOME) {\n        log('quitting because cannot remove home directory', branch)\n        return cb(null)\n      }\n\n      log('removing', branch)\n      lstat(branch, function (error, stat) {\n        if (error) {\n          if (error.code === 'ENOENT') return cb(null)\n\n          log('unable to lstat', branch, 'due to', error.message)\n          return cb(error)\n        }\n\n        var remove = stat.isDirectory() ? rmdir : unlink\n        remove(branch, function (error) {\n          if (error) {\n            if (error.code === 'ENOENT') {\n              log('quitting because lost the race to remove', branch)\n              return cb(null)\n            }\n            if (error.code === 'ENOTEMPTY' || error.code === 'EEXIST') {\n              log('quitting because new (racy) entries in', branch)\n              return cb(null)\n            }\n\n            log('unable to remove', branch, 'due to', error.message)\n            return cb(error)\n          }\n\n          next(dirname(branch))\n        })\n      })\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read-cmd-shim/index.js":"'use strict'\nvar fs = require('graceful-fs')\n\nfunction extractPath (path, cmdshimContents) {\n  if (/[.]cmd$/.test(path)) {\n    return extractPathFromCmd(cmdshimContents)\n  } else {\n    return extractPathFromCygwin(cmdshimContents)\n  }\n}\n\nfunction extractPathFromCmd (cmdshimContents) {\n  var matches = cmdshimContents.match(/\"%~dp0\\\\([^\"]+?)\"\\s+%[*]/)\n  return matches && matches[1]\n}\n\nfunction extractPathFromCygwin (cmdshimContents) {\n  var matches = cmdshimContents.match(/\"[$]basedir[/]([^\"]+?)\"\\s+\"[$]@\"/)\n  return matches && matches[1]\n}\n\nfunction wrapError (thrown, newError) {\n  newError.message = thrown.message\n  newError.code = thrown.code\n  return newError\n}\n\nfunction notaShim (path, er) {\n  if (!er) {\n    er = new Error()\n    Error.captureStackTrace(er, notaShim)\n  }\n  er.code = 'ENOTASHIM'\n  er.message = \"Can't read shim path from '\" + path + \"', it doesn't appear to be a cmd-shim\"\n  return er\n}\n\nvar readCmdShim = module.exports = function (path, cb) {\n  var er = new Error()\n  Error.captureStackTrace(er, readCmdShim)\n  fs.readFile(path, function (readFileEr, contents) {\n    if (readFileEr) return cb(wrapError(readFileEr, er))\n    var destination = extractPath(path, contents.toString())\n    if (destination) return cb(null, destination)\n    return cb(notaShim(path, er))\n  })\n}\n\nmodule.exports.sync = function (path) {\n  var contents = fs.readFileSync(path)\n  var destination = extractPath(path, contents.toString())\n  if (!destination) throw notaShim(path)\n  return destination\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/tar.js":"// commands for packing and unpacking tarballs\n// this file is used by lib/cache.js\n\nvar fs = require('graceful-fs')\nvar path = require('path')\nvar writeFileAtomic = require('write-file-atomic')\nvar writeStreamAtomic = require('fs-write-stream-atomic')\nvar log = require('npmlog')\nvar uidNumber = require('uid-number')\nvar readJson = require('read-package-json')\nvar tar = require('tar')\nvar zlib = require('zlib')\nvar fstream = require('fstream')\nvar Packer = require('fstream-npm')\nvar iferr = require('iferr')\nvar inherits = require('inherits')\nvar npm = require('../npm.js')\nvar rm = require('./gently-rm.js')\nvar myUid = process.getuid && process.getuid()\nvar myGid = process.getgid && process.getgid()\nvar readPackageTree = require('read-package-tree')\nvar union = require('lodash.union')\nvar moduleName = require('./module-name.js')\nvar packageId = require('./package-id.js')\nvar pulseTillDone = require('../utils/pulse-till-done.js')\n\nif (process.env.SUDO_UID && myUid === 0) {\n  if (!isNaN(process.env.SUDO_UID)) myUid = +process.env.SUDO_UID\n  if (!isNaN(process.env.SUDO_GID)) myGid = +process.env.SUDO_GID\n}\n\nexports.pack = pack\nexports.unpack = unpack\n\nfunction pack (tarball, folder, pkg, cb) {\n  log.verbose('tar pack', [tarball, folder])\n\n  log.verbose('tarball', tarball)\n  log.verbose('folder', folder)\n\n  readJson(path.join(folder, 'package.json'), function (er, pkg) {\n    if (er || !pkg.bundleDependencies) {\n      pack_(tarball, folder, null, pkg, cb)\n    } else {\n      // we require this at runtime due to load-order issues, because recursive\n      // requires fail if you replace the exports object, and we do, not in deps, but\n      // in a dep of it.\n      var recalculateMetadata = require('../install/deps.js').recalculateMetadata\n\n      readPackageTree(folder, pulseTillDone('pack:readTree:' + packageId(pkg), iferr(cb, function (tree) {\n        var recalcGroup = log.newGroup('pack:recalc:' + packageId(pkg))\n        recalculateMetadata(tree, recalcGroup, iferr(cb, function () {\n          recalcGroup.finish()\n          pack_(tarball, folder, tree, pkg, pulseTillDone('pack:' + packageId(pkg), cb))\n        }))\n      })))\n    }\n  })\n}\n\nfunction BundledPacker (props) {\n  Packer.call(this, props)\n}\ninherits(BundledPacker, Packer)\n\nBundledPacker.prototype.applyIgnores = function (entry, partial, entryObj) {\n  if (!entryObj || entryObj.type !== 'Directory') {\n    // package.json files can never be ignored.\n    if (entry === 'package.json') return true\n\n    // readme files should never be ignored.\n    if (entry.match(/^readme(\\.[^\\.]*)$/i)) return true\n\n    // license files should never be ignored.\n    if (entry.match(/^(license|licence)(\\.[^\\.]*)?$/i)) return true\n\n    // copyright notice files should never be ignored.\n    if (entry.match(/^(notice)(\\.[^\\.]*)?$/i)) return true\n\n    // changelogs should never be ignored.\n    if (entry.match(/^(changes|changelog|history)(\\.[^\\.]*)?$/i)) return true\n  }\n\n  // special rules.  see below.\n  if (entry === 'node_modules' && this.packageRoot) return true\n\n  // package.json main file should never be ignored.\n  var mainFile = this.package && this.package.main\n  if (mainFile && path.resolve(this.path, entry) === path.resolve(this.path, mainFile)) return true\n\n  // some files are *never* allowed under any circumstances\n  // (VCS folders, native build cruft, npm cruft, regular cruft)\n  if (entry === '.git' ||\n      entry === 'CVS' ||\n      entry === '.svn' ||\n      entry === '.hg' ||\n      entry === '.lock-wscript' ||\n      entry.match(/^\\.wafpickle-[0-9]+$/) ||\n      (this.parent && this.parent.packageRoot && this.basename === 'build' &&\n       entry === 'config.gypi') ||\n      entry === 'npm-debug.log' ||\n      entry === '.npmrc' ||\n      entry.match(/^\\..*\\.swp$/) ||\n      entry === '.DS_Store' ||\n      entry.match(/^\\._/) ||\n      entry.match(/^.*\\.orig$/)\n    ) {\n    return false\n  }\n\n  // in a node_modules folder, we only include bundled dependencies\n  // also, prevent packages in node_modules from being affected\n  // by rules set in the containing package, so that\n  // bundles don't get busted.\n  // Also, once in a bundle, everything is installed as-is\n  // To prevent infinite cycles in the case of cyclic deps that are\n  // linked with npm link, even in a bundle, deps are only bundled\n  // if they're not already present at a higher level.\n  if (this.bundleMagic) {\n    // bubbling up.  stop here and allow anything the bundled pkg allows\n    if (entry.charAt(0) === '@') {\n      var firstSlash = entry.indexOf('/')\n      // continue to list the packages in this scope\n      if (firstSlash === -1) return true\n\n      // bubbling up.  stop here and allow anything the bundled pkg allows\n      if (entry.indexOf('/', firstSlash + 1) !== -1) return true\n    // bubbling up.  stop here and allow anything the bundled pkg allows\n    } else if (entry.indexOf('/') !== -1) {\n      return true\n    }\n\n    // never include the .bin.  It's typically full of platform-specific\n    // stuff like symlinks and .cmd files anyway.\n    if (entry === '.bin') return false\n\n    // the package root.\n    var p = this.parent\n    // the directory before this one.\n    var pp = p && p.parent\n    // the directory before that (if this is scoped)\n    if (pp && pp.basename[0] === '@') pp = pp && pp.parent\n\n    // if this entry has already been bundled, and is a symlink,\n    // and it is the *same* symlink as this one, then exclude it.\n    if (pp && pp.bundleLinks && this.bundleLinks &&\n        pp.bundleLinks[entry] &&\n        pp.bundleLinks[entry] === this.bundleLinks[entry]) {\n      return false\n    }\n\n    // since it's *not* a symbolic link, if we're *already* in a bundle,\n    // then we should include everything.\n    if (pp && pp.package && pp.basename === 'node_modules') {\n      return true\n    }\n\n    // only include it at this point if it's a bundleDependency\n    return this.isBundled(entry)\n  }\n  // if (this.bundled) return true\n\n  return Packer.prototype.applyIgnores.call(this, entry, partial, entryObj)\n}\n\nfunction nameMatch (name) { return function (other) { return name === moduleName(other) } }\n\nfunction pack_ (tarball, folder, tree, pkg, cb) {\n  function InstancePacker (props) {\n    BundledPacker.call(this, props)\n  }\n  inherits(InstancePacker, BundledPacker)\n  InstancePacker.prototype.isBundled = function (name) {\n    var bd = this.package && this.package.bundleDependencies\n    if (!bd) return false\n\n    if (!Array.isArray(bd)) {\n      throw new Error(packageId(this) + '\\'s `bundledDependencies` should ' +\n                      'be an array')\n    }\n    if (!tree) return false\n\n    if (bd.indexOf(name) !== -1) return true\n    var pkg = tree.children.filter(nameMatch(name))[0]\n    if (!pkg) return false\n    var requiredBy = [].concat(pkg.requiredBy)\n    var seen = {}\n    while (requiredBy.length) {\n      var reqPkg = requiredBy.shift()\n      if (seen[reqPkg.path]) continue\n      seen[reqPkg.path] = true\n      if (!reqPkg) continue\n      if (reqPkg.parent === tree && bd.indexOf(moduleName(reqPkg)) !== -1) {\n        return true\n      }\n      requiredBy = union(requiredBy, reqPkg.requiredBy)\n    }\n    return false\n  }\n\n  new InstancePacker({ path: folder, type: 'Directory', isDirectory: true })\n    .on('error', function (er) {\n      if (er) log.error('tar pack', 'Error reading ' + folder)\n      return cb(er)\n    })\n\n    // By default, npm includes some proprietary attributes in the\n    // package tarball.  This is sane, and allowed by the spec.\n    // However, npm *itself* excludes these from its own package,\n    // so that it can be more easily bootstrapped using old and\n    // non-compliant tar implementations.\n    .pipe(tar.Pack({ noProprietary: !npm.config.get('proprietary-attribs') }))\n    .on('error', function (er) {\n      if (er) log.error('tar.pack', 'tar creation error', tarball)\n      cb(er)\n    })\n    .pipe(zlib.Gzip())\n    .on('error', function (er) {\n      if (er) log.error('tar.pack', 'gzip error ' + tarball)\n      cb(er)\n    })\n    .pipe(writeStreamAtomic(tarball))\n    .on('error', function (er) {\n      if (er) log.error('tar.pack', 'Could not write ' + tarball)\n      cb(er)\n    })\n    .on('close', cb)\n}\n\nfunction unpack (tarball, unpackTarget, dMode, fMode, uid, gid, cb) {\n  log.verbose('tar', 'unpack', tarball)\n  log.verbose('tar', 'unpacking to', unpackTarget)\n  if (typeof cb !== 'function') {\n    cb = gid\n    gid = null\n  }\n  if (typeof cb !== 'function') {\n    cb = uid\n    uid = null\n  }\n  if (typeof cb !== 'function') {\n    cb = fMode\n    fMode = npm.modes.file\n  }\n  if (typeof cb !== 'function') {\n    cb = dMode\n    dMode = npm.modes.exec\n  }\n\n  uidNumber(uid, gid, function (er, uid, gid) {\n    if (er) return cb(er)\n    unpack_(tarball, unpackTarget, dMode, fMode, uid, gid, cb)\n  })\n}\n\nfunction unpack_ (tarball, unpackTarget, dMode, fMode, uid, gid, cb) {\n  rm(unpackTarget, function (er) {\n    if (er) return cb(er)\n    // gzip {tarball} --decompress --stdout \\\n    //   | tar -mvxpf - --strip-components=1 -C {unpackTarget}\n    gunzTarPerm(tarball, unpackTarget,\n                dMode, fMode,\n                uid, gid,\n                function (er, folder) {\n                  if (er) return cb(er)\n                  readJson(path.resolve(folder, 'package.json'), cb)\n                })\n  })\n}\n\nfunction gunzTarPerm (tarball, target, dMode, fMode, uid, gid, cb_) {\n  if (!dMode) dMode = npm.modes.exec\n  if (!fMode) fMode = npm.modes.file\n  log.silly('gunzTarPerm', 'modes', [dMode.toString(8), fMode.toString(8)])\n\n  var cbCalled = false\n  function cb (er) {\n    if (cbCalled) return\n    cbCalled = true\n    cb_(er, target)\n  }\n\n  var fst = fs.createReadStream(tarball)\n\n  fst.on('open', function (fd) {\n    fs.fstat(fd, function (er, st) {\n      if (er) return fst.emit('error', er)\n      if (st.size === 0) {\n        er = new Error('0-byte tarball\\n' +\n                       'Please run `npm cache clean`')\n        fst.emit('error', er)\n      }\n    })\n  })\n\n  // figure out who we're supposed to be, if we're not pretending\n  // to be a specific user.\n  if (npm.config.get('unsafe-perm') && process.platform !== 'win32') {\n    uid = myUid\n    gid = myGid\n  }\n\n  function extractEntry (entry) {\n    log.silly('gunzTarPerm', 'extractEntry', entry.path)\n    // never create things that are user-unreadable,\n    // or dirs that are user-un-listable. Only leads to headaches.\n    var originalMode = entry.mode = entry.mode || entry.props.mode\n    entry.mode = entry.mode | (entry.type === 'Directory' ? dMode : fMode)\n    entry.mode = entry.mode & (~npm.modes.umask)\n    entry.props.mode = entry.mode\n    if (originalMode !== entry.mode) {\n      log.silly('gunzTarPerm', 'modified mode',\n                [entry.path, originalMode, entry.mode])\n    }\n\n    // if there's a specific owner uid/gid that we want, then set that\n    if (process.platform !== 'win32' &&\n        typeof uid === 'number' &&\n        typeof gid === 'number') {\n      entry.props.uid = entry.uid = uid\n      entry.props.gid = entry.gid = gid\n    }\n  }\n\n  var extractOpts = { type: 'Directory', path: target, strip: 1 }\n\n  if (process.platform !== 'win32' &&\n      typeof uid === 'number' &&\n      typeof gid === 'number') {\n    extractOpts.uid = uid\n    extractOpts.gid = gid\n  }\n\n  var sawIgnores = {}\n  extractOpts.filter = function () {\n    // symbolic links are not allowed in packages.\n    if (this.type.match(/^.*Link$/)) {\n      log.warn('excluding symbolic link',\n               this.path.substr(target.length + 1) +\n               ' -> ' + this.linkpath)\n      return false\n    }\n\n    // Note: This mirrors logic in the fs read operations that are\n    // employed during tarball creation, in the fstream-npm module.\n    // It is duplicated here to handle tarballs that are created\n    // using other means, such as system tar or git archive.\n    if (this.type === 'File') {\n      var base = path.basename(this.path)\n      if (base === '.npmignore') {\n        sawIgnores[ this.path ] = true\n      } else if (base === '.gitignore') {\n        var npmignore = this.path.replace(/\\.gitignore$/, '.npmignore')\n        if (sawIgnores[npmignore]) {\n          // Skip this one, already seen.\n          return false\n        } else {\n          // Rename, may be clobbered later.\n          this.path = npmignore\n          this._path = npmignore\n        }\n      }\n    }\n\n    return true\n  }\n\n  fst\n    .on('error', function (er) {\n      if (er) log.error('tar.unpack', 'error reading ' + tarball)\n      cb(er)\n    })\n    .on('data', function OD (c) {\n      // detect what it is.\n      // Then, depending on that, we'll figure out whether it's\n      // a single-file module, gzipped tarball, or naked tarball.\n      // gzipped files all start with 1f8b08\n      if (c[0] === 0x1F &&\n          c[1] === 0x8B &&\n          c[2] === 0x08) {\n        fst\n          .pipe(zlib.Unzip())\n          .on('error', function (er) {\n            if (er) log.error('tar.unpack', 'unzip error ' + tarball)\n            cb(er)\n          })\n          .pipe(tar.Extract(extractOpts))\n          .on('entry', extractEntry)\n          .on('error', function (er) {\n            if (er) log.error('tar.unpack', 'untar error ' + tarball)\n            cb(er)\n          })\n          .on('close', cb)\n      } else if (hasTarHeader(c)) {\n        // naked tar\n        fst\n          .pipe(tar.Extract(extractOpts))\n          .on('entry', extractEntry)\n          .on('error', function (er) {\n            if (er) log.error('tar.unpack', 'untar error ' + tarball)\n            cb(er)\n          })\n          .on('close', cb)\n      } else {\n        // naked js file\n        var jsOpts = { path: path.resolve(target, 'index.js') }\n\n        if (process.platform !== 'win32' &&\n            typeof uid === 'number' &&\n            typeof gid === 'number') {\n          jsOpts.uid = uid\n          jsOpts.gid = gid\n        }\n\n        fst\n          .pipe(fstream.Writer(jsOpts))\n          .on('error', function (er) {\n            if (er) log.error('tar.unpack', 'copy error ' + tarball)\n            cb(er)\n          })\n          .on('close', function () {\n            var j = path.resolve(target, 'package.json')\n            readJson(j, function (er, d) {\n              if (er) {\n                log.error('not a package', tarball)\n                return cb(er)\n              }\n              writeFileAtomic(j, JSON.stringify(d) + '\\n', cb)\n            })\n          })\n      }\n\n      // now un-hook, and re-emit the chunk\n      fst.removeListener('data', OD)\n      fst.emit('data', c)\n    })\n}\n\nfunction hasTarHeader (c) {\n  return c[257] === 0x75 && // tar archives have 7573746172 at position\n         c[258] === 0x73 && // 257 and 003030 or 202000 at position 262\n         c[259] === 0x74 &&\n         c[260] === 0x61 &&\n         c[261] === 0x72 &&\n\n       ((c[262] === 0x00 &&\n         c[263] === 0x30 &&\n         c[264] === 0x30) ||\n\n        (c[262] === 0x20 &&\n         c[263] === 0x20 &&\n         c[264] === 0x00))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fs-write-stream-atomic/index.js":"var fs = require('graceful-fs')\nvar Writable = require('readable-stream').Writable\nvar util = require('util')\nvar MurmurHash3 = require('imurmurhash')\nvar iferr = require('iferr')\nvar crypto = require('crypto')\n\nfunction murmurhex () {\n  var hash = MurmurHash3('')\n  for (var ii = 0; ii < arguments.length; ++ii) {\n    hash.hash('' + arguments[ii])\n  }\n  return hash.result()\n}\n\nvar invocations = 0\nfunction getTmpname (filename) {\n  return filename + '.' + murmurhex(__filename, process.pid, ++invocations)\n}\n\nvar setImmediate = global.setImmediate || setTimeout\n\nmodule.exports = WriteStreamAtomic\n\n// Requirements:\n//   1. Write everything written to the stream to a temp file.\n//   2. If there are no errors:\n//      a. moves the temp file into its final destination\n//      b. emits `finish` & `closed` ONLY after the file is\n//         fully flushed and renamed.\n//   3. If there's an error, removes the temp file.\n\nutil.inherits(WriteStreamAtomic, Writable)\nfunction WriteStreamAtomic (path, options) {\n  if (!(this instanceof WriteStreamAtomic)) {\n    return new WriteStreamAtomic(path, options)\n  }\n  Writable.call(this, options)\n\n  this.__isWin = options && options.hasOwnProperty('isWin') ? options.isWin : process.platform === 'win32'\n\n  this.__atomicTarget = path\n  this.__atomicTmp = getTmpname(path)\n\n  this.__atomicChown = options && options.chown\n\n  this.__atomicClosed = false\n\n  this.__atomicStream = fs.WriteStream(this.__atomicTmp, options)\n\n  this.__atomicStream.once('open', handleOpen(this))\n  this.__atomicStream.once('close', handleClose(this))\n  this.__atomicStream.once('error', handleError(this))\n}\n\n// We have to suppress default finish emitting, because ordinarily it\n// would happen as soon as `end` is called on us and all of the\n// data has been written to our target stream. So we suppress\n// finish from being emitted here, and only emit it after our\n// target stream is closed and we've moved everything around.\nWriteStreamAtomic.prototype.emit = function (event) {\n  if (event === 'finish') return this.__atomicStream.end()\n  return Writable.prototype.emit.apply(this, arguments)\n}\n\nWriteStreamAtomic.prototype._write = function (buffer, encoding, cb) {\n  var flushed = this.__atomicStream.write(buffer, encoding)\n  if (flushed) return cb()\n  this.__atomicStream.once('drain', cb)\n}\n\nfunction handleOpen (writeStream) {\n  return function (fd) {\n    writeStream.emit('open', fd)\n  }\n}\n\nfunction handleClose (writeStream) {\n  return function () {\n    if (writeStream.__atomicClosed) return\n    writeStream.__atomicClosed = true\n    if (writeStream.__atomicChown) {\n      var uid = writeStream.__atomicChown.uid\n      var gid = writeStream.__atomicChown.gid\n      return fs.chown(writeStream.__atomicTmp, uid, gid, iferr(cleanup, moveIntoPlace))\n    } else {\n      moveIntoPlace()\n    }\n  }\n\n  function moveIntoPlace () {\n    fs.rename(writeStream.__atomicTmp, writeStream.__atomicTarget, iferr(trapWindowsEPERM, end))\n  }\n\n  function trapWindowsEPERM (err) {\n    if (writeStream.__isWin &&\n        err.syscall && err.syscall === 'rename' &&\n        err.code && err.code === 'EPERM'\n    ) {\n      checkFileHashes(err)\n    } else {\n      cleanup(err)\n    }\n  }\n\n  function checkFileHashes (eperm) {\n    var inprocess = 2\n    var tmpFileHash = crypto.createHash('sha512')\n    var targetFileHash = crypto.createHash('sha512')\n\n    fs.createReadStream(writeStream.__atomicTmp)\n      .on('data', function (data, enc) { tmpFileHash.update(data, enc) })\n      .on('error', fileHashError)\n      .on('end', fileHashComplete)\n    fs.createReadStream(writeStream.__atomicTarget)\n      .on('data', function (data, enc) { targetFileHash.update(data, enc) })\n      .on('error', fileHashError)\n      .on('end', fileHashComplete)\n\n    function fileHashError () {\n      if (inprocess === 0) return\n      inprocess = 0\n      cleanup(eperm)\n    }\n\n    function fileHashComplete () {\n      if (inprocess === 0) return\n      if (--inprocess) return\n      if (tmpFileHash.digest('hex') === targetFileHash.digest('hex')) {\n        return cleanup()\n      } else {\n        return cleanup(eperm)\n      }\n    }\n  }\n\n  function cleanup (err) {\n    fs.unlink(writeStream.__atomicTmp, function () {\n      if (err) {\n        writeStream.emit('error', err)\n        writeStream.emit('close')\n      } else {\n        end()\n      }\n    })\n  }\n\n  function end () {\n    // We have to use our parent class directly because we suppress `finish`\n    // events fired via our own emit method.\n    Writable.prototype.emit.call(writeStream, 'finish')\n\n    // Delay the close to provide the same temporal separation a physical\n    // file operation would have that is, the close event is emitted only\n    // after the async close operation completes.\n    setImmediate(function () {\n      writeStream.emit('close')\n    })\n  }\n}\n\nfunction handleError (writeStream) {\n  return function (er) {\n    cleanupSync()\n    writeStream.emit('error', er)\n    writeStream.__atomicClosed = true\n    writeStream.emit('close')\n  }\n  function cleanupSync () {\n    try {\n      fs.unlinkSync(writeStream.__atomicTmp)\n    } finally {\n      return\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream-npm/fstream-npm.js":"var Ignore = require('fstream-ignore')\nvar inherits = require('inherits')\nvar path = require('path')\nvar fs = require('fs')\n\nmodule.exports = Packer\n\ninherits(Packer, Ignore)\n\nfunction Packer (props) {\n  if (!(this instanceof Packer)) {\n    return new Packer(props)\n  }\n\n  if (typeof props === 'string') {\n    props = { path: props }\n  }\n\n  props.ignoreFiles = props.ignoreFiles || [ '.npmignore',\n                                             '.gitignore',\n                                             'package.json' ]\n\n  Ignore.call(this, props)\n\n  this.bundled = props.bundled\n  this.bundleLinks = props.bundleLinks\n  this.package = props.package\n\n  // only do the magic bundling stuff for the node_modules folder that\n  // lives right next to a package.json file.\n  this.bundleMagic = this.parent &&\n                     this.parent.packageRoot &&\n                     this.basename === 'node_modules'\n\n  // in a node_modules folder, resolve symbolic links to\n  // bundled dependencies when creating the package.\n  props.follow = this.follow = this.bundleMagic\n  // console.error(\"follow?\", this.path, props.follow)\n\n  if (this === this.root ||\n      this.parent &&\n      this.parent.bundleMagic &&\n      this.basename.charAt(0) !== '.') {\n    this.readBundledLinks()\n  }\n\n  this.on('entryStat', function (entry, props) {\n    // files should *always* get into tarballs\n    // in a user-writable state, even if they're\n    // being installed from some wackey vm-mounted\n    // read-only filesystem.\n    entry.mode = props.mode = props.mode | parseInt('0200', 8)\n  })\n}\n\nPacker.prototype.readBundledLinks = function () {\n  if (this._paused) {\n    this.once('resume', this.addIgnoreFiles)\n    return\n  }\n\n  this.pause()\n  fs.readdir(this.path + '/node_modules', function (er, list) {\n    // no harm if there's no bundle\n    var l = list && list.length\n    if (er || l === 0) return this.resume()\n\n    var errState = null\n    var then = function then (er) {\n      if (errState) return\n      if (er) {\n        errState = er\n        return this.resume()\n      }\n      if (--l === 0) return this.resume()\n    }.bind(this)\n\n    list.forEach(function (pkg) {\n      if (pkg.charAt(0) === '.') return then()\n      var pd = this.path + '/node_modules/' + pkg\n\n      // scoped packages\n      if (pkg.charAt(0) === '@') {\n        fs.readdir(pd, function (er, slist) {\n          var sl = slist && slist.length\n          if (er || sl === 0) return then(er)\n\n          l += sl\n          slist.forEach(function (spkg) {\n            if (spkg.charAt(0) === '.') return then()\n            var spd = pd + '/' + spkg\n            fs.realpath(spd, function (er, rp) {\n              if (er) return then()\n              this.bundleLinks = this.bundleLinks || {}\n              this.bundleLinks[pkg + '/' + spkg] = rp\n              then()\n            }.bind(this))\n          }, this)\n          then()\n        }.bind(this))\n        return\n      }\n\n      fs.realpath(pd, function (er, rp) {\n        if (er) return then()\n        this.bundleLinks = this.bundleLinks || {}\n        this.bundleLinks[pkg] = rp\n        then()\n      }.bind(this))\n    }, this)\n  }.bind(this))\n}\n\nPacker.prototype.applyIgnores = function (entry, partial, entryObj) {\n  if (!entryObj || entryObj.type !== 'Directory') {\n    // package.json files can never be ignored.\n    if (entry === 'package.json') return true\n\n    // readme files should never be ignored.\n    if (entry.match(/^readme(\\.[^\\.]*)$/i)) return true\n\n    // license files should never be ignored.\n    if (entry.match(/^(license|licence)(\\.[^\\.]*)?$/i)) return true\n\n    // copyright notice files should never be ignored.\n    if (entry.match(/^(notice)(\\.[^\\.]*)?$/i)) return true\n\n    // changelogs should never be ignored.\n    if (entry.match(/^(changes|changelog|history)(\\.[^\\.]*)?$/i)) return true\n  }\n\n  // special rules.  see below.\n  if (entry === 'node_modules' && this.packageRoot) return true\n\n  // package.json main file should never be ignored.\n  var mainFile = this.package && this.package.main\n  if (mainFile && path.resolve(this.path, entry) === path.resolve(this.path, mainFile)) return true\n\n  // some files are *never* allowed under any circumstances\n  // (VCS folders, native build cruft, npm cruft, regular cruft)\n  if (entry === '.git' ||\n      entry === 'CVS' ||\n      entry === '.svn' ||\n      entry === '.hg' ||\n      entry === '.lock-wscript' ||\n      entry.match(/^\\.wafpickle-[0-9]+$/) ||\n      (this.parent && this.parent.packageRoot && this.basename === 'build' &&\n       entry === 'config.gypi') ||\n      entry === 'npm-debug.log' ||\n      entry === '.npmrc' ||\n      entry.match(/^\\..*\\.swp$/) ||\n      entry === '.DS_Store' ||\n      entry.match(/^\\._/) ||\n      entry.match(/^.*\\.orig$/)\n    ) {\n    return false\n  }\n\n  // in a node_modules folder, we only include bundled dependencies\n  // also, prevent packages in node_modules from being affected\n  // by rules set in the containing package, so that\n  // bundles don't get busted.\n  // Also, once in a bundle, everything is installed as-is\n  // To prevent infinite cycles in the case of cyclic deps that are\n  // linked with npm link, even in a bundle, deps are only bundled\n  // if they're not already present at a higher level.\n  if (this.bundleMagic) {\n    if (entry.charAt(0) === '@') {\n      var firstSlash = entry.indexOf('/')\n      // continue to list the packages in this scope\n      if (firstSlash === -1) return true\n\n      // bubbling up.  stop here and allow anything the bundled pkg allows\n      if (entry.indexOf('/', firstSlash + 1) !== -1) return true\n    }\n    // bubbling up.  stop here and allow anything the bundled pkg allows\n    else if (entry.indexOf('/') !== -1) return true\n\n    // never include the .bin.  It's typically full of platform-specific\n    // stuff like symlinks and .cmd files anyway.\n    if (entry === '.bin') return false\n\n    // the package root.\n    var p = this.parent\n    // the package before this one.\n    var pp = p && p.parent\n\n    // if this entry has already been bundled, and is a symlink,\n    // and it is the *same* symlink as this one, then exclude it.\n    if (pp && pp.bundleLinks && this.bundleLinks &&\n        pp.bundleLinks[entry] &&\n        pp.bundleLinks[entry] === this.bundleLinks[entry]) {\n      return false\n    }\n\n    // since it's *not* a symbolic link, if we're *already* in a bundle,\n    // then we should include everything.\n    if (pp && pp.package && pp.basename === 'node_modules') {\n      return true\n    }\n\n    // only include it at this point if it's a bundleDependency\n    var bd = this.package && this.package.bundleDependencies\n\n    if (bd && !Array.isArray(bd)) {\n      throw new Error(this.package.name + '\\'s `bundledDependencies` should ' +\n                      'be an array')\n    }\n\n    var shouldBundle = bd && bd.indexOf(entry) !== -1\n    // if we're not going to bundle it, then it doesn't count as a bundleLink\n    // if (this.bundleLinks && !shouldBundle) delete this.bundleLinks[entry]\n    return shouldBundle\n  }\n  // if (this.bundled) return true\n\n  return Ignore.prototype.applyIgnores.call(this, entry, partial, entryObj)\n}\n\nPacker.prototype.addIgnoreFiles = function () {\n  var entries = this.entries\n  // if there's a .npmignore, then we do *not* want to\n  // read the .gitignore.\n  if (entries.indexOf('.npmignore') !== -1) {\n    var i = entries.indexOf('.gitignore')\n    if (i !== -1) {\n      entries.splice(i, 1)\n    }\n  }\n\n  this.entries = entries\n\n  Ignore.prototype.addIgnoreFiles.call(this)\n}\n\nPacker.prototype.readRules = function (buf, e) {\n  if (e !== 'package.json') {\n    return Ignore.prototype.readRules.call(this, buf, e)\n  }\n\n  buf = buf.toString().trim()\n\n  if (buf.length === 0) return []\n\n  try {\n    var p = this.package = JSON.parse(buf)\n  } catch (er) {\n    // just pretend it's a normal old file, not magic at all.\n    return []\n  }\n\n  if (this === this.root) {\n    this.bundleLinks = this.bundleLinks || {}\n    this.bundleLinks[p.name] = this._path\n  }\n\n  this.packageRoot = true\n  this.emit('package', p)\n\n  // make bundle deps predictable\n  if (p.bundledDependencies && !p.bundleDependencies) {\n    p.bundleDependencies = p.bundledDependencies\n    delete p.bundledDependencies\n  }\n\n  if (!p.files || !Array.isArray(p.files)) return []\n\n  // ignore everything except what's in the files array.\n  return ['*'].concat(p.files.map(function (f) {\n    return '!' + f\n  })).concat(p.files.map(function (f) {\n    return '!' + f.replace(/\\/+$/, '') + '/**'\n  }))\n}\n\nPacker.prototype.getChildProps = function (stat) {\n  var props = Ignore.prototype.getChildProps.call(this, stat)\n\n  props.package = this.package\n\n  props.bundled = this.bundled && this.bundled.slice(0)\n  props.bundleLinks = this.bundleLinks &&\n    Object.create(this.bundleLinks)\n\n  // Directories have to be read as Packers\n  // otherwise fstream.Reader will create a DirReader instead.\n  if (stat.isDirectory()) {\n    props.type = this.constructor\n  }\n\n  // only follow symbolic links directly in the node_modules folder.\n  props.follow = false\n  return props\n}\n\nvar order = [\n  'package.json',\n  '.npmignore',\n  '.gitignore',\n  /^README(\\.md)?$/,\n  'LICENCE',\n  'LICENSE',\n  /\\.js$/\n]\n\nPacker.prototype.sort = function (a, b) {\n  for (var i = 0, l = order.length; i < l; i++) {\n    var o = order[i]\n    if (typeof o === 'string') {\n      if (a === o) return -1\n      if (b === o) return 1\n    } else {\n      if (a.match(o)) return -1\n      if (b.match(o)) return 1\n    }\n  }\n\n  // deps go in the back\n  if (a === 'node_modules') return 1\n  if (b === 'node_modules') return -1\n\n  return Ignore.prototype.sort.call(this, a, b)\n}\n\nPacker.prototype.emitEntry = function (entry) {\n  if (this._paused) {\n    this.once('resume', this.emitEntry.bind(this, entry))\n    return\n  }\n\n  // if there is a .gitignore, then we're going to\n  // rename it to .npmignore in the output.\n  if (entry.basename === '.gitignore') {\n    entry.basename = '.npmignore'\n    entry.path = path.resolve(entry.dirname, entry.basename)\n  }\n\n  // all *.gyp files are renamed to binding.gyp for node-gyp\n  // but only when they are in the same folder as a package.json file.\n  if (entry.basename.match(/\\.gyp$/) &&\n      this.entries.indexOf('package.json') !== -1) {\n    entry.basename = 'binding.gyp'\n    entry.path = path.resolve(entry.dirname, entry.basename)\n  }\n\n  // skip over symbolic links\n  if (entry.type === 'SymbolicLink') {\n    entry.abort()\n    return\n  }\n\n  if (entry.type !== 'Directory') {\n    // make it so that the folder in the tarball is named \"package\"\n    var h = path.dirname((entry.root || entry).path)\n    var t = entry.path.substr(h.length + 1).replace(/^[^\\/\\\\]+/, 'package')\n    var p = h + '/' + t\n\n    entry.path = p\n    entry.dirname = path.dirname(p)\n    return Ignore.prototype.emitEntry.call(this, entry)\n  }\n\n  // we don't want empty directories to show up in package\n  // tarballs.\n  // don't emit entry events for dirs, but still walk through\n  // and read them.  This means that we need to proxy up their\n  // entry events so that those entries won't be missed, since\n  // .pipe() doesn't do anythign special with \"child\" events, on\n  // with \"entry\" events.\n  var me = this\n  entry.on('entry', function (e) {\n    if (e.parent === entry) {\n      e.parent = me\n      me.emit('entry', e)\n    }\n  })\n  entry.on('package', this.emit.bind(this, 'package'))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream-npm/node_modules/fstream-ignore/ignore.js":"// Essentially, this is a fstream.DirReader class, but with a\n// bit of special logic to read the specified sort of ignore files,\n// and a filter that prevents it from picking up anything excluded\n// by those files.\n\nvar Minimatch = require(\"minimatch\").Minimatch\n, fstream = require(\"fstream\")\n, DirReader = fstream.DirReader\n, inherits = require(\"inherits\")\n, path = require(\"path\")\n, fs = require(\"fs\")\n\nmodule.exports = IgnoreReader\n\ninherits(IgnoreReader, DirReader)\n\nfunction IgnoreReader (props) {\n  if (!(this instanceof IgnoreReader)) {\n    return new IgnoreReader(props)\n  }\n\n  // must be a Directory type\n  if (typeof props === \"string\") {\n    props = { path: path.resolve(props) }\n  }\n\n  props.type = \"Directory\"\n  props.Directory = true\n\n  if (!props.ignoreFiles) props.ignoreFiles = [\".ignore\"]\n  this.ignoreFiles = props.ignoreFiles\n\n  this.ignoreRules = null\n\n  // ensure that .ignore files always show up at the top of the list\n  // that way, they can be read before proceeding to handle other\n  // entries in that same folder\n  if (props.sort) {\n    this._sort = props.sort === \"alpha\" ? alphasort : props.sort\n    props.sort = null\n  }\n\n  this.on(\"entries\", function () {\n    // if there are any ignore files in the list, then\n    // pause and add them.\n    // then, filter the list based on our ignoreRules\n\n    var hasIg = this.entries.some(this.isIgnoreFile, this)\n\n    if (!hasIg) return this.filterEntries()\n\n    this.addIgnoreFiles()\n  })\n\n  // we filter entries before we know what they are.\n  // however, directories have to be re-tested against\n  // rules with a \"/\" appended, because \"a/b/\" will only\n  // match if \"a/b\" is a dir, and not otherwise.\n  this.on(\"_entryStat\", function (entry, props) {\n    var t = entry.basename\n    if (!this.applyIgnores(entry.basename,\n                           entry.type === \"Directory\",\n                           entry)) {\n      entry.abort()\n    }\n  }.bind(this))\n\n  DirReader.call(this, props)\n}\n\n\nIgnoreReader.prototype.addIgnoreFiles = function () {\n  if (this._paused) {\n    this.once(\"resume\", this.addIgnoreFiles)\n    return\n  }\n  if (this._ignoreFilesAdded) return\n  this._ignoreFilesAdded = true\n\n  var newIg = this.entries.filter(this.isIgnoreFile, this)\n  , count = newIg.length\n  , errState = null\n\n  if (!count) return\n\n  this.pause()\n\n  var then = function (er) {\n    if (errState) return\n    if (er) return this.emit(\"error\", errState = er)\n    if (-- count === 0) {\n      this.filterEntries()\n      this.resume()\n    } else {\n      this.addIgnoreFile(newIg[newIg.length - count], then)\n    }\n  }.bind(this)\n\n  this.addIgnoreFile(newIg[0], then)\n}\n\n\nIgnoreReader.prototype.isIgnoreFile = function (e) {\n  return e !== \".\" &&\n         e !== \"..\" &&\n         -1 !== this.ignoreFiles.indexOf(e)\n}\n\n\nIgnoreReader.prototype.getChildProps = function (stat) {\n  var props = DirReader.prototype.getChildProps.call(this, stat)\n  props.ignoreFiles = this.ignoreFiles\n\n  // Directories have to be read as IgnoreReaders\n  // otherwise fstream.Reader will create a DirReader instead.\n  if (stat.isDirectory()) {\n    props.type = this.constructor\n  }\n  return props\n}\n\n\nIgnoreReader.prototype.addIgnoreFile = function (e, cb) {\n  // read the file, and then call addIgnoreRules\n  // if there's an error, then tell the cb about it.\n\n  var ig = path.resolve(this.path, e)\n  fs.readFile(ig, function (er, data) {\n    if (er) return cb(er)\n\n    this.emit(\"ignoreFile\", e, data)\n    var rules = this.readRules(data, e)\n    this.addIgnoreRules(rules, e)\n    cb()\n  }.bind(this))\n}\n\n\nIgnoreReader.prototype.readRules = function (buf, e) {\n  return buf.toString().split(/\\r?\\n/)\n}\n\n\n// Override this to do fancier things, like read the\n// \"files\" array from a package.json file or something.\nIgnoreReader.prototype.addIgnoreRules = function (set, e) {\n  // filter out anything obvious\n  set = set.filter(function (s) {\n    s = s.trim()\n    return s && !s.match(/^#/)\n  })\n\n  // no rules to add!\n  if (!set.length) return\n\n  // now get a minimatch object for each one of these.\n  // Note that we need to allow dot files by default, and\n  // not switch the meaning of their exclusion\n  var mmopt = { matchBase: true, dot: true, flipNegate: true }\n  , mm = set.map(function (s) {\n    var m = new Minimatch(s, mmopt)\n    m.ignoreFile = e\n    return m\n  })\n\n  if (!this.ignoreRules) this.ignoreRules = []\n  this.ignoreRules.push.apply(this.ignoreRules, mm)\n}\n\n\nIgnoreReader.prototype.filterEntries = function () {\n  // this exclusion is at the point where we know the list of\n  // entries in the dir, but don't know what they are.  since\n  // some of them *might* be directories, we have to run the\n  // match in dir-mode as well, so that we'll pick up partials\n  // of files that will be included later.  Anything included\n  // at this point will be checked again later once we know\n  // what it is.\n  this.entries = this.entries.filter(function (entry) {\n    // at this point, we don't know if it's a dir or not.\n    return this.applyIgnores(entry) || this.applyIgnores(entry, true)\n  }, this)\n}\n\n\nIgnoreReader.prototype.applyIgnores = function (entry, partial, obj) {\n  var included = true\n\n  // this = /a/b/c\n  // entry = d\n  // parent /a/b sees c/d\n  if (this.parent && this.parent.applyIgnores) {\n    var pt = this.basename + \"/\" + entry\n    included = this.parent.applyIgnores(pt, partial)\n  }\n\n  // Negated Rules\n  // Since we're *ignoring* things here, negating means that a file\n  // is re-included, if it would have been excluded by a previous\n  // rule.  So, negated rules are only relevant if the file\n  // has been excluded.\n  //\n  // Similarly, if a file has been excluded, then there's no point\n  // trying it against rules that have already been applied\n  //\n  // We're using the \"flipnegate\" flag here, which tells minimatch\n  // to set the \"negate\" for our information, but still report\n  // whether the core pattern was a hit or a miss.\n\n  if (!this.ignoreRules) {\n    return included\n  }\n\n  this.ignoreRules.forEach(function (rule) {\n    // negation means inclusion\n    if (rule.negate && included ||\n        !rule.negate && !included) {\n      // unnecessary\n      return\n    }\n\n    // first, match against /foo/bar\n    var match = rule.match(\"/\" + entry)\n\n    if (!match) {\n      // try with the leading / trimmed off the test\n      // eg: foo/bar instead of /foo/bar\n      match = rule.match(entry)\n    }\n\n    // if the entry is a directory, then it will match\n    // with a trailing slash. eg: /foo/bar/ or foo/bar/\n    if (!match && partial) {\n      match = rule.match(\"/\" + entry + \"/\") ||\n              rule.match(entry + \"/\")\n    }\n\n    // When including a file with a negated rule, it's\n    // relevant if a directory partially matches, since\n    // it may then match a file within it.\n    // Eg, if you ignore /a, but !/a/b/c\n    if (!match && rule.negate && partial) {\n      match = rule.match(\"/\" + entry, true) ||\n              rule.match(entry, true)\n    }\n\n    if (match) {\n      included = rule.negate\n    }\n  }, this)\n\n  return included\n}\n\n\nIgnoreReader.prototype.sort = function (a, b) {\n  var aig = this.ignoreFiles.indexOf(a) !== -1\n  , big = this.ignoreFiles.indexOf(b) !== -1\n\n  if (aig && !big) return -1\n  if (big && !aig) return 1\n  return this._sort(a, b)\n}\n\nIgnoreReader.prototype._sort = function (a, b) {\n  return 0\n}\n\nfunction alphasort (a, b) {\n  return a === b ? 0\n       : a.toLowerCase() > b.toLowerCase() ? 1\n       : a.toLowerCase() < b.toLowerCase() ? -1\n       : a > b ? 1\n       : -1\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream-npm/node_modules/fstream-ignore/node_modules/minimatch/minimatch.js":"module.exports = minimatch\nminimatch.Minimatch = Minimatch\n\nvar path = { sep: '/' }\ntry {\n  path = require('path')\n} catch (er) {}\n\nvar GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {}\nvar expand = require('brace-expansion')\n\nvar plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n}\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nvar qmark = '[^/]'\n\n// * => any number of characters\nvar star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nvar twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nvar twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'\n\n// characters that need to be escaped in RegExp.\nvar reSpecials = charSet('().*{}+?[]^$\\\\!')\n\n// \"abc\" -> { a:true, b:true, c:true }\nfunction charSet (s) {\n  return s.split('').reduce(function (set, c) {\n    set[c] = true\n    return set\n  }, {})\n}\n\n// normalizes slashes.\nvar slashSplit = /\\/+/\n\nminimatch.filter = filter\nfunction filter (pattern, options) {\n  options = options || {}\n  return function (p, i, list) {\n    return minimatch(p, pattern, options)\n  }\n}\n\nfunction ext (a, b) {\n  a = a || {}\n  b = b || {}\n  var t = {}\n  Object.keys(b).forEach(function (k) {\n    t[k] = b[k]\n  })\n  Object.keys(a).forEach(function (k) {\n    t[k] = a[k]\n  })\n  return t\n}\n\nminimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return minimatch\n\n  var orig = minimatch\n\n  var m = function minimatch (p, pattern, options) {\n    return orig.minimatch(p, pattern, ext(def, options))\n  }\n\n  m.Minimatch = function Minimatch (pattern, options) {\n    return new orig.Minimatch(pattern, ext(def, options))\n  }\n\n  return m\n}\n\nMinimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return Minimatch\n  return minimatch.defaults(def).Minimatch\n}\n\nfunction minimatch (p, pattern, options) {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  // \"\" only matches \"\"\n  if (pattern.trim() === '') return p === ''\n\n  return new Minimatch(pattern, options).match(p)\n}\n\nfunction Minimatch (pattern, options) {\n  if (!(this instanceof Minimatch)) {\n    return new Minimatch(pattern, options)\n  }\n\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n  pattern = pattern.trim()\n\n  // windows support: need to use /, not \\\n  if (path.sep !== '/') {\n    pattern = pattern.split(path.sep).join('/')\n  }\n\n  this.options = options\n  this.set = []\n  this.pattern = pattern\n  this.regexp = null\n  this.negate = false\n  this.comment = false\n  this.empty = false\n\n  // make the set of regexps etc.\n  this.make()\n}\n\nMinimatch.prototype.debug = function () {}\n\nMinimatch.prototype.make = make\nfunction make () {\n  // don't do it more than once.\n  if (this._made) return\n\n  var pattern = this.pattern\n  var options = this.options\n\n  // empty patterns and comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    this.comment = true\n    return\n  }\n  if (!pattern) {\n    this.empty = true\n    return\n  }\n\n  // step 1: figure out negation, etc.\n  this.parseNegate()\n\n  // step 2: expand braces\n  var set = this.globSet = this.braceExpand()\n\n  if (options.debug) this.debug = console.error\n\n  this.debug(this.pattern, set)\n\n  // step 3: now we have a set, so turn each one into a series of path-portion\n  // matching patterns.\n  // These will be regexps, except in the case of \"**\", which is\n  // set to the GLOBSTAR object for globstar behavior,\n  // and will not contain any / characters\n  set = this.globParts = set.map(function (s) {\n    return s.split(slashSplit)\n  })\n\n  this.debug(this.pattern, set)\n\n  // glob --> regexps\n  set = set.map(function (s, si, set) {\n    return s.map(this.parse, this)\n  }, this)\n\n  this.debug(this.pattern, set)\n\n  // filter out everything that didn't compile properly.\n  set = set.filter(function (s) {\n    return s.indexOf(false) === -1\n  })\n\n  this.debug(this.pattern, set)\n\n  this.set = set\n}\n\nMinimatch.prototype.parseNegate = parseNegate\nfunction parseNegate () {\n  var pattern = this.pattern\n  var negate = false\n  var options = this.options\n  var negateOffset = 0\n\n  if (options.nonegate) return\n\n  for (var i = 0, l = pattern.length\n    ; i < l && pattern.charAt(i) === '!'\n    ; i++) {\n    negate = !negate\n    negateOffset++\n  }\n\n  if (negateOffset) this.pattern = pattern.substr(negateOffset)\n  this.negate = negate\n}\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch.braceExpand = function (pattern, options) {\n  return braceExpand(pattern, options)\n}\n\nMinimatch.prototype.braceExpand = braceExpand\n\nfunction braceExpand (pattern, options) {\n  if (!options) {\n    if (this instanceof Minimatch) {\n      options = this.options\n    } else {\n      options = {}\n    }\n  }\n\n  pattern = typeof pattern === 'undefined'\n    ? this.pattern : pattern\n\n  if (typeof pattern === 'undefined') {\n    throw new TypeError('undefined pattern')\n  }\n\n  if (options.nobrace ||\n    !pattern.match(/\\{.*\\}/)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nMinimatch.prototype.parse = parse\nvar SUBPARSE = {}\nfunction parse (pattern, isSub) {\n  if (pattern.length > 1024 * 64) {\n    throw new TypeError('pattern is too long')\n  }\n\n  var options = this.options\n\n  // shortcuts\n  if (!options.noglobstar && pattern === '**') return GLOBSTAR\n  if (pattern === '') return ''\n\n  var re = ''\n  var hasMagic = !!options.nocase\n  var escaping = false\n  // ? => one single character\n  var patternListStack = []\n  var negativeLists = []\n  var stateChar\n  var inClass = false\n  var reClassStart = -1\n  var classStart = -1\n  // . and .. never match anything that doesn't start with .,\n  // even when options.dot is set.\n  var patternStart = pattern.charAt(0) === '.' ? '' // anything\n  // not (start or / followed by . or .. followed by / or end)\n  : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))'\n  : '(?!\\\\.)'\n  var self = this\n\n  function clearStateChar () {\n    if (stateChar) {\n      // we had some state-tracking character\n      // that wasn't consumed by this pass.\n      switch (stateChar) {\n        case '*':\n          re += star\n          hasMagic = true\n        break\n        case '?':\n          re += qmark\n          hasMagic = true\n        break\n        default:\n          re += '\\\\' + stateChar\n        break\n      }\n      self.debug('clearStateChar %j %j', stateChar, re)\n      stateChar = false\n    }\n  }\n\n  for (var i = 0, len = pattern.length, c\n    ; (i < len) && (c = pattern.charAt(i))\n    ; i++) {\n    this.debug('%s\\t%s %s %j', pattern, i, re, c)\n\n    // skip over any that are escaped.\n    if (escaping && reSpecials[c]) {\n      re += '\\\\' + c\n      escaping = false\n      continue\n    }\n\n    switch (c) {\n      case '/':\n        // completely not allowed, even escaped.\n        // Should already be path-split by now.\n        return false\n\n      case '\\\\':\n        clearStateChar()\n        escaping = true\n      continue\n\n      // the various stateChar values\n      // for the \"extglob\" stuff.\n      case '?':\n      case '*':\n      case '+':\n      case '@':\n      case '!':\n        this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c)\n\n        // all of those are literals inside a class, except that\n        // the glob [!a] means [^a] in regexp\n        if (inClass) {\n          this.debug('  in class')\n          if (c === '!' && i === classStart + 1) c = '^'\n          re += c\n          continue\n        }\n\n        // if we already have a stateChar, then it means\n        // that there was something like ** or +? in there.\n        // Handle the stateChar, then proceed with this one.\n        self.debug('call clearStateChar %j', stateChar)\n        clearStateChar()\n        stateChar = c\n        // if extglob is disabled, then +(asdf|foo) isn't a thing.\n        // just clear the statechar *now*, rather than even diving into\n        // the patternList stuff.\n        if (options.noext) clearStateChar()\n      continue\n\n      case '(':\n        if (inClass) {\n          re += '('\n          continue\n        }\n\n        if (!stateChar) {\n          re += '\\\\('\n          continue\n        }\n\n        patternListStack.push({\n          type: stateChar,\n          start: i - 1,\n          reStart: re.length,\n          open: plTypes[stateChar].open,\n          close: plTypes[stateChar].close\n        })\n        // negation is (?:(?!js)[^/]*)\n        re += stateChar === '!' ? '(?:(?!(?:' : '(?:'\n        this.debug('plType %j %j', stateChar, re)\n        stateChar = false\n      continue\n\n      case ')':\n        if (inClass || !patternListStack.length) {\n          re += '\\\\)'\n          continue\n        }\n\n        clearStateChar()\n        hasMagic = true\n        var pl = patternListStack.pop()\n        // negation is (?:(?!js)[^/]*)\n        // The others are (?:<pattern>)<type>\n        re += pl.close\n        if (pl.type === '!') {\n          negativeLists.push(pl)\n        }\n        pl.reEnd = re.length\n      continue\n\n      case '|':\n        if (inClass || !patternListStack.length || escaping) {\n          re += '\\\\|'\n          escaping = false\n          continue\n        }\n\n        clearStateChar()\n        re += '|'\n      continue\n\n      // these are mostly the same in regexp and glob\n      case '[':\n        // swallow any state-tracking char before the [\n        clearStateChar()\n\n        if (inClass) {\n          re += '\\\\' + c\n          continue\n        }\n\n        inClass = true\n        classStart = i\n        reClassStart = re.length\n        re += c\n      continue\n\n      case ']':\n        //  a right bracket shall lose its special\n        //  meaning and represent itself in\n        //  a bracket expression if it occurs\n        //  first in the list.  -- POSIX.2 2.8.3.2\n        if (i === classStart + 1 || !inClass) {\n          re += '\\\\' + c\n          escaping = false\n          continue\n        }\n\n        // handle the case where we left a class open.\n        // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n        if (inClass) {\n          // split where the last [ was, make sure we don't have\n          // an invalid re. if so, re-walk the contents of the\n          // would-be class to re-translate any characters that\n          // were passed through as-is\n          // TODO: It would probably be faster to determine this\n          // without a try/catch and a new RegExp, but it's tricky\n          // to do safely.  For now, this is safe and works.\n          var cs = pattern.substring(classStart + 1, i)\n          try {\n            RegExp('[' + cs + ']')\n          } catch (er) {\n            // not a valid class!\n            var sp = this.parse(cs, SUBPARSE)\n            re = re.substr(0, reClassStart) + '\\\\[' + sp[0] + '\\\\]'\n            hasMagic = hasMagic || sp[1]\n            inClass = false\n            continue\n          }\n        }\n\n        // finish up the class.\n        hasMagic = true\n        inClass = false\n        re += c\n      continue\n\n      default:\n        // swallow any state char that wasn't consumed\n        clearStateChar()\n\n        if (escaping) {\n          // no need\n          escaping = false\n        } else if (reSpecials[c]\n          && !(c === '^' && inClass)) {\n          re += '\\\\'\n        }\n\n        re += c\n\n    } // switch\n  } // for\n\n  // handle the case where we left a class open.\n  // \"[abc\" is valid, equivalent to \"\\[abc\"\n  if (inClass) {\n    // split where the last [ was, and escape it\n    // this is a huge pita.  We now have to re-walk\n    // the contents of the would-be class to re-translate\n    // any characters that were passed through as-is\n    cs = pattern.substr(classStart + 1)\n    sp = this.parse(cs, SUBPARSE)\n    re = re.substr(0, reClassStart) + '\\\\[' + sp[0]\n    hasMagic = hasMagic || sp[1]\n  }\n\n  // handle the case where we had a +( thing at the *end*\n  // of the pattern.\n  // each pattern list stack adds 3 chars, and we need to go through\n  // and escape any | chars that were passed through as-is for the regexp.\n  // Go through and escape them, taking care not to double-escape any\n  // | chars that were already escaped.\n  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n    var tail = re.slice(pl.reStart + pl.open.length)\n    this.debug('setting tail', re, pl)\n    // maybe some even number of \\, then maybe 1 \\, followed by a |\n    tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, function (_, $1, $2) {\n      if (!$2) {\n        // the | isn't already escaped, so escape it.\n        $2 = '\\\\'\n      }\n\n      // need to escape all those slashes *again*, without escaping the\n      // one that we need for escaping the | character.  As it works out,\n      // escaping an even number of slashes can be done by simply repeating\n      // it exactly after itself.  That's why this trick works.\n      //\n      // I am sorry that you have to see this.\n      return $1 + $1 + $2 + '|'\n    })\n\n    this.debug('tail=%j\\n   %s', tail, tail, pl, re)\n    var t = pl.type === '*' ? star\n      : pl.type === '?' ? qmark\n      : '\\\\' + pl.type\n\n    hasMagic = true\n    re = re.slice(0, pl.reStart) + t + '\\\\(' + tail\n  }\n\n  // handle trailing things that only matter at the very end.\n  clearStateChar()\n  if (escaping) {\n    // trailing \\\\\n    re += '\\\\\\\\'\n  }\n\n  // only need to apply the nodot start if the re starts with\n  // something that could conceivably capture a dot\n  var addPatternStart = false\n  switch (re.charAt(0)) {\n    case '.':\n    case '[':\n    case '(': addPatternStart = true\n  }\n\n  // Hack to work around lack of negative lookbehind in JS\n  // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n  // like 'a.xyz.yz' doesn't match.  So, the first negative\n  // lookahead, has to look ALL the way ahead, to the end of\n  // the pattern.\n  for (var n = negativeLists.length - 1; n > -1; n--) {\n    var nl = negativeLists[n]\n\n    var nlBefore = re.slice(0, nl.reStart)\n    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8)\n    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd)\n    var nlAfter = re.slice(nl.reEnd)\n\n    nlLast += nlAfter\n\n    // Handle nested stuff like *(*.js|!(*.json)), where open parens\n    // mean that we should *not* include the ) in the bit that is considered\n    // \"after\" the negated section.\n    var openParensBefore = nlBefore.split('(').length - 1\n    var cleanAfter = nlAfter\n    for (i = 0; i < openParensBefore; i++) {\n      cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '')\n    }\n    nlAfter = cleanAfter\n\n    var dollar = ''\n    if (nlAfter === '' && isSub !== SUBPARSE) {\n      dollar = '$'\n    }\n    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast\n    re = newRe\n  }\n\n  // if the re is not \"\" at this point, then we need to make sure\n  // it doesn't match against an empty path part.\n  // Otherwise a/* will match a/, which it should not.\n  if (re !== '' && hasMagic) {\n    re = '(?=.)' + re\n  }\n\n  if (addPatternStart) {\n    re = patternStart + re\n  }\n\n  // parsing just a piece of a larger pattern.\n  if (isSub === SUBPARSE) {\n    return [re, hasMagic]\n  }\n\n  // skip the regexp for non-magical patterns\n  // unescape anything in it, though, so that it'll be\n  // an exact match against a file etc.\n  if (!hasMagic) {\n    return globUnescape(pattern)\n  }\n\n  var flags = options.nocase ? 'i' : ''\n  try {\n    var regExp = new RegExp('^' + re + '$', flags)\n  } catch (er) {\n    // If it was an invalid regular expression, then it can't match\n    // anything.  This trick looks for a character after the end of\n    // the string, which is of course impossible, except in multi-line\n    // mode, but it's not a /m regex.\n    return new RegExp('$.')\n  }\n\n  regExp._glob = pattern\n  regExp._src = re\n\n  return regExp\n}\n\nminimatch.makeRe = function (pattern, options) {\n  return new Minimatch(pattern, options || {}).makeRe()\n}\n\nMinimatch.prototype.makeRe = makeRe\nfunction makeRe () {\n  if (this.regexp || this.regexp === false) return this.regexp\n\n  // at this point, this.set is a 2d array of partial\n  // pattern strings, or \"**\".\n  //\n  // It's better to use .match().  This function shouldn't\n  // be used, really, but it's pretty convenient sometimes,\n  // when you just want to work with a regex.\n  var set = this.set\n\n  if (!set.length) {\n    this.regexp = false\n    return this.regexp\n  }\n  var options = this.options\n\n  var twoStar = options.noglobstar ? star\n    : options.dot ? twoStarDot\n    : twoStarNoDot\n  var flags = options.nocase ? 'i' : ''\n\n  var re = set.map(function (pattern) {\n    return pattern.map(function (p) {\n      return (p === GLOBSTAR) ? twoStar\n      : (typeof p === 'string') ? regExpEscape(p)\n      : p._src\n    }).join('\\\\\\/')\n  }).join('|')\n\n  // must match entire pattern\n  // ending in a * or ** will make it less strict.\n  re = '^(?:' + re + ')$'\n\n  // can match anything, as long as it's not this.\n  if (this.negate) re = '^(?!' + re + ').*$'\n\n  try {\n    this.regexp = new RegExp(re, flags)\n  } catch (ex) {\n    this.regexp = false\n  }\n  return this.regexp\n}\n\nminimatch.match = function (list, pattern, options) {\n  options = options || {}\n  var mm = new Minimatch(pattern, options)\n  list = list.filter(function (f) {\n    return mm.match(f)\n  })\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\n\nMinimatch.prototype.match = match\nfunction match (f, partial) {\n  this.debug('match', f, this.pattern)\n  // short-circuit in the case of busted things.\n  // comments, etc.\n  if (this.comment) return false\n  if (this.empty) return f === ''\n\n  if (f === '/' && partial) return true\n\n  var options = this.options\n\n  // windows: need to use /, not \\\n  if (path.sep !== '/') {\n    f = f.split(path.sep).join('/')\n  }\n\n  // treat the test path as a set of pathparts.\n  f = f.split(slashSplit)\n  this.debug(this.pattern, 'split', f)\n\n  // just ONE of the pattern sets in this.set needs to match\n  // in order for it to be valid.  If negating, then just one\n  // match means that we have failed.\n  // Either way, return on the first hit.\n\n  var set = this.set\n  this.debug(this.pattern, 'set', set)\n\n  // Find the basename of the path by looking for the last non-empty segment\n  var filename\n  var i\n  for (i = f.length - 1; i >= 0; i--) {\n    filename = f[i]\n    if (filename) break\n  }\n\n  for (i = 0; i < set.length; i++) {\n    var pattern = set[i]\n    var file = f\n    if (options.matchBase && pattern.length === 1) {\n      file = [filename]\n    }\n    var hit = this.matchOne(file, pattern, partial)\n    if (hit) {\n      if (options.flipNegate) return true\n      return !this.negate\n    }\n  }\n\n  // didn't get any hits.  this is success if it's a negative\n  // pattern, failure otherwise.\n  if (options.flipNegate) return false\n  return this.negate\n}\n\n// set partial to true to test if, for example,\n// \"/a/b\" matches the start of \"/*/b/*/d\"\n// Partial means, if you run out of file before you run\n// out of pattern, then that's fine, as long as all\n// the parts match.\nMinimatch.prototype.matchOne = function (file, pattern, partial) {\n  var options = this.options\n\n  this.debug('matchOne',\n    { 'this': this, file: file, pattern: pattern })\n\n  this.debug('matchOne', file.length, pattern.length)\n\n  for (var fi = 0,\n      pi = 0,\n      fl = file.length,\n      pl = pattern.length\n      ; (fi < fl) && (pi < pl)\n      ; fi++, pi++) {\n    this.debug('matchOne loop')\n    var p = pattern[pi]\n    var f = file[fi]\n\n    this.debug(pattern, p, f)\n\n    // should be impossible.\n    // some invalid regexp stuff in the set.\n    if (p === false) return false\n\n    if (p === GLOBSTAR) {\n      this.debug('GLOBSTAR', [pattern, p, f])\n\n      // \"**\"\n      // a/**/b/**/c would match the following:\n      // a/b/x/y/z/c\n      // a/x/y/z/b/c\n      // a/b/x/b/x/c\n      // a/b/c\n      // To do this, take the rest of the pattern after\n      // the **, and see if it would match the file remainder.\n      // If so, return success.\n      // If not, the ** \"swallows\" a segment, and try again.\n      // This is recursively awful.\n      //\n      // a/**/b/**/c matching a/b/x/y/z/c\n      // - a matches a\n      // - doublestar\n      //   - matchOne(b/x/y/z/c, b/**/c)\n      //     - b matches b\n      //     - doublestar\n      //       - matchOne(x/y/z/c, c) -> no\n      //       - matchOne(y/z/c, c) -> no\n      //       - matchOne(z/c, c) -> no\n      //       - matchOne(c, c) yes, hit\n      var fr = fi\n      var pr = pi + 1\n      if (pr === pl) {\n        this.debug('** at the end')\n        // a ** at the end will just swallow the rest.\n        // We have found a match.\n        // however, it will not swallow /.x, unless\n        // options.dot is set.\n        // . and .. are *never* matched by **, for explosively\n        // exponential reasons.\n        for (; fi < fl; fi++) {\n          if (file[fi] === '.' || file[fi] === '..' ||\n            (!options.dot && file[fi].charAt(0) === '.')) return false\n        }\n        return true\n      }\n\n      // ok, let's see if we can swallow whatever we can.\n      while (fr < fl) {\n        var swallowee = file[fr]\n\n        this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n        // XXX remove this slice.  Just pass the start index.\n        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n          this.debug('globstar found match!', fr, fl, swallowee)\n          // found a match.\n          return true\n        } else {\n          // can't swallow \".\" or \"..\" ever.\n          // can only swallow \".foo\" when explicitly asked.\n          if (swallowee === '.' || swallowee === '..' ||\n            (!options.dot && swallowee.charAt(0) === '.')) {\n            this.debug('dot detected!', file, fr, pattern, pr)\n            break\n          }\n\n          // ** swallows a segment, and continue.\n          this.debug('globstar swallow a segment, and continue')\n          fr++\n        }\n      }\n\n      // no match was found.\n      // However, in partial mode, we can't say this is necessarily over.\n      // If there's more *pattern* left, then\n      if (partial) {\n        // ran out of file\n        this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n        if (fr === fl) return true\n      }\n      return false\n    }\n\n    // something other than **\n    // non-magic patterns just have to match exactly\n    // patterns with magic have been turned into regexps.\n    var hit\n    if (typeof p === 'string') {\n      if (options.nocase) {\n        hit = f.toLowerCase() === p.toLowerCase()\n      } else {\n        hit = f === p\n      }\n      this.debug('string match', p, f, hit)\n    } else {\n      hit = f.match(p)\n      this.debug('pattern match', p, f, hit)\n    }\n\n    if (!hit) return false\n  }\n\n  // Note: ending in / means that we'll get a final \"\"\n  // at the end of the pattern.  This can only match a\n  // corresponding \"\" at the end of the file.\n  // If the file ends in /, then it can only match a\n  // a pattern that ends in /, unless the pattern just\n  // doesn't have any more for it. But, a/b/ should *not*\n  // match \"a/b/*\", even though \"\" matches against the\n  // [^/]*? pattern, except in partial mode, where it might\n  // simply not be reached yet.\n  // However, a/b/ should still satisfy a/*\n\n  // now either we fell off the end of the pattern, or we're done.\n  if (fi === fl && pi === pl) {\n    // ran out of pattern and filename at the same time.\n    // an exact hit!\n    return true\n  } else if (fi === fl) {\n    // ran out of file, but still had pattern left.\n    // this is ok if we're doing the match as part of\n    // a glob fs traversal.\n    return partial\n  } else if (pi === pl) {\n    // ran out of pattern, still have file left.\n    // this is only acceptable if we're on the very last\n    // empty segment of a file with a trailing slash.\n    // a/* should match a/b/\n    var emptyFileEnd = (fi === fl - 1) && (file[fi] === '')\n    return emptyFileEnd\n  }\n\n  // should be unreachable.\n  throw new Error('wtf?')\n}\n\n// replace stuff like \\* with *\nfunction globUnescape (s) {\n  return s.replace(/\\\\(.)/g, '$1')\n}\n\nfunction regExpEscape (s) {\n  return s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream-npm/node_modules/fstream-ignore/node_modules/minimatch/node_modules/brace-expansion/index.js":"var concatMap = require('concat-map');\nvar balanced = require('balanced-match');\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction identity(e) {\n  return e;\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m || /\\$$/.test(m.pre)) return [str];\n\n  var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isSequence = isNumericSequence || isAlphaSequence;\n  var isOptions = /^(.*,)+(.+)?$/.test(m.body);\n  if (!isSequence && !isOptions) {\n    // {a},b}\n    if (m.post.match(/,.*\\}/)) {\n      str = m.pre + '{' + m.body + escClose + m.post;\n      return expand(str);\n    }\n    return [str];\n  }\n\n  var n;\n  if (isSequence) {\n    n = m.body.split(/\\.\\./);\n  } else {\n    n = parseCommaParts(m.body);\n    if (n.length === 1) {\n      // x{{a,b}}y ==> x{a}y x{b}y\n      n = expand(n[0], false).map(embrace);\n      if (n.length === 1) {\n        var post = m.post.length\n          ? expand(m.post, false)\n          : [''];\n        return post.map(function(p) {\n          return m.pre + n[0] + p;\n        });\n      }\n    }\n  }\n\n  // at this point, n is the parts, and we know it's not a comma set\n  // with a single entry.\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  var N;\n\n  if (isSequence) {\n    var x = numeric(n[0]);\n    var y = numeric(n[1]);\n    var width = Math.max(n[0].length, n[1].length)\n    var incr = n.length == 3\n      ? Math.abs(numeric(n[2]))\n      : 1;\n    var test = lte;\n    var reverse = y < x;\n    if (reverse) {\n      incr *= -1;\n      test = gte;\n    }\n    var pad = n.some(isPadded);\n\n    N = [];\n\n    for (var i = x; test(i, y); i += incr) {\n      var c;\n      if (isAlphaSequence) {\n        c = String.fromCharCode(i);\n        if (c === '\\\\')\n          c = '';\n      } else {\n        c = String(i);\n        if (pad) {\n          var need = width - c.length;\n          if (need > 0) {\n            var z = new Array(need + 1).join('0');\n            if (i < 0)\n              c = '-' + z + c.slice(1);\n            else\n              c = z + c;\n          }\n        }\n      }\n      N.push(c);\n    }\n  } else {\n    N = concatMap(n, function(el) { return expand(el, false) });\n  }\n\n  for (var j = 0; j < N.length; j++) {\n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre + N[j] + post[k];\n      if (!isTop || isSequence || expansion)\n        expansions.push(expansion);\n    }\n  }\n\n  return expansions;\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream-npm/node_modules/fstream-ignore/node_modules/minimatch/node_modules/brace-expansion/node_modules/concat-map/index.js":"module.exports = function (xs, fn) {\n    var res = [];\n    for (var i = 0; i < xs.length; i++) {\n        var x = fn(xs[i], i);\n        if (isArray(x)) res.push.apply(res, x);\n        else res.push(x);\n    }\n    return res;\n};\n\nvar isArray = Array.isArray || function (xs) {\n    return Object.prototype.toString.call(xs) === '[object Array]';\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/fstream-npm/node_modules/fstream-ignore/node_modules/minimatch/node_modules/brace-expansion/node_modules/balanced-match/index.js":"module.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/lodash.union/index.js":"/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_SAFE_INTEGER = 9007199254740991;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/**\n * A faster alternative to `Function#apply`, this function invokes `func`\n * with the `this` binding of `thisArg` and the arguments of `args`.\n *\n * @private\n * @param {Function} func The function to invoke.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} args The arguments to invoke `func` with.\n * @returns {*} Returns the result of `func`.\n */\nfunction apply(func, thisArg, args) {\n  switch (args.length) {\n    case 0: return func.call(thisArg);\n    case 1: return func.call(thisArg, args[0]);\n    case 2: return func.call(thisArg, args[0], args[1]);\n    case 3: return func.call(thisArg, args[0], args[1], args[2]);\n  }\n  return func.apply(thisArg, args);\n}\n\n/**\n * A specialized version of `_.includes` for arrays without support for\n * specifying an index to search from.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludes(array, value) {\n  var length = array ? array.length : 0;\n  return !!length && baseIndexOf(array, value, 0) > -1;\n}\n\n/**\n * This function is like `arrayIncludes` except that it accepts a comparator.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @param {Function} comparator The comparator invoked per element.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludesWith(array, value, comparator) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  while (++index < length) {\n    if (comparator(value, array[index])) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\n/**\n * The base implementation of `_.findIndex` and `_.findLastIndex` without\n * support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} predicate The function invoked per iteration.\n * @param {number} fromIndex The index to search from.\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseFindIndex(array, predicate, fromIndex, fromRight) {\n  var length = array.length,\n      index = fromIndex + (fromRight ? 1 : -1);\n\n  while ((fromRight ? index-- : ++index < length)) {\n    if (predicate(array[index], index, array)) {\n      return index;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.indexOf` without `fromIndex` bounds checks.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseIndexOf(array, value, fromIndex) {\n  if (value !== value) {\n    return baseFindIndex(array, baseIsNaN, fromIndex);\n  }\n  var index = fromIndex - 1,\n      length = array.length;\n\n  while (++index < length) {\n    if (array[index] === value) {\n      return index;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.isNaN` without support for number objects.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is `NaN`, else `false`.\n */\nfunction baseIsNaN(value) {\n  return value !== value;\n}\n\n/**\n * Checks if a cache value for `key` exists.\n *\n * @private\n * @param {Object} cache The cache to query.\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction cacheHas(cache, key) {\n  return cache.has(key);\n}\n\n/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\n/**\n * Checks if `value` is a host object in IE < 9.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a host object, else `false`.\n */\nfunction isHostObject(value) {\n  // Many host objects are `Object` objects that can coerce to strings\n  // despite having improperly defined `toString` methods.\n  var result = false;\n  if (value != null && typeof value.toString != 'function') {\n    try {\n      result = !!(value + '');\n    } catch (e) {}\n  }\n  return result;\n}\n\n/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype,\n    funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/** Built-in value references. */\nvar Symbol = root.Symbol,\n    propertyIsEnumerable = objectProto.propertyIsEnumerable,\n    splice = arrayProto.splice,\n    spreadableSymbol = Symbol ? Symbol.isConcatSpreadable : undefined;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/* Built-in method references that are verified to be native. */\nvar Map = getNative(root, 'Map'),\n    Set = getNative(root, 'Set'),\n    nativeCreate = getNative(Object, 'create');\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n}\n\n/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  return this.has(key) && delete this.__data__[key];\n}\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);\n}\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n}\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  return true;\n}\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  return getMapData(this, key)['delete'](key);\n}\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  getMapData(this, key).set(key, value);\n  return this;\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\n/**\n *\n * Creates an array cache object to store unique values.\n *\n * @private\n * @constructor\n * @param {Array} [values] The values to cache.\n */\nfunction SetCache(values) {\n  var index = -1,\n      length = values ? values.length : 0;\n\n  this.__data__ = new MapCache;\n  while (++index < length) {\n    this.add(values[index]);\n  }\n}\n\n/**\n * Adds `value` to the array cache.\n *\n * @private\n * @name add\n * @memberOf SetCache\n * @alias push\n * @param {*} value The value to cache.\n * @returns {Object} Returns the cache instance.\n */\nfunction setCacheAdd(value) {\n  this.__data__.set(value, HASH_UNDEFINED);\n  return this;\n}\n\n/**\n * Checks if `value` is in the array cache.\n *\n * @private\n * @name has\n * @memberOf SetCache\n * @param {*} value The value to search for.\n * @returns {number} Returns `true` if `value` is found, else `false`.\n */\nfunction setCacheHas(value) {\n  return this.__data__.has(value);\n}\n\n// Add methods to `SetCache`.\nSetCache.prototype.add = SetCache.prototype.push = setCacheAdd;\nSetCache.prototype.has = setCacheHas;\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.flatten` with support for restricting flattening.\n *\n * @private\n * @param {Array} array The array to flatten.\n * @param {number} depth The maximum recursion depth.\n * @param {boolean} [predicate=isFlattenable] The function invoked per iteration.\n * @param {boolean} [isStrict] Restrict to values that pass `predicate` checks.\n * @param {Array} [result=[]] The initial result value.\n * @returns {Array} Returns the new flattened array.\n */\nfunction baseFlatten(array, depth, predicate, isStrict, result) {\n  var index = -1,\n      length = array.length;\n\n  predicate || (predicate = isFlattenable);\n  result || (result = []);\n\n  while (++index < length) {\n    var value = array[index];\n    if (depth > 0 && predicate(value)) {\n      if (depth > 1) {\n        // Recursively flatten arrays (susceptible to call stack limits).\n        baseFlatten(value, depth - 1, predicate, isStrict, result);\n      } else {\n        arrayPush(result, value);\n      }\n    } else if (!isStrict) {\n      result[result.length] = value;\n    }\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = (isFunction(value) || isHostObject(value)) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\n/**\n * The base implementation of `_.rest` which doesn't validate or coerce arguments.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @returns {Function} Returns the new function.\n */\nfunction baseRest(func, start) {\n  start = nativeMax(start === undefined ? (func.length - 1) : start, 0);\n  return function() {\n    var args = arguments,\n        index = -1,\n        length = nativeMax(args.length - start, 0),\n        array = Array(length);\n\n    while (++index < length) {\n      array[index] = args[start + index];\n    }\n    index = -1;\n    var otherArgs = Array(start + 1);\n    while (++index < start) {\n      otherArgs[index] = args[index];\n    }\n    otherArgs[start] = array;\n    return apply(func, this, otherArgs);\n  };\n}\n\n/**\n * The base implementation of `_.uniqBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n */\nfunction baseUniq(array, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      length = array.length,\n      isCommon = true,\n      result = [],\n      seen = result;\n\n  if (comparator) {\n    isCommon = false;\n    includes = arrayIncludesWith;\n  }\n  else if (length >= LARGE_ARRAY_SIZE) {\n    var set = iteratee ? null : createSet(array);\n    if (set) {\n      return setToArray(set);\n    }\n    isCommon = false;\n    includes = cacheHas;\n    seen = new SetCache;\n  }\n  else {\n    seen = iteratee ? [] : result;\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee ? iteratee(value) : value;\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var seenIndex = seen.length;\n      while (seenIndex--) {\n        if (seen[seenIndex] === computed) {\n          continue outer;\n        }\n      }\n      if (iteratee) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n    else if (!includes(seen, computed, comparator)) {\n      if (seen !== result) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n  }\n  return result;\n}\n\n/**\n * Creates a set object of `values`.\n *\n * @private\n * @param {Array} values The values to add to the set.\n * @returns {Object} Returns the new set.\n */\nvar createSet = !(Set && (1 / setToArray(new Set([,-0]))[1]) == INFINITY) ? noop : function(values) {\n  return new Set(values);\n};\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\n/**\n * Checks if `value` is a flattenable `arguments` object or array.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is flattenable, else `false`.\n */\nfunction isFlattenable(value) {\n  return isArray(value) || isArguments(value) ||\n    !!(spreadableSymbol && value && value[spreadableSymbol]);\n}\n\n/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to process.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\n/**\n * Creates an array of unique values, in order, from all given arrays using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {...Array} [arrays] The arrays to inspect.\n * @returns {Array} Returns the new array of combined values.\n * @example\n *\n * _.union([2], [1, 2]);\n * // => [2, 1]\n */\nvar union = baseRest(function(arrays) {\n  return baseUniq(baseFlatten(arrays, 1, isArrayLikeObject, true));\n});\n\n/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nfunction isArguments(value) {\n  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.\n  return isArrayLikeObject(value) && hasOwnProperty.call(value, 'callee') &&\n    (!propertyIsEnumerable.call(value, 'callee') || objectToString.call(value) == argsTag);\n}\n\n/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 8-9 which returns 'object' for typed array and other constructors.\n  var tag = isObject(value) ? objectToString.call(value) : '';\n  return tag == funcTag || tag == genTag;\n}\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\n/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return !!value && (type == 'object' || type == 'function');\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\n/**\n * This method returns `undefined`.\n *\n * @static\n * @memberOf _\n * @since 2.3.0\n * @category Util\n * @example\n *\n * _.times(2, _.noop);\n * // => [undefined, undefined]\n */\nfunction noop() {\n  // No operation performed.\n}\n\nmodule.exports = union;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/module-name.js":"'use strict'\nvar path = require('path')\nvar validate = require('aproba')\n\nmodule.exports = moduleName\nmodule.exports.test = {}\n\nmodule.exports.test.pathToPackageName = pathToPackageName\nfunction pathToPackageName (dir) {\n  if (dir == null) return ''\n  if (dir === '') return ''\n  var name = path.relative(path.resolve(dir, '..'), dir)\n  var scoped = path.relative(path.resolve(dir, '../..'), dir)\n  if (scoped[0] === '@') return scoped.replace(/\\\\/g, '/')\n  return name\n}\n\nmodule.exports.test.isNotEmpty = isNotEmpty\nfunction isNotEmpty (str) {\n  return str != null && str !== ''\n}\n\nvar unknown = 0\nfunction moduleName (tree) {\n  validate('O', arguments)\n  var pkg = tree.package || tree\n  if (isNotEmpty(pkg.name)) return pkg.name\n  var pkgName = pathToPackageName(tree.path)\n  if (pkgName !== '') return pkgName\n  if (tree._invalidName != null) return tree._invalidName\n  tree._invalidName = '!invalid#' + (++unknown)\n  return tree._invalidName\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/package-id.js":"'use strict'\nvar moduleName = require('./module-name.js')\n\nmodule.exports = function (tree) {\n  var pkg = tree.package || tree\n  // FIXME: Excluding the '@' here is cleaning up after the mess that\n  // read-package-json makes. =(\n  if (pkg._id && pkg._id !== '@') return pkg._id\n  var name = moduleName(tree)\n  if (pkg.version) {\n    return name + '@' + pkg.version\n  } else {\n    return name\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/pulse-till-done.js":"'use strict'\nvar validate = require('aproba')\nvar log = require('npmlog')\n\nvar pulsers = 0\nvar pulse\n\nmodule.exports = function (prefix, cb) {\n  validate('SF', [prefix, cb])\n  if (!prefix) prefix = 'network'\n  if (!pulsers++) {\n    pulse = setInterval(function () {\n      log.gauge.pulse(prefix)\n    }, 250)\n  }\n  return function () {\n    if (!--pulsers) {\n      clearInterval(pulse)\n    }\n    cb.apply(null, arguments)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/completion/file-completion.js":"module.exports = fileCompletion\n\nvar mkdir = require('mkdirp')\nvar glob = require('glob')\n\nfunction fileCompletion (root, req, depth, cb) {\n  if (typeof cb !== 'function') {\n    cb = depth\n    depth = Infinity\n  }\n  mkdir(root, function (er) {\n    if (er) return cb(er)\n\n    // can be either exactly the req, or a descendent\n    var pattern = root + '/{' + req + ',' + req + '/**/*}'\n    var opts = { mark: true, dot: true, maxDepth: depth }\n    glob(pattern, opts, function (er, files) {\n      if (er) return cb(er)\n      return cb(null, (files || []).map(function (f) {\n        return f.substr(root.length + 1).replace(/^\\/|\\/$/g, '')\n      }))\n    })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/depr-check.js":"var log = require('npmlog')\n\nvar deprecated = {}\nvar deprWarned = {}\nmodule.exports = function deprCheck (data) {\n  if (deprecated[data._id]) data.deprecated = deprecated[data._id]\n  if (data.deprecated) deprecated[data._id] = data.deprecated\n  else return\n  if (!deprWarned[data._id]) {\n    deprWarned[data._id] = true\n    log.warn('deprecated', '%s: %s', data._id, data.deprecated)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/add-named.js":"var path = require('path')\nvar assert = require('assert')\nvar fs = require('graceful-fs')\nvar http = require('http')\nvar log = require('npmlog')\nvar semver = require('semver')\nvar readJson = require('read-package-json')\nvar url = require('url')\nvar npm = require('../npm.js')\nvar deprCheck = require('../utils/depr-check.js')\nvar inflight = require('inflight')\nvar addRemoteTarball = require('./add-remote-tarball.js')\nvar cachedPackageRoot = require('./cached-package-root.js')\nvar mapToRegistry = require('../utils/map-to-registry.js')\nvar pulseTillDone = require('../utils/pulse-till-done.js')\nvar packageId = require('../utils/package-id.js')\nvar pickManifestFromRegistryMetadata = require('../utils/pick-manifest-from-registry-metadata.js')\n\nmodule.exports = addNamed\n\nfunction getOnceFromRegistry (name, from, next, done) {\n  function fixName (err, data, json, resp) {\n    // this is only necessary until npm/npm-registry-client#80 is fixed\n    if (err && err.pkgid && err.pkgid !== name) {\n      err.message = err.message.replace(\n        new RegExp(': ' + err.pkgid.replace(/(\\W)/g, '\\\\$1') + '$'),\n        ': ' + name\n      )\n      err.pkgid = name\n    }\n    next(err, data, json, resp)\n  }\n\n  mapToRegistry(name, npm.config, function (er, uri, auth) {\n    if (er) return done(er)\n\n    var key = 'registry:' + uri\n    next = inflight(key, next)\n    if (!next) return log.verbose(from, key, 'already in flight; waiting')\n    else log.verbose(from, key, 'not in flight; fetching')\n\n    npm.registry.get(uri, { auth: auth }, pulseTillDone('fetchRegistry', fixName))\n  })\n}\n\nfunction addNamed (name, version, data, cb_) {\n  assert(typeof name === 'string', 'must have module name')\n  assert(typeof cb_ === 'function', 'must have callback')\n\n  var key = name + '@' + version\n  log.silly('addNamed', key)\n\n  function cb (er, data) {\n    if (data && !data._fromHosted) data._from = key\n    cb_(er, data)\n  }\n\n  if (semver.valid(version, true)) {\n    log.verbose('addNamed', JSON.stringify(version), 'is a plain semver version for', name)\n    addNameVersion(name, version, data, cb)\n  } else if (semver.validRange(version, true)) {\n    log.verbose('addNamed', JSON.stringify(version), 'is a valid semver range for', name)\n    addNameRange(name, version, data, cb)\n  } else {\n    log.verbose('addNamed', JSON.stringify(version), 'is being treated as a dist-tag for', name)\n    addNameTag(name, version, data, cb)\n  }\n}\n\nfunction addNameTag (name, tag, data, cb) {\n  log.info('addNameTag', [name, tag])\n  var explicit = true\n  if (!tag) {\n    explicit = false\n    tag = npm.config.get('tag')\n  }\n\n  getOnceFromRegistry(name, 'addNameTag', next, cb)\n\n  function next (er, data, json, resp) {\n    if (!er) er = errorResponse(name, resp)\n    if (er) return cb(er)\n\n    log.silly('addNameTag', 'next cb for', name, 'with tag', tag)\n\n    engineFilter(data)\n    if (data['dist-tags'] && data['dist-tags'][tag] &&\n        data.versions[data['dist-tags'][tag]]) {\n      var ver = data['dist-tags'][tag]\n      return addNamed(name, ver, data.versions[ver], cb)\n    }\n    if (!explicit && Object.keys(data.versions).length) {\n      return addNamed(name, '*', data, cb)\n    }\n\n    er = installTargetsError(tag, data)\n    return cb(er)\n  }\n}\n\nfunction engineFilter (data) {\n  var npmv = npm.version\n  var nodev = npm.config.get('node-version')\n  var strict = npm.config.get('engine-strict')\n\n  if (!nodev || npm.config.get('force')) return data\n\n  Object.keys(data.versions || {}).forEach(function (v) {\n    var eng = data.versions[v].engines\n    if (!eng) return\n    if (!strict) return\n    if (eng.node && !semver.satisfies(nodev, eng.node, true) ||\n        eng.npm && !semver.satisfies(npmv, eng.npm, true)) {\n      delete data.versions[v]\n    }\n  })\n}\n\nfunction addNameVersion (name, v, data, cb) {\n  var ver = semver.valid(v, true)\n  if (!ver) return cb(new Error('Invalid version: ' + v))\n\n  var response\n\n  if (data) {\n    response = null\n    return next()\n  }\n\n  getOnceFromRegistry(name, 'addNameVersion', setData, cb)\n\n  function setData (er, d, json, resp) {\n    if (!er) {\n      er = errorResponse(name, resp)\n    }\n    if (er) return cb(er)\n    data = d && d.versions[ver]\n    if (!data) {\n      er = new Error('version not found: ' + name + '@' + ver)\n      er.package = name\n      er.statusCode = 404\n      return cb(er)\n    }\n    response = resp\n    next()\n  }\n\n  function next () {\n    deprCheck(data)\n    var dist = data.dist\n\n    if (!dist) return cb(new Error('No dist in ' + packageId(data) + ' package'))\n\n    if (!dist.tarball) {\n      return cb(new Error(\n      'No dist.tarball in ' + packageId(data) + ' package'\n      ))\n    }\n\n    if ((response && response.statusCode !== 304) || npm.config.get('force')) {\n      return fetchit()\n    }\n\n    // we got cached data, so let's see if we have a tarball.\n    var pkgroot = cachedPackageRoot({ name: name, version: ver })\n    var pkgtgz = path.join(pkgroot, 'package.tgz')\n    var pkgjson = path.join(pkgroot, 'package', 'package.json')\n    fs.stat(pkgtgz, function (er) {\n      if (!er) {\n        readJson(pkgjson, function (er, data) {\n          if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n\n          if (data) {\n            if (!data.name) return cb(new Error('No name provided'))\n            if (!data.version) return cb(new Error('No version provided'))\n\n            // check the SHA of the package we have, to ensure it wasn't installed\n            // from somewhere other than the registry (eg, a fork)\n            if (data._shasum && dist.shasum && data._shasum !== dist.shasum) {\n              return fetchit()\n            }\n          }\n\n          if (er) return fetchit()\n            else return cb(null, data)\n        })\n      } else return fetchit()\n    })\n\n    function fetchit () {\n      mapToRegistry(name, npm.config, function (er, _, auth, ruri) {\n        if (er) return cb(er)\n\n        // Use the same protocol as the registry.  https registry --> https\n        // tarballs, but only if they're the same hostname, or else detached\n        // tarballs may not work.\n        var tb = url.parse(dist.tarball)\n        var rp = url.parse(ruri)\n        if (tb.hostname === rp.hostname && tb.protocol !== rp.protocol) {\n          tb.protocol = rp.protocol\n          // If a different port is associated with the other protocol\n          // we need to update that as well\n          if (rp.port !== tb.port) {\n            tb.port = rp.port\n            delete tb.host\n          }\n          delete tb.href\n        }\n        tb = url.format(tb)\n\n        // Only add non-shasum'ed packages if --forced. Only ancient things\n        // would lack this for good reasons nowadays.\n        if (!dist.shasum && !npm.config.get('force')) {\n          return cb(new Error('package lacks shasum: ' + packageId(data)))\n        }\n\n        addRemoteTarball(tb, data, dist.shasum, auth, cb)\n      })\n    }\n  }\n}\n\nfunction addNameRange (name, range, data, cb) {\n  range = semver.validRange(range, true)\n  if (range === null) {\n    return cb(new Error(\n      'Invalid version range: ' + range\n    ))\n  }\n\n  log.silly('addNameRange', { name: name, range: range, hasData: !!data })\n\n  if (data) return next()\n\n  getOnceFromRegistry(name, 'addNameRange', setData, cb)\n\n  function setData (er, d, json, resp) {\n    if (!er) {\n      er = errorResponse(name, resp)\n    }\n    if (er) return cb(er)\n    data = d\n    next()\n  }\n\n  function next () {\n    log.silly(\n      'addNameRange',\n      'number 2', { name: name, range: range, hasData: !!data }\n    )\n    engineFilter(data)\n\n    log.silly('addNameRange', 'versions'\n             , [data.name, Object.keys(data.versions || {})])\n\n    var versions = Object.keys(data.versions).filter(function (v) { return semver.valid(v) })\n    var picked = pickManifestFromRegistryMetadata(range, npm.config.get('tag'), versions, data)\n    if (picked) return addNamed(name, picked.resolvedTo, picked.manifest, cb)\n    return cb(installTargetsError(range, data))\n  }\n}\n\nfunction installTargetsError (requested, data) {\n  var targets = Object.keys(data['dist-tags']).filter(function (f) {\n    return (data.versions || {}).hasOwnProperty(f)\n  }).concat(Object.keys(data.versions || {}))\n\n  requested = data.name + (requested ? \"@'\" + requested + \"'\" : '')\n\n  targets = targets.length\n          ? 'Valid install targets:\\n' + targets.join(', ') + '\\n'\n          : 'No valid targets found.\\n' +\n            'Perhaps not compatible with your version of node?'\n\n  var er = new Error('No compatible version found: ' + requested + '\\n' + targets)\n  er.code = 'ETARGET'\n  return er\n}\n\nfunction errorResponse (name, response) {\n  var er\n  if (response.statusCode >= 400) {\n    er = new Error(http.STATUS_CODES[response.statusCode])\n    er.statusCode = response.statusCode\n    er.code = 'E' + er.statusCode\n    er.pkgid = name\n  }\n  return er\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/add-remote-tarball.js":"var mkdir = require('mkdirp')\nvar assert = require('assert')\nvar log = require('npmlog')\nvar path = require('path')\nvar sha = require('sha')\nvar retry = require('retry')\nvar writeStreamAtomic = require('fs-write-stream-atomic')\nvar PassThrough = require('readable-stream').PassThrough\nvar npm = require('../npm.js')\nvar inflight = require('inflight')\nvar addLocalTarball = require('./add-local-tarball.js')\nvar cacheFile = require('npm-cache-filename')\nvar rimraf = require('rimraf')\nvar pulseTillDone = require('../utils/pulse-till-done.js')\n\nmodule.exports = addRemoteTarball\n\nfunction addRemoteTarball (u, pkgData, shasum, auth, cb_) {\n  assert(typeof u === 'string', 'must have module URL')\n  assert(typeof cb_ === 'function', 'must have callback')\n\n  function cb (er, data) {\n    if (data) {\n      data._from = u\n      data._resolved = u\n      data._shasum = data._shasum || shasum\n    }\n    cb_(er, data)\n  }\n\n  cb_ = inflight(u, cb_)\n  if (!cb_) return log.verbose('addRemoteTarball', u, 'already in flight; waiting')\n  log.verbose('addRemoteTarball', u, 'not in flight; adding')\n\n  // XXX Fetch direct to cache location, store tarballs under\n  // ${cache}/registry.npmjs.org/pkg/-/pkg-1.2.3.tgz\n  var tmp = cacheFile(npm.tmp, u)\n\n  function next (er, resp, shasum) {\n    if (er) return cb(er)\n    addLocalTarball(tmp, pkgData, shasum, cleanup)\n  }\n  function cleanup (er, data) {\n    if (er) return cb(er)\n    rimraf(tmp, function () {\n      cb(er, data)\n    })\n  }\n\n  log.verbose('addRemoteTarball', [u, shasum])\n  mkdir(path.dirname(tmp), function (er) {\n    if (er) return cb(er)\n    addRemoteTarball_(u, tmp, shasum, auth, next)\n  })\n}\n\nfunction addRemoteTarball_ (u, tmp, shasum, auth, cb) {\n  // Tuned to spread 3 attempts over about a minute.\n  // See formula at <https://github.com/tim-kos/node-retry>.\n  var operation = retry.operation({\n    retries: npm.config.get('fetch-retries'),\n    factor: npm.config.get('fetch-retry-factor'),\n    minTimeout: npm.config.get('fetch-retry-mintimeout'),\n    maxTimeout: npm.config.get('fetch-retry-maxtimeout')\n  })\n\n  operation.attempt(function (currentAttempt) {\n    log.info(\n      'retry',\n      'fetch attempt', currentAttempt,\n      'at', (new Date()).toLocaleTimeString()\n    )\n    fetchAndShaCheck(u, tmp, shasum, auth, function (er, response, shasum) {\n      // Only retry on 408, 5xx or no `response`.\n      var sc = response && response.statusCode\n      var statusRetry = !sc || (sc === 408 || sc >= 500)\n      if (er && statusRetry && operation.retry(er)) {\n        log.warn('retry', 'will retry, error on last attempt: ' + er)\n        return\n      }\n      cb(er, response, shasum)\n    })\n  })\n}\n\nfunction fetchAndShaCheck (u, tmp, shasum, auth, cb) {\n  cb = pulseTillDone('fetchTarball', cb)\n  npm.registry.fetch(u, { auth: auth }, function (er, response) {\n    if (er) {\n      log.error('fetch failed', u)\n      return cb(er, response)\n    }\n\n    var tarball = writeStreamAtomic(tmp, { mode: npm.modes.file })\n    tarball.on('error', function (er) {\n      cb(er)\n      tarball.destroy()\n    })\n\n    tarball.on('finish', function () {\n      if (!shasum) {\n        // Well, we weren't given a shasum, so at least sha what we have\n        // in case we want to compare it to something else later\n        return sha.get(tmp, function (er, shasum) {\n          log.silly('fetchAndShaCheck', 'shasum', shasum)\n          cb(er, response, shasum)\n        })\n      }\n\n      // validate that the url we just downloaded matches the expected shasum.\n      log.silly('fetchAndShaCheck', 'shasum', shasum)\n      sha.check(tmp, shasum, function (er) {\n        if (er && er.message) {\n          // add original filename for better debuggability\n          er.message = er.message + '\\n' + 'From:     ' + u\n        }\n        return cb(er, response, shasum)\n      })\n    })\n\n    // 0.8 http streams have a bug, where if they're paused with data in\n    // their buffers when the socket closes, they call `end` before emptying\n    // those buffers, which results in the entire pipeline ending and thus\n    // the point that applied backpressure never being able to trigger a\n    // `resume`.\n    // We work around this by piping into a pass through stream that has\n    // unlimited buffering. The pass through stream is from readable-stream\n    // and is thus a current streams3 implementation that is free of these\n    // bugs even on 0.8.\n    response.pipe(PassThrough({highWaterMark: Infinity})).pipe(tarball)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sha/index.js":"'use strict'\n\nvar Transform = require('stream').Transform || require('readable-stream').Transform\nvar crypto = require('crypto')\nvar fs = require('graceful-fs')\n\nexports.check = check\nexports.checkSync = checkSync\nexports.get = get\nexports.getSync = getSync\nexports.stream = stream\n\nfunction check(file, expected, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = undefined\n  }\n  expected = expected.toLowerCase().trim()\n  get(file, options, function (er, actual) {\n    if (er) {\n      if (er.message) er.message += ' while getting shasum for ' + file\n      return cb(er)\n    }\n    if (actual === expected) return cb(null)\n    cb(new Error(\n        'shasum check failed for ' + file + '\\n'\n      + 'Expected: ' + expected + '\\n'\n      + 'Actual:   ' + actual))\n  })\n}\nfunction checkSync(file, expected, options) {\n  expected = expected.toLowerCase().trim()\n  var actual\n  try {\n    actual = getSync(file, options)\n  } catch (er) {\n    if (er.message) er.message += ' while getting shasum for ' + file\n    throw er\n  }\n  if (actual !== expected) {\n    var ex = new Error(\n        'shasum check failed for ' + file + '\\n'\n      + 'Expected: ' + expected + '\\n'\n      + 'Actual:   ' + actual)\n    throw ex\n  }\n}\n\n\nfunction get(file, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = undefined\n  }\n  options = options || {}\n  var algorithm = options.algorithm || 'sha1'\n  var hash = crypto.createHash(algorithm)\n  var source = fs.createReadStream(file)\n  var errState = null\n  source\n    .on('error', function (er) {\n      if (errState) return\n      return cb(errState = er)\n    })\n    .on('data', function (chunk) {\n      if (errState) return\n      hash.update(chunk)\n    })\n    .on('end', function () {\n      if (errState) return\n      var actual = hash.digest(\"hex\").toLowerCase().trim()\n      cb(null, actual)\n    })\n}\n\nfunction getSync(file, options) {\n  options = options || {}\n  var algorithm = options.algorithm || 'sha1'\n  var hash = crypto.createHash(algorithm)\n  var source = fs.readFileSync(file)\n  hash.update(source)\n  return hash.digest(\"hex\").toLowerCase().trim()\n}\n\nfunction stream(expected, options) {\n  expected = expected.toLowerCase().trim()\n  options = options || {}\n  var algorithm = options.algorithm || 'sha1'\n  var hash = crypto.createHash(algorithm)\n\n  var stream = new Transform()\n  stream._transform = function (chunk, encoding, callback) {\n    hash.update(chunk)\n    stream.push(chunk)\n    callback()\n  }\n  stream._flush = function (cb) {\n    var actual = hash.digest(\"hex\").toLowerCase().trim()\n    if (actual === expected) return cb(null)\n    cb(new Error(\n        'shasum check failed for:\\n'\n      + '  Expected: ' + expected + '\\n'\n      + '  Actual:   ' + actual))\n    this.push(null)\n  }\n  return stream\n}","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/retry/index.js":"module.exports = require('./lib/retry');","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/retry/lib/retry.js":"var RetryOperation = require('./retry_operation');\n\nexports.operation = function(options) {\n  var timeouts = exports.timeouts(options);\n  return new RetryOperation(timeouts, {\n      forever: options && options.forever,\n      unref: options && options.unref\n  });\n};\n\nexports.timeouts = function(options) {\n  if (options instanceof Array) {\n    return [].concat(options);\n  }\n\n  var opts = {\n    retries: 10,\n    factor: 2,\n    minTimeout: 1 * 1000,\n    maxTimeout: Infinity,\n    randomize: false\n  };\n  for (var key in options) {\n    opts[key] = options[key];\n  }\n\n  if (opts.minTimeout > opts.maxTimeout) {\n    throw new Error('minTimeout is greater than maxTimeout');\n  }\n\n  var timeouts = [];\n  for (var i = 0; i < opts.retries; i++) {\n    timeouts.push(this.createTimeout(i, opts));\n  }\n\n  if (options && options.forever && !timeouts.length) {\n    timeouts.push(this.createTimeout(i, opts));\n  }\n\n  // sort the array numerically ascending\n  timeouts.sort(function(a,b) {\n    return a - b;\n  });\n\n  return timeouts;\n};\n\nexports.createTimeout = function(attempt, opts) {\n  var random = (opts.randomize)\n    ? (Math.random() + 1)\n    : 1;\n\n  var timeout = Math.round(random * opts.minTimeout * Math.pow(opts.factor, attempt));\n  timeout = Math.min(timeout, opts.maxTimeout);\n\n  return timeout;\n};\n\nexports.wrap = function(obj, options, methods) {\n  if (options instanceof Array) {\n    methods = options;\n    options = null;\n  }\n\n  if (!methods) {\n    methods = [];\n    for (var key in obj) {\n      if (typeof obj[key] === 'function') {\n        methods.push(key);\n      }\n    }\n  }\n\n  for (var i = 0; i < methods.length; i++) {\n    var method   = methods[i];\n    var original = obj[method];\n\n    obj[method] = function retryWrapper() {\n      var op       = exports.operation(options);\n      var args     = Array.prototype.slice.call(arguments);\n      var callback = args.pop();\n\n      args.push(function(err) {\n        if (op.retry(err)) {\n          return;\n        }\n        if (err) {\n          arguments[0] = op.mainError();\n        }\n        callback.apply(this, arguments);\n      });\n\n      op.attempt(function() {\n        original.apply(obj, args);\n      });\n    };\n    obj[method].options = options;\n  }\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/retry/lib/retry_operation.js":"function RetryOperation(timeouts, options) {\n  // Compatibility for the old (timeouts, retryForever) signature\n  if (typeof options === 'boolean') {\n    options = { forever: options };\n  }\n\n  this._timeouts = timeouts;\n  this._options = options || {};\n  this._fn = null;\n  this._errors = [];\n  this._attempts = 1;\n  this._operationTimeout = null;\n  this._operationTimeoutCb = null;\n  this._timeout = null;\n\n  if (this._options.forever) {\n    this._cachedTimeouts = this._timeouts.slice(0);\n  }\n}\nmodule.exports = RetryOperation;\n\nRetryOperation.prototype.stop = function() {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n\n  this._timeouts       = [];\n  this._cachedTimeouts = null;\n};\n\nRetryOperation.prototype.retry = function(err) {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n\n  if (!err) {\n    return false;\n  }\n\n  this._errors.push(err);\n\n  var timeout = this._timeouts.shift();\n  if (timeout === undefined) {\n    if (this._cachedTimeouts) {\n      // retry forever, only keep last error\n      this._errors.splice(this._errors.length - 1, this._errors.length);\n      this._timeouts = this._cachedTimeouts.slice(0);\n      timeout = this._timeouts.shift();\n    } else {\n      return false;\n    }\n  }\n\n  var self = this;\n  var timer = setTimeout(function() {\n    self._attempts++;\n\n    if (self._operationTimeoutCb) {\n      self._timeout = setTimeout(function() {\n        self._operationTimeoutCb(self._attempts);\n      }, self._operationTimeout);\n\n      if (this._options.unref) {\n          self._timeout.unref();\n      }\n    }\n\n    self._fn(self._attempts);\n  }, timeout);\n\n  if (this._options.unref) {\n      timer.unref();\n  }\n\n  return true;\n};\n\nRetryOperation.prototype.attempt = function(fn, timeoutOps) {\n  this._fn = fn;\n\n  if (timeoutOps) {\n    if (timeoutOps.timeout) {\n      this._operationTimeout = timeoutOps.timeout;\n    }\n    if (timeoutOps.cb) {\n      this._operationTimeoutCb = timeoutOps.cb;\n    }\n  }\n\n  var self = this;\n  if (this._operationTimeoutCb) {\n    this._timeout = setTimeout(function() {\n      self._operationTimeoutCb();\n    }, self._operationTimeout);\n  }\n\n  this._fn(this._attempts);\n};\n\nRetryOperation.prototype.try = function(fn) {\n  console.log('Using RetryOperation.try() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = function(fn) {\n  console.log('Using RetryOperation.start() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = RetryOperation.prototype.try;\n\nRetryOperation.prototype.errors = function() {\n  return this._errors;\n};\n\nRetryOperation.prototype.attempts = function() {\n  return this._attempts;\n};\n\nRetryOperation.prototype.mainError = function() {\n  if (this._errors.length === 0) {\n    return null;\n  }\n\n  var counts = {};\n  var mainError = null;\n  var mainErrorCount = 0;\n\n  for (var i = 0; i < this._errors.length; i++) {\n    var error = this._errors[i];\n    var message = error.message;\n    var count = (counts[message] || 0) + 1;\n\n    counts[message] = count;\n\n    if (count >= mainErrorCount) {\n      mainError = error;\n      mainErrorCount = count;\n    }\n  }\n\n  return mainError;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/add-local-tarball.js":"var mkdir = require('mkdirp')\nvar assert = require('assert')\nvar fs = require('graceful-fs')\nvar writeFileAtomic = require('write-file-atomic')\nvar path = require('path')\nvar sha = require('sha')\nvar npm = require('../npm.js')\nvar log = require('npmlog')\nvar tar = require('../utils/tar.js')\nvar pathIsInside = require('path-is-inside')\nvar getCacheStat = require('./get-stat.js')\nvar cachedPackageRoot = require('./cached-package-root.js')\nvar chownr = require('chownr')\nvar inflight = require('inflight')\nvar once = require('once')\nvar writeStreamAtomic = require('fs-write-stream-atomic')\nvar tempFilename = require('../utils/temp-filename.js')\nvar rimraf = require('rimraf')\nvar packageId = require('../utils/package-id.js')\n\nmodule.exports = addLocalTarball\n\nfunction addLocalTarball (p, pkgData, shasum, cb) {\n  assert(typeof p === 'string', 'must have path')\n  assert(typeof cb === 'function', 'must have callback')\n\n  if (!pkgData) pkgData = {}\n\n  // If we don't have a shasum yet, compute it.\n  if (!shasum) {\n    return sha.get(p, function (er, shasum) {\n      if (er) return cb(er)\n      log.silly('addLocalTarball', 'shasum (computed)', shasum)\n      addLocalTarball(p, pkgData, shasum, cb)\n    })\n  }\n\n  if (pathIsInside(p, npm.cache)) {\n    if (path.basename(p) !== 'package.tgz') {\n      return cb(new Error('Not a valid cache tarball name: ' + p))\n    }\n    log.verbose('addLocalTarball', 'adding from inside cache', p)\n    return addPlacedTarball(p, pkgData, shasum, cb)\n  }\n\n  addTmpTarball(p, pkgData, shasum, function (er, data) {\n    if (data) {\n      data._resolved = p\n      data._shasum = data._shasum || shasum\n    }\n    return cb(er, data)\n  })\n}\n\nfunction addPlacedTarball (p, pkgData, shasum, cb) {\n  assert(pkgData, 'should have package data by now')\n  assert(typeof cb === 'function', 'cb function required')\n\n  getCacheStat(function (er, cs) {\n    if (er) return cb(er)\n    return addPlacedTarball_(p, pkgData, cs.uid, cs.gid, shasum, cb)\n  })\n}\n\nfunction addPlacedTarball_ (p, pkgData, uid, gid, resolvedSum, cb) {\n  var folder = path.join(cachedPackageRoot(pkgData), 'package')\n\n  // First, make sure we have the shasum, if we don't already.\n  if (!resolvedSum) {\n    sha.get(p, function (er, shasum) {\n      if (er) return cb(er)\n      addPlacedTarball_(p, pkgData, uid, gid, shasum, cb)\n    })\n    return\n  }\n\n  mkdir(folder, function (er) {\n    if (er) return cb(er)\n    var pj = path.join(folder, 'package.json')\n    var json = JSON.stringify(pkgData, null, 2)\n    writeFileAtomic(pj, json, function (er) {\n      cb(er, pkgData)\n    })\n  })\n}\n\nfunction addTmpTarball (tgz, pkgData, shasum, cb) {\n  assert(typeof cb === 'function', 'must have callback function')\n  assert(shasum, 'must have shasum by now')\n\n  cb = inflight('addTmpTarball:' + tgz, cb)\n  if (!cb) return log.verbose('addTmpTarball', tgz, 'already in flight; not adding')\n  log.verbose('addTmpTarball', tgz, 'not in flight; adding')\n\n  // we already have the package info, so just move into place\n  if (pkgData && pkgData.name && pkgData.version) {\n    log.verbose(\n      'addTmpTarball',\n      'already have metadata; skipping unpack for',\n      packageId(pkgData)\n    )\n    return addTmpTarball_(tgz, pkgData, shasum, cb)\n  }\n\n  // This is a tarball we probably downloaded from the internet.  The shasum's\n  // already been checked, but we haven't ever had a peek inside, so we unpack\n  // it here just to make sure it is what it says it is.\n  //\n  // NOTE: we might not have any clue what we think it is, for example if the\n  // user just did `npm install ./foo.tgz`\n\n  var target = tempFilename('unpack')\n  getCacheStat(function (er, cs) {\n    if (er) return cb(er)\n\n    log.verbose('addTmpTarball', 'validating metadata from', tgz)\n    tar.unpack(tgz, target, null, null, cs.uid, cs.gid, function (unpackEr, data) {\n      // cleanup the extracted package and move on with the metadata\n      rimraf(target, function () {\n        if (unpackEr) return cb(unpackEr)\n        // check that this is what we expected.\n        if (!data.name) {\n          return cb(new Error('No name provided'))\n        } else if (pkgData.name && data.name !== pkgData.name) {\n          return cb(new Error('Invalid Package: expected ' + pkgData.name +\n                              ' but found ' + data.name))\n        }\n\n        if (!data.version) {\n          return cb(new Error('No version provided'))\n        } else if (pkgData.version && data.version !== pkgData.version) {\n          return cb(new Error('Invalid Package: expected ' +\n                              packageId(pkgData) +\n                              ' but found ' + packageId(data)))\n        }\n\n        addTmpTarball_(tgz, data, shasum, cb)\n      })\n    })\n  })\n}\n\nfunction addTmpTarball_ (tgz, data, shasum, cb) {\n  assert(typeof cb === 'function', 'must have callback function')\n  cb = once(cb)\n\n  assert(data.name, 'should have package name by now')\n  assert(data.version, 'should have package version by now')\n\n  var root = cachedPackageRoot(data)\n  var pkg = path.resolve(root, 'package')\n  var target = path.resolve(root, 'package.tgz')\n  getCacheStat(function (er, cs) {\n    if (er) return cb(er)\n    mkdir(pkg, function (er, created) {\n      // chown starting from the first dir created by mkdirp,\n      // or the root dir, if none had to be created, so that\n      // we know that we get all the children.\n      function chown () {\n        chownr(created || root, cs.uid, cs.gid, done)\n      }\n\n      if (er) return cb(er)\n      var read = fs.createReadStream(tgz)\n      var write = writeStreamAtomic(target, { mode: npm.modes.file })\n      var fin = cs.uid && cs.gid ? chown : done\n      read.on('error', cb).pipe(write).on('error', cb).on('close', fin)\n    })\n  })\n\n  function done () {\n    data._shasum = data._shasum || shasum\n    cb(null, data)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/get-stat.js":"var npm = require('../npm.js')\nvar correctMkdir = require('../utils/correct-mkdir.js')\n\nmodule.exports = function getCacheStat (cb) {\n  correctMkdir(npm.cache, cb)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/correct-mkdir.js":"var chownr = require('chownr')\nvar dezalgo = require('dezalgo')\nvar fs = require('graceful-fs')\nvar inflight = require('inflight')\nvar log = require('npmlog')\nvar mkdirp = require('mkdirp')\n\n// memoize the directories created by this step\nvar stats = {}\nvar effectiveOwner\nmodule.exports = function correctMkdir (path, cb) {\n  cb = dezalgo(cb)\n  cb = inflight('correctMkdir:' + path, cb)\n  if (!cb) {\n    return log.verbose('correctMkdir', path, 'correctMkdir already in flight; waiting')\n  } else {\n    log.verbose('correctMkdir', path, 'correctMkdir not in flight; initializing')\n  }\n\n  if (stats[path]) return cb(null, stats[path])\n\n  fs.stat(path, function (er, st) {\n    if (er) return makeDirectory(path, cb)\n\n    if (!st.isDirectory()) {\n      log.error('correctMkdir', 'invalid dir %s', path)\n      return cb(er)\n    }\n\n    var ownerStats = calculateOwner()\n    // there's always a chance the permissions could have been frobbed, so fix\n    if (st.uid !== ownerStats.uid) {\n      stats[path] = ownerStats\n      setPermissions(path, ownerStats, cb)\n    } else {\n      stats[path] = st\n      cb(null, stats[path])\n    }\n  })\n}\n\nfunction calculateOwner () {\n  if (!effectiveOwner) {\n    effectiveOwner = { uid: 0, gid: 0 }\n\n    // Pretty much only on windows\n    if (!process.getuid) {\n      return effectiveOwner\n    }\n\n    effectiveOwner.uid = +process.getuid()\n    effectiveOwner.gid = +process.getgid()\n\n    if (effectiveOwner.uid === 0) {\n      if (process.env.SUDO_UID) effectiveOwner.uid = +process.env.SUDO_UID\n      if (process.env.SUDO_GID) effectiveOwner.gid = +process.env.SUDO_GID\n    }\n  }\n\n  return effectiveOwner\n}\n\nfunction makeDirectory (path, cb) {\n  cb = inflight('makeDirectory:' + path, cb)\n  if (!cb) {\n    return log.verbose('makeDirectory', path, 'creation already in flight; waiting')\n  } else {\n    log.verbose('makeDirectory', path, 'creation not in flight; initializing')\n  }\n\n  var owner = calculateOwner()\n\n  if (!process.getuid) {\n    return mkdirp(path, function (er) {\n      log.verbose('makeCacheDir', 'UID & GID are irrelevant on', process.platform)\n\n      stats[path] = owner\n      return cb(er, stats[path])\n    })\n  }\n\n  if (owner.uid !== 0 || !process.env.HOME) {\n    log.silly(\n      'makeDirectory', path,\n      'uid:', owner.uid,\n      'gid:', owner.gid\n    )\n    stats[path] = owner\n    mkdirp(path, afterMkdir)\n  } else {\n    fs.stat(process.env.HOME, function (er, st) {\n      if (er) {\n        log.error('makeDirectory', 'homeless?')\n        return cb(er)\n      }\n\n      log.silly(\n        'makeDirectory', path,\n        'uid:', st.uid,\n        'gid:', st.gid\n      )\n      stats[path] = st\n      mkdirp(path, afterMkdir)\n    })\n  }\n\n  function afterMkdir (er, made) {\n    if (er || !stats[path] || isNaN(stats[path].uid) || isNaN(stats[path].gid)) {\n      return cb(er, stats[path])\n    }\n\n    if (!made) return cb(er, stats[path])\n\n    setPermissions(made, stats[path], cb)\n  }\n}\n\nfunction setPermissions (path, st, cb) {\n  chownr(path, st.uid, st.gid, function (er) {\n    if (er && er.code === 'ENOENT') return cb(null, st)\n    return cb(er, st)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/chownr/chownr.js":"module.exports = chownr\nchownr.sync = chownrSync\n\nvar fs = require(\"fs\")\n, path = require(\"path\")\n\nfunction chownr (p, uid, gid, cb) {\n  fs.readdir(p, function (er, children) {\n    // any error other than ENOTDIR means it's not readable, or\n    // doesn't exist.  give up.\n    if (er && er.code !== \"ENOTDIR\") return cb(er)\n    if (er || !children.length) return fs.chown(p, uid, gid, cb)\n\n    var len = children.length\n    , errState = null\n    children.forEach(function (child) {\n      var pathChild = path.resolve(p, child);\n      fs.lstat(pathChild, function(er, stats) {\n        if (er)\n          return cb(er)\n        if (!stats.isSymbolicLink())\n          chownr(pathChild, uid, gid, then)\n        else\n          then()\n        })\n    })\n    function then (er) {\n      if (errState) return\n      if (er) return cb(errState = er)\n      if (-- len === 0) return fs.chown(p, uid, gid, cb)\n    }\n  })\n}\n\nfunction chownrSync (p, uid, gid) {\n  var children\n  try {\n    children = fs.readdirSync(p)\n  } catch (er) {\n    if (er && er.code === \"ENOTDIR\") return fs.chownSync(p, uid, gid)\n    throw er\n  }\n  if (!children.length) return fs.chownSync(p, uid, gid)\n\n  children.forEach(function (child) {\n    var pathChild = path.resolve(p, child)\n    var stats = fs.lstatSync(pathChild)\n    if (!stats.isSymbolicLink())\n      chownrSync(pathChild, uid, gid)\n  })\n  return fs.chownSync(p, uid, gid)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/cached-package-root.js":"var assert = require('assert')\nvar resolve = require('path').resolve\n\nvar npm = require('../npm.js')\n\nmodule.exports = getCacheRoot\n\nfunction getCacheRoot (data) {\n  assert(data, 'must pass package metadata')\n  assert(data.name, 'package metadata must include name')\n  assert(data.version, 'package metadata must include version')\n\n  return resolve(npm.cache, data.name, data.version)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/temp-filename.js":"'use strict'\nvar uniqueFilename = require('unique-filename')\nvar npm = require('../npm.js')\n\nmodule.exports = function (prefix) {\n  return uniqueFilename(npm.tmp, prefix)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/unique-filename/index.js":"'use strict'\nvar path = require('path')\n\nvar uniqueSlug = require('unique-slug')\n\nmodule.exports = function (filepath, prefix, uniq) {\n  return path.join(filepath, (prefix ? prefix + '-' : '') + uniqueSlug(uniq))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/unique-filename/node_modules/unique-slug/index.js":"'use strict'\nvar crypto = require('crypto')\nvar MurmurHash3 = require('imurmurhash')\n\nmodule.exports = function (uniq) {\n  if (uniq) {\n    var hash = new MurmurHash3(uniq)\n    return ('00000000' + hash.result().toString(16)).substr(-8)\n  } else {\n    // Called without a callback, because this interface should neither block\n    // nor error (by contrast with randomBytes which will throw an exception\n    // without enough entropy).\n    //\n    // However, due to a change in Node 0.10.27+, pseudoRandomBytes is now the\n    // same as randomBytes, and may in fact block in situations where\n    // insufficent entropy is available.\n    return crypto.pseudoRandomBytes(4).toString('hex')\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npm-cache-filename/index.js":"var url = require('url');;\nvar path = require('path');;\n\nmodule.exports = cf;;\n\nfunction cf(root, u) {\n  if (!u)\n    return cf.bind(null, root);;\n\n  u = url.parse(u);;\n  var h = u.host.replace(/:/g, '_');;\n  // Strip off any /-rev/... or ?rev=... bits\n  var revre = /(\\?rev=|\\?.*?&rev=|\\/-rev\\/).*$/;;\n  var parts = u.path.replace(revre, '').split('/').slice(1);;\n  // Make sure different git references get different folders\n  if (u.hash && u.hash.length > 1) {\n    parts.push(u.hash.slice(1));;\n  };;\n  var p = [root, h].concat(parts.map(function(part) {\n    return encodeURIComponent(part).replace(/%/g, '_');;\n  }));;\n\n  return path.join.apply(path, p);;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/pick-manifest-from-registry-metadata.js":"'use strict'\nmodule.exports = pickManifestFromRegistryMetadata\n\nvar log = require('npmlog')\nvar semver = require('semver')\n\nfunction pickManifestFromRegistryMetadata (spec, tag, versions, metadata) {\n  log.silly('pickManifestFromRegistryMetadata', 'spec', spec, 'tag', tag, 'versions', versions)\n\n  // if the tagged version satisfies, then use that.\n  var tagged = metadata['dist-tags'][tag]\n  if (tagged &&\n      metadata.versions[tagged] &&\n      semver.satisfies(tagged, spec, true)) {\n    return {resolvedTo: tag, manifest: metadata.versions[tagged]}\n  }\n  // find the max satisfying version.\n  var ms = semver.maxSatisfying(versions, spec, true)\n  if (ms) {\n    return {resolvedTo: ms, manifest: metadata.versions[ms]}\n  } else if (spec === '*' && versions.length && tagged && metadata.versions[tagged]) {\n    return {resolvedTo: tag, manifest: metadata.versions[tagged]}\n  } else {\n    return\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/add-local.js":"var assert = require('assert')\nvar path = require('path')\nvar mkdir = require('mkdirp')\nvar chownr = require('chownr')\nvar pathIsInside = require('path-is-inside')\nvar readJson = require('read-package-json')\nvar log = require('npmlog')\nvar npm = require('../npm.js')\nvar tar = require('../utils/tar.js')\nvar deprCheck = require('../utils/depr-check.js')\nvar prepublishWarning = require('../utils/warn-deprecated.js')('prepublish-on-install')\nvar getCacheStat = require('./get-stat.js')\nvar cachedPackageRoot = require('./cached-package-root.js')\nvar addLocalTarball = require('./add-local-tarball.js')\nvar sha = require('sha')\nvar inflight = require('inflight')\nvar lifecycle = require('../utils/lifecycle.js')\nvar iferr = require('iferr')\nvar chain = require('slide').chain\n\nmodule.exports = addLocal\n\nfunction addLocal (p, pkgData, cb_) {\n  assert(typeof p === 'object', 'must have spec info')\n  assert(typeof cb_ === 'function', 'must have callback')\n\n  pkgData = pkgData || {}\n\n  function cb (er, data) {\n    if (er) {\n      log.error('addLocal', 'Could not install %s', p.spec)\n      return cb_(er)\n    }\n    if (data && !data._fromHosted) {\n      data._from = path.relative(npm.prefix, p.spec) || '.'\n      var resolved = path.relative(npm.prefix, p.spec)\n      if (resolved) data._resolved = 'file:' + resolved\n    }\n    return cb_(er, data)\n  }\n\n  if (p.type === 'directory') {\n    addLocalDirectory(p.spec, pkgData, null, cb)\n  } else {\n    addLocalTarball(p.spec, pkgData, null, cb)\n  }\n}\n\n// At this point, if shasum is set, it's something that we've already\n// read and checked.  Just stashing it in the data at this point.\nfunction addLocalDirectory (p, pkgData, shasum, cb) {\n  assert(pkgData, 'must pass package data')\n  assert(typeof cb === 'function', 'must have callback')\n\n  // if it's a folder, then read the package.json,\n  // tar it to the proper place, and add the cache tar\n  if (pathIsInside(p, npm.cache)) {\n    return cb(new Error(\n    'Adding a cache directory to the cache will make the world implode.'\n    ))\n  }\n\n  readJson(path.join(p, 'package.json'), false, function (er, data) {\n    if (er) return cb(er)\n\n    if (!data.name) {\n      return cb(new Error('No name provided in package.json'))\n    } else if (pkgData.name && pkgData.name !== data.name) {\n      return cb(new Error(\n        'Invalid package: expected ' + pkgData.name + ' but found ' + data.name\n      ))\n    }\n\n    if (!data.version) {\n      return cb(new Error('No version provided in package.json'))\n    } else if (pkgData.version && pkgData.version !== data.version) {\n      return cb(new Error(\n        'Invalid package: expected ' + pkgData.name + '@' + pkgData.version +\n          ' but found ' + data.name + '@' + data.version\n      ))\n    }\n\n    deprCheck(data)\n\n    // pack to {cache}/name/ver/package.tgz\n    var root = cachedPackageRoot(data)\n    var tgz = path.resolve(root, 'package.tgz')\n    var pj = path.resolve(root, 'package/package.json')\n\n    var wrapped = inflight(tgz, next)\n    if (!wrapped) return log.verbose('addLocalDirectory', tgz, 'already in flight; waiting')\n    log.verbose('addLocalDirectory', tgz, 'not in flight; packing')\n\n    getCacheStat(function (er, cs) {\n      mkdir(path.dirname(pj), function (er, made) {\n        if (er) return wrapped(er)\n        var doPrePublish = !pathIsInside(p, npm.tmp)\n        if (doPrePublish) {\n          // TODO: for `npm@5`, change the behavior and remove this warning.\n          // see https://github.com/npm/npm/issues/10074 for details\n          if (data && data.scripts && data.scripts.prepublish) {\n            prepublishWarning([\n              'As of npm@5, `prepublish` scripts will run only for `npm publish`.',\n              '(In npm@4 and previous versions, it also runs for `npm install`.)',\n              'See the deprecation note in `npm help scripts` for more information.'\n            ])\n          }\n\n          chain(\n            [\n              [lifecycle, data, 'prepublish', p],\n              [lifecycle, data, 'prepare', p]\n            ],\n            iferr(wrapped, thenPack)\n          )\n        } else {\n          thenPack()\n        }\n        function thenPack () {\n          tar.pack(tgz, p, data, function (er) {\n            if (er) {\n              log.error('addLocalDirectory', 'Could not pack', p, 'to', tgz)\n              return wrapped(er)\n            }\n\n            if (!cs || isNaN(cs.uid) || isNaN(cs.gid)) return wrapped()\n\n            chownr(made || tgz, cs.uid, cs.gid, function (er) {\n              if (er && er.code === 'ENOENT') return wrapped()\n              wrapped(er)\n            })\n          })\n        }\n      })\n    })\n\n    function next (er) {\n      if (er) return cb(er)\n      // if we have the shasum already, just add it\n      if (shasum) {\n        return addLocalTarball(tgz, data, shasum, cb)\n      } else {\n        sha.get(tgz, function (er, shasum) {\n          if (er) {\n            return cb(er)\n          }\n          data._shasum = shasum\n          return addLocalTarball(tgz, data, shasum, cb)\n        })\n      }\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/warn-deprecated.js":"module.exports = warnDeprecated\n\nvar log = require('npmlog')\n\nvar deprecations = {}\n\nfunction warnDeprecated (type) {\n  return function warn (messages, instance) {\n    if (!instance) {\n      if (!deprecations[type]) {\n        deprecations[type] = {}\n        messages.forEach(function (m) { log.warn(type, m) })\n      }\n    } else {\n      if (!deprecations[type]) deprecations[type] = {}\n\n      if (!deprecations[type][instance]) {\n        deprecations[type][instance] = true\n        messages.forEach(function (m) { log.warn(type, m) })\n      }\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/lifecycle.js":"exports = module.exports = lifecycle\nexports.cmd = cmd\nexports.makeEnv = makeEnv\nexports._incorrectWorkingDirectory = _incorrectWorkingDirectory\n\nvar log = require('npmlog')\nvar spawn = require('./spawn')\nvar npm = require('../npm.js')\nvar path = require('path')\nvar fs = require('graceful-fs')\nvar chain = require('slide').chain\nvar Stream = require('stream').Stream\nvar PATH = 'PATH'\nvar uidNumber = require('uid-number')\nvar umask = require('./umask')\nvar usage = require('./usage')\nvar output = require('./output.js')\nvar which = require('which')\n\n// windows calls it's path 'Path' usually, but this is not guaranteed.\nif (process.platform === 'win32') {\n  PATH = 'Path'\n  Object.keys(process.env).forEach(function (e) {\n    if (e.match(/^PATH$/i)) {\n      PATH = e\n    }\n  })\n}\n\nfunction logid (pkg, stage) {\n  return pkg._id + '~' + stage + ':'\n}\n\nfunction lifecycle (pkg, stage, wd, unsafe, failOk, cb) {\n  if (typeof cb !== 'function') {\n    cb = failOk\n    failOk = false\n  }\n  if (typeof cb !== 'function') {\n    cb = unsafe\n    unsafe = false\n  }\n  if (typeof cb !== 'function') {\n    cb = wd\n    wd = null\n  }\n\n  while (pkg && pkg._data) pkg = pkg._data\n  if (!pkg) return cb(new Error('Invalid package data'))\n\n  log.info('lifecycle', logid(pkg, stage), pkg._id)\n  if (!pkg.scripts) pkg.scripts = {}\n\n  if (npm.config.get('ignore-scripts')) {\n    log.info('lifecycle', logid(pkg, stage), 'ignored because ignore-scripts is set to true', pkg._id)\n    pkg.scripts = {}\n  }\n\n  validWd(wd || path.resolve(npm.dir, pkg.name), function (er, wd) {\n    if (er) return cb(er)\n\n    unsafe = unsafe || npm.config.get('unsafe-perm')\n\n    if ((wd.indexOf(npm.dir) !== 0 || _incorrectWorkingDirectory(wd, pkg)) &&\n        !unsafe && pkg.scripts[stage]) {\n      log.warn('lifecycle', logid(pkg, stage), 'cannot run in wd',\n        '%s %s (wd=%s)', pkg._id, pkg.scripts[stage], wd\n      )\n      return cb()\n    }\n\n    // set the env variables, then run scripts as a child process.\n    var env = makeEnv(pkg)\n    env.npm_lifecycle_event = stage\n    env.npm_node_execpath = env.NODE = env.NODE || process.execPath\n    env.npm_execpath = require.main.filename\n\n    // 'nobody' typically doesn't have permission to write to /tmp\n    // even if it's never used, sh freaks out.\n    if (!npm.config.get('unsafe-perm')) env.TMPDIR = wd\n\n    lifecycle_(pkg, stage, wd, env, unsafe, failOk, cb)\n  })\n}\n\nfunction _incorrectWorkingDirectory (wd, pkg) {\n  return wd.lastIndexOf(pkg.name) !== wd.length - pkg.name.length\n}\n\nfunction lifecycle_ (pkg, stage, wd, env, unsafe, failOk, cb) {\n  var pathArr = []\n  var p = wd.split(/[\\\\\\/]node_modules[\\\\\\/]/)\n  var acc = path.resolve(p.shift())\n\n  p.forEach(function (pp) {\n    pathArr.unshift(path.join(acc, 'node_modules', '.bin'))\n    acc = path.join(acc, 'node_modules', pp)\n  })\n  pathArr.unshift(path.join(acc, 'node_modules', '.bin'))\n\n  // we also unshift the bundled node-gyp-bin folder so that\n  // the bundled one will be used for installing things.\n  pathArr.unshift(path.join(__dirname, '..', '..', 'bin', 'node-gyp-bin'))\n\n  if (shouldPrependCurrentNodeDirToPATH()) {\n    // prefer current node interpreter in child scripts\n    pathArr.push(path.dirname(process.execPath))\n  }\n\n  if (env[PATH]) pathArr.push(env[PATH])\n  env[PATH] = pathArr.join(process.platform === 'win32' ? ';' : ':')\n\n  var packageLifecycle = pkg.scripts && pkg.scripts.hasOwnProperty(stage)\n\n  if (packageLifecycle) {\n    // define this here so it's available to all scripts.\n    env.npm_lifecycle_script = pkg.scripts[stage]\n  } else {\n    log.silly('lifecycle', logid(pkg, stage), 'no script for ' + stage + ', continuing')\n  }\n\n  function done (er) {\n    if (er) {\n      if (npm.config.get('force')) {\n        log.info('lifecycle', logid(pkg, stage), 'forced, continuing', er)\n        er = null\n      } else if (failOk) {\n        log.warn('lifecycle', logid(pkg, stage), 'continuing anyway', er.message)\n        er = null\n      }\n    }\n    cb(er)\n  }\n\n  chain(\n    [\n      packageLifecycle && [runPackageLifecycle, pkg, env, wd, unsafe],\n      [runHookLifecycle, pkg, env, wd, unsafe]\n    ],\n    done\n  )\n}\n\nfunction shouldPrependCurrentNodeDirToPATH () {\n  var cfgsetting = npm.config.get('scripts-prepend-node-path')\n  if (cfgsetting === false) return false\n  if (cfgsetting === true) return true\n\n  var isDifferentNodeInPath\n\n  var isWindows = process.platform === 'win32'\n  var foundExecPath\n  try {\n    foundExecPath = which.sync(path.basename(process.execPath), {pathExt: isWindows ? ';' : ':'})\n    // Apply `fs.realpath()` here to avoid false positives when `node` is a symlinked executable.\n    isDifferentNodeInPath = fs.realpathSync(process.execPath).toUpperCase() !==\n        fs.realpathSync(foundExecPath).toUpperCase()\n  } catch (e) {\n    isDifferentNodeInPath = true\n  }\n\n  if (cfgsetting === 'warn-only') {\n    if (isDifferentNodeInPath && !shouldPrependCurrentNodeDirToPATH.hasWarned) {\n      if (foundExecPath) {\n        log.warn('lifecycle', 'The node binary used for scripts is', foundExecPath, 'but npm is using', process.execPath, 'itself. Use the `--scripts-prepend-node-path` option to include the path for the node binary npm was executed with.')\n      } else {\n        log.warn('lifecycle', 'npm is using', process.execPath, 'but there is no node binary in the current PATH. Use the `--scripts-prepend-node-path` option to include the path for the node binary npm was executed with.')\n      }\n      shouldPrependCurrentNodeDirToPATH.hasWarned = true\n    }\n\n    return false\n  }\n\n  return isDifferentNodeInPath\n}\n\nfunction validWd (d, cb) {\n  fs.stat(d, function (er, st) {\n    if (er || !st.isDirectory()) {\n      var p = path.dirname(d)\n      if (p === d) {\n        return cb(new Error('Could not find suitable wd'))\n      }\n      return validWd(p, cb)\n    }\n    return cb(null, d)\n  })\n}\n\nfunction runPackageLifecycle (pkg, env, wd, unsafe, cb) {\n  // run package lifecycle scripts in the package root, or the nearest parent.\n  var stage = env.npm_lifecycle_event\n  var cmd = env.npm_lifecycle_script\n\n  var note = '\\n> ' + pkg._id + ' ' + stage + ' ' + wd +\n             '\\n> ' + cmd + '\\n'\n  runCmd(note, cmd, pkg, env, stage, wd, unsafe, cb)\n}\n\nvar running = false\nvar queue = []\nfunction dequeue () {\n  running = false\n  if (queue.length) {\n    var r = queue.shift()\n    runCmd.apply(null, r)\n  }\n}\n\nfunction runCmd (note, cmd, pkg, env, stage, wd, unsafe, cb) {\n  if (running) {\n    queue.push([note, cmd, pkg, env, stage, wd, unsafe, cb])\n    return\n  }\n\n  running = true\n  log.pause()\n  var user = unsafe ? null : npm.config.get('user')\n  var group = unsafe ? null : npm.config.get('group')\n\n  if (log.level !== 'silent') {\n    output(note)\n  }\n  log.verbose('lifecycle', logid(pkg, stage), 'unsafe-perm in lifecycle', unsafe)\n\n  if (process.platform === 'win32') {\n    unsafe = true\n  }\n\n  if (unsafe) {\n    runCmd_(cmd, pkg, env, wd, stage, unsafe, 0, 0, cb)\n  } else {\n    uidNumber(user, group, function (er, uid, gid) {\n      runCmd_(cmd, pkg, env, wd, stage, unsafe, uid, gid, cb)\n    })\n  }\n}\n\nfunction runCmd_ (cmd, pkg, env, wd, stage, unsafe, uid, gid, cb_) {\n  function cb (er) {\n    cb_.apply(null, arguments)\n    log.resume()\n    process.nextTick(dequeue)\n  }\n\n  var conf = {\n    cwd: wd,\n    env: env,\n    stdio: [ 0, 1, 2 ]\n  }\n\n  if (!unsafe) {\n    conf.uid = uid ^ 0\n    conf.gid = gid ^ 0\n  }\n\n  var sh = 'sh'\n  var shFlag = '-c'\n\n  if (process.platform === 'win32') {\n    sh = process.env.comspec || 'cmd'\n    shFlag = '/d /s /c'\n    conf.windowsVerbatimArguments = true\n  }\n\n  log.verbose('lifecycle', logid(pkg, stage), 'PATH:', env[PATH])\n  log.verbose('lifecycle', logid(pkg, stage), 'CWD:', wd)\n  log.silly('lifecycle', logid(pkg, stage), 'Args:', [shFlag, cmd])\n\n  var proc = spawn(sh, [shFlag, cmd], conf)\n\n  proc.on('error', procError)\n  proc.on('close', function (code, signal) {\n    log.silly('lifecycle', logid(pkg, stage), 'Returned: code:', code, ' signal:', signal)\n    if (signal) {\n      process.kill(process.pid, signal)\n    } else if (code) {\n      var er = new Error('Exit status ' + code)\n      er.errno = code\n    }\n    procError(er)\n  })\n  process.once('SIGTERM', procKill)\n  process.once('SIGINT', procInterupt)\n\n  function procError (er) {\n    if (er) {\n      log.info('lifecycle', logid(pkg, stage), 'Failed to exec ' + stage + ' script')\n      er.message = pkg._id + ' ' + stage + ': `' + cmd + '`\\n' +\n                   er.message\n      if (er.code !== 'EPERM') {\n        er.code = 'ELIFECYCLE'\n      }\n      fs.stat(npm.dir, function (statError, d) {\n        if (statError && statError.code === 'ENOENT' && npm.dir.split(path.sep).slice(-1)[0] === 'node_modules') {\n          log.warn('', 'Local package.json exists, but node_modules missing, did you mean to install?')\n        }\n      })\n      er.pkgid = pkg._id\n      er.stage = stage\n      er.script = cmd\n      er.pkgname = pkg.name\n    }\n    process.removeListener('SIGTERM', procKill)\n    process.removeListener('SIGTERM', procInterupt)\n    process.removeListener('SIGINT', procKill)\n    return cb(er)\n  }\n  function procKill () {\n    proc.kill()\n  }\n  function procInterupt () {\n    proc.kill('SIGINT')\n    proc.on('exit', function () {\n      process.exit()\n    })\n    process.once('SIGINT', procKill)\n  }\n}\n\nfunction runHookLifecycle (pkg, env, wd, unsafe, cb) {\n  // check for a hook script, run if present.\n  var stage = env.npm_lifecycle_event\n  var hook = path.join(npm.dir, '.hooks', stage)\n  var cmd = hook\n\n  fs.stat(hook, function (er) {\n    if (er) return cb()\n    var note = '\\n> ' + pkg._id + ' ' + stage + ' ' + wd +\n               '\\n> ' + cmd\n    runCmd(note, hook, pkg, env, stage, wd, unsafe, cb)\n  })\n}\n\nfunction makeEnv (data, prefix, env) {\n  prefix = prefix || 'npm_package_'\n  if (!env) {\n    env = {}\n    for (var i in process.env) {\n      if (!i.match(/^npm_/)) {\n        env[i] = process.env[i]\n      }\n    }\n\n    // express and others respect the NODE_ENV value.\n    if (npm.config.get('production')) env.NODE_ENV = 'production'\n  } else if (!data.hasOwnProperty('_lifecycleEnv')) {\n    Object.defineProperty(data, '_lifecycleEnv',\n      {\n        value: env,\n        enumerable: false\n      }\n    )\n  }\n\n  for (i in data) {\n    if (i.charAt(0) !== '_') {\n      var envKey = (prefix + i).replace(/[^a-zA-Z0-9_]/g, '_')\n      if (i === 'readme') {\n        continue\n      }\n      if (data[i] && typeof data[i] === 'object') {\n        try {\n          // quick and dirty detection for cyclical structures\n          JSON.stringify(data[i])\n          makeEnv(data[i], envKey + '_', env)\n        } catch (ex) {\n          // usually these are package objects.\n          // just get the path and basic details.\n          var d = data[i]\n          makeEnv(\n            { name: d.name, version: d.version, path: d.path },\n            envKey + '_',\n            env\n          )\n        }\n      } else {\n        env[envKey] = String(data[i])\n        env[envKey] = env[envKey].indexOf('\\n') !== -1\n                        ? JSON.stringify(env[envKey])\n                        : env[envKey]\n      }\n    }\n  }\n\n  if (prefix !== 'npm_package_') return env\n\n  prefix = 'npm_config_'\n  var pkgConfig = {}\n  var keys = npm.config.keys\n  var pkgVerConfig = {}\n  var namePref = data.name + ':'\n  var verPref = data.name + '@' + data.version + ':'\n\n  keys.forEach(function (i) {\n    // in some rare cases (e.g. working with nerf darts), there are segmented\n    // \"private\" (underscore-prefixed) config names -- don't export\n    if (i.charAt(0) === '_' && i.indexOf('_' + namePref) !== 0 || i.match(/:_/)) {\n      return\n    }\n    var value = npm.config.get(i)\n    if (value instanceof Stream || Array.isArray(value)) return\n    if (i.match(/umask/)) value = umask.toString(value)\n    if (!value) value = ''\n    else if (typeof value === 'number') value = '' + value\n    else if (typeof value !== 'string') value = JSON.stringify(value)\n\n    value = value.indexOf('\\n') !== -1\n          ? JSON.stringify(value)\n          : value\n    i = i.replace(/^_+/, '')\n    var k\n    if (i.indexOf(namePref) === 0) {\n      k = i.substr(namePref.length).replace(/[^a-zA-Z0-9_]/g, '_')\n      pkgConfig[k] = value\n    } else if (i.indexOf(verPref) === 0) {\n      k = i.substr(verPref.length).replace(/[^a-zA-Z0-9_]/g, '_')\n      pkgVerConfig[k] = value\n    }\n    var envKey = (prefix + i).replace(/[^a-zA-Z0-9_]/g, '_')\n    env[envKey] = value\n  })\n\n  prefix = 'npm_package_config_'\n  ;[pkgConfig, pkgVerConfig].forEach(function (conf) {\n    for (var i in conf) {\n      var envKey = (prefix + i)\n      env[envKey] = conf[i]\n    }\n  })\n\n  return env\n}\n\nfunction cmd (stage) {\n  function CMD (args, cb) {\n    npm.commands['run-script']([stage].concat(args), cb)\n  }\n  CMD.usage = usage(stage, 'npm ' + stage + ' [-- <args>]')\n  var installedShallow = require('./completion/installed-shallow.js')\n  CMD.completion = function (opts, cb) {\n    installedShallow(opts, function (d) {\n      return d.scripts && d.scripts[stage]\n    }, cb)\n  }\n  return CMD\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/spawn.js":"module.exports = spawn\n\nvar _spawn = require('child_process').spawn\nvar EventEmitter = require('events').EventEmitter\nvar npwr = require('./no-progress-while-running.js')\n\nfunction willCmdOutput (stdio) {\n  if (stdio === 'inherit') return true\n  if (!Array.isArray(stdio)) return false\n  for (var fh = 1; fh <= 2; ++fh) {\n    if (stdio[fh] === 'inherit') return true\n    if (stdio[fh] === 1 || stdio[fh] === 2) return true\n  }\n  return false\n}\n\nfunction spawn (cmd, args, options) {\n  var cmdWillOutput = willCmdOutput(options && options.stdio)\n\n  if (cmdWillOutput) npwr.startRunning()\n  var raw = _spawn(cmd, args, options)\n  var cooked = new EventEmitter()\n\n  raw.on('error', function (er) {\n    if (cmdWillOutput) npwr.stopRunning()\n    er.file = cmd\n    cooked.emit('error', er)\n  }).on('close', function (code, signal) {\n    if (cmdWillOutput) npwr.stopRunning()\n    // Create ENOENT error because Node.js v0.8 will not emit\n    // an `error` event if the command could not be found.\n    if (code === 127) {\n      var er = new Error('spawn ENOENT')\n      er.code = 'ENOENT'\n      er.errno = 'ENOENT'\n      er.syscall = 'spawn'\n      er.file = cmd\n      cooked.emit('error', er)\n    } else {\n      cooked.emit('close', code, signal)\n    }\n  })\n\n  cooked.stdin = raw.stdin\n  cooked.stdout = raw.stdout\n  cooked.stderr = raw.stderr\n  cooked.kill = function (sig) { return raw.kill(sig) }\n\n  return cooked\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/no-progress-while-running.js":"'use strict'\nvar log = require('npmlog')\nvar progressEnabled\nvar running = 0\n\nvar startRunning = exports.startRunning = function () {\n  if (progressEnabled == null) progressEnabled = log.progressEnabled\n  if (progressEnabled) log.disableProgress()\n  ++running\n}\n\nvar stopRunning = exports.stopRunning = function () {\n  --running\n  if (progressEnabled && running === 0) log.enableProgress()\n}\n\nexports.tillDone = function noProgressTillDone (cb) {\n  startRunning()\n  return function () {\n    stopRunning()\n    cb.apply(this, arguments)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/add-remote-git.js":"var assert = require('assert')\nvar fs = require('graceful-fs')\nvar path = require('path')\nvar url = require('url')\n\nvar chownr = require('chownr')\nvar dezalgo = require('dezalgo')\nvar hostedFromURL = require('hosted-git-info').fromUrl\nvar inflight = require('inflight')\nvar log = require('npmlog')\nvar mkdir = require('mkdirp')\nvar normalizeGitUrl = require('normalize-git-url')\nvar npa = require('npm-package-arg')\nvar realizePackageSpecifier = require('realize-package-specifier')\nvar uniqueFilename = require('unique-filename')\n\nvar addLocal = require('./add-local.js')\nvar correctMkdir = require('../utils/correct-mkdir.js')\nvar git = require('../utils/git.js')\nvar npm = require('../npm.js')\nvar rm = require('../utils/gently-rm.js')\nvar tempFilename = require('../utils/temp-filename.js')\n\nvar remotes = path.resolve(npm.config.get('cache'), '_git-remotes')\nvar templates = path.join(remotes, '_templates')\n\nvar VALID_VARIABLES = [\n  'GIT_ASKPASS',\n  'GIT_EXEC_PATH',\n  'GIT_PROXY_COMMAND',\n  'GIT_SSH',\n  'GIT_SSH_COMMAND',\n  'GIT_SSL_CAINFO',\n  'GIT_SSL_NO_VERIFY'\n]\n\nmodule.exports = addRemoteGit\nfunction addRemoteGit (uri, _cb) {\n  assert(typeof uri === 'string', 'must have git URL')\n  assert(typeof _cb === 'function', 'must have callback')\n  var cb = dezalgo(_cb)\n\n  log.verbose('addRemoteGit', 'caching', uri)\n\n  // the URL comes in exactly as it was passed on the command line, or as\n  // normalized by normalize-package-data / read-package-json / read-installed,\n  // so figure out what to do with it using hosted-git-info\n  var parsed = hostedFromURL(uri)\n  if (parsed) {\n    // normalize GitHub syntax to org/repo (for now)\n    var from\n    if (parsed.type === 'github' && parsed.getDefaultRepresentation() === 'shortcut') {\n      from = parsed.path()\n    } else {\n      from = parsed.toString()\n    }\n\n    log.verbose('addRemoteGit', from, 'is a repository hosted by', parsed.type)\n\n    // prefer explicit URLs to pushing everything through shortcuts\n    if (parsed.getDefaultRepresentation() !== 'shortcut') {\n      return tryClone(from, parsed.toString(), false, cb)\n    }\n\n    // try git:, then git+ssh:, then git+https: before failing\n    tryGitProto(from, parsed, cb)\n  } else {\n    // verify that this is a Git URL before continuing\n    parsed = npa(uri)\n    if (parsed.type !== 'git') {\n      return cb(new Error(uri + 'is not a Git or GitHub URL'))\n    }\n\n    tryClone(parsed.rawSpec, uri, false, cb)\n  }\n}\n\nfunction tryGitProto (from, hostedInfo, cb) {\n  var gitURL = hostedInfo.git()\n  if (!gitURL) return tryHTTPS(from, hostedInfo, cb)\n\n  log.silly('tryGitProto', 'attempting to clone', gitURL)\n  tryClone(from, gitURL, true, function (er) {\n    if (er) return tryHTTPS(from, hostedInfo, cb)\n\n    cb.apply(this, arguments)\n  })\n}\n\nfunction tryHTTPS (from, hostedInfo, cb) {\n  var httpsURL = hostedInfo.https()\n  if (!httpsURL) {\n    return cb(new Error(from + ' can not be cloned via Git, SSH, or HTTPS'))\n  }\n\n  log.silly('tryHTTPS', 'attempting to clone', httpsURL)\n  tryClone(from, httpsURL, true, function (er) {\n    if (er) return trySSH(from, hostedInfo, cb)\n\n    cb.apply(this, arguments)\n  })\n}\n\nfunction trySSH (from, hostedInfo, cb) {\n  var sshURL = hostedInfo.ssh()\n  if (!sshURL) return tryHTTPS(from, hostedInfo, cb)\n\n  log.silly('trySSH', 'attempting to clone', sshURL)\n  tryClone(from, sshURL, false, cb)\n}\n\nfunction tryClone (from, combinedURL, silent, cb) {\n  log.silly('tryClone', 'cloning', from, 'via', combinedURL)\n\n  var normalized = normalizeGitUrl(combinedURL)\n  var cloneURL = normalized.url\n  var treeish = normalized.branch\n\n  // ensure that similarly-named remotes don't collide\n  var cachedRemote = uniqueFilename(remotes, combinedURL.replace(/[^a-zA-Z0-9]+/g, '-'), cloneURL)\n  var repoID = path.relative(remotes, cachedRemote)\n  cachedRemote = path.join(remotes, repoID)\n\n  cb = inflight(repoID, cb)\n  if (!cb) {\n    return log.verbose('tryClone', repoID, 'already in flight; waiting')\n  }\n  log.verbose('tryClone', repoID, 'not in flight; caching')\n\n  // initialize the remotes cache with the correct perms\n  getGitDir(function (er) {\n    if (er) return cb(er)\n    fs.stat(cachedRemote, function (er, s) {\n      if (er) return mirrorRemote(from, cloneURL, treeish, cachedRemote, silent, finish)\n      if (!s.isDirectory()) return resetRemote(from, cloneURL, treeish, cachedRemote, finish)\n\n      validateExistingRemote(from, cloneURL, treeish, cachedRemote, finish)\n    })\n\n    // always set permissions on the cached remote\n    function finish (er, data) {\n      if (er) return cb(er, data)\n      addModeRecursive(cachedRemote, npm.modes.file, function (er) {\n        return cb(er, data)\n      })\n    }\n  })\n}\n\n// don't try too hard to hold on to a remote\nfunction resetRemote (from, cloneURL, treeish, cachedRemote, cb) {\n  log.info('resetRemote', 'resetting', cachedRemote, 'for', from)\n  rm(cachedRemote, function (er) {\n    if (er) return cb(er)\n    mirrorRemote(from, cloneURL, treeish, cachedRemote, false, cb)\n  })\n}\n\n// reuse a cached remote when possible, but nuke it if it's in an\n// inconsistent state\nfunction validateExistingRemote (from, cloneURL, treeish, cachedRemote, cb) {\n  git.whichAndExec(\n    ['config', '--get', 'remote.origin.url'],\n    { cwd: cachedRemote, env: gitEnv() },\n    function (er, stdout, stderr) {\n      var originURL\n      if (stdout) {\n        originURL = stdout.trim()\n        log.silly('validateExistingRemote', from, 'remote.origin.url:', originURL)\n      }\n\n      if (stderr) stderr = stderr.trim()\n      if (stderr || er) {\n        log.warn('addRemoteGit', from, 'resetting remote', cachedRemote, 'because of error:', stderr || er)\n        return resetRemote(from, cloneURL, treeish, cachedRemote, cb)\n      } else if (cloneURL !== originURL) {\n        log.warn(\n          'addRemoteGit',\n          from,\n          'pre-existing cached repo', cachedRemote, 'points to', originURL, 'and not', cloneURL\n        )\n        return resetRemote(from, cloneURL, treeish, cachedRemote, cb)\n      }\n\n      log.verbose('validateExistingRemote', from, 'is updating existing cached remote', cachedRemote)\n      updateRemote(from, cloneURL, treeish, cachedRemote, cb)\n    }\n  )\n}\n\n// make a complete bare mirror of the remote repo\n// NOTE: npm uses a blank template directory to prevent weird inconsistencies\n// https://github.com/npm/npm/issues/5867\nfunction mirrorRemote (from, cloneURL, treeish, cachedRemote, silent, cb) {\n  mkdir(cachedRemote, function (er) {\n    if (er) return cb(er)\n\n    var args = [\n      'clone',\n      '--template=' + templates,\n      '--mirror',\n      cloneURL, cachedRemote\n    ]\n    git.whichAndExec(\n      ['clone', '--template=' + templates, '--mirror', cloneURL, cachedRemote],\n      { cwd: cachedRemote, env: gitEnv() },\n      function (er, stdout, stderr) {\n        if (er) {\n          var combined = (stdout + '\\n' + stderr).trim()\n          var command = 'git ' + args.join(' ') + ':'\n          if (silent) {\n            log.verbose(command, combined)\n          } else {\n            log.error(command, combined)\n          }\n          return cb(er)\n        }\n        log.verbose('mirrorRemote', from, 'git clone ' + cloneURL, stdout.trim())\n        setPermissions(from, cloneURL, treeish, cachedRemote, cb)\n      }\n    )\n  })\n}\n\nfunction setPermissions (from, cloneURL, treeish, cachedRemote, cb) {\n  if (process.platform === 'win32') {\n    log.verbose('setPermissions', from, 'skipping chownr on Windows')\n    resolveHead(from, cloneURL, treeish, cachedRemote, cb)\n  } else {\n    getGitDir(function (er, cs) {\n      if (er) {\n        log.error('setPermissions', from, 'could not get cache stat')\n        return cb(er)\n      }\n\n      chownr(cachedRemote, cs.uid, cs.gid, function (er) {\n        if (er) {\n          log.error(\n            'setPermissions',\n            'Failed to change git repository ownership under npm cache for',\n            cachedRemote\n          )\n          return cb(er)\n        }\n\n        log.verbose('setPermissions', from, 'set permissions on', cachedRemote)\n        resolveHead(from, cloneURL, treeish, cachedRemote, cb)\n      })\n    })\n  }\n}\n\n// always fetch the origin, even right after mirroring, because this way\n// permissions will get set correctly\nfunction updateRemote (from, cloneURL, treeish, cachedRemote, cb) {\n  git.whichAndExec(\n    ['fetch', '-a', 'origin'],\n    { cwd: cachedRemote, env: gitEnv() },\n    function (er, stdout, stderr) {\n      if (er) {\n        var combined = (stdout + '\\n' + stderr).trim()\n        log.error('git fetch -a origin (' + cloneURL + ')', combined)\n        return cb(er)\n      }\n      log.verbose('updateRemote', 'git fetch -a origin (' + cloneURL + ')', stdout.trim())\n\n      setPermissions(from, cloneURL, treeish, cachedRemote, cb)\n    }\n  )\n}\n\n// branches and tags are both symbolic labels that can be attached to different\n// commits, so resolve the commit-ish to the current actual treeish the label\n// corresponds to\n//\n// important for shrinkwrap\nfunction resolveHead (from, cloneURL, treeish, cachedRemote, cb) {\n  log.verbose('resolveHead', from, 'original treeish:', treeish)\n  var args = ['rev-list', '-n1', treeish]\n  git.whichAndExec(\n    args,\n    { cwd: cachedRemote, env: gitEnv() },\n    function (er, stdout, stderr) {\n      if (er) {\n        log.error('git ' + args.join(' ') + ':', stderr)\n        return cb(er)\n      }\n\n      var resolvedTreeish = stdout.trim()\n      log.silly('resolveHead', from, 'resolved treeish:', resolvedTreeish)\n\n      var resolvedURL = getResolved(cloneURL, resolvedTreeish)\n      if (!resolvedURL) {\n        return cb(new Error(\n          'unable to clone ' + from + ' because git clone string ' +\n            cloneURL + ' is in a form npm can\\'t handle'\n        ))\n      }\n      log.verbose('resolveHead', from, 'resolved Git URL:', resolvedURL)\n\n      // generate a unique filename\n      var tmpdir = path.join(tempFilename('git-cache'), resolvedTreeish)\n      log.silly('resolveHead', 'Git working directory:', tmpdir)\n\n      mkdir(tmpdir, function (er) {\n        if (er) return cb(er)\n\n        cloneResolved(from, resolvedURL, resolvedTreeish, cachedRemote, tmpdir, cb)\n      })\n    }\n  )\n}\n\n// make a clone from the mirrored cache so we have a temporary directory in\n// which we can check out the resolved treeish\nfunction cloneResolved (from, resolvedURL, resolvedTreeish, cachedRemote, tmpdir, cb) {\n  var args = ['clone', cachedRemote, tmpdir]\n  git.whichAndExec(\n    args,\n    { cwd: cachedRemote, env: gitEnv() },\n    function (er, stdout, stderr) {\n      stdout = (stdout + '\\n' + stderr).trim()\n      if (er) {\n        log.error('git ' + args.join(' ') + ':', stderr)\n        return cb(er)\n      }\n      log.verbose('cloneResolved', from, 'clone', stdout)\n\n      checkoutTreeish(from, resolvedURL, resolvedTreeish, tmpdir, cb)\n    }\n  )\n}\n\n// there is no safe way to do a one-step clone to a treeish that isn't\n// guaranteed to be a branch, so explicitly check out the treeish once it's\n// cloned\nfunction checkoutTreeish (from, resolvedURL, resolvedTreeish, tmpdir, cb) {\n  var args = ['checkout', resolvedTreeish]\n  git.whichAndExec(\n    args,\n    { cwd: tmpdir, env: gitEnv() },\n    function (er, stdout, stderr) {\n      stdout = (stdout + '\\n' + stderr).trim()\n      if (er) {\n        log.error('git ' + args.join(' ') + ':', stderr)\n        return cb(er)\n      }\n      log.verbose('checkoutTreeish', from, 'checkout', stdout)\n\n      updateSubmodules(from, resolvedURL, tmpdir, cb)\n    }\n  )\n}\n\nfunction updateSubmodules (from, resolvedURL, tmpdir, cb) {\n  var args = ['submodule', '-q', 'update', '--init', '--recursive']\n  git.whichAndExec(\n    args,\n    { cwd: tmpdir, env: gitEnv() },\n    function (er, stdout, stderr) {\n      stdout = (stdout + '\\n' + stderr).trim()\n      if (er) {\n        log.error('git ' + args.join(' ') + ':', stderr)\n        return cb(er)\n      }\n      log.verbose('updateSubmodules', from, 'submodule update', stdout)\n\n      // convince addLocal that the checkout is a local dependency\n      realizePackageSpecifier(tmpdir, function (er, spec) {\n        if (er) {\n          log.error('addRemoteGit', 'Failed to map', tmpdir, 'to a package specifier')\n          return cb(er)\n        }\n\n        // ensure pack logic is applied\n        // https://github.com/npm/npm/issues/6400\n        addLocal(spec, null, function (er, data) {\n          if (data) {\n            if (npm.config.get('save-exact')) {\n              log.verbose('addRemoteGit', 'data._from:', resolvedURL, '(save-exact)')\n              data._from = resolvedURL\n            } else {\n              log.verbose('addRemoteGit', 'data._from:', from)\n              data._from = from\n            }\n\n            log.verbose('addRemoteGit', 'data._resolved:', resolvedURL)\n            data._resolved = resolvedURL\n          }\n\n          cb(er, data)\n        })\n      })\n    }\n  )\n}\n\nfunction getGitDir (cb) {\n  correctMkdir(remotes, function (er, stats) {\n    if (er) return cb(er)\n\n    // We don't need global templates when cloning. Use an empty directory for\n    // the templates, creating it (and setting its permissions) if necessary.\n    mkdir(templates, function (er) {\n      if (er) return cb(er)\n\n      // Ensure that both the template and remotes directories have the correct\n      // permissions.\n      fs.chown(templates, stats.uid, stats.gid, function (er) {\n        cb(er, stats)\n      })\n    })\n  })\n}\n\nvar gitEnv_\nfunction gitEnv () {\n  // git responds to env vars in some weird ways in post-receive hooks\n  // so don't carry those along.\n  if (gitEnv_) return gitEnv_\n\n  // allow users to override npm's insistence on not prompting for\n  // passphrases, but default to just failing when credentials\n  // aren't available\n  gitEnv_ = { GIT_ASKPASS: 'echo' }\n\n  for (var k in process.env) {\n    if (!~VALID_VARIABLES.indexOf(k) && k.match(/^GIT/)) continue\n    gitEnv_[k] = process.env[k]\n  }\n  return gitEnv_\n}\n\naddRemoteGit.getResolved = getResolved\nfunction getResolved (uri, treeish) {\n  // normalize hosted-git-info clone URLs back into regular URLs\n  // this will only work on URLs that hosted-git-info recognizes\n  // https://github.com/npm/npm/issues/7961\n  var rehydrated = hostedFromURL(uri)\n  if (rehydrated) uri = rehydrated.toString()\n\n  var parsed = url.parse(uri)\n\n  // Checks for known protocols:\n  // http:, https:, ssh:, and git:, with optional git+ prefix.\n  if (!parsed.protocol ||\n      !parsed.protocol.match(/^(((git\\+)?(https?|ssh|file))|git|file):$/)) {\n    uri = 'git+ssh://' + uri\n  }\n\n  if (!/^git[+:]/.test(uri)) {\n    uri = 'git+' + uri\n  }\n\n  // Not all URIs are actually URIs, so use regex for the treeish.\n  return uri.replace(/(?:#.*)?$/, '#' + treeish)\n}\n\n// similar to chmodr except it add permissions rather than overwriting them\n// adapted from https://github.com/isaacs/chmodr/blob/master/chmodr.js\nfunction addModeRecursive (cachedRemote, mode, cb) {\n  fs.readdir(cachedRemote, function (er, children) {\n    // Any error other than ENOTDIR means it's not readable, or doesn't exist.\n    // Give up.\n    if (er && er.code !== 'ENOTDIR') return cb(er)\n    if (er || !children.length) return addMode(cachedRemote, mode, cb)\n\n    var len = children.length\n    var errState = null\n    children.forEach(function (child) {\n      addModeRecursive(path.resolve(cachedRemote, child), mode, then)\n    })\n\n    function then (er) {\n      if (errState) return undefined\n      if (er) return cb(errState = er)\n      if (--len === 0) return addMode(cachedRemote, dirMode(mode), cb)\n    }\n  })\n}\n\nfunction addMode (cachedRemote, mode, cb) {\n  fs.stat(cachedRemote, function (er, stats) {\n    if (er) return cb(er)\n    mode = stats.mode | mode\n    fs.chmod(cachedRemote, mode, cb)\n  })\n}\n\n// taken from https://github.com/isaacs/chmodr/blob/master/chmodr.js\nfunction dirMode (mode) {\n  if (mode & parseInt('0400', 8)) mode |= parseInt('0100', 8)\n  if (mode & parseInt('040', 8)) mode |= parseInt('010', 8)\n  if (mode & parseInt('04', 8)) mode |= parseInt('01', 8)\n  return mode\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/normalize-git-url/normalize-git-url.js":"var url = require('url')\n\nmodule.exports = function normalize (u) {\n  var parsed = url.parse(u)\n  // If parsing actually alters the URL, it is almost certainly an\n  // scp-style URL, or an invalid one.\n  var altered = u !== url.format(parsed)\n\n  // git is so tricky!\n  // if the path is like ssh://foo:22/some/path then it works, but\n  // it needs the ssh://\n  // If the path is like ssh://foo:some/path then it works, but\n  // only if you remove the ssh://\n  if (parsed.protocol) {\n    parsed.protocol = parsed.protocol.replace(/^git\\+/, '')\n  }\n\n  // figure out what we should check out.\n  var checkout = parsed.hash && parsed.hash.substr(1) || 'master'\n  parsed.hash = ''\n\n  var returnedUrl\n  if (altered) {\n    if (u.match(/^git\\+https?/) && parsed.pathname.match(/\\/?:[^0-9]/)) {\n      returnedUrl = u.replace(/^git\\+(.*:[^:]+):(.*)/, '$1/$2')\n    } else if (u.match(/^git\\+file/)) {\n      returnedUrl = u.replace(/^git\\+/, '')\n    } else {\n      returnedUrl = u.replace(/^(?:git\\+)?ssh:\\/\\//, '')\n    }\n    returnedUrl = returnedUrl.replace(/#[^#]*$/, '')\n  } else {\n    returnedUrl = url.format(parsed)\n  }\n\n  return {\n    url: returnedUrl,\n    branch: checkout\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/git.js":"// handle some git configuration for windows\n\nexports.spawn = spawnGit\nexports.chainableExec = chainableExec\nexports.whichAndExec = whichAndExec\n\nvar exec = require('child_process').execFile\nvar spawn = require('./spawn')\nvar npm = require('../npm.js')\nvar which = require('which')\nvar git = npm.config.get('git')\nvar assert = require('assert')\nvar log = require('npmlog')\nvar noProgressTillDone = require('./no-progress-while-running.js').tillDone\n\nfunction prefixGitArgs () {\n  return process.platform === 'win32' ? ['-c', 'core.longpaths=true'] : []\n}\n\nfunction execGit (args, options, cb) {\n  log.info('git', args)\n  var fullArgs = prefixGitArgs().concat(args || [])\n  return exec(git, fullArgs, options, noProgressTillDone(cb))\n}\n\nfunction spawnGit (args, options) {\n  log.info('git', args)\n  return spawn(git, prefixGitArgs().concat(args || []), options)\n}\n\nfunction chainableExec () {\n  var args = Array.prototype.slice.call(arguments)\n  return [execGit].concat(args)\n}\n\nfunction whichAndExec (args, options, cb) {\n  assert.equal(typeof cb, 'function', 'no callback provided')\n  // check for git\n  which(git, function (err) {\n    if (err) {\n      err.code = 'ENOGIT'\n      return cb(err)\n    }\n\n    execGit(args, options, cb)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/completion.js":"module.exports = completion\n\ncompletion.usage = 'source <(npm completion)'\n\nvar npm = require('./npm.js')\nvar npmconf = require('./config/core.js')\nvar configDefs = npmconf.defs\nvar configTypes = configDefs.types\nvar shorthands = configDefs.shorthands\nvar nopt = require('nopt')\nvar configNames = Object.keys(configTypes)\n  .filter(function (e) { return e.charAt(0) !== '_' })\nvar shorthandNames = Object.keys(shorthands)\nvar allConfs = configNames.concat(shorthandNames)\nvar once = require('once')\nvar isWindowsShell = require('./utils/is-windows-shell.js')\nvar output = require('./utils/output.js')\n\ncompletion.completion = function (opts, cb) {\n  if (opts.w > 3) return cb()\n\n  var fs = require('graceful-fs')\n  var path = require('path')\n  var bashExists = null\n  var zshExists = null\n  fs.stat(path.resolve(process.env.HOME, '.bashrc'), function (er) {\n    bashExists = !er\n    next()\n  })\n  fs.stat(path.resolve(process.env.HOME, '.zshrc'), function (er) {\n    zshExists = !er\n    next()\n  })\n  function next () {\n    if (zshExists === null || bashExists === null) return\n    var out = []\n    if (zshExists) out.push('~/.zshrc')\n    if (bashExists) out.push('~/.bashrc')\n    if (opts.w === 2) {\n      out = out.map(function (m) {\n        return ['>>', m]\n      })\n    }\n    cb(null, out)\n  }\n}\n\nfunction completion (args, cb) {\n  if (isWindowsShell) {\n    var e = new Error('npm completion supported only in MINGW / Git bash on Windows')\n    e.code = 'ENOTSUP'\n    e.errno = require('constants').ENOTSUP\n    return cb(e)\n  }\n\n  // if the COMP_* isn't in the env, then just dump the script.\n  if (process.env.COMP_CWORD === undefined ||\n      process.env.COMP_LINE === undefined ||\n      process.env.COMP_POINT === undefined) {\n    return dumpScript(cb)\n  }\n\n  console.error(process.env.COMP_CWORD)\n  console.error(process.env.COMP_LINE)\n  console.error(process.env.COMP_POINT)\n\n  // get the partial line and partial word,\n  // if the point isn't at the end.\n  // ie, tabbing at: npm foo b|ar\n  var w = +process.env.COMP_CWORD\n  var words = args.map(unescape)\n  var word = words[w]\n  var line = process.env.COMP_LINE\n  var point = +process.env.COMP_POINT\n  var partialLine = line.substr(0, point)\n  var partialWords = words.slice(0, w)\n\n  // figure out where in that last word the point is.\n  var partialWord = args[w]\n  var i = partialWord.length\n  while (partialWord.substr(0, i) !== partialLine.substr(-1 * i) && i > 0) {\n    i--\n  }\n  partialWord = unescape(partialWord.substr(0, i))\n  partialWords.push(partialWord)\n\n  var opts = {\n    words: words,\n    w: w,\n    word: word,\n    line: line,\n    lineLength: line.length,\n    point: point,\n    partialLine: partialLine,\n    partialWords: partialWords,\n    partialWord: partialWord,\n    raw: args\n  }\n\n  cb = wrapCb(cb, opts)\n\n  console.error(opts)\n\n  if (partialWords.slice(0, -1).indexOf('--') === -1) {\n    if (word.charAt(0) === '-') return configCompl(opts, cb)\n    if (words[w - 1] &&\n        words[w - 1].charAt(0) === '-' &&\n        !isFlag(words[w - 1])) {\n      // awaiting a value for a non-bool config.\n      // don't even try to do this for now\n      console.error('configValueCompl')\n      return configValueCompl(opts, cb)\n    }\n  }\n\n  // try to find the npm command.\n  // it's the first thing after all the configs.\n  // take a little shortcut and use npm's arg parsing logic.\n  // don't have to worry about the last arg being implicitly\n  // boolean'ed, since the last block will catch that.\n  var parsed = opts.conf =\n    nopt(configTypes, shorthands, partialWords.slice(0, -1), 0)\n  // check if there's a command already.\n  console.error(parsed)\n  var cmd = parsed.argv.remain[1]\n  if (!cmd) return cmdCompl(opts, cb)\n\n  Object.keys(parsed).forEach(function (k) {\n    npm.config.set(k, parsed[k])\n  })\n\n  // at this point, if words[1] is some kind of npm command,\n  // then complete on it.\n  // otherwise, do nothing\n  cmd = npm.commands[cmd]\n  if (cmd && cmd.completion) return cmd.completion(opts, cb)\n\n  // nothing to do.\n  cb()\n}\n\nfunction dumpScript (cb) {\n  var fs = require('graceful-fs')\n  var path = require('path')\n  var p = path.resolve(__dirname, 'utils/completion.sh')\n\n  // The Darwin patch below results in callbacks first for the write and then\n  // for the error handler, so make sure we only call our callback once.\n  cb = once(cb)\n\n  fs.readFile(p, 'utf8', function (er, d) {\n    if (er) return cb(er)\n    d = d.replace(/^\\#\\!.*?\\n/, '')\n\n    process.stdout.write(d, function () { cb() })\n    process.stdout.on('error', function (er) {\n      // Darwin is a pain sometimes.\n      //\n      // This is necessary because the \"source\" or \".\" program in\n      // bash on OS X closes its file argument before reading\n      // from it, meaning that you get exactly 1 write, which will\n      // work most of the time, and will always raise an EPIPE.\n      //\n      // Really, one should not be tossing away EPIPE errors, or any\n      // errors, so casually.  But, without this, `. <(npm completion)`\n      // can never ever work on OS X.\n      if (er.errno === 'EPIPE') er = null\n      cb(er)\n    })\n  })\n}\n\nfunction unescape (w) {\n  if (w.charAt(0) === '\\'') return w.replace(/^'|'$/g, '')\n  else return w.replace(/\\\\ /g, ' ')\n}\n\nfunction escape (w) {\n  if (!w.match(/\\s+/)) return w\n  return '\\'' + w + '\\''\n}\n\n// The command should respond with an array.  Loop over that,\n// wrapping quotes around any that have spaces, and writing\n// them to stdout.  Use console.log, not the outfd config.\n// If any of the items are arrays, then join them with a space.\n// Ie, returning ['a', 'b c', ['d', 'e']] would allow it to expand\n// to: 'a', 'b c', or 'd' 'e'\nfunction wrapCb (cb, opts) {\n  return function (er, compls) {\n    if (!Array.isArray(compls)) compls = compls ? [compls] : []\n    compls = compls.map(function (c) {\n      if (Array.isArray(c)) c = c.map(escape).join(' ')\n      else c = escape(c)\n      return c\n    })\n\n    if (opts.partialWord) {\n      compls = compls.filter(function (c) {\n        return c.indexOf(opts.partialWord) === 0\n      })\n    }\n\n    console.error([er && er.stack, compls, opts.partialWord])\n    if (er || compls.length === 0) return cb(er)\n\n    output(compls.join('\\n'))\n    cb()\n  }\n}\n\n// the current word has a dash.  Return the config names,\n// with the same number of dashes as the current word has.\nfunction configCompl (opts, cb) {\n  var word = opts.word\n  var split = word.match(/^(-+)((?:no-)*)(.*)$/)\n  var dashes = split[1]\n  var no = split[2]\n  var flags = configNames.filter(isFlag)\n  console.error(flags)\n\n  return cb(null, allConfs.map(function (c) {\n    return dashes + c\n  }).concat(flags.map(function (f) {\n    return dashes + (no || 'no-') + f\n  })))\n}\n\n// expand with the valid values of various config values.\n// not yet implemented.\nfunction configValueCompl (opts, cb) {\n  console.error('configValue', opts)\n  return cb(null, [])\n}\n\n// check if the thing is a flag or not.\nfunction isFlag (word) {\n  // shorthands never take args.\n  var split = word.match(/^(-*)((?:no-)+)?(.*)$/)\n  var no = split[2]\n  var conf = split[3]\n  return no || configTypes[conf] === Boolean || shorthands[conf]\n}\n\n// complete against the npm commands\nfunction cmdCompl (opts, cb) {\n  return cb(null, npm.fullList)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/is-windows-shell.js":"'use strict'\nvar isWindows = require('./is-windows.js')\nvar isWindowsBash = require('./is-windows-bash.js')\nmodule.exports = isWindows && !isWindowsBash\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/is-windows-bash.js":"'use strict'\nvar isWindows = require('./is-windows.js')\nmodule.exports = isWindows && /^MINGW(32|64)$/.test(process.env.MSYSTEM)\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/config.js":"module.exports = config\n\nvar log = require('npmlog')\nvar npm = require('./npm.js')\nvar npmconf = require('./config/core.js')\nvar fs = require('graceful-fs')\nvar writeFileAtomic = require('write-file-atomic')\nvar types = npmconf.defs.types\nvar ini = require('ini')\nvar editor = require('editor')\nvar os = require('os')\nvar umask = require('./utils/umask')\nvar usage = require('./utils/usage')\nvar output = require('./utils/output')\nvar noProgressTillDone = require('./utils/no-progress-while-running').tillDone\n\nconfig.usage = usage(\n  'config',\n  'npm config set <key> <value>' +\n  '\\nnpm config get [<key>]' +\n  '\\nnpm config delete <key>' +\n  '\\nnpm config list' +\n  '\\nnpm config edit' +\n  '\\nnpm set <key> <value>' +\n  '\\nnpm get [<key>]'\n)\nconfig.completion = function (opts, cb) {\n  var argv = opts.conf.argv.remain\n  if (argv[1] !== 'config') argv.unshift('config')\n  if (argv.length === 2) {\n    var cmds = ['get', 'set', 'delete', 'ls', 'rm', 'edit']\n    if (opts.partialWord !== 'l') cmds.push('list')\n    return cb(null, cmds)\n  }\n\n  var action = argv[2]\n  switch (action) {\n    case 'set':\n      // todo: complete with valid values, if possible.\n      if (argv.length > 3) return cb(null, [])\n      // fallthrough\n      /*eslint no-fallthrough:0*/\n    case 'get':\n    case 'delete':\n    case 'rm':\n      return cb(null, Object.keys(types))\n    case 'edit':\n    case 'list': case 'ls':\n      return cb(null, [])\n    default: return cb(null, [])\n  }\n}\n\n// npm config set key value\n// npm config get key\n// npm config list\nfunction config (args, cb) {\n  var action = args.shift()\n  switch (action) {\n    case 'set': return set(args[0], args[1], cb)\n    case 'get': return get(args[0], cb)\n    case 'delete': case 'rm': case 'del': return del(args[0], cb)\n    case 'list': case 'ls': return list(cb)\n    case 'edit': return edit(cb)\n    default: return unknown(action, cb)\n  }\n}\n\nfunction edit (cb) {\n  var e = npm.config.get('editor')\n  var which = npm.config.get('global') ? 'global' : 'user'\n  var f = npm.config.get(which + 'config')\n  if (!e) return cb(new Error('No EDITOR config or environ set.'))\n  npm.config.save(which, function (er) {\n    if (er) return cb(er)\n    fs.readFile(f, 'utf8', function (er, data) {\n      if (er) data = ''\n      data = [\n        ';;;;',\n        '; npm ' + (npm.config.get('global')\n                  ? 'globalconfig' : 'userconfig') + ' file',\n        '; this is a simple ini-formatted file',\n        '; lines that start with semi-colons are comments.',\n        '; read `npm help config` for help on the various options',\n        ';;;;',\n        '',\n        data\n      ].concat([\n        ';;;;',\n        '; all options with default values',\n        ';;;;'\n      ]).concat(Object.keys(npmconf.defaults).reduce(function (arr, key) {\n        var obj = {}\n        obj[key] = npmconf.defaults[key]\n        if (key === 'logstream') return arr\n        return arr.concat(\n          ini.stringify(obj)\n            .replace(/\\n$/m, '')\n            .replace(/^/g, '; ')\n            .replace(/\\n/g, '\\n; ')\n            .split('\\n'))\n      }, []))\n      .concat([''])\n      .join(os.EOL)\n      writeFileAtomic(\n        f,\n        data,\n        function (er) {\n          if (er) return cb(er)\n          editor(f, { editor: e }, noProgressTillDone(cb))\n        }\n      )\n    })\n  })\n}\n\nfunction del (key, cb) {\n  if (!key) return cb(new Error('no key provided'))\n  var where = npm.config.get('global') ? 'global' : 'user'\n  npm.config.del(key, where)\n  npm.config.save(where, cb)\n}\n\nfunction set (key, val, cb) {\n  if (key === undefined) {\n    return unknown('', cb)\n  }\n  if (val === undefined) {\n    if (key.indexOf('=') !== -1) {\n      var k = key.split('=')\n      key = k.shift()\n      val = k.join('=')\n    } else {\n      val = ''\n    }\n  }\n  key = key.trim()\n  val = val.trim()\n  log.info('config', 'set %j %j', key, val)\n  var where = npm.config.get('global') ? 'global' : 'user'\n  if (key.match(/umask/)) val = umask.fromString(val)\n  npm.config.set(key, val, where)\n  npm.config.save(where, cb)\n}\n\nfunction get (key, cb) {\n  if (!key) return list(cb)\n  if (!publicVar(key)) {\n    return cb(new Error('---sekretz---'))\n  }\n  var val = npm.config.get(key)\n  if (key.match(/umask/)) val = umask.toString(val)\n  output(val)\n  cb()\n}\n\nfunction sort (a, b) {\n  return a > b ? 1 : -1\n}\n\nfunction publicVar (k) {\n  return !(k.charAt(0) === '_' ||\n           k.indexOf(':_') !== -1 ||\n           types[k] !== types[k])\n}\n\nfunction getKeys (data) {\n  return Object.keys(data).filter(publicVar).sort(sort)\n}\n\nfunction list (cb) {\n  var msg = ''\n  var long = npm.config.get('long')\n\n  var cli = npm.config.sources.cli.data\n  var cliKeys = getKeys(cli)\n  if (cliKeys.length) {\n    msg += '; cli configs\\n'\n    cliKeys.forEach(function (k) {\n      if (cli[k] && typeof cli[k] === 'object') return\n      if (k === 'argv') return\n      msg += k + ' = ' + JSON.stringify(cli[k]) + '\\n'\n    })\n    msg += '\\n'\n  }\n\n  // env configs\n  var env = npm.config.sources.env.data\n  var envKeys = getKeys(env)\n  if (envKeys.length) {\n    msg += '; environment configs\\n'\n    envKeys.forEach(function (k) {\n      if (env[k] !== npm.config.get(k)) {\n        if (!long) return\n        msg += '; ' + k + ' = ' +\n          JSON.stringify(env[k]) + ' (overridden)\\n'\n      } else msg += k + ' = ' + JSON.stringify(env[k]) + '\\n'\n    })\n    msg += '\\n'\n  }\n\n  // project config file\n  var project = npm.config.sources.project\n  var pconf = project.data\n  var ppath = project.path\n  var pconfKeys = getKeys(pconf)\n  if (pconfKeys.length) {\n    msg += '; project config ' + ppath + '\\n'\n    pconfKeys.forEach(function (k) {\n      var val = (k.charAt(0) === '_')\n              ? '---sekretz---'\n              : JSON.stringify(pconf[k])\n      if (pconf[k] !== npm.config.get(k)) {\n        if (!long) return\n        msg += '; ' + k + ' = ' + val + ' (overridden)\\n'\n      } else msg += k + ' = ' + val + '\\n'\n    })\n    msg += '\\n'\n  }\n\n  // user config file\n  var uconf = npm.config.sources.user.data\n  var uconfKeys = getKeys(uconf)\n  if (uconfKeys.length) {\n    msg += '; userconfig ' + npm.config.get('userconfig') + '\\n'\n    uconfKeys.forEach(function (k) {\n      var val = (k.charAt(0) === '_')\n              ? '---sekretz---'\n              : JSON.stringify(uconf[k])\n      if (uconf[k] !== npm.config.get(k)) {\n        if (!long) return\n        msg += '; ' + k + ' = ' + val + ' (overridden)\\n'\n      } else msg += k + ' = ' + val + '\\n'\n    })\n    msg += '\\n'\n  }\n\n  // global config file\n  var gconf = npm.config.sources.global.data\n  var gconfKeys = getKeys(gconf)\n  if (gconfKeys.length) {\n    msg += '; globalconfig ' + npm.config.get('globalconfig') + '\\n'\n    gconfKeys.forEach(function (k) {\n      var val = (k.charAt(0) === '_')\n              ? '---sekretz---'\n              : JSON.stringify(gconf[k])\n      if (gconf[k] !== npm.config.get(k)) {\n        if (!long) return\n        msg += '; ' + k + ' = ' + val + ' (overridden)\\n'\n      } else msg += k + ' = ' + val + '\\n'\n    })\n    msg += '\\n'\n  }\n\n  // builtin config file\n  var builtin = npm.config.sources.builtin || {}\n  if (builtin && builtin.data) {\n    var bconf = builtin.data\n    var bpath = builtin.path\n    var bconfKeys = getKeys(bconf)\n    if (bconfKeys.length) {\n      msg += '; builtin config ' + bpath + '\\n'\n      bconfKeys.forEach(function (k) {\n        var val = (k.charAt(0) === '_')\n                ? '---sekretz---'\n                : JSON.stringify(bconf[k])\n        if (bconf[k] !== npm.config.get(k)) {\n          if (!long) return\n          msg += '; ' + k + ' = ' + val + ' (overridden)\\n'\n        } else msg += k + ' = ' + val + '\\n'\n      })\n      msg += '\\n'\n    }\n  }\n\n  // only show defaults if --long\n  if (!long) {\n    msg += '; node bin location = ' + process.execPath + '\\n' +\n           '; cwd = ' + process.cwd() + '\\n' +\n           '; HOME = ' + process.env.HOME + '\\n' +\n           '; \"npm config ls -l\" to show all defaults.\\n'\n\n    output(msg)\n    return cb()\n  }\n\n  var defaults = npmconf.defaults\n  var defKeys = getKeys(defaults)\n  msg += '; default values\\n'\n  defKeys.forEach(function (k) {\n    if (defaults[k] && typeof defaults[k] === 'object') return\n    var val = JSON.stringify(defaults[k])\n    if (defaults[k] !== npm.config.get(k)) {\n      msg += '; ' + k + ' = ' + val + ' (overridden)\\n'\n    } else msg += k + ' = ' + val + '\\n'\n  })\n  msg += '\\n'\n\n  output(msg)\n  return cb()\n}\n\nfunction unknown (action, cb) {\n  cb('Usage:\\n' + config.usage)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/editor/index.js":"var spawn = require('child_process').spawn;\n\nmodule.exports = function (file, opts, cb) {\n    if (typeof opts === 'function') {\n        cb = opts;\n        opts = {};\n    }\n    if (!opts) opts = {};\n    \n    var ed = /^win/.test(process.platform) ? 'notepad' : 'vim';\n    var editor = opts.editor || process.env.VISUAL || process.env.EDITOR || ed;\n    var args = editor.split(/\\s+/);\n    var bin = args.shift();\n    \n    var ps = spawn(bin, args.concat([ file ]), { stdio: 'inherit' });\n    \n    ps.on('exit', function (code, sig) {\n        if (typeof cb === 'function') cb(code, sig)\n    });\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/dedupe.js":"var util = require('util')\nvar path = require('path')\nvar validate = require('aproba')\nvar without = require('lodash.without')\nvar asyncMap = require('slide').asyncMap\nvar chain = require('slide').chain\nvar npa = require('npm-package-arg')\nvar log = require('npmlog')\nvar npm = require('./npm.js')\nvar Installer = require('./install.js').Installer\nvar findRequirement = require('./install/deps.js').findRequirement\nvar earliestInstallable = require('./install/deps.js').earliestInstallable\nvar checkPermissions = require('./install/check-permissions.js')\nvar decomposeActions = require('./install/decompose-actions.js')\nvar loadExtraneous = require('./install/deps.js').loadExtraneous\nvar filterInvalidActions = require('./install/filter-invalid-actions.js')\nvar recalculateMetadata = require('./install/deps.js').recalculateMetadata\nvar sortActions = require('./install/diff-trees.js').sortActions\nvar moduleName = require('./utils/module-name.js')\nvar packageId = require('./utils/package-id.js')\nvar childPath = require('./utils/child-path.js')\nvar usage = require('./utils/usage')\n\nmodule.exports = dedupe\nmodule.exports.Deduper = Deduper\n\ndedupe.usage = usage(\n  'dedupe',\n  'npm dedupe'\n)\n\nfunction dedupe (args, cb) {\n  validate('AF', arguments)\n  // the /path/to/node_modules/..\n  var where = path.resolve(npm.dir, '..')\n  var dryrun = false\n  if (npm.command.match(/^find/)) dryrun = true\n  if (npm.config.get('dry-run')) dryrun = true\n\n  new Deduper(where, dryrun).run(cb)\n}\n\nfunction Deduper (where, dryrun) {\n  validate('SB', arguments)\n  Installer.call(this, where, dryrun, [])\n  this.noPackageJsonOk = true\n  this.topLevelLifecycles = false\n}\nutil.inherits(Deduper, Installer)\n\nDeduper.prototype.loadIdealTree = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'loadIdealTree')\n\n  var self = this\n  chain([\n    [this.newTracker(this.progress.loadIdealTree, 'cloneCurrentTree')],\n    [this, this.cloneCurrentTreeToIdealTree],\n    [this, this.finishTracker, 'cloneCurrentTree'],\n\n    [this.newTracker(this.progress.loadIdealTree, 'loadAllDepsIntoIdealTree', 10)],\n    [ function (next) {\n      loadExtraneous(self.idealTree, self.progress.loadAllDepsIntoIdealTree, next)\n    } ],\n    [this, this.finishTracker, 'loadAllDepsIntoIdealTree'],\n\n    [this, function (next) { recalculateMetadata(this.idealTree, log, next) }]\n  ], cb)\n}\n\nDeduper.prototype.generateActionsToTake = function (cb) {\n  validate('F', arguments)\n  log.silly('dedupe', 'generateActionsToTake')\n  chain([\n    [this.newTracker(log, 'hoist', 1)],\n    [hoistChildren, this.idealTree, this.differences],\n    [this, this.finishTracker, 'hoist'],\n    [this.newTracker(log, 'sort-actions', 1)],\n    [this, function (next) {\n      this.differences = sortActions(this.differences)\n      next()\n    }],\n    [this, this.finishTracker, 'sort-actions'],\n    [filterInvalidActions, this.where, this.differences],\n    [checkPermissions, this.differences],\n    [decomposeActions, this.differences, this.todo]\n  ], cb)\n}\n\nfunction move (node, hoistTo, diff) {\n  node.parent.children = without(node.parent.children, node)\n  hoistTo.children.push(node)\n  node.fromPath = node.path\n  node.path = childPath(hoistTo.path, node)\n  node.parent = hoistTo\n  if (!diff.filter(function (action) { return action[0] === 'move' && action[1] === node }).length) {\n    diff.push(['move', node])\n  }\n}\n\nfunction moveRemainingChildren (node, diff) {\n  node.children.forEach(function (child) {\n    move(child, node, diff)\n    moveRemainingChildren(child, diff)\n  })\n}\n\nfunction remove (child, diff, done) {\n  remove_(child, diff, {}, done)\n}\n\nfunction remove_ (child, diff, seen, done) {\n  if (seen[child.path]) return done()\n  seen[child.path] = true\n  diff.push(['remove', child])\n  child.parent.children = without(child.parent.children, child)\n  asyncMap(child.children, function (child, next) {\n    remove_(child, diff, seen, next)\n  }, done)\n}\n\nfunction hoistChildren (tree, diff, next) {\n  hoistChildren_(tree, diff, {}, next)\n}\n\nfunction hoistChildren_ (tree, diff, seen, next) {\n  validate('OAOF', arguments)\n  if (seen[tree.path]) return next()\n  seen[tree.path] = true\n  asyncMap(tree.children, function (child, done) {\n    if (!tree.parent) return hoistChildren_(child, diff, seen, done)\n    var better = findRequirement(tree.parent, moduleName(child), child.package._requested || npa(packageId(child)))\n    if (better) {\n      return chain([\n        [remove, child, diff],\n        [recalculateMetadata, tree, log]\n      ], done)\n    }\n    var hoistTo = earliestInstallable(tree, tree.parent, child.package)\n    if (hoistTo) {\n      move(child, hoistTo, diff)\n      chain([\n        [recalculateMetadata, hoistTo, log],\n        [hoistChildren_, child, diff, seen],\n        [ function (next) {\n          moveRemainingChildren(child, diff)\n          next()\n        } ]\n      ], done)\n    } else {\n      done()\n    }\n  }, next)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/lodash.without/index.js":"/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** `Object#toString` result references. */\nvar funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/**\n * A faster alternative to `Function#apply`, this function invokes `func`\n * with the `this` binding of `thisArg` and the arguments of `args`.\n *\n * @private\n * @param {Function} func The function to invoke.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} args The arguments to invoke `func` with.\n * @returns {*} Returns the result of `func`.\n */\nfunction apply(func, thisArg, args) {\n  switch (args.length) {\n    case 0: return func.call(thisArg);\n    case 1: return func.call(thisArg, args[0]);\n    case 2: return func.call(thisArg, args[0], args[1]);\n    case 3: return func.call(thisArg, args[0], args[1], args[2]);\n  }\n  return func.apply(thisArg, args);\n}\n\n/**\n * A specialized version of `_.includes` for arrays without support for\n * specifying an index to search from.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludes(array, value) {\n  var length = array ? array.length : 0;\n  return !!length && baseIndexOf(array, value, 0) > -1;\n}\n\n/**\n * This function is like `arrayIncludes` except that it accepts a comparator.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @param {Function} comparator The comparator invoked per element.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludesWith(array, value, comparator) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  while (++index < length) {\n    if (comparator(value, array[index])) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * A specialized version of `_.map` for arrays without support for iteratee\n * shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction arrayMap(array, iteratee) {\n  var index = -1,\n      length = array ? array.length : 0,\n      result = Array(length);\n\n  while (++index < length) {\n    result[index] = iteratee(array[index], index, array);\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.findIndex` and `_.findLastIndex` without\n * support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} predicate The function invoked per iteration.\n * @param {number} fromIndex The index to search from.\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseFindIndex(array, predicate, fromIndex, fromRight) {\n  var length = array.length,\n      index = fromIndex + (fromRight ? 1 : -1);\n\n  while ((fromRight ? index-- : ++index < length)) {\n    if (predicate(array[index], index, array)) {\n      return index;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.indexOf` without `fromIndex` bounds checks.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseIndexOf(array, value, fromIndex) {\n  if (value !== value) {\n    return baseFindIndex(array, baseIsNaN, fromIndex);\n  }\n  var index = fromIndex - 1,\n      length = array.length;\n\n  while (++index < length) {\n    if (array[index] === value) {\n      return index;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.isNaN` without support for number objects.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is `NaN`, else `false`.\n */\nfunction baseIsNaN(value) {\n  return value !== value;\n}\n\n/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\n/**\n * Checks if a cache value for `key` exists.\n *\n * @private\n * @param {Object} cache The cache to query.\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction cacheHas(cache, key) {\n  return cache.has(key);\n}\n\n/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\n/**\n * Checks if `value` is a host object in IE < 9.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a host object, else `false`.\n */\nfunction isHostObject(value) {\n  // Many host objects are `Object` objects that can coerce to strings\n  // despite having improperly defined `toString` methods.\n  var result = false;\n  if (value != null && typeof value.toString != 'function') {\n    try {\n      result = !!(value + '');\n    } catch (e) {}\n  }\n  return result;\n}\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype,\n    funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/** Built-in value references. */\nvar splice = arrayProto.splice;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/* Built-in method references that are verified to be native. */\nvar Map = getNative(root, 'Map'),\n    nativeCreate = getNative(Object, 'create');\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n}\n\n/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  return this.has(key) && delete this.__data__[key];\n}\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);\n}\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n}\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  return true;\n}\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  return getMapData(this, key)['delete'](key);\n}\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  getMapData(this, key).set(key, value);\n  return this;\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\n/**\n *\n * Creates an array cache object to store unique values.\n *\n * @private\n * @constructor\n * @param {Array} [values] The values to cache.\n */\nfunction SetCache(values) {\n  var index = -1,\n      length = values ? values.length : 0;\n\n  this.__data__ = new MapCache;\n  while (++index < length) {\n    this.add(values[index]);\n  }\n}\n\n/**\n * Adds `value` to the array cache.\n *\n * @private\n * @name add\n * @memberOf SetCache\n * @alias push\n * @param {*} value The value to cache.\n * @returns {Object} Returns the cache instance.\n */\nfunction setCacheAdd(value) {\n  this.__data__.set(value, HASH_UNDEFINED);\n  return this;\n}\n\n/**\n * Checks if `value` is in the array cache.\n *\n * @private\n * @name has\n * @memberOf SetCache\n * @param {*} value The value to search for.\n * @returns {number} Returns `true` if `value` is found, else `false`.\n */\nfunction setCacheHas(value) {\n  return this.__data__.has(value);\n}\n\n// Add methods to `SetCache`.\nSetCache.prototype.add = SetCache.prototype.push = setCacheAdd;\nSetCache.prototype.has = setCacheHas;\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of methods like `_.difference` without support\n * for excluding multiple arrays or iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Array} values The values to exclude.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of filtered values.\n */\nfunction baseDifference(array, values, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values.length;\n\n  if (!length) {\n    return result;\n  }\n  if (iteratee) {\n    values = arrayMap(values, baseUnary(iteratee));\n  }\n  if (comparator) {\n    includes = arrayIncludesWith;\n    isCommon = false;\n  }\n  else if (values.length >= LARGE_ARRAY_SIZE) {\n    includes = cacheHas;\n    isCommon = false;\n    values = new SetCache(values);\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee ? iteratee(value) : value;\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var valuesIndex = valuesLength;\n      while (valuesIndex--) {\n        if (values[valuesIndex] === computed) {\n          continue outer;\n        }\n      }\n      result.push(value);\n    }\n    else if (!includes(values, computed, comparator)) {\n      result.push(value);\n    }\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = (isFunction(value) || isHostObject(value)) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\n/**\n * The base implementation of `_.rest` which doesn't validate or coerce arguments.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @returns {Function} Returns the new function.\n */\nfunction baseRest(func, start) {\n  start = nativeMax(start === undefined ? (func.length - 1) : start, 0);\n  return function() {\n    var args = arguments,\n        index = -1,\n        length = nativeMax(args.length - start, 0),\n        array = Array(length);\n\n    while (++index < length) {\n      array[index] = args[start + index];\n    }\n    index = -1;\n    var otherArgs = Array(start + 1);\n    while (++index < start) {\n      otherArgs[index] = args[index];\n    }\n    otherArgs[start] = array;\n    return apply(func, this, otherArgs);\n  };\n}\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\n/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to process.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\n/**\n * Creates an array excluding all given values using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * **Note:** Unlike `_.pull`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {...*} [values] The values to exclude.\n * @returns {Array} Returns the new array of filtered values.\n * @see _.difference, _.xor\n * @example\n *\n * _.without([2, 1, 2, 3], 1, 2);\n * // => [3]\n */\nvar without = baseRest(function(array, values) {\n  return isArrayLikeObject(array)\n    ? baseDifference(array, values)\n    : [];\n});\n\n/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 8-9 which returns 'object' for typed array and other constructors.\n  var tag = isObject(value) ? objectToString.call(value) : '';\n  return tag == funcTag || tag == genTag;\n}\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\n/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return !!value && (type == 'object' || type == 'function');\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\nmodule.exports = without;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/install.js":"'use strict'\n// npm install <pkg> <pkg> <pkg>\n//\n// See doc/cli/npm-install.md for more description\n//\n// Managing contexts...\n// there's a lot of state associated with an \"install\" operation, including\n// packages that are already installed, parent packages, current shrinkwrap, and\n// so on. We maintain this state in a \"context\" object that gets passed around.\n// every time we dive into a deeper node_modules folder, the \"family\" list that\n// gets passed along uses the previous \"family\" list as its __proto__.  Any\n// \"resolved precise dependency\" things that aren't already on this object get\n// added, and then that's passed to the next generation of installation.\n\nmodule.exports = install\nmodule.exports.Installer = Installer\n\nvar usage = require('./utils/usage')\n\ninstall.usage = usage(\n  'install',\n  '\\nnpm install (with no args, in package dir)' +\n  '\\nnpm install [<@scope>/]<pkg>' +\n  '\\nnpm install [<@scope>/]<pkg>@<tag>' +\n  '\\nnpm install [<@scope>/]<pkg>@<version>' +\n  '\\nnpm install [<@scope>/]<pkg>@<version range>' +\n  '\\nnpm install <folder>' +\n  '\\nnpm install <tarball file>' +\n  '\\nnpm install <tarball url>' +\n  '\\nnpm install <git:// url>' +\n  '\\nnpm install <github username>/<github project>',\n  '[--save|--save-dev|--save-optional] [--save-exact]'\n)\n\ninstall.completion = function (opts, cb) {\n  validate('OF', arguments)\n  // install can complete to a folder with a package.json, or any package.\n  // if it has a slash, then it's gotta be a folder\n  // if it starts with https?://, then just give up, because it's a url\n  if (/^https?:\\/\\//.test(opts.partialWord)) {\n    // do not complete to URLs\n    return cb(null, [])\n  }\n\n  if (/\\//.test(opts.partialWord)) {\n    // Complete fully to folder if there is exactly one match and it\n    // is a folder containing a package.json file.  If that is not the\n    // case we return 0 matches, which will trigger the default bash\n    // complete.\n    var lastSlashIdx = opts.partialWord.lastIndexOf('/')\n    var partialName = opts.partialWord.slice(lastSlashIdx + 1)\n    var partialPath = opts.partialWord.slice(0, lastSlashIdx)\n    if (partialPath === '') partialPath = '/'\n\n    var annotatePackageDirMatch = function (sibling, cb) {\n      var fullPath = path.join(partialPath, sibling)\n      if (sibling.slice(0, partialName.length) !== partialName) {\n        return cb(null, null) // not name match\n      }\n      fs.readdir(fullPath, function (err, contents) {\n        if (err) return cb(null, { isPackage: false })\n\n        cb(\n          null,\n          {\n            fullPath: fullPath,\n            isPackage: contents.indexOf('package.json') !== -1\n          }\n        )\n      })\n    }\n\n    return fs.readdir(partialPath, function (err, siblings) {\n      if (err) return cb(null, []) // invalid dir: no matching\n\n      asyncMap(siblings, annotatePackageDirMatch, function (err, matches) {\n        if (err) return cb(err)\n\n        var cleaned = matches.filter(function (x) { return x !== null })\n        if (cleaned.length !== 1) return cb(null, [])\n        if (!cleaned[0].isPackage) return cb(null, [])\n\n        // Success - only one match and it is a package dir\n        return cb(null, [cleaned[0].fullPath])\n      })\n    })\n  }\n\n  // FIXME: there used to be registry completion here, but it stopped making\n  // sense somewhere around 50,000 packages on the registry\n  cb()\n}\n\n// system packages\nvar fs = require('fs')\nvar path = require('path')\n\n// dependencies\nvar log = require('npmlog')\nvar readPackageTree = require('read-package-tree')\nvar chain = require('slide').chain\nvar asyncMap = require('slide').asyncMap\nvar archy = require('archy')\nvar mkdirp = require('mkdirp')\nvar rimraf = require('rimraf')\nvar iferr = require('iferr')\nvar validate = require('aproba')\n\n// npm internal utils\nvar npm = require('./npm.js')\nvar locker = require('./utils/locker.js')\nvar lock = locker.lock\nvar unlock = locker.unlock\nvar ls = require('./ls.js')\nvar parseJSON = require('./utils/parse-json.js')\nvar output = require('./utils/output.js')\nvar saveMetrics = require('./utils/metrics.js').save\n\n// install specific libraries\nvar copyTree = require('./install/copy-tree.js')\nvar readShrinkwrap = require('./install/read-shrinkwrap.js')\nvar recalculateMetadata = require('./install/deps.js').recalculateMetadata\nvar loadDeps = require('./install/deps.js').loadDeps\nvar loadDevDeps = require('./install/deps.js').loadDevDeps\nvar getAllMetadata = require('./install/deps.js').getAllMetadata\nvar loadRequestedDeps = require('./install/deps.js').loadRequestedDeps\nvar loadExtraneous = require('./install/deps.js').loadExtraneous\nvar diffTrees = require('./install/diff-trees.js')\nvar checkPermissions = require('./install/check-permissions.js')\nvar decomposeActions = require('./install/decompose-actions.js')\nvar filterInvalidActions = require('./install/filter-invalid-actions.js')\nvar validateTree = require('./install/validate-tree.js')\nvar validateArgs = require('./install/validate-args.js')\nvar saveRequested = require('./install/save.js').saveRequested\nvar getSaveType = require('./install/save.js').getSaveType\nvar doSerialActions = require('./install/actions.js').doSerial\nvar doReverseSerialActions = require('./install/actions.js').doReverseSerial\nvar doParallelActions = require('./install/actions.js').doParallel\nvar doOneAction = require('./install/actions.js').doOne\nvar removeObsoleteDep = require('./install/deps.js').removeObsoleteDep\nvar packageId = require('./utils/package-id.js')\nvar moduleName = require('./utils/module-name.js')\nvar errorMessage = require('./utils/error-message.js')\nvar andIgnoreErrors = require('./install/and-ignore-errors.js')\n\nfunction unlockCB (lockPath, name, cb) {\n  validate('SSF', arguments)\n  return function (installEr) {\n    var args = arguments\n    try {\n      unlock(lockPath, name, reportErrorAndReturn)\n    } catch (unlockEx) {\n      process.nextTick(function () {\n        reportErrorAndReturn(unlockEx)\n      })\n    }\n    function reportErrorAndReturn (unlockEr) {\n      if (installEr) {\n        if (unlockEr && unlockEr.code !== 'ENOTLOCKED') {\n          log.warn('unlock' + name, unlockEr)\n        }\n        return cb.apply(null, args)\n      }\n      if (unlockEr) return cb(unlockEr)\n      return cb.apply(null, args)\n    }\n  }\n}\n\nfunction install (where, args, cb) {\n  if (!cb) {\n    cb = args\n    args = where\n    where = null\n  }\n  var globalTop = path.resolve(npm.globalDir, '..')\n  if (!where) {\n    where = npm.config.get('global')\n          ? globalTop\n          : npm.prefix\n  }\n  validate('SAF', [where, args, cb])\n  // the /path/to/node_modules/..\n  var dryrun = !!npm.config.get('dry-run')\n\n  if (npm.config.get('dev')) {\n    log.warn('install', 'Usage of the `--dev` option is deprecated. Use `--only=dev` instead.')\n  }\n\n  if (where === globalTop && !args.length) {\n    args = ['.']\n  }\n  args = args.filter(function (a) {\n    return path.resolve(a) !== npm.prefix\n  })\n\n  new Installer(where, dryrun, args).run(cb)\n}\n\nfunction Installer (where, dryrun, args) {\n  validate('SBA', arguments)\n  this.where = where\n  this.dryrun = dryrun\n  this.args = args\n  this.currentTree = null\n  this.idealTree = null\n  this.differences = []\n  this.todo = []\n  this.progress = {}\n  this.noPackageJsonOk = !!args.length\n  this.topLevelLifecycles = !args.length\n  this.dev = npm.config.get('dev') || (!/^prod(uction)?$/.test(npm.config.get('only')) && !npm.config.get('production')) || /^dev(elopment)?$/.test(npm.config.get('only'))\n  this.prod = !/^dev(elopment)?$/.test(npm.config.get('only'))\n  this.rollback = npm.config.get('rollback')\n  this.link = npm.config.get('link')\n  this.global = this.where === path.resolve(npm.globalDir, '..')\n}\nInstaller.prototype = {}\n\nInstaller.prototype.run = function (_cb) {\n  validate('F', arguments)\n\n  var cb = function (err) {\n    saveMetrics(!err)\n    return _cb.apply(this, arguments)\n  }\n\n  // FIXME: This is bad and I should feel bad.\n  // lib/install needs to have some way of sharing _limited_\n  // state with the things it calls. Passing the object is too\n  // much. The global config is WAY too much. =( =(\n  // But not having this is gonna break linked modules in\n  // subtle stupid ways, and refactoring all this code isn't\n  // the right thing to do just yet.\n  if (this.global) {\n    var prevGlobal = npm.config.get('global')\n    npm.config.set('global', true)\n    var next = cb\n    cb = function () {\n      npm.config.set('global', prevGlobal)\n      next.apply(null, arguments)\n    }\n  }\n\n  var installSteps = []\n  var postInstallSteps = []\n  installSteps.push(\n    [this.newTracker(log, 'loadCurrentTree', 4)],\n    [this, this.loadCurrentTree],\n    [this, this.finishTracker, 'loadCurrentTree'],\n\n    [this.newTracker(log, 'loadIdealTree', 12)],\n    [this, this.loadIdealTree],\n    [this, this.finishTracker, 'loadIdealTree'],\n\n    [this, this.debugTree, 'currentTree', 'currentTree'],\n    [this, this.debugTree, 'idealTree', 'idealTree'],\n\n    [this.newTracker(log, 'generateActionsToTake')],\n    [this, this.generateActionsToTake],\n    [this, this.finishTracker, 'generateActionsToTake'],\n\n    [this, this.debugActions, 'diffTrees', 'differences'],\n    [this, this.debugActions, 'decomposeActions', 'todo'])\n  if (!this.dryrun) {\n    installSteps.push(\n      [this.newTracker(log, 'runTopLevelLifecycles', 2)],\n      [this, this.runPreinstallTopLevelLifecycles],\n\n      [this.newTracker(log, 'executeActions', 8)],\n      [this, this.executeActions],\n      [this, this.finishTracker, 'executeActions'])\n    var node_modules = path.resolve(this.where, 'node_modules')\n    var staging = path.resolve(node_modules, '.staging')\n    postInstallSteps.push(\n      [this.newTracker(log, 'rollbackFailedOptional', 1)],\n      [this, this.rollbackFailedOptional, staging, this.todo],\n      [this, this.finishTracker, 'rollbackFailedOptional'],\n      [this, this.commit, staging, this.todo],\n\n      [this, this.runPostinstallTopLevelLifecycles],\n      [this, this.finishTracker, 'runTopLevelLifecycles'])\n    if (getSaveType(this.args)) {\n      postInstallSteps.push(\n        [this, this.saveToDependencies])\n    }\n  }\n  postInstallSteps.push(\n    [this, this.printInstalled])\n\n  var self = this\n  chain(installSteps, function (installEr) {\n    if (installEr) self.failing = true\n    chain(postInstallSteps, function (postInstallEr) {\n      if (self.idealTree) {\n        self.idealTree.warnings.forEach(function (warning) {\n          if (warning.code === 'EPACKAGEJSON' && self.global) return\n          if (warning.code === 'ENOTDIR') return\n          var output = errorMessage(warning)\n          output.summary.forEach(function (logline) {\n            log.warn.apply(log, logline)\n          })\n          output.detail.forEach(function (logline) {\n            log.verbose.apply(log, logline)\n          })\n        })\n      }\n      if (installEr && postInstallEr) {\n        var msg = errorMessage(postInstallEr)\n        msg.summary.forEach(function (logline) {\n          log.warn.apply(log, logline)\n        })\n        msg.detail.forEach(function (logline) {\n          log.verbose.apply(log, logline)\n        })\n      }\n      cb(installEr || postInstallEr, self.getInstalledModules(), self.idealTree)\n    })\n  })\n}\n\nInstaller.prototype.loadArgMetadata = function (next) {\n  var self = this\n  getAllMetadata(this.args, this.currentTree, process.cwd(), iferr(next, function (args) {\n    self.args = args\n    next()\n  }))\n}\n\nInstaller.prototype.newTracker = function (tracker, name, size) {\n  validate('OS', [tracker, name])\n  if (size) validate('N', [size])\n  this.progress[name] = tracker.newGroup(name, size)\n  var self = this\n  return function (next) {\n    self.progress[name].silly(name, 'Starting')\n    next()\n  }\n}\n\nInstaller.prototype.finishTracker = function (name, cb) {\n  validate('SF', arguments)\n  this.progress[name].silly(name, 'Finishing')\n  this.progress[name].finish()\n  cb()\n}\n\nInstaller.prototype.loadCurrentTree = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'loadCurrentTree')\n  var todo = []\n  if (this.global) {\n    todo.push([this, this.readGlobalPackageData])\n  } else {\n    todo.push([this, this.readLocalPackageData])\n  }\n  todo.push(\n    [this, this.normalizeTree, log.newGroup('normalizeTree')])\n  chain(todo, cb)\n}\n\nInstaller.prototype.loadIdealTree = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'loadIdealTree')\n\n  chain([\n    [this.newTracker(this.progress.loadIdealTree, 'cloneCurrentTree')],\n    [this, this.cloneCurrentTreeToIdealTree],\n    [this, this.finishTracker, 'cloneCurrentTree'],\n\n    [this.newTracker(this.progress.loadIdealTree, 'loadShrinkwrap')],\n    [this, this.loadShrinkwrap],\n    [this, this.finishTracker, 'loadShrinkwrap'],\n\n    [this.newTracker(this.progress.loadIdealTree, 'loadAllDepsIntoIdealTree', 10)],\n    [this, this.loadAllDepsIntoIdealTree],\n    [this, this.finishTracker, 'loadAllDepsIntoIdealTree'],\n\n    // TODO: Remove this (should no longer be necessary, instead counter productive)\n    [this, function (next) { recalculateMetadata(this.idealTree, log, next) }]\n  ], cb)\n}\n\nInstaller.prototype.loadAllDepsIntoIdealTree = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'loadAllDepsIntoIdealTree')\n  var saveDeps = getSaveType(this.args)\n\n  var cg = this.progress.loadAllDepsIntoIdealTree\n  var installNewModules = !!this.args.length\n  var steps = []\n\n  if (installNewModules) {\n    steps.push([validateArgs, this.idealTree, this.args])\n    steps.push([loadRequestedDeps, this.args, this.idealTree, saveDeps, cg.newGroup('loadRequestedDeps')])\n  } else {\n    if (this.prod) {\n      steps.push(\n        [loadDeps, this.idealTree, cg.newGroup('loadDeps')])\n    }\n    if (this.dev) {\n      steps.push(\n        [loadDevDeps, this.idealTree, cg.newGroup('loadDevDeps')])\n    }\n  }\n  steps.push(\n    [loadExtraneous.andResolveDeps, this.idealTree, cg.newGroup('loadExtraneous')])\n  chain(steps, cb)\n}\n\nInstaller.prototype.generateActionsToTake = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'generateActionsToTake')\n  var cg = this.progress.generateActionsToTake\n  chain([\n    [validateTree, this.idealTree, cg.newGroup('validateTree')],\n    [diffTrees, this.currentTree, this.idealTree, this.differences, cg.newGroup('diffTrees')],\n    [this, this.computeLinked],\n    [filterInvalidActions, this.where, this.differences],\n    [checkPermissions, this.differences],\n    [decomposeActions, this.differences, this.todo]\n  ], cb)\n}\n\nInstaller.prototype.computeLinked = function (cb) {\n  validate('F', arguments)\n  if (!this.link || this.global) return cb()\n  var linkTodoList = []\n  var self = this\n  asyncMap(this.differences, function (action, next) {\n    var cmd = action[0]\n    var pkg = action[1]\n    if (cmd !== 'add' && cmd !== 'update') return next()\n    var isReqByTop = pkg.requiredBy.filter(function (mod) { return mod.isTop }).length\n    var isReqByUser = pkg.userRequired\n    var isExtraneous = pkg.requiredBy.length === 0\n    if (!isReqByTop && !isReqByUser && !isExtraneous) return next()\n    isLinkable(pkg, function (install, link) {\n      if (install) linkTodoList.push(['global-install', pkg])\n      if (link) linkTodoList.push(['global-link', pkg])\n      if (install || link) removeObsoleteDep(pkg)\n      next()\n    })\n  }, function () {\n    if (linkTodoList.length === 0) return cb()\n    self.differences.length = 0\n    Array.prototype.push.apply(self.differences, linkTodoList)\n    diffTrees(self.currentTree, self.idealTree, self.differences, log.newGroup('d2'), cb)\n  })\n}\n\nfunction isLinkable (pkg, cb) {\n  var globalPackage = path.resolve(npm.globalPrefix, 'lib', 'node_modules', moduleName(pkg))\n  var globalPackageJson = path.resolve(globalPackage, 'package.json')\n  fs.stat(globalPackage, function (er) {\n    if (er) return cb(true, true)\n    fs.readFile(globalPackageJson, function (er, data) {\n      var json = parseJSON.noExceptions(data)\n      cb(false, json && json.version === pkg.package.version)\n    })\n  })\n}\n\nInstaller.prototype.executeActions = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'executeActions')\n  var todo = this.todo\n  var cg = this.progress.executeActions\n\n  var node_modules = path.resolve(this.where, 'node_modules')\n  var staging = path.resolve(node_modules, '.staging')\n  var steps = []\n  var trackLifecycle = cg.newGroup('lifecycle')\n\n  cb = unlockCB(node_modules, '.staging', cb)\n\n  steps.push(\n    [doSerialActions, 'global-install', staging, todo, trackLifecycle.newGroup('global-install')],\n    [doParallelActions, 'fetch', staging, todo, cg.newGroup('fetch', 10)],\n    [lock, node_modules, '.staging'],\n    [rimraf, staging],\n    [mkdirp, staging],\n    [doParallelActions, 'extract', staging, todo, cg.newGroup('extract', 10)],\n    [doParallelActions, 'preinstall', staging, todo, trackLifecycle.newGroup('preinstall')],\n    [doReverseSerialActions, 'remove', staging, todo, cg.newGroup('remove')],\n    [doSerialActions, 'move', staging, todo, cg.newGroup('move')],\n    [doSerialActions, 'finalize', staging, todo, cg.newGroup('finalize')],\n    [doSerialActions, 'build', staging, todo, trackLifecycle.newGroup('build')],\n    [doSerialActions, 'global-link', staging, todo, trackLifecycle.newGroup('global-link')],\n    [doParallelActions, 'update-linked', staging, todo, trackLifecycle.newGroup('update-linked')],\n    [doSerialActions, 'install', staging, todo, trackLifecycle.newGroup('install')],\n    [doSerialActions, 'postinstall', staging, todo, trackLifecycle.newGroup('postinstall')])\n\n  var self = this\n  chain(steps, function (er) {\n    if (!er || self.rollback) {\n      rimraf(staging, function () { cb(er) })\n    } else {\n      cb(er)\n    }\n  })\n}\n\nInstaller.prototype.rollbackFailedOptional = function (staging, actionsToRun, cb) {\n  if (!this.rollback) return cb()\n  var failed = actionsToRun.map(function (action) {\n    return action[1]\n  }).filter(function (pkg) {\n    return pkg.failed && pkg.rollback\n  })\n  var top = this.currentTree && this.currentTree.path\n  asyncMap(failed, function (pkg, next) {\n    asyncMap(pkg.rollback, function (rollback, done) {\n      rollback(top, staging, pkg, done)\n    }, next)\n  }, cb)\n}\n\nInstaller.prototype.commit = function (staging, actionsToRun, cb) {\n  var toCommit = actionsToRun.map(function (action) { return action[1] }).filter(function (pkg) { return !pkg.failed && pkg.commit })\n  asyncMap(toCommit, function (pkg, next) {\n    asyncMap(pkg.commit, function (commit, done) {\n      commit(staging, pkg, done)\n    }, function () {\n      pkg.commit = []\n      next.apply(null, arguments)\n    })\n  }, cb)\n}\n\nInstaller.prototype.runPreinstallTopLevelLifecycles = function (cb) {\n  validate('F', arguments)\n  if (this.failing) return cb()\n  if (!this.topLevelLifecycles) return cb()\n  log.silly('install', 'runPreinstallTopLevelLifecycles')\n  var steps = []\n  var trackLifecycle = this.progress.runTopLevelLifecycles\n\n  steps.push(\n    [doOneAction, 'preinstall', this.idealTree.path, this.idealTree, trackLifecycle.newGroup('preinstall:.')]\n  )\n  chain(steps, cb)\n}\n\nInstaller.prototype.runPostinstallTopLevelLifecycles = function (cb) {\n  validate('F', arguments)\n  if (this.failing) return cb()\n  if (!this.topLevelLifecycles) return cb()\n  log.silly('install', 'runPostinstallTopLevelLifecycles')\n  var steps = []\n  var trackLifecycle = this.progress.runTopLevelLifecycles\n\n  steps.push(\n    [doOneAction, 'build', this.idealTree.path, this.idealTree, trackLifecycle.newGroup('build:.')],\n    [doOneAction, 'install', this.idealTree.path, this.idealTree, trackLifecycle.newGroup('install:.')],\n    [doOneAction, 'postinstall', this.idealTree.path, this.idealTree, trackLifecycle.newGroup('postinstall:.')])\n  if (this.dev) {\n    steps.push(\n      [doOneAction, 'prepare', this.idealTree.path, this.idealTree, trackLifecycle.newGroup('prepare')])\n  }\n  chain(steps, cb)\n}\n\nInstaller.prototype.saveToDependencies = function (cb) {\n  validate('F', arguments)\n  if (this.failing) return cb()\n  log.silly('install', 'saveToDependencies')\n  saveRequested(this.args, this.idealTree, cb)\n}\n\nInstaller.prototype.readGlobalPackageData = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'readGlobalPackageData')\n  var self = this\n  this.loadArgMetadata(iferr(cb, function () {\n    mkdirp(self.where, iferr(cb, function () {\n      var pkgs = {}\n      self.args.forEach(function (pkg) {\n        pkgs[pkg.name] = true\n      })\n      readPackageTree(self.where, function (ctx, kid) { return ctx.parent || pkgs[kid] }, iferr(cb, function (currentTree) {\n        self.currentTree = currentTree\n        return cb()\n      }))\n    }))\n  }))\n}\n\nInstaller.prototype.readLocalPackageData = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'readLocalPackageData')\n  var self = this\n  mkdirp(this.where, iferr(cb, function () {\n    readPackageTree(self.where, iferr(cb, function (currentTree) {\n      self.currentTree = currentTree\n      self.currentTree.warnings = []\n      if (currentTree.error && currentTree.error.code === 'EJSONPARSE') {\n        return cb(currentTree.error)\n      }\n      if (!self.noPackageJsonOk && !currentTree.package) {\n        log.error('install', \"Couldn't read dependencies\")\n        var er = new Error(\"ENOENT, open '\" + path.join(self.where, 'package.json') + \"'\")\n        er.code = 'ENOPACKAGEJSON'\n        er.errno = 34\n        return cb(er)\n      }\n      if (!currentTree.package) currentTree.package = {}\n      readShrinkwrap(currentTree, function (err) {\n        if (err) {\n          cb(err)\n        } else {\n          self.loadArgMetadata(cb)\n        }\n      })\n    }))\n  }))\n}\n\nInstaller.prototype.cloneCurrentTreeToIdealTree = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'cloneCurrentTreeToIdealTree')\n  this.idealTree = copyTree(this.currentTree)\n  this.idealTree.warnings = []\n  cb()\n}\n\nInstaller.prototype.loadShrinkwrap = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'loadShrinkwrap')\n  var installNewModules = !!this.args.length\n  if (installNewModules) {\n    readShrinkwrap(this.idealTree, cb)\n  } else {\n    readShrinkwrap.andInflate(this.idealTree, cb)\n  }\n}\n\nInstaller.prototype.normalizeTree = function (log, cb) {\n  validate('OF', arguments)\n  log.silly('install', 'normalizeTree')\n  recalculateMetadata(this.currentTree, log, iferr(cb, function (tree) {\n    tree.children.forEach(function (child) {\n      if (child.requiredBy.length === 0) {\n        child.existing = true\n      }\n    })\n    cb(null, tree)\n  }))\n}\n\nInstaller.prototype.getInstalledModules = function () {\n  return this.differences.filter(function (action) {\n    var mutation = action[0]\n    return (mutation === 'add' || mutation === 'update')\n  }).map(function (action) {\n    var child = action[1]\n    return [child.package._id, child.path]\n  })\n}\n\nInstaller.prototype.printInstalled = function (cb) {\n  validate('F', arguments)\n  log.silly('install', 'printInstalled')\n  var self = this\n  this.differences.forEach(function (action) {\n    var mutation = action[0]\n    var child = action[1]\n    var name = packageId(child)\n    var where = path.relative(self.where, child.path)\n    if (mutation === 'remove') {\n      output('- ' + name + ' ' + where)\n    } else if (mutation === 'move') {\n      var oldWhere = path.relative(self.where, child.fromPath)\n      output(name + ' ' + oldWhere + ' -> ' + where)\n    }\n  })\n  var addedOrMoved = this.differences.filter(function (action) {\n    var mutation = action[0]\n    var child = action[1]\n    return !child.failed && (mutation === 'add' || mutation === 'update')\n  }).map(function (action) {\n    var child = action[1]\n    return child.path\n  })\n  if (!addedOrMoved.length) return cb()\n  // TODO: remove the recalculateMetadata, should not be needed\n  recalculateMetadata(this.idealTree, log, iferr(cb, function (tree) {\n    // These options control both how installs happen AND how `ls` shows output.\n    // Something like `npm install --production` only installs production deps.\n    // By contrast `npm install --production foo` installs `foo` and the\n    // `production` option is ignored. But when it comes time for `ls` to show\n    // its output, it excludes the thing we just installed because that flag.\n    // The summary output we get should be unfiltered, showing everything\n    // installed, so we clear these options before calling `ls`.\n    npm.config.set('production', false)\n    npm.config.set('dev', false)\n    npm.config.set('only', '')\n    npm.config.set('also', '')\n    ls.fromTree(self.where, tree, addedOrMoved, false, andIgnoreErrors(cb))\n  }))\n}\n\nInstaller.prototype.debugActions = function (name, actionListName, cb) {\n  validate('SSF', arguments)\n  var actionsToLog = this[actionListName]\n  log.silly(name, 'action count', actionsToLog.length)\n  actionsToLog.forEach(function (action) {\n    log.silly(name, action.map(function (value) {\n      return (value && value.package) ? packageId(value) : value\n    }).join(' '))\n  })\n  cb()\n}\n\n// This takes an object and a property name instead of a value to allow us\n// to define the arguments for use by chain before the property exists yet.\nInstaller.prototype.debugTree = function (name, treeName, cb) {\n  validate('SSF', arguments)\n  log.silly(name, this.prettify(this[treeName]).trim())\n  cb()\n}\n\nInstaller.prototype.prettify = function (tree) {\n  validate('O', arguments)\n  var seen = {}\n  function byName (aa, bb) {\n    return packageId(aa).localeCompare(packageId(bb))\n  }\n  function expandTree (tree) {\n    seen[tree.path] = true\n    return {\n      label: packageId(tree),\n      nodes: tree.children.filter(function (tree) { return !seen[tree.path] }).sort(byName).map(expandTree)\n    }\n  }\n  return archy(expandTree(tree), '', { unicode: npm.config.get('unicode') })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/archy/index.js":"module.exports = function archy (obj, prefix, opts) {\n    if (prefix === undefined) prefix = '';\n    if (!opts) opts = {};\n    var chr = function (s) {\n        var chars = {\n            '' : '|',\n            '' : '`',\n            '' : '+',\n            '' : '-',\n            '' : '-'\n        };\n        return opts.unicode === false ? chars[s] : s;\n    };\n    \n    if (typeof obj === 'string') obj = { label : obj };\n    \n    var nodes = obj.nodes || [];\n    var lines = (obj.label || '').split('\\n');\n    var splitter = '\\n' + prefix + (nodes.length ? chr('') : ' ') + ' ';\n    \n    return prefix\n        + lines.join(splitter) + '\\n'\n        + nodes.map(function (node, ix) {\n            var last = ix === nodes.length - 1;\n            var more = node.nodes && node.nodes.length;\n            var prefix_ = prefix + (last ? ' ' : chr('')) + ' ';\n            \n            return prefix\n                + (last ? chr('') : chr('')) + chr('')\n                + (more ? chr('') : chr('')) + ' '\n                + archy(node, prefix_, opts).slice(prefix.length + 2)\n            ;\n        }).join('')\n    ;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/locker.js":"var crypto = require('crypto')\nvar resolve = require('path').resolve\n\nvar lockfile = require('lockfile')\nvar log = require('npmlog')\n\nvar npm = require('../npm.js')\nvar correctMkdir = require('../utils/correct-mkdir.js')\n\nvar installLocks = {}\n\nfunction lockFileName (base, name) {\n  var c = name.replace(/[^a-zA-Z0-9]+/g, '-').replace(/^-+|-+$/g, '')\n  var p = resolve(base, name)\n  var h = crypto.createHash('sha1').update(p).digest('hex')\n  var l = resolve(npm.cache, '_locks')\n\n  return resolve(l, c.substr(0, 24) + '-' + h.substr(0, 16) + '.lock')\n}\n\nfunction lock (base, name, cb) {\n  var lockDir = resolve(npm.cache, '_locks')\n  correctMkdir(lockDir, function (er) {\n    if (er) return cb(er)\n\n    var opts = {\n      stale: npm.config.get('cache-lock-stale'),\n      retries: npm.config.get('cache-lock-retries'),\n      wait: npm.config.get('cache-lock-wait')\n    }\n    var lf = lockFileName(base, name)\n    lockfile.lock(lf, opts, function (er) {\n      if (er) log.warn('locking', lf, 'failed', er)\n\n      if (!er) {\n        log.verbose('lock', 'using', lf, 'for', resolve(base, name))\n        installLocks[lf] = true\n      }\n\n      cb(er)\n    })\n  })\n}\n\nfunction unlock (base, name, cb) {\n  var lf = lockFileName(base, name)\n  var locked = installLocks[lf]\n  if (locked === false) {\n    return process.nextTick(cb)\n  } else if (locked === true) {\n    lockfile.unlock(lf, function (er) {\n      if (er) {\n        log.warn('unlocking', lf, 'failed', er)\n      } else {\n        installLocks[lf] = false\n        log.verbose('unlock', 'done using', lf, 'for', resolve(base, name))\n      }\n\n      cb(er)\n    })\n  } else {\n    var notLocked = new Error(\n      'Attempt to unlock ' + resolve(base, name) + \", which hasn't been locked\"\n    )\n    notLocked.code = 'ENOTLOCKED'\n    throw notLocked\n  }\n}\n\nmodule.exports = {\n  lock: lock,\n  unlock: unlock\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/lockfile/lockfile.js":"var fs = require('fs')\n\nvar wx = 'wx'\nif (process.version.match(/^v0\\.[0-6]/)) {\n  var c = require('constants')\n  wx = c.O_TRUNC | c.O_CREAT | c.O_WRONLY | c.O_EXCL\n}\n\nvar os = require('os')\nexports.filetime = 'ctime'\nif (os.platform() == \"win32\") {\n  exports.filetime = 'mtime'\n}\n\nvar debug\nvar util = require('util')\nif (util.debuglog)\n  debug = util.debuglog('LOCKFILE')\nelse if (/\\blockfile\\b/i.test(process.env.NODE_DEBUG))\n  debug = function() {\n    var msg = util.format.apply(util, arguments)\n    console.error('LOCKFILE %d %s', process.pid, msg)\n  }\nelse\n  debug = function() {}\n\nvar locks = {}\n\nfunction hasOwnProperty (obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop)\n}\n\nprocess.on('exit', function () {\n  debug('exit listener')\n  // cleanup\n  Object.keys(locks).forEach(exports.unlockSync)\n})\n\n// XXX https://github.com/joyent/node/issues/3555\n// Remove when node 0.8 is deprecated.\nif (/^v0\\.[0-8]\\./.test(process.version)) {\n  debug('uncaughtException, version = %s', process.version)\n  process.on('uncaughtException', function H (er) {\n    debug('uncaughtException')\n    var l = process.listeners('uncaughtException').filter(function (h) {\n      return h !== H\n    })\n    if (!l.length) {\n      // cleanup\n      try { Object.keys(locks).forEach(exports.unlockSync) } catch (e) {}\n      process.removeListener('uncaughtException', H)\n      throw er\n    }\n  })\n}\n\nexports.unlock = function (path, cb) {\n  debug('unlock', path)\n  // best-effort.  unlocking an already-unlocked lock is a noop\n  delete locks[path]\n  fs.unlink(path, function (unlinkEr) { cb && cb() })\n}\n\nexports.unlockSync = function (path) {\n  debug('unlockSync', path)\n  // best-effort.  unlocking an already-unlocked lock is a noop\n  try { fs.unlinkSync(path) } catch (er) {}\n  delete locks[path]\n}\n\n\n// if the file can be opened in readonly mode, then it's there.\n// if the error is something other than ENOENT, then it's not.\nexports.check = function (path, opts, cb) {\n  if (typeof opts === 'function') cb = opts, opts = {}\n  debug('check', path, opts)\n  fs.open(path, 'r', function (er, fd) {\n    if (er) {\n      if (er.code !== 'ENOENT') return cb(er)\n      return cb(null, false)\n    }\n\n    if (!opts.stale) {\n      return fs.close(fd, function (er) {\n        return cb(er, true)\n      })\n    }\n\n    fs.fstat(fd, function (er, st) {\n      if (er) return fs.close(fd, function (er2) {\n        return cb(er)\n      })\n\n      fs.close(fd, function (er) {\n        var age = Date.now() - st[exports.filetime].getTime()\n        return cb(er, age <= opts.stale)\n      })\n    })\n  })\n}\n\nexports.checkSync = function (path, opts) {\n  opts = opts || {}\n  debug('checkSync', path, opts)\n  if (opts.wait) {\n    throw new Error('opts.wait not supported sync for obvious reasons')\n  }\n\n  try {\n    var fd = fs.openSync(path, 'r')\n  } catch (er) {\n    if (er.code !== 'ENOENT') throw er\n    return false\n  }\n\n  if (!opts.stale) {\n    try { fs.closeSync(fd) } catch (er) {}\n    return true\n  }\n\n  // file exists.  however, might be stale\n  if (opts.stale) {\n    try {\n      var st = fs.fstatSync(fd)\n    } finally {\n      fs.closeSync(fd)\n    }\n    var age = Date.now() - st[exports.filetime].getTime()\n    return (age <= opts.stale)\n  }\n}\n\n\n\nvar req = 1\nexports.lock = function (path, opts, cb) {\n  if (typeof opts === 'function') cb = opts, opts = {}\n  opts.req = opts.req || req++\n  debug('lock', path, opts)\n  opts.start = opts.start || Date.now()\n\n  if (typeof opts.retries === 'number' && opts.retries > 0) {\n    debug('has retries', opts.retries)\n    var retries = opts.retries\n    opts.retries = 0\n    cb = (function (orig) { return function cb (er, fd) {\n      debug('retry-mutated callback')\n      retries -= 1\n      if (!er || retries < 0) return orig(er, fd)\n\n      debug('lock retry', path, opts)\n\n      if (opts.retryWait) setTimeout(retry, opts.retryWait)\n      else retry()\n\n      function retry () {\n        opts.start = Date.now()\n        debug('retrying', opts.start)\n        exports.lock(path, opts, cb)\n      }\n    }})(cb)\n  }\n\n  // try to engage the lock.\n  // if this succeeds, then we're in business.\n  fs.open(path, wx, function (er, fd) {\n    if (!er) {\n      debug('locked', path, fd)\n      locks[path] = fd\n      return fs.close(fd, function () {\n        return cb()\n      })\n    }\n\n    // something other than \"currently locked\"\n    // maybe eperm or something.\n    if (er.code !== 'EEXIST') return cb(er)\n\n    // someone's got this one.  see if it's valid.\n    if (!opts.stale) return notStale(er, path, opts, cb)\n\n    return maybeStale(er, path, opts, false, cb)\n  })\n}\n\n\n// Staleness checking algorithm\n// 1. acquire $lock, fail\n// 2. stat $lock, find that it is stale\n// 3. acquire $lock.STALE\n// 4. stat $lock, assert that it is still stale\n// 5. unlink $lock\n// 6. link $lock.STALE $lock\n// 7. unlink $lock.STALE\n// On any failure, clean up whatever we've done, and raise the error.\nfunction maybeStale (originalEr, path, opts, hasStaleLock, cb) {\n  fs.stat(path, function (statEr, st) {\n    if (statEr) {\n      if (statEr.code === 'ENOENT') {\n        // expired already!\n        opts.stale = false\n        debug('lock stale enoent retry', path, opts)\n        exports.lock(path, opts, cb)\n        return\n      }\n      return cb(statEr)\n    }\n\n    var age = Date.now() - st[exports.filetime].getTime()\n    if (age <= opts.stale) return notStale(originalEr, path, opts, cb)\n\n    debug('lock stale', path, opts)\n    if (hasStaleLock) {\n      exports.unlock(path, function (er) {\n        if (er) return cb(er)\n        debug('lock stale retry', path, opts)\n        fs.link(path + '.STALE', path, function (er) {\n          fs.unlink(path + '.STALE', function () {\n            // best effort.  if the unlink fails, oh well.\n            cb(er)\n          })\n        })\n      })\n    } else {\n      debug('acquire .STALE file lock', opts)\n      exports.lock(path + '.STALE', opts, function (er) {\n        if (er) return cb(er)\n        maybeStale(originalEr, path, opts, true, cb)\n      })\n    }\n  })\n}\n\nfunction notStale (er, path, opts, cb) {\n  debug('notStale', path, opts)\n\n  // if we can't wait, then just call it a failure\n  if (typeof opts.wait !== 'number' || opts.wait <= 0)\n    return cb(er)\n\n  // poll for some ms for the lock to clear\n  var now = Date.now()\n  var start = opts.start || now\n  var end = start + opts.wait\n\n  if (end <= now)\n    return cb(er)\n\n  debug('now=%d, wait until %d (delta=%d)', start, end, end-start)\n  var wait = Math.min(end - start, opts.pollPeriod || 100)\n  var timer = setTimeout(poll, wait)\n\n  function poll () {\n    debug('notStale, polling', path, opts)\n    exports.lock(path, opts, cb)\n  }\n}\n\nexports.lockSync = function (path, opts) {\n  opts = opts || {}\n  opts.req = opts.req || req++\n  debug('lockSync', path, opts)\n  if (opts.wait || opts.retryWait) {\n    throw new Error('opts.wait not supported sync for obvious reasons')\n  }\n\n  try {\n    var fd = fs.openSync(path, wx)\n    locks[path] = fd\n    try { fs.closeSync(fd) } catch (er) {}\n    debug('locked sync!', path, fd)\n    return\n  } catch (er) {\n    if (er.code !== 'EEXIST') return retryThrow(path, opts, er)\n\n    if (opts.stale) {\n      var st = fs.statSync(path)\n      var ct = st[exports.filetime].getTime()\n      if (!(ct % 1000) && (opts.stale % 1000)) {\n        // probably don't have subsecond resolution.\n        // round up the staleness indicator.\n        // Yes, this will be wrong 1/1000 times on platforms\n        // with subsecond stat precision, but that's acceptable\n        // in exchange for not mistakenly removing locks on\n        // most other systems.\n        opts.stale = 1000 * Math.ceil(opts.stale / 1000)\n      }\n      var age = Date.now() - ct\n      if (age > opts.stale) {\n        debug('lockSync stale', path, opts, age)\n        exports.unlockSync(path)\n        return exports.lockSync(path, opts)\n      }\n    }\n\n    // failed to lock!\n    debug('failed to lock', path, opts, er)\n    return retryThrow(path, opts, er)\n  }\n}\n\nfunction retryThrow (path, opts, er) {\n  if (typeof opts.retries === 'number' && opts.retries > 0) {\n    var newRT = opts.retries - 1\n    debug('retryThrow', path, opts, newRT)\n    opts.retries = newRT\n    return exports.lockSync(path, opts)\n  }\n  throw er\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/ls.js":"// show the installed versions of packages\n//\n// --parseable creates output like this:\n// <fullpath>:<name@ver>:<realpath>:<flags>\n// Flags are a :-separated list of zero or more indicators\n\nmodule.exports = exports = ls\n\nvar path = require('path')\nvar url = require('url')\nvar readPackageTree = require('read-package-tree')\nvar log = require('npmlog')\nvar archy = require('archy')\nvar semver = require('semver')\nvar color = require('ansicolors')\nvar npa = require('npm-package-arg')\nvar iferr = require('iferr')\nvar sortedObject = require('sorted-object')\nvar extend = Object.assign || require('util')._extend\nvar npm = require('./npm.js')\nvar mutateIntoLogicalTree = require('./install/mutate-into-logical-tree.js')\nvar recalculateMetadata = require('./install/deps.js').recalculateMetadata\nvar packageId = require('./utils/package-id.js')\nvar usage = require('./utils/usage')\nvar output = require('./utils/output.js')\n\nls.usage = usage(\n  'ls',\n  'npm ls [[<@scope>/]<pkg> ...]'\n)\n\nls.completion = require('./utils/completion/installed-deep.js')\n\nfunction ls (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n  var dir = path.resolve(npm.dir, '..')\n  readPackageTree(dir, andRecalculateMetadata(iferr(cb, function (physicalTree) {\n    lsFromTree(dir, physicalTree, args, silent, cb)\n  })))\n}\n\nfunction andRecalculateMetadata (next) {\n  return function (er, tree) {\n    recalculateMetadata(tree || {}, log, next)\n  }\n}\n\nfunction inList (list, value) {\n  return list.indexOf(value) !== -1\n}\n\nvar lsFromTree = ls.fromTree = function (dir, physicalTree, args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n\n  // npm ls 'foo@~1.3' bar 'baz@<2'\n  if (!args) {\n    args = []\n  } else {\n    args = args.map(function (a) {\n      var p = npa(a)\n      var name = p.name\n      // When version spec is missing, we'll skip using it when filtering.\n      // Otherwise, `semver.validRange` would return '*', which won't\n      // match prerelease versions.\n      var ver = (p.rawSpec &&\n                 (semver.validRange(p.rawSpec) || ''))\n      return [ name, ver, a ]\n    })\n  }\n\n  var data = mutateIntoLogicalTree.asReadInstalled(physicalTree)\n\n  pruneNestedExtraneous(data)\n  filterByEnv(data)\n  var unlooped = filterFound(unloop(data), args)\n  var lite = getLite(unlooped)\n\n  if (silent) return cb(null, data, lite)\n\n  var long = npm.config.get('long')\n  var json = npm.config.get('json')\n  var out\n  if (json) {\n    var seen = []\n    var d = long ? unlooped : lite\n    // the raw data can be circular\n    out = JSON.stringify(d, function (k, o) {\n      if (typeof o === 'object') {\n        if (inList(seen, o)) return '[Circular]'\n        seen.push(o)\n      }\n      return o\n    }, 2)\n  } else if (npm.config.get('parseable')) {\n    out = makeParseable(unlooped, long, dir)\n  } else if (data) {\n    out = makeArchy(unlooped, long, dir)\n  }\n  output(out)\n\n  if (args.length && !data._found) process.exitCode = 1\n\n  var er\n  // if any errors were found, then complain and exit status 1\n  if (lite.problems && lite.problems.length) {\n    er = lite.problems.join('\\n')\n  }\n  cb(er, data, lite)\n}\n\nfunction pruneNestedExtraneous (data, visited) {\n  visited = visited || []\n  visited.push(data)\n  for (var i in data.dependencies) {\n    if (data.dependencies[i].extraneous) {\n      data.dependencies[i].dependencies = {}\n    } else if (visited.indexOf(data.dependencies[i]) === -1) {\n      pruneNestedExtraneous(data.dependencies[i], visited)\n    }\n  }\n}\n\nfunction filterByEnv (data) {\n  var dev = npm.config.get('dev') || /^dev(elopment)?$/.test(npm.config.get('only'))\n  var production = npm.config.get('production') || /^prod(uction)?$/.test(npm.config.get('only'))\n  var dependencies = {}\n  var devKeys = Object.keys(data.devDependencies || [])\n  var prodKeys = Object.keys(data._dependencies || [])\n  Object.keys(data.dependencies).forEach(function (name) {\n    if (!dev && inList(devKeys, name) && data.dependencies[name].missing) {\n      return\n    }\n\n    if ((dev && inList(devKeys, name)) ||            // only --dev\n        (production && inList(prodKeys, name)) ||    // only --production\n        (!dev && !production)) {                            // no --production|--dev|--only=xxx\n      dependencies[name] = data.dependencies[name]\n    }\n  })\n  data.dependencies = dependencies\n}\n\nfunction alphasort (a, b) {\n  a = a.toLowerCase()\n  b = b.toLowerCase()\n  return a > b ? 1\n       : a < b ? -1 : 0\n}\n\nfunction isCruft (data) {\n  return data.extraneous && data.error && data.error.code === 'ENOTDIR'\n}\n\nfunction getLite (data, noname, depth) {\n  var lite = {}\n\n  if (isCruft(data)) return lite\n\n  var maxDepth = npm.config.get('depth')\n\n  if (typeof depth === 'undefined') depth = 0\n  if (!noname && data.name) lite.name = data.name\n  if (data.version) lite.version = data.version\n  if (data.extraneous) {\n    lite.extraneous = true\n    lite.problems = lite.problems || []\n    lite.problems.push('extraneous: ' + packageId(data) + ' ' + (data.path || ''))\n  }\n\n  if (data.error && data.path !== path.resolve(npm.globalDir, '..') &&\n      (data.error.code !== 'ENOENT' || noname)) {\n    lite.invalid = true\n    lite.problems = lite.problems || []\n    var message = data.error.message\n    lite.problems.push('error in ' + data.path + ': ' + message)\n  }\n\n  if (data._from) {\n    lite.from = data._from\n  }\n\n  if (data._resolved) {\n    lite.resolved = data._resolved\n  }\n\n  if (data.invalid) {\n    lite.invalid = true\n    lite.problems = lite.problems || []\n    lite.problems.push('invalid: ' +\n                       packageId(data) +\n                       ' ' + (data.path || ''))\n  }\n\n  if (data.peerInvalid) {\n    lite.peerInvalid = true\n    lite.problems = lite.problems || []\n    lite.problems.push('peer dep not met: ' +\n                       packageId(data) +\n                       ' ' + (data.path || ''))\n  }\n\n  var deps = (data.dependencies && Object.keys(data.dependencies)) || []\n  if (deps.length) {\n    lite.dependencies = deps.map(function (d) {\n      var dep = data.dependencies[d]\n      if (dep.missing && !dep.optional) {\n        lite.problems = lite.problems || []\n        var p\n        if (data.depth > maxDepth) {\n          p = 'max depth reached: '\n        } else {\n          p = 'missing: '\n        }\n        p += d + '@' + dep.requiredBy +\n            ', required by ' +\n            packageId(data)\n        lite.problems.push(p)\n        return [d, { required: dep.requiredBy, missing: true }]\n      } else if (dep.peerMissing) {\n        lite.problems = lite.problems || []\n        dep.peerMissing.forEach(function (missing) {\n          var pdm = 'peer dep missing: ' +\n              missing.requires +\n              ', required by ' +\n              missing.requiredBy\n          lite.problems.push(pdm)\n        })\n        return [d, { required: dep, peerMissing: true }]\n      } else if (npm.config.get('json')) {\n        if (depth === maxDepth) delete dep.dependencies\n        return [d, getLite(dep, true, depth + 1)]\n      }\n      return [d, getLite(dep, true)]\n    }).reduce(function (deps, d) {\n      if (d[1].problems) {\n        lite.problems = lite.problems || []\n        lite.problems.push.apply(lite.problems, d[1].problems)\n      }\n      deps[d[0]] = d[1]\n      return deps\n    }, {})\n  }\n  return lite\n}\n\nfunction unloop (root) {\n  var queue = [root]\n  var seen = {}\n  seen[root.path] = true\n\n  while (queue.length) {\n    var current = queue.shift()\n    var deps = current.dependencies = current.dependencies || {}\n    Object.keys(deps).forEach(function (d) {\n      var dep = deps[d]\n      if (dep.missing) return\n      if (dep.path && seen[dep.path]) {\n        dep = deps[d] = extend({}, dep)\n        dep.dependencies = {}\n        dep._deduped = path.relative(root.path, dep.path).replace(/node_modules\\//g, '')\n        return\n      }\n      seen[dep.path] = true\n      queue.push(dep)\n    })\n  }\n\n  return root\n}\n\nfunction filterFound (root, args) {\n  if (!args.length) return root\n  if (!root.dependencies) return root\n\n  // Mark all deps\n  var toMark = [root]\n  while (toMark.length) {\n    var markPkg = toMark.shift()\n    var markDeps = markPkg.dependencies\n    if (!markDeps) continue\n    Object.keys(markDeps).forEach(function (depName) {\n      var dep = markDeps[depName]\n      if (dep.peerMissing) return\n      dep._parent = markPkg\n      for (var ii = 0; ii < args.length; ii++) {\n        var argName = args[ii][0]\n        var argVersion = args[ii][1]\n        var argRaw = args[ii][2]\n        var found\n        if (depName === argName && argVersion) {\n          found = semver.satisfies(dep.version, argVersion, true)\n        } else if (depName === argName) {\n          // If version is missing from arg, just do a name match.\n          found = true\n        } else if (dep.path === argRaw) {\n          found = true\n        }\n        if (found) {\n          dep._found = 'explicit'\n          var parent = dep._parent\n          while (parent && !parent._found && !parent._deduped) {\n            parent._found = 'implicit'\n            parent = parent._parent\n          }\n          break\n        }\n      }\n      toMark.push(dep)\n    })\n  }\n  var toTrim = [root]\n  while (toTrim.length) {\n    var trimPkg = toTrim.shift()\n    var trimDeps = trimPkg.dependencies\n    if (!trimDeps) continue\n    trimPkg.dependencies = {}\n    Object.keys(trimDeps).forEach(function (name) {\n      var dep = trimDeps[name]\n      if (!dep._found) return\n      if (dep._found === 'implicit' && dep._deduped) return\n      trimPkg.dependencies[name] = dep\n      toTrim.push(dep)\n    })\n  }\n  return root\n}\n\nfunction makeArchy (data, long, dir) {\n  var out = makeArchy_(data, long, dir, 0)\n  return archy(out, '', { unicode: npm.config.get('unicode') })\n}\n\nfunction makeArchy_ (data, long, dir, depth, parent, d) {\n  if (data.missing) {\n    if (depth - 1 <= npm.config.get('depth')) {\n      // just missing\n      var unmet = 'UNMET ' + (data.optional ? 'OPTIONAL ' : '') + 'DEPENDENCY'\n      if (npm.color) {\n        if (data.optional) {\n          unmet = color.bgBlack(color.yellow(unmet))\n        } else {\n          unmet = color.bgBlack(color.red(unmet))\n        }\n      }\n      data = unmet + ' ' + d + '@' + data.requiredBy\n    } else {\n      data = d + '@' + data.requiredBy\n    }\n    return data\n  }\n\n  var out = {}\n  // the top level is a bit special.\n  out.label = data._id || ''\n  if (data._found === 'explicit' && data._id) {\n    if (npm.color) {\n      out.label = color.bgBlack(color.yellow(out.label.trim())) + ' '\n    } else {\n      out.label = out.label.trim() + ' '\n    }\n  }\n  if (data.link) out.label += ' -> ' + data.link\n\n  if (data._deduped) {\n    if (npm.color) {\n      out.label += ' ' + color.brightBlack('deduped')\n    } else {\n      out.label += ' deduped'\n    }\n  }\n\n  if (data.invalid) {\n    if (data.realName !== data.name) out.label += ' (' + data.realName + ')'\n    var invalid = 'invalid'\n    if (npm.color) invalid = color.bgBlack(color.red(invalid))\n    out.label += ' ' + invalid\n  }\n\n  if (data.peerInvalid) {\n    var peerInvalid = 'peer invalid'\n    if (npm.color) peerInvalid = color.bgBlack(color.red(peerInvalid))\n    out.label += ' ' + peerInvalid\n  }\n\n  if (data.peerMissing) {\n    var peerMissing = 'UNMET PEER DEPENDENCY'\n\n    if (npm.color) peerMissing = color.bgBlack(color.red(peerMissing))\n    out.label = peerMissing + ' ' + out.label\n  }\n\n  if (data.extraneous && data.path !== dir) {\n    var extraneous = 'extraneous'\n    if (npm.color) extraneous = color.bgBlack(color.green(extraneous))\n    out.label += ' ' + extraneous\n  }\n\n  if (data.error && depth) {\n    var message = data.error.message\n    if (message.indexOf('\\n')) message = message.slice(0, message.indexOf('\\n'))\n    var error = 'error: ' + message\n    if (npm.color) error = color.bgRed(color.brightWhite(error))\n    out.label += ' ' + error\n  }\n\n  // add giturl to name@version\n  if (data._resolved) {\n    try {\n      var type = npa(data._resolved).type\n      var isGit = type === 'git' || type === 'hosted'\n      if (isGit) {\n        out.label += ' (' + data._resolved + ')'\n      }\n    } catch (ex) {\n      // npa threw an exception then it ain't git so whatev\n    }\n  }\n\n  if (long) {\n    if (dir === data.path) out.label += '\\n' + dir\n    out.label += '\\n' + getExtras(data, dir)\n  } else if (dir === data.path) {\n    if (out.label) out.label += ' '\n    out.label += dir\n  }\n\n  // now all the children.\n  out.nodes = []\n  if (depth <= npm.config.get('depth')) {\n    out.nodes = Object.keys(data.dependencies || {})\n      .sort(alphasort).filter(function (d) {\n        return !isCruft(data.dependencies[d])\n      }).map(function (d) {\n        return makeArchy_(sortedObject(data.dependencies[d]), long, dir, depth + 1, data, d)\n      })\n  }\n\n  if (out.nodes.length === 0 && data.path === dir) {\n    out.nodes = ['(empty)']\n  }\n\n  return out\n}\n\nfunction getExtras (data) {\n  var extras = []\n\n  if (data.description) extras.push(data.description)\n  if (data.repository) extras.push(data.repository.url)\n  if (data.homepage) extras.push(data.homepage)\n  if (data._from) {\n    var from = data._from\n    if (from.indexOf(data.name + '@') === 0) {\n      from = from.substr(data.name.length + 1)\n    }\n    var u = url.parse(from)\n    if (u.protocol) extras.push(from)\n  }\n  return extras.join('\\n')\n}\n\nfunction makeParseable (data, long, dir, depth, parent, d) {\n  if (data._deduped) return []\n  depth = depth || 0\n  if (depth > npm.config.get('depth')) return [ makeParseable_(data, long, dir, depth, parent, d) ]\n  return [ makeParseable_(data, long, dir, depth, parent, d) ]\n    .concat(Object.keys(data.dependencies || {})\n      .sort(alphasort).map(function (d) {\n        return makeParseable(data.dependencies[d], long, dir, depth + 1, data, d)\n      }))\n    .filter(function (x) { return x })\n    .join('\\n')\n}\n\nfunction makeParseable_ (data, long, dir, depth, parent, d) {\n  if (data.hasOwnProperty('_found') && data._found !== 'explicit') return ''\n\n  if (data.missing) {\n    if (depth < npm.config.get('depth')) {\n      data = npm.config.get('long')\n           ? path.resolve(parent.path, 'node_modules', d) +\n             ':' + d + '@' + JSON.stringify(data.requiredBy) + ':INVALID:MISSING'\n           : ''\n    } else {\n      data = path.resolve(dir || '', 'node_modules', d || '') +\n             (npm.config.get('long')\n             ? ':' + d + '@' + JSON.stringify(data.requiredBy) +\n               ':' + // no realpath resolved\n               ':MAXDEPTH'\n             : '')\n    }\n\n    return data\n  }\n\n  if (!npm.config.get('long')) return data.path\n\n  return data.path +\n         ':' + (data._id || '') +\n         ':' + (data.realPath !== data.path ? data.realPath : '') +\n         (data.extraneous ? ':EXTRANEOUS' : '') +\n         (data.error && data.path !== path.resolve(npm.globalDir, '..') ? ':ERROR' : '') +\n         (data.invalid ? ':INVALID' : '') +\n         (data.peerInvalid ? ':PEERINVALID' : '') +\n         (data.peerMissing ? ':PEERINVALID:MISSING' : '')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/ansicolors/ansicolors.js":"// ColorCodes explained: http://www.termsys.demon.co.uk/vtansi.htm\n'use strict';\n\nvar colorNums = {\n      white         :  37\n    , black         :  30\n    , blue          :  34\n    , cyan          :  36\n    , green         :  32\n    , magenta       :  35\n    , red           :  31\n    , yellow        :  33\n    , brightBlack   :  90\n    , brightRed     :  91\n    , brightGreen   :  92\n    , brightYellow  :  93\n    , brightBlue    :  94\n    , brightMagenta :  95\n    , brightCyan    :  96\n    , brightWhite   :  97\n    }\n  , backgroundColorNums = {\n      bgBlack         :  40\n    , bgRed           :  41\n    , bgGreen         :  42\n    , bgYellow        :  43\n    , bgBlue          :  44\n    , bgMagenta       :  45\n    , bgCyan          :  46\n    , bgWhite         :  47\n    , bgBrightBlack   :  100\n    , bgBrightRed     :  101\n    , bgBrightGreen   :  102\n    , bgBrightYellow  :  103\n    , bgBrightBlue    :  104\n    , bgBrightMagenta :  105\n    , bgBrightCyan    :  106\n    , bgBrightWhite   :  107\n    } \n  , open   =  {}\n  , close  =  {}\n  , colors =  {}\n  ;\n\nObject.keys(colorNums).forEach(function (k) {\n  var o =  open[k]  =  '\\u001b[' + colorNums[k] + 'm';\n  var c =  close[k] =  '\\u001b[39m';\n\n  colors[k] = function (s) { \n    return o + s + c;\n  };\n});\n\nObject.keys(backgroundColorNums).forEach(function (k) {\n  var o =  open[k]  =  '\\u001b[' + backgroundColorNums[k] + 'm';\n  var c =  close[k] =  '\\u001b[49m';\n\n  colors[k] = function (s) { \n    return o + s + c;\n  };\n});\n\nmodule.exports =  colors;\ncolors.open    =  open;\ncolors.close   =  close;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-object/lib/sorted-object.js":"\"use strict\";\n\nmodule.exports = function (input) {\n    var output = {};\n\n    Object.keys(input).sort().forEach(function (key) {\n        output[key] = input[key];\n    });\n\n    return output;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/install/mutate-into-logical-tree.js":"'use strict'\nvar union = require('lodash.union')\nvar without = require('lodash.without')\nvar validate = require('aproba')\nvar flattenTree = require('./flatten-tree.js')\nvar isExtraneous = require('./is-extraneous.js')\nvar validateAllPeerDeps = require('./deps.js').validateAllPeerDeps\nvar packageId = require('../utils/package-id.js')\nvar moduleName = require('../utils/module-name.js')\n\n// Return true if tree is a part of a cycle that:\n//   A) Never connects to the top of the tree\n//   B) Has not not had a point in the cycle arbitraryly declared its top\n//      yet.\nfunction isDisconnectedCycle (tree, seen) {\n  if (!seen) seen = {}\n  if (tree.isTop || tree.cycleTop || tree.requiredBy.length === 0) {\n    return false\n  } else if (seen[tree.path]) {\n    return true\n  } else {\n    seen[tree.path] = true\n    return tree.requiredBy.every(function (node) {\n      return isDisconnectedCycle(node, Object.create(seen))\n    })\n  }\n}\n\nvar mutateIntoLogicalTree = module.exports = function (tree) {\n  validate('O', arguments)\n\n  validateAllPeerDeps(tree, function (tree, pkgname, version) {\n    if (!tree.missingPeers) tree.missingPeers = {}\n    tree.missingPeers[pkgname] = version\n  })\n\n  var flat = flattenTree(tree)\n\n  Object.keys(flat).sort().forEach(function (flatname) {\n    var node = flat[flatname]\n    if (!(node.requiredBy && node.requiredBy.length)) return\n\n    if (node.parent) {\n      // If a node is a cycle that never reaches the root of the logical\n      // tree then we'll leave it attached to the root, or else it\n      // would go missing. Further we'll note that this is the node in the\n      // cycle that we picked arbitrarily to be the one attached to the root.\n      // others will fall\n      if (isDisconnectedCycle(node)) {\n        node.cycleTop = true\n      // Nor do we want to disconnect non-cyclical extraneous modules from the tree.\n      } else if (node.requiredBy.length) {\n        // regular deps though, we do, as we're moving them into the capable\n        // hands of the modules that require them.\n        node.parent.children = without(node.parent.children, node)\n      }\n    }\n\n    node.requiredBy.forEach(function (parentNode) {\n      parentNode.children = union(parentNode.children, [node])\n    })\n  })\n  return tree\n}\n\nmodule.exports.asReadInstalled = function (tree) {\n  mutateIntoLogicalTree(tree)\n  return translateTree(tree)\n}\n\nfunction translateTree (tree) {\n  return translateTree_(tree, {})\n}\n\nfunction translateTree_ (tree, seen) {\n  var pkg = tree.package\n  if (seen[tree.path]) return pkg\n  seen[tree.path] = pkg\n  if (pkg._dependencies) return pkg\n  pkg._dependencies = pkg.dependencies\n  pkg.dependencies = {}\n  tree.children.forEach(function (child) {\n    pkg.dependencies[moduleName(child)] = translateTree_(child, seen)\n  })\n\n  function markMissing (name, requiredBy) {\n    if (pkg.dependencies[name]) {\n      if (pkg.dependencies[name].missing) return\n      pkg.dependencies[name].invalid = true\n      pkg.dependencies[name].realName = name\n      pkg.dependencies[name].extraneous = false\n    } else {\n      pkg.dependencies[name] = {\n        requiredBy: requiredBy,\n        missing: true,\n        optional: !!pkg.optionalDependencies[name]\n      }\n    }\n  }\n\n  Object.keys(tree.missingDeps).forEach(function (name) {\n    markMissing(name, tree.missingDeps[name])\n  })\n  Object.keys(tree.missingDevDeps).forEach(function (name) {\n    markMissing(name, tree.missingDevDeps[name])\n  })\n  var checkForMissingPeers = (tree.parent ? [] : [tree]).concat(tree.children)\n  checkForMissingPeers.filter(function (child) {\n    return child.missingPeers\n  }).forEach(function (child) {\n    Object.keys(child.missingPeers).forEach(function (pkgname) {\n      var version = child.missingPeers[pkgname]\n      var peerPkg = pkg.dependencies[pkgname]\n      if (!peerPkg) {\n        peerPkg = pkg.dependencies[pkgname] = {\n          _id: pkgname + '@' + version,\n          name: pkgname,\n          version: version\n        }\n      }\n      if (!peerPkg.peerMissing) peerPkg.peerMissing = []\n      peerPkg.peerMissing.push({\n        requiredBy: packageId(child),\n        requires: pkgname + '@' + version\n      })\n    })\n  })\n  pkg.path = tree.path\n\n  pkg.error = tree.error\n  pkg.extraneous = isExtraneous(tree)\n  if (tree.target && tree.parent && !tree.parent.target) pkg.link = tree.realpath\n  return pkg\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/install/flatten-tree.js":"'use strict'\nvar validate = require('aproba')\nvar moduleName = require('../utils/module-name.js')\n\nmodule.exports = flattenTree\nmodule.exports.flatName = flatName\nmodule.exports.flatNameFromTree = flatNameFromTree\n\nfunction flattenTree (tree) {\n  validate('O', arguments)\n  var seen = {}\n  var flat = {}\n  var todo = [[tree, '/']]\n  while (todo.length) {\n    var next = todo.shift()\n    var pkg = next[0]\n    seen[pkg.path] = true\n    var path = next[1]\n    flat[path] = pkg\n    if (path !== '/') path += '/'\n    for (var ii = 0; ii < pkg.children.length; ++ii) {\n      var child = pkg.children[ii]\n      if (!seen[child.path]) {\n        todo.push([child, flatName(path, child)])\n      }\n    }\n  }\n  return flat\n}\n\nfunction flatName (path, child) {\n  validate('SO', arguments)\n  return path + (moduleName(child) || 'TOP')\n}\n\nfunction flatNameFromTree (tree) {\n  validate('O', arguments)\n  if (tree.isTop) return '/'\n  var path = flatNameFromTree(tree.parent)\n  if (path !== '/') path += '/'\n  return flatName(path, tree)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/install/is-extraneous.js":"'use strict'\nmodule.exports = isExtraneous\n\nfunction isExtraneous (tree) {\n  var result = !isNotExtraneous(tree)\n  return result\n}\n\nfunction isNotRequired (tree) {\n  return tree.requiredBy && tree.requiredBy.length === 0\n}\n\nfunction parentHasNoPjson (tree) {\n  return tree.parent && tree.parent.isTop && tree.parent.error\n}\n\nfunction topHasNoPjson (tree) {\n  var top = tree\n  while (!top.isTop) top = top.parent\n  return top.error\n}\n\nfunction isNotExtraneous (tree, isCycle) {\n  if (!isCycle) isCycle = {}\n  if (tree.isTop || tree.userRequired) {\n    return true\n  } else if (isNotRequired(tree) && parentHasNoPjson(tree)) {\n    return true\n  } else if (isCycle[tree.path]) {\n    return topHasNoPjson(tree)\n  } else {\n    isCycle[tree.path] = true\n    return tree.requiredBy && tree.requiredBy.some(function (node) {\n      return isNotExtraneous(node, Object.create(isCycle))\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/install/deps.js":"'use strict'\nvar assert = require('assert')\nvar path = require('path')\nvar semver = require('semver')\nvar asyncMap = require('slide').asyncMap\nvar chain = require('slide').chain\nvar union = require('lodash.union')\nvar iferr = require('iferr')\nvar npa = require('npm-package-arg')\nvar validate = require('aproba')\nvar realizePackageSpecifier = require('realize-package-specifier')\nvar realizeShrinkwrapSpecifier = require('./realize-shrinkwrap-specifier')\nvar asap = require('asap')\nvar dezalgo = require('dezalgo')\nvar fetchPackageMetadata = require('../fetch-package-metadata.js')\nvar andAddParentToErrors = require('./and-add-parent-to-errors.js')\nvar addShrinkwrap = require('../fetch-package-metadata.js').addShrinkwrap\nvar addBundled = require('../fetch-package-metadata.js').addBundled\nvar readShrinkwrap = require('./read-shrinkwrap.js')\nvar inflateShrinkwrap = require('./inflate-shrinkwrap.js')\nvar inflateBundled = require('./inflate-bundled.js')\nvar andFinishTracker = require('./and-finish-tracker.js')\nvar npm = require('../npm.js')\nvar flatNameFromTree = require('./flatten-tree.js').flatNameFromTree\nvar createChild = require('./node.js').create\nvar resetMetadata = require('./node.js').reset\nvar andIgnoreErrors = require('./and-ignore-errors.js')\nvar isInstallable = require('./validate-args.js').isInstallable\nvar packageId = require('../utils/package-id.js')\nvar moduleName = require('../utils/module-name.js')\nvar isDevDep = require('./is-dev-dep.js')\nvar isProdDep = require('./is-prod-dep.js')\nvar reportOptionalFailure = require('./report-optional-failure.js')\n\n// The export functions in this module mutate a dependency tree, adding\n// items to them.\n\nfunction isDep (tree, child, cb) {\n  var name = moduleName(child)\n  var prodVer = isProdDep(tree, name)\n  var devVer = isDevDep(tree, name)\n\n  childDependencySpecifier(tree, name, prodVer, function (er, prodSpec) {\n    if (er) return cb(child.fromShrinkwrap)\n    var matches\n    if (prodSpec) matches = doesChildVersionMatch(child, prodSpec, tree)\n    if (matches) return cb(true, prodSpec)\n    if (devVer === prodVer) return cb(child.fromShrinkwrap)\n    childDependencySpecifier(tree, name, devVer, function (er, devSpec) {\n      if (er) return cb(child.fromShrinkwrap)\n      cb(doesChildVersionMatch(child, devSpec, tree) || child.fromShrinkwrap, null, devSpec)\n    })\n  })\n}\n\nvar registryTypes = { range: true, version: true }\n\nfunction doesChildVersionMatch (child, requested, requestor) {\n  // we always consider deps provided by a shrinkwrap as \"correct\" or else\n  // we'll subvert them if they're intentionally \"invalid\"\n  if (child.parent === requestor && child.fromShrinkwrap) return true\n  // ranges of * ALWAYS count as a match, because when downloading we allow\n  // prereleases to match * if there are ONLY prereleases\n  if (requested.spec === '*') return true\n\n  var childReq = child.package._requested\n  if (!childReq) childReq = npa(moduleName(child) + '@' + child.package._from)\n  if (childReq) {\n    if (childReq.rawSpec === requested.rawSpec) return true\n    if (childReq.type === requested.type && childReq.spec === requested.spec) return true\n  }\n  // If _requested didn't exist OR if it didn't match then we'll try using\n  // _from. We pass it through npa to normalize the specifier.\n  // This can happen when installing from an `npm-shrinkwrap.json` where `_requested` will\n  // be the tarball URL from `resolved` and thus can't match what's in the `package.json`.\n  // In those cases _from, will be preserved and we can compare that to ensure that they\n  // really came from the same sources.\n  // You'll see this scenario happen with at least tags and git dependencies.\n  if (!registryTypes[requested.type]) {\n    if (child.package._from) {\n      var fromReq = npa(child.package._from)\n      if (fromReq.rawSpec === requested.rawSpec) return true\n      if (fromReq.type === requested.type && fromReq.spec === requested.spec) return true\n    }\n    return false\n  }\n  return semver.satisfies(child.package.version, requested.spec)\n}\n\n// TODO: Rename to maybe computeMetadata or computeRelationships\nexports.recalculateMetadata = function (tree, log, next) {\n  recalculateMetadata(tree, log, {}, next)\n}\n\nexports._childDependencySpecifier = childDependencySpecifier\nfunction childDependencySpecifier (tree, name, spec, cb) {\n  if (!tree.resolved) tree.resolved = {}\n  if (!tree.resolved[name]) tree.resolved[name] = {}\n  if (tree.resolved[name][spec]) {\n    return asap(function () {\n      cb(null, tree.resolved[name][spec])\n    })\n  }\n  realizePackageSpecifier(name + '@' + spec, packageRelativePath(tree), function (er, req) {\n    if (er) return cb(er)\n    tree.resolved[name][spec] = req\n    cb(null, req)\n  })\n}\n\nfunction recalculateMetadata (tree, log, seen, next) {\n  validate('OOOF', arguments)\n  if (seen[tree.path]) return next()\n  seen[tree.path] = true\n  if (tree.parent == null) {\n    resetMetadata(tree)\n    tree.isTop = true\n  }\n\n  function markDeps (toMark, done) {\n    var name = toMark.name\n    var spec = toMark.spec\n    var kind = toMark.kind\n    childDependencySpecifier(tree, name, spec, function (er, req) {\n      if (er || !req.name) return done()\n      var child = findRequirement(tree, req.name, req)\n      if (child) {\n        resolveWithExistingModule(child, tree, log, andIgnoreErrors(done))\n      } else if (kind === 'dep') {\n        tree.missingDeps[req.name] = req.rawSpec\n        done()\n      } else if (kind === 'dev') {\n        tree.missingDevDeps[req.name] = req.rawSpec\n        done()\n      } else {\n        done()\n      }\n    })\n  }\n\n  function makeMarkable (deps, kind) {\n    if (!deps) return []\n    return Object.keys(deps).map(function (depname) { return { name: depname, spec: deps[depname], kind: kind } })\n  }\n\n  // Ensure dependencies and dev dependencies are marked as required\n  var tomark = makeMarkable(tree.package.dependencies, 'dep')\n  if (tree.isTop) tomark = union(tomark, makeMarkable(tree.package.devDependencies, 'dev'))\n\n  // Ensure any children ONLY from a shrinkwrap are also included\n  var childrenOnlyInShrinkwrap = tree.children.filter(function (child) {\n    return child.fromShrinkwrap &&\n      !tree.package.dependencies[child.package.name] &&\n      !tree.package.devDependencies[child.package.name]\n  })\n  var tomarkOnlyInShrinkwrap = childrenOnlyInShrinkwrap.map(function (child) {\n    var name = child.package.name\n    var matched = child.package._spec.match(/^@?[^@]+@(.*)$/)\n    var spec = matched ? matched[1] : child.package._spec\n    var kind = tree.package.dependencies[name] ? 'dep'\n             : tree.package.devDependencies[name] ? 'dev'\n             : 'dep'\n    return { name: name, spec: spec, kind: kind }\n  })\n  tomark = union(tomark, tomarkOnlyInShrinkwrap)\n\n  // Don't bother trying to recalc children of failed deps\n  tree.children = tree.children.filter(function (child) { return !child.failed })\n\n  chain([\n    [asyncMap, tomark, markDeps],\n    [asyncMap, tree.children, function (child, done) { recalculateMetadata(child, log, seen, done) }]\n  ], function () {\n    tree.location = flatNameFromTree(tree)\n    next(null, tree)\n  })\n}\n\nfunction addRequiredDep (tree, child, cb) {\n  isDep(tree, child, function (childIsDep, childIsProdDep, childIsDevDep) {\n    if (!childIsDep) return cb(false)\n    replaceModuleByPath(child, 'requiredBy', tree)\n    replaceModuleByName(tree, 'requires', child)\n    if (childIsProdDep && tree.missingDeps) delete tree.missingDeps[moduleName(child)]\n    if (childIsDevDep && tree.missingDevDeps) delete tree.missingDevDeps[moduleName(child)]\n    cb(true)\n  })\n}\n\nexports.removeObsoleteDep = removeObsoleteDep\nfunction removeObsoleteDep (child, log) {\n  if (child.removed) return\n  child.removed = true\n  if (log) {\n    log.silly('removeObsoleteDep', 'removing ' + packageId(child) +\n      ' from the tree as its been replaced by a newer version or is no longer required')\n  }\n  // remove from physical tree\n  if (child.parent) {\n    child.parent.children = child.parent.children.filter(function (pchild) { return pchild !== child })\n  }\n  // remove from logical tree\n  var requires = child.requires || []\n  requires.forEach(function (requirement) {\n    requirement.requiredBy = requirement.requiredBy.filter(function (reqBy) { return reqBy !== child })\n    if (requirement.requiredBy.length === 0) removeObsoleteDep(requirement, log)\n  })\n}\n\nfunction matchingDep (tree, name) {\n  if (tree.package.dependencies && tree.package.dependencies[name]) return tree.package.dependencies[name]\n  if (tree.package.devDependencies && tree.package.devDependencies[name]) return tree.package.devDependencies[name]\n  return\n}\n\nfunction packageRelativePath (tree) {\n  if (!tree) return ''\n  var requested = tree.package._requested || {}\n  var isLocal = requested.type === 'directory' || requested.type === 'local'\n  return isLocal ? requested.spec : tree.path\n}\n\nfunction getShrinkwrap (tree, name) {\n  return tree.package._shrinkwrap && tree.package._shrinkwrap.dependencies && tree.package._shrinkwrap.dependencies[name]\n}\n\nexports.getAllMetadata = function (args, tree, where, next) {\n  asyncMap(args, function (arg, done) {\n    function fetchMetadataWithVersion () {\n      var version = matchingDep(tree, arg)\n      var spec = version == null ? arg : arg + '@' + version\n      return fetchPackageMetadata(spec, where, done)\n    }\n    if (tree && arg.lastIndexOf('@') <= 0) {\n      var sw = getShrinkwrap(tree, arg)\n      if (sw) {\n        return realizeShrinkwrapSpecifier(arg, sw, where, function (err, spec) {\n          if (err) {\n            return fetchMetadataWithVersion()\n          } else {\n            return fetchPackageMetadata(spec, where, done)\n          }\n        })\n      } else {\n        return fetchMetadataWithVersion()\n      }\n    } else {\n      return fetchPackageMetadata(arg, where, done)\n    }\n  }, next)\n}\n\n// Add a list of args to tree's top level dependencies\nexports.loadRequestedDeps = function (args, tree, saveToDependencies, log, next) {\n  validate('AOOF', [args, tree, log, next])\n  asyncMap(args, function (pkg, done) {\n    var depLoaded = andAddParentToErrors(tree, done)\n    resolveWithNewModule(pkg, tree, log.newGroup('loadRequestedDeps'), iferr(depLoaded, function (child, tracker) {\n      validate('OO', arguments)\n      if (npm.config.get('global')) {\n        child.isGlobal = true\n      }\n      var childName = moduleName(child)\n      if (saveToDependencies) {\n        tree.package[saveToDependencies][childName] =\n          child.package._requested.rawSpec || child.package._requested.spec\n      }\n      if (saveToDependencies && saveToDependencies !== 'devDependencies') {\n        tree.package.dependencies[childName] =\n          child.package._requested.rawSpec || child.package._requested.spec\n      }\n      child.userRequired = true\n      child.save = saveToDependencies\n\n      // For things the user asked to install, that aren't a dependency (or\n      // won't be when we're done), flag it as \"depending\" on the user\n      // themselves, so we don't remove it as a dep that no longer exists\n      addRequiredDep(tree, child, function (childIsDep) {\n        if (!childIsDep) child.userRequired = true\n        depLoaded(null, child, tracker)\n      })\n    }))\n  }, andForEachChild(loadDeps, andFinishTracker(log, next)))\n}\n\nfunction moduleNameMatches (name) {\n  return function (child) { return moduleName(child) === name }\n}\n\nfunction noModuleNameMatches (name) {\n  return function (child) { return moduleName(child) !== name }\n}\n\n// while this implementation does not require async calling, doing so\n// gives this a consistent interface with loadDeps et al\nexports.removeDeps = function (args, tree, saveToDependencies, log, next) {\n  validate('AOOF', [args, tree, log, next])\n  args.forEach(function (pkg) {\n    var pkgName = moduleName(pkg)\n    var toRemove = tree.children.filter(moduleNameMatches(pkgName))\n    var pkgToRemove = toRemove[0] || createChild({package: {name: pkgName}})\n    if (saveToDependencies) {\n      replaceModuleByPath(tree, 'removed', pkgToRemove)\n      pkgToRemove.save = saveToDependencies\n    }\n    removeObsoleteDep(pkgToRemove)\n  })\n  log.finish()\n  next()\n}\n\nfunction andForEachChild (load, next) {\n  validate('F', [next])\n  next = dezalgo(next)\n  return function (er, children, logs) {\n    // when children is empty, logs won't be passed in at all (asyncMap is weird)\n    // so shortcircuit before arg validation\n    if (!er && (!children || children.length === 0)) return next()\n    validate('EAA', arguments)\n    if (er) return next(er)\n    assert(children.length === logs.length)\n    var cmds = []\n    for (var ii = 0; ii < children.length; ++ii) {\n      cmds.push([load, children[ii], logs[ii]])\n    }\n    var sortedCmds = cmds.sort(function installOrder (aa, bb) {\n      return moduleName(aa[1]).localeCompare(moduleName(bb[1]))\n    })\n    chain(sortedCmds, next)\n  }\n}\n\nfunction isDepOptional (tree, name, pkg) {\n  if (pkg.package && pkg.package._optional) return true\n  if (!tree.package.optionalDependencies) return false\n  if (tree.package.optionalDependencies[name] != null) return true\n  return false\n}\n\nvar failedDependency = exports.failedDependency = function (tree, name_pkg) {\n  var name\n  var pkg = {}\n  if (typeof name_pkg === 'string') {\n    name = name_pkg\n  } else {\n    pkg = name_pkg\n    name = moduleName(pkg)\n  }\n  tree.children = tree.children.filter(noModuleNameMatches(name))\n\n  if (isDepOptional(tree, name, pkg)) {\n    return false\n  }\n\n  tree.failed = true\n\n  if (tree.isTop) return true\n\n  if (tree.userRequired) return true\n\n  removeObsoleteDep(tree)\n\n  if (!tree.requiredBy) return false\n\n  for (var ii = 0; ii < tree.requiredBy.length; ++ii) {\n    var requireParent = tree.requiredBy[ii]\n    if (failedDependency(requireParent, tree.package)) {\n      return true\n    }\n  }\n  return false\n}\n\nfunction andHandleOptionalErrors (log, tree, name, done) {\n  validate('OOSF', arguments)\n  return function (er, child, childLog) {\n    if (!er) validate('OO', [child, childLog])\n    if (!er) return done(er, child, childLog)\n    var isFatal = failedDependency(tree, name)\n    if (er && !isFatal) {\n      tree.children = tree.children.filter(noModuleNameMatches(name))\n      reportOptionalFailure(tree, name, er)\n      return done()\n    } else {\n      return done(er, child, childLog)\n    }\n  }\n}\n\n// Load any missing dependencies in the given tree\nexports.loadDeps = loadDeps\nfunction loadDeps (tree, log, next) {\n  validate('OOF', arguments)\n  if (tree.loaded || (tree.parent && tree.parent.failed) || tree.removed) return andFinishTracker.now(log, next)\n  if (tree.parent) tree.loaded = true\n  if (!tree.package.dependencies) tree.package.dependencies = {}\n  asyncMap(Object.keys(tree.package.dependencies), function (dep, done) {\n    var version = tree.package.dependencies[dep]\n    if (tree.package.optionalDependencies &&\n        tree.package.optionalDependencies[dep] &&\n        !npm.config.get('optional')) {\n      return done()\n    }\n\n    addDependency(dep, version, tree, log.newGroup('loadDep:' + dep), andHandleOptionalErrors(log, tree, dep, done))\n  }, andForEachChild(loadDeps, andFinishTracker(log, next)))\n}\n\n// Load development dependencies into the given tree\nexports.loadDevDeps = function (tree, log, next) {\n  validate('OOF', arguments)\n  if (!tree.package.devDependencies) return andFinishTracker.now(log, next)\n  // if any of our prexisting children are from a shrinkwrap then we skip\n  // loading dev deps as the shrinkwrap will already have provided them for us.\n  if (tree.children.some(function (child) { return child.shrinkwrapDev })) {\n    return andFinishTracker.now(log, next)\n  }\n  asyncMap(Object.keys(tree.package.devDependencies), function (dep, done) {\n    // things defined as both dev dependencies and regular dependencies are treated\n    // as the former\n    if (tree.package.dependencies[dep]) return done()\n\n    var logGroup = log.newGroup('loadDevDep:' + dep)\n    addDependency(dep, tree.package.devDependencies[dep], tree, logGroup, done)\n  }, andForEachChild(loadDeps, andFinishTracker(log, next)))\n}\n\nvar loadExtraneous = exports.loadExtraneous = function (tree, log, next) {\n  var seen = {}\n  function loadExtraneous (tree, log, next) {\n    validate('OOF', arguments)\n    if (seen[tree.path]) return next()\n    seen[tree.path] = true\n    asyncMap(tree.children.filter(function (child) { return !child.loaded }), function (child, done) {\n      resolveWithExistingModule(child, tree, log, done)\n    }, andForEachChild(loadExtraneous, andFinishTracker(log, next)))\n  }\n  loadExtraneous(tree, log, next)\n}\n\nexports.loadExtraneous.andResolveDeps = function (tree, log, next) {\n  validate('OOF', arguments)\n  // For canonicalized trees (eg from shrinkwrap) we don't want to bother\n  // resolving the dependencies of extraneous deps.\n  if (tree.loaded) return loadExtraneous(tree, log, next)\n  asyncMap(tree.children.filter(function (child) { return !child.loaded }), function (child, done) {\n    resolveWithExistingModule(child, tree, log, done)\n  }, andForEachChild(loadDeps, andFinishTracker(log, next)))\n}\n\nfunction addDependency (name, versionSpec, tree, log, done) {\n  validate('SSOOF', arguments)\n  var next = andAddParentToErrors(tree, done)\n  childDependencySpecifier(tree, name, versionSpec, iferr(done, function (req) {\n    var child = findRequirement(tree, name, req)\n    if (child) {\n      resolveWithExistingModule(child, tree, log, iferr(next, function (child, log) {\n        if (child.package._shrinkwrap === undefined) {\n          readShrinkwrap.andInflate(child, function (er) { next(er, child, log) })\n        } else {\n          next(null, child, log)\n        }\n      }))\n    } else {\n      fetchPackageMetadata(req, packageRelativePath(tree), {tracker: log.newItem('fetchMetadata')}, iferr(next, function (pkg) {\n        resolveWithNewModule(pkg, tree, log, next)\n      }))\n    }\n  }))\n}\n\nfunction resolveWithExistingModule (child, tree, log, next) {\n  validate('OOOF', arguments)\n  addRequiredDep(tree, child, function () {\n    if (tree.parent && child.parent !== tree) updatePhantomChildren(tree.parent, child)\n    next(null, child, log)\n  })\n}\n\nvar updatePhantomChildren = exports.updatePhantomChildren = function (current, child) {\n  validate('OO', arguments)\n  while (current && current !== child.parent) {\n    if (!current.phantomChildren) current.phantomChildren = {}\n    current.phantomChildren[moduleName(child)] = child\n    current = current.parent\n  }\n}\n\nexports._replaceModuleByPath = replaceModuleByPath\nfunction replaceModuleByPath (obj, key, child) {\n  return replaceModule(obj, key, child, function (replacing, child) {\n    return replacing.path === child.path\n  })\n}\n\nexports._replaceModuleByName = replaceModuleByName\nfunction replaceModuleByName (obj, key, child) {\n  var childName = moduleName(child)\n  return replaceModule(obj, key, child, function (replacing, child) {\n    return moduleName(replacing) === childName\n  })\n}\n\nfunction replaceModule (obj, key, child, matchBy) {\n  validate('OSOF', arguments)\n  if (!obj[key]) obj[key] = []\n  // we replace children with a new array object instead of mutating it\n  // because mutating it results in weird failure states.\n  // I would very much like to know _why_ this is. =/\n  var children = [].concat(obj[key])\n  for (var replaceAt = 0; replaceAt < children.length; ++replaceAt) {\n    if (matchBy(children[replaceAt], child)) break\n  }\n  var replacing = children.splice(replaceAt, 1, child)\n  obj[key] = children\n  return replacing[0]\n}\n\nfunction resolveWithNewModule (pkg, tree, log, next) {\n  validate('OOOF', arguments)\n\n  log.silly('resolveWithNewModule', packageId(pkg), 'checking installable status')\n  return isInstallable(pkg, iferr(next, function () {\n    if (!pkg._from) {\n      pkg._from = pkg._requested.name + '@' + pkg._requested.spec\n    }\n    addShrinkwrap(pkg, iferr(next, function () {\n      addBundled(pkg, iferr(next, function () {\n        var parent = earliestInstallable(tree, tree, pkg) || tree\n        var child = createChild({\n          package: pkg,\n          parent: parent,\n          path: path.join(parent.path, 'node_modules', pkg.name),\n          realpath: path.resolve(parent.realpath, 'node_modules', pkg.name),\n          children: pkg._bundled || [],\n          isLink: tree.isLink,\n          knownInstallable: true\n        })\n        delete pkg._bundled\n        var hasBundled = child.children.length\n\n        var replaced = replaceModuleByName(parent, 'children', child)\n        if (replaced) removeObsoleteDep(replaced)\n        addRequiredDep(tree, child, function () {\n          child.location = flatNameFromTree(child)\n\n          if (tree.parent && parent !== tree) updatePhantomChildren(tree.parent, child)\n\n          if (hasBundled) {\n            inflateBundled(child, child, child.children)\n          }\n\n          if (pkg._shrinkwrap && pkg._shrinkwrap.dependencies) {\n            return inflateShrinkwrap(child, pkg._shrinkwrap.dependencies, function (er) {\n              next(er, child, log)\n            })\n          }\n\n          next(null, child, log)\n        })\n      }))\n    }))\n  }))\n}\n\nvar validatePeerDeps = exports.validatePeerDeps = function (tree, onInvalid) {\n  if (!tree.package.peerDependencies) return\n  Object.keys(tree.package.peerDependencies).forEach(function (pkgname) {\n    var version = tree.package.peerDependencies[pkgname]\n    var match = findRequirement(tree.parent || tree, pkgname, npa(pkgname + '@' + version))\n    if (!match) onInvalid(tree, pkgname, version)\n  })\n}\n\nexports.validateAllPeerDeps = function (tree, onInvalid) {\n  validateAllPeerDeps(tree, onInvalid, {})\n}\n\nfunction validateAllPeerDeps (tree, onInvalid, seen) {\n  validate('OFO', arguments)\n  if (seen[tree.path]) return\n  seen[tree.path] = true\n  validatePeerDeps(tree, onInvalid)\n  tree.children.forEach(function (child) { validateAllPeerDeps(child, onInvalid, seen) })\n}\n\n// Determine if a module requirement is already met by the tree at or above\n// our current location in the tree.\nvar findRequirement = exports.findRequirement = function (tree, name, requested, requestor) {\n  validate('OSO', [tree, name, requested])\n  if (!requestor) requestor = tree\n  var nameMatch = function (child) {\n    return moduleName(child) === name && child.parent && !child.removed\n  }\n  var versionMatch = function (child) {\n    return doesChildVersionMatch(child, requested, requestor)\n  }\n  if (nameMatch(tree)) {\n    // this *is* the module, but it doesn't match the version, so a\n    // new copy will have to be installed\n    return versionMatch(tree) ? tree : null\n  }\n\n  var matches = tree.children.filter(nameMatch)\n  if (matches.length) {\n    matches = matches.filter(versionMatch)\n    // the module exists as a dependent, but the version doesn't match, so\n    // a new copy will have to be installed above here\n    if (matches.length) return matches[0]\n    return null\n  }\n  if (tree.isTop) return null\n  return findRequirement(tree.parent, name, requested, requestor)\n}\n\n// Find the highest level in the tree that we can install this module in.\n// If the module isn't installed above us yet, that'd be the very top.\n// If it is, then it's the level below where its installed.\nvar earliestInstallable = exports.earliestInstallable = function (requiredBy, tree, pkg) {\n  validate('OOO', arguments)\n\n  function undeletedModuleMatches (child) {\n    return !child.removed && moduleName(child) === pkg.name\n  }\n  if (tree.children.some(undeletedModuleMatches)) return null\n\n  // If any of the children of this tree have conflicting\n  // binaries then we need to decline to install this package here.\n  var binaryMatches = pkg.bin && tree.children.some(function (child) {\n    if (child.removed || !child.package.bin) return false\n    return Object.keys(child.package.bin).some(function (bin) {\n      return pkg.bin[bin]\n    })\n  })\n\n  if (binaryMatches) return null\n\n  // if this tree location requested the same module then we KNOW it\n  // isn't compatible because if it were findRequirement would have\n  // found that version.\n  var deps = tree.package.dependencies || {}\n  if (!tree.removed && requiredBy !== tree && deps[pkg.name]) {\n    return null\n  }\n\n  var devDeps = tree.package.devDependencies || {}\n  if (tree.isTop && devDeps[pkg.name]) {\n    var requested = npa(pkg.name + '@' + devDeps[pkg.name])\n    if (!doesChildVersionMatch({package: pkg}, requested, tree)) {\n      return null\n    }\n  }\n\n  if (tree.phantomChildren && tree.phantomChildren[pkg.name]) return null\n\n  if (tree.isTop) return tree\n  if (tree.isGlobal) return tree\n\n  if (npm.config.get('global-style') && tree.parent.isTop) return tree\n  if (npm.config.get('legacy-bundling')) return tree\n\n  return (earliestInstallable(requiredBy, tree.parent, pkg) || tree)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/install/realize-shrinkwrap-specifier.js":"'use strict'\nvar realizePackageSpecifier = require('realize-package-specifier')\nvar isRegistrySpecifier = require('./is-registry-specifier.js')\n\nmodule.exports = function (name, sw, where, cb) {\n  function lookup (ver, cb) {\n    realizePackageSpecifier(name + '@' + ver, where, cb)\n  }\n  if (sw.resolved) {\n    return lookup(sw.resolved, cb)\n  } else if (sw.from) {\n    return lookup(sw.from, function (err, spec) {\n      if (err || isRegistrySpecifier(spec)) {\n        return thenUseVersion()\n      } else {\n        return cb(null, spec)\n      }\n    })\n  } else {\n    return thenUseVersion()\n  }\n  function thenUseVersion () {\n    lookup(sw.version, cb)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/install/is-registry-specifier.js":"'use strict'\nmodule.exports = isRegistrySpecifier\n\nfunction isRegistrySpecifier (spec) {\n  return spec.type === 'range' || spec.type === 'version' || spec.type === 'tag'\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/deprecate.js":"var npm = require('./npm.js')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar npa = require('npm-package-arg')\n\nmodule.exports = deprecate\n\ndeprecate.usage = 'npm deprecate <pkg>[@<version>] <message>'\n\ndeprecate.completion = function (opts, cb) {\n  // first, get a list of remote packages this user owns.\n  // once we have a user account, then don't complete anything.\n  if (opts.conf.argv.remain.length > 2) return cb()\n  // get the list of packages by user\n  var path = '/-/by-user/'\n  mapToRegistry(path, npm.config, function (er, uri, c) {\n    if (er) return cb(er)\n\n    if (!(c && c.username)) return cb()\n\n    var params = {\n      timeout: 60000,\n      auth: c\n    }\n    npm.registry.get(uri + c.username, params, function (er, list) {\n      if (er) return cb()\n      console.error(list)\n      return cb(null, list[c.username])\n    })\n  })\n}\n\nfunction deprecate (args, cb) {\n  var pkg = args[0]\n  var msg = args[1]\n  if (msg === undefined) return cb('Usage: ' + deprecate.usage)\n\n  // fetch the data and make sure it exists.\n  var p = npa(pkg)\n\n  // npa makes the default spec \"latest\", but for deprecation\n  // \"*\" is the appropriate default.\n  if (p.rawSpec === '') p.spec = '*'\n\n  mapToRegistry(p.name, npm.config, function (er, uri, auth) {\n    if (er) return cb(er)\n\n    var params = {\n      version: p.spec,\n      message: msg,\n      auth: auth\n    }\n    npm.registry.deprecate(uri, params, cb)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/doctor.js":"var path = require('path')\nvar chain = require('slide').chain\nvar table = require('text-table')\nvar color = require('ansicolors')\nvar styles = require('ansistyles')\nvar semver = require('semver')\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar ansiTrim = require('./utils/ansi-trim.js')\nvar output = require('./utils/output.js')\nvar defaultRegistry = require('./config/defaults.js').defaults.registry\nvar checkPing = require('./doctor/check-ping.js')\nvar getGitPath = require('./doctor/get-git-path.js')\nvar checksumCachedFiles = require('./doctor/checksum-cached-files.js')\nvar checkFilesPermission = require('./doctor/check-files-permission.js')\nvar getLatestNodejsVersion = require('./doctor/get-latest-nodejs-version.js')\nvar getLatestNpmVersion = require('./doctor/get-latest-npm-version')\nvar globalNodeModules = path.join(npm.config.globalPrefix, 'lib', 'node_modules')\nvar localNodeModules = path.join(npm.config.localPrefix, 'node_modules')\n\nmodule.exports = doctor\n\ndoctor.usage = 'npm doctor'\n\nfunction doctor (args, silent, cb) {\n  args = args || {}\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n\n  var actionsToRun = [\n    [checkPing],\n    [getLatestNpmVersion],\n    [getLatestNodejsVersion, args['node-url']],\n    [getGitPath],\n    [checkFilesPermission, npm.cache, 6],\n    [checkFilesPermission, globalNodeModules, 4],\n    [checkFilesPermission, localNodeModules, 6],\n    [checksumCachedFiles]\n  ]\n\n  log.info('doctor', 'Running checkup')\n  chain(actionsToRun, function (stderr, stdout) {\n    if (stderr && stderr.message !== 'not found: git') return cb(stderr)\n    var outHead = ['Check', 'Value', 'Recommendation']\n    var list = makePretty(stdout)\n    var outBody = list\n\n    if (npm.color) {\n      outHead = outHead.map(function (item) {\n        return styles.underline(item)\n      })\n      outBody = outBody.map(function (item) {\n        if (item[2]) {\n          item[0] = color.red(item[0])\n          item[2] = color.magenta(item[2])\n        }\n        return item\n      })\n    }\n\n    var outTable = [outHead].concat(outBody)\n    var tableOpts = {\n      stringLength: function (s) { return ansiTrim(s).length }\n    }\n\n    if (!silent) output(table(outTable, tableOpts))\n\n    cb(null, list)\n  })\n}\n\nfunction makePretty (p) {\n  var ping = p[0] ? 'ok' : 'notOk'\n  var npmLTS = p[1]\n  var nodeLTS = p[2].replace('v', '')\n  var whichGit = p[3] || 'not installed'\n  var readbleCaches = p[4] ? 'ok' : 'notOk'\n  var executableGlobalModules = p[5] ? 'ok' : 'notOk'\n  var executableLocalModules = p[6] ? 'ok' : 'notOk'\n  var checksumCachedFiles = p[7] ? 'ok' : 'notOk'\n  var npmV = npm.version\n  var nodeV = process.version.replace('v', '')\n  var registry = npm.config.get('registry')\n  var list = [\n    ['npm ping', ping],\n    ['npm -v', 'v' + npmV],\n    ['node -v', 'v' + nodeV],\n    ['npm config get registry', registry],\n    ['which git', whichGit],\n    ['Perms check on cached files', readbleCaches],\n    ['Perms check on global node_modules', executableGlobalModules],\n    ['Perms check on local node_modules', executableLocalModules],\n    ['Checksum cached files', checksumCachedFiles]\n  ]\n\n  if (ping !== 'ok') list[0][2] = 'Check your internet connection'\n  if (!semver.satisfies(npmV, '>=' + npmLTS)) list[1][2] = 'Use npm v' + npmLTS\n  if (!semver.satisfies(nodeV, '>=' + nodeLTS)) list[2][2] = 'Use node v' + nodeLTS\n  if (registry !== defaultRegistry) list[3][2] = 'Try `npm config set registry ' + defaultRegistry + '`'\n  if (whichGit === 'not installed') list[4][2] = 'Install git and ensure it\\'s in your PATH.'\n  if (readbleCaches !== 'ok') list[5][2] = 'Check the permissions of your files in ' + npm.config.get('cache')\n  if (executableGlobalModules !== 'ok') list[6][2] = globalNodeModules + ' must be readable and writable by the current user.'\n  if (executableLocalModules !== 'ok') list[7][2] = localNodeModules + ' must be readable and writable by the current user.'\n  if (checksumCachedFiles !== 'ok') list[8][2] = 'You have some broken packages in your cache.'\n\n  return list\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/text-table/index.js":"module.exports = function (rows_, opts) {\n    if (!opts) opts = {};\n    var hsep = opts.hsep === undefined ? '  ' : opts.hsep;\n    var align = opts.align || [];\n    var stringLength = opts.stringLength\n        || function (s) { return String(s).length; }\n    ;\n    \n    var dotsizes = reduce(rows_, function (acc, row) {\n        forEach(row, function (c, ix) {\n            var n = dotindex(c);\n            if (!acc[ix] || n > acc[ix]) acc[ix] = n;\n        });\n        return acc;\n    }, []);\n    \n    var rows = map(rows_, function (row) {\n        return map(row, function (c_, ix) {\n            var c = String(c_);\n            if (align[ix] === '.') {\n                var index = dotindex(c);\n                var size = dotsizes[ix] + (/\\./.test(c) ? 1 : 2)\n                    - (stringLength(c) - index)\n                ;\n                return c + Array(size).join(' ');\n            }\n            else return c;\n        });\n    });\n    \n    var sizes = reduce(rows, function (acc, row) {\n        forEach(row, function (c, ix) {\n            var n = stringLength(c);\n            if (!acc[ix] || n > acc[ix]) acc[ix] = n;\n        });\n        return acc;\n    }, []);\n    \n    return map(rows, function (row) {\n        return map(row, function (c, ix) {\n            var n = (sizes[ix] - stringLength(c)) || 0;\n            var s = Array(Math.max(n + 1, 1)).join(' ');\n            if (align[ix] === 'r' || align[ix] === '.') {\n                return s + c;\n            }\n            if (align[ix] === 'c') {\n                return Array(Math.ceil(n / 2 + 1)).join(' ')\n                    + c + Array(Math.floor(n / 2 + 1)).join(' ')\n                ;\n            }\n            \n            return c + s;\n        }).join(hsep).replace(/\\s+$/, '');\n    }).join('\\n');\n};\n\nfunction dotindex (c) {\n    var m = /\\.[^.]*$/.exec(c);\n    return m ? m.index + 1 : c.length;\n}\n\nfunction reduce (xs, f, init) {\n    if (xs.reduce) return xs.reduce(f, init);\n    var i = 0;\n    var acc = arguments.length >= 3 ? init : xs[i++];\n    for (; i < xs.length; i++) {\n        f(acc, xs[i], i);\n    }\n    return acc;\n}\n\nfunction forEach (xs, f) {\n    if (xs.forEach) return xs.forEach(f);\n    for (var i = 0; i < xs.length; i++) {\n        f.call(xs, xs[i], i);\n    }\n}\n\nfunction map (xs, f) {\n    if (xs.map) return xs.map(f);\n    var res = [];\n    for (var i = 0; i < xs.length; i++) {\n        res.push(f.call(xs, xs[i], i));\n    }\n    return res;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/ansistyles/ansistyles.js":"'use strict';\n\n/*\n * Info: http://www.termsys.demon.co.uk/vtansi.htm#colors \n * Following caveats\n * bright    - brightens the color (bold-blue is same as brigthtBlue)\n * dim       - nothing on Mac or Linux\n * italic    - nothing on Mac or Linux\n * underline - underlines string\n * blink     - nothing on Mac or linux\n * inverse   - background becomes foreground and vice versa\n *\n * In summary, the only styles that work are:\n *  - bright, underline and inverse\n *  - the others are only included for completeness\n */\n\nvar styleNums = {\n    reset     :  [0, 22]\n  , bright    :  [1, 22]\n  , dim       :  [2, 22]\n  , italic    :  [3, 23]\n  , underline :  [4, 24]\n  , blink     :  [5, 25]\n  , inverse   :  [7, 27]\n  }\n  , styles = {}\n  ;\n\nObject.keys(styleNums).forEach(function (k) {\n  styles[k] = function (s) { \n    var open = styleNums[k][0]\n      , close = styleNums[k][1];\n    return '\\u001b[' + open + 'm' + s + '\\u001b[' + close + 'm';\n  };\n});\n\nmodule.exports = styles;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/ansi-trim.js":"function ansiTrim (str) {\n  var r = new RegExp('\\x1b(?:\\\\[(?:\\\\d+[ABCDEFGJKSTm]|\\\\d+;\\\\d+[Hfm]|' +\n        '\\\\d+;\\\\d+;\\\\d+m|6n|s|u|\\\\?25[lh])|\\\\w)', 'g')\n  return str.replace(r, '')\n}\n\nmodule.exports = ansiTrim\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/doctor/check-ping.js":"var log = require('npmlog')\nvar ping = require('../ping.js')\n\nfunction checkPing (cb) {\n  var tracker = log.newItem('checkPing', 1)\n  tracker.info('checkPing', 'Pinging registry')\n  ping({}, true, function (err, pong) {\n    tracker.finish()\n    cb(err, pong)\n  })\n}\n\nmodule.exports = checkPing\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/ping.js":"var npm = require('./npm.js')\nvar output = require('./utils/output.js')\n\nmodule.exports = ping\n\nping.usage = 'npm ping\\nping registry'\n\nfunction ping (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n  var registry = npm.config.get('registry')\n  if (!registry) return cb(new Error('no default registry set'))\n  var auth = npm.config.getCredentialsByURI(registry)\n\n  npm.registry.ping(registry, {auth: auth}, function (er, pong) {\n    if (!silent) output(JSON.stringify(pong))\n    cb(er, er ? null : pong)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/doctor/get-git-path.js":"var log = require('npmlog')\nvar which = require('which')\n\nfunction getGitPath (cb) {\n  var tracker = log.newItem('getGitPath', 1)\n  tracker.info('getGitPath', 'Finding git in your PATH')\n  which('git', function (err, path) {\n    tracker.finish()\n    cb(err, path)\n  })\n}\n\nmodule.exports = getGitPath\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/doctor/checksum-cached-files.js":"var crypto = require('crypto')\nvar fs = require('fs')\nvar path = require('path')\nvar chain = require('slide').chain\nvar log = require('npmlog')\nvar npm = require('../npm')\nvar fileCompletion = require('../utils/completion/file-completion.js')\n\nfunction checksum (str) {\n  return crypto\n    .createHash('sha1')\n    .update(str, 'utf8')\n    .digest('hex')\n}\n\nfunction checksumCachedFiles (cb) {\n  var tracker = log.newItem('checksumCachedFiles', 1)\n  tracker.info('checksumCachedFiles', 'Building file list of ' + npm.cache)\n  fileCompletion(npm.cache, '.', Infinity, function (e, files) {\n    if (e) {\n      tracker.finish()\n      return cb(e)\n    }\n    tracker.addWork(files.length)\n    tracker.completeWork(1)\n    chain(files.map(andChecksumFile), function (er) {\n      tracker.finish()\n      cb(null, !er)\n    })\n    function andChecksumFile (f) {\n      return [function (next) { process.nextTick(function () { checksumFile(f, next) }) }]\n    }\n    function checksumFile (f, next) {\n      var file = path.join(npm.cache, f)\n      tracker.silly('checksumFile', f)\n      if (!/.tgz$/.test(file)) {\n        tracker.completeWork(1)\n        return next()\n      }\n      fs.readFile(file, function (err, tgz) {\n        tracker.completeWork(1)\n        if (err) return next(err)\n        try {\n          var pkgJSON = fs.readFileSync(path.join(path.dirname(file), 'package/package.json'))\n        } catch (e) {\n          return next() // no package.json in cche is ok\n        }\n        try {\n          var pkg = JSON.parse(pkgJSON)\n          var shasum = (pkg.dist && pkg.dist.shasum) || pkg._shasum\n          var actual = checksum(tgz)\n          if (actual !== shasum) return next(new Error('Checksum mismatch on ' + file + ', expected: ' + shasum + ', got: ' + shasum))\n          return next()\n        } catch (e) {\n          return next(new Error('Error parsing JSON in ' + file + ': ' + e))\n        }\n      })\n    }\n  })\n}\n\nmodule.exports = checksumCachedFiles\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/doctor/check-files-permission.js":"var fs = require('fs')\nvar path = require('path')\nvar getUid = require('uid-number')\nvar chain = require('slide').chain\nvar log = require('npmlog')\nvar npm = require('../npm.js')\nvar fileCompletion = require('../utils/completion/file-completion.js')\n\nfunction checkFilesPermission (root, mask, cb) {\n  if (process.platform === 'win32') return cb(null, true)\n  getUid(npm.config.get('user'), npm.config.get('group'), function (e, uid, gid) {\n    if (e) {\n      tracker.finish()\n      tracker.warn('checkFilePermissions', 'Error looking up user and group:', e)\n      return cb(e)\n    }\n    var tracker = log.newItem('checkFilePermissions', 1)\n    tracker.info('checkFilePermissions', 'Building file list of ' + root)\n    fileCompletion(root, '.', Infinity, function (e, files) {\n      if (e) {\n        tracker.warn('checkFilePermissions', 'Error building file list:', e)\n        tracker.finish()\n        return cb(e)\n      }\n      tracker.addWork(files.length)\n      tracker.completeWork(1)\n      chain(files.map(andCheckFile), function (er) {\n        tracker.finish()\n        cb(null, !er)\n      })\n      function andCheckFile (f) {\n        return [checkFile, f]\n      }\n      function checkFile (f, next) {\n        var file = path.join(root, f)\n        tracker.silly('checkFilePermissions', f)\n        fs.lstat(file, function (e, stat) {\n          tracker.completeWork(1)\n          if (e) return next(e)\n          if (!stat.isFile()) return next()\n          var mode = stat.mode\n          var isGroup = stat.gid ? stat.gid === gid : true\n          var isUser = stat.uid ? stat.uid === uid : true\n          if ((mode & parseInt('000' + mask, 8))) return next()\n          if ((isGroup && mode & parseInt('00' + mask + '0', 8))) return next()\n          if ((isUser && mode & parseInt('0' + mask + '00', 8))) return next()\n          tracker.error('checkFilePermissions', 'Missing permissions on (' + isGroup + ', ' + isUser + ', ' + mode + ')', file)\n          return next(new Error('Missing permissions for ' + file))\n        })\n      }\n    })\n  })\n}\n\nmodule.exports = checkFilesPermission\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/doctor/get-latest-nodejs-version.js":"var log = require('npmlog')\nvar request = require('request')\n\nfunction getLatestNodejsVersion (url, cb) {\n  var tracker = log.newItem('getLatestNodejsVersion', 1)\n  tracker.info('getLatestNodejsVersion', 'Getting Node.js release information')\n  var version = ''\n  url = url || 'https://nodejs.org/dist/index.json'\n  request(url, function (e, res, index) {\n    tracker.finish()\n    if (e) return cb(e)\n    if (res.statusCode !== 200) {\n      return cb(new Error('Status not 200, ' + res.statusCode))\n    }\n    try {\n      JSON.parse(index).forEach(function (item) {\n        if (item.lts && item.version > version) version = item.version\n      })\n      cb(null, version)\n    } catch (e) {\n      cb(e)\n    }\n  })\n}\n\nmodule.exports = getLatestNodejsVersion\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/index.js":"// Copyright 2010-2012 Mikeal Rogers\n//\n//    Licensed under the Apache License, Version 2.0 (the \"License\");\n//    you may not use this file except in compliance with the License.\n//    You may obtain a copy of the License at\n//\n//        http://www.apache.org/licenses/LICENSE-2.0\n//\n//    Unless required by applicable law or agreed to in writing, software\n//    distributed under the License is distributed on an \"AS IS\" BASIS,\n//    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//    See the License for the specific language governing permissions and\n//    limitations under the License.\n\n'use strict'\n\nvar extend                = require('extend')\n  , cookies               = require('./lib/cookies')\n  , helpers               = require('./lib/helpers')\n\nvar paramsHaveRequestBody = helpers.paramsHaveRequestBody\n\n\n// organize params for patch, post, put, head, del\nfunction initParams(uri, options, callback) {\n  if (typeof options === 'function') {\n    callback = options\n  }\n\n  var params = {}\n  if (typeof options === 'object') {\n    extend(params, options, {uri: uri})\n  } else if (typeof uri === 'string') {\n    extend(params, {uri: uri})\n  } else {\n    extend(params, uri)\n  }\n\n  params.callback = callback || params.callback\n  return params\n}\n\nfunction request (uri, options, callback) {\n  if (typeof uri === 'undefined') {\n    throw new Error('undefined is not a valid uri or options object.')\n  }\n\n  var params = initParams(uri, options, callback)\n\n  if (params.method === 'HEAD' && paramsHaveRequestBody(params)) {\n    throw new Error('HTTP HEAD requests MUST NOT include a request body.')\n  }\n\n  return new request.Request(params)\n}\n\nfunction verbFunc (verb) {\n  var method = verb.toUpperCase()\n  return function (uri, options, callback) {\n    var params = initParams(uri, options, callback)\n    params.method = method\n    return request(params, params.callback)\n  }\n}\n\n// define like this to please codeintel/intellisense IDEs\nrequest.get = verbFunc('get')\nrequest.head = verbFunc('head')\nrequest.post = verbFunc('post')\nrequest.put = verbFunc('put')\nrequest.patch = verbFunc('patch')\nrequest.del = verbFunc('delete')\nrequest['delete'] = verbFunc('delete')\n\nrequest.jar = function (store) {\n  return cookies.jar(store)\n}\n\nrequest.cookie = function (str) {\n  return cookies.parse(str)\n}\n\nfunction wrapRequestMethod (method, options, requester, verb) {\n\n  return function (uri, opts, callback) {\n    var params = initParams(uri, opts, callback)\n\n    var target = {}\n    extend(true, target, options, params)\n\n    target.pool = params.pool || options.pool\n\n    if (verb) {\n      target.method = verb.toUpperCase()\n    }\n\n    if (typeof requester === 'function') {\n      method = requester\n    }\n\n    return method(target, target.callback)\n  }\n}\n\nrequest.defaults = function (options, requester) {\n  var self = this\n\n  options = options || {}\n\n  if (typeof options === 'function') {\n    requester = options\n    options = {}\n  }\n\n  var defaults      = wrapRequestMethod(self, options, requester)\n\n  var verbs = ['get', 'head', 'post', 'put', 'patch', 'del', 'delete']\n  verbs.forEach(function(verb) {\n    defaults[verb]  = wrapRequestMethod(self[verb], options, requester, verb)\n  })\n\n  defaults.cookie   = wrapRequestMethod(self.cookie, options, requester)\n  defaults.jar      = self.jar\n  defaults.defaults = self.defaults\n  return defaults\n}\n\nrequest.forever = function (agentOptions, optionsArg) {\n  var options = {}\n  if (optionsArg) {\n    extend(options, optionsArg)\n  }\n  if (agentOptions) {\n    options.agentOptions = agentOptions\n  }\n\n  options.forever = true\n  return request.defaults(options)\n}\n\n// Exports\n\nmodule.exports = request\nrequest.Request = require('./request')\nrequest.initParams = initParams\n\n// Backwards compatibility for request.debug\nObject.defineProperty(request, 'debug', {\n  enumerable : true,\n  get : function() {\n    return request.Request.debug\n  },\n  set : function(debug) {\n    request.Request.debug = debug\n  }\n})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/extend/index.js":"'use strict';\n\nvar hasOwn = Object.prototype.hasOwnProperty;\nvar toStr = Object.prototype.toString;\n\nvar isArray = function isArray(arr) {\n\tif (typeof Array.isArray === 'function') {\n\t\treturn Array.isArray(arr);\n\t}\n\n\treturn toStr.call(arr) === '[object Array]';\n};\n\nvar isPlainObject = function isPlainObject(obj) {\n\tif (!obj || toStr.call(obj) !== '[object Object]') {\n\t\treturn false;\n\t}\n\n\tvar hasOwnConstructor = hasOwn.call(obj, 'constructor');\n\tvar hasIsPrototypeOf = obj.constructor && obj.constructor.prototype && hasOwn.call(obj.constructor.prototype, 'isPrototypeOf');\n\t// Not own constructor property must be Object\n\tif (obj.constructor && !hasOwnConstructor && !hasIsPrototypeOf) {\n\t\treturn false;\n\t}\n\n\t// Own properties are enumerated firstly, so to speed up,\n\t// if last one is own, then all properties are own.\n\tvar key;\n\tfor (key in obj) {/**/}\n\n\treturn typeof key === 'undefined' || hasOwn.call(obj, key);\n};\n\nmodule.exports = function extend() {\n\tvar options, name, src, copy, copyIsArray, clone,\n\t\ttarget = arguments[0],\n\t\ti = 1,\n\t\tlength = arguments.length,\n\t\tdeep = false;\n\n\t// Handle a deep copy situation\n\tif (typeof target === 'boolean') {\n\t\tdeep = target;\n\t\ttarget = arguments[1] || {};\n\t\t// skip the boolean and the target\n\t\ti = 2;\n\t} else if ((typeof target !== 'object' && typeof target !== 'function') || target == null) {\n\t\ttarget = {};\n\t}\n\n\tfor (; i < length; ++i) {\n\t\toptions = arguments[i];\n\t\t// Only deal with non-null/undefined values\n\t\tif (options != null) {\n\t\t\t// Extend the base object\n\t\t\tfor (name in options) {\n\t\t\t\tsrc = target[name];\n\t\t\t\tcopy = options[name];\n\n\t\t\t\t// Prevent never-ending loop\n\t\t\t\tif (target !== copy) {\n\t\t\t\t\t// Recurse if we're merging plain objects or arrays\n\t\t\t\t\tif (deep && copy && (isPlainObject(copy) || (copyIsArray = isArray(copy)))) {\n\t\t\t\t\t\tif (copyIsArray) {\n\t\t\t\t\t\t\tcopyIsArray = false;\n\t\t\t\t\t\t\tclone = src && isArray(src) ? src : [];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tclone = src && isPlainObject(src) ? src : {};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Never move original objects, clone them\n\t\t\t\t\t\ttarget[name] = extend(deep, clone, copy);\n\n\t\t\t\t\t// Don't bring in undefined values\n\t\t\t\t\t} else if (typeof copy !== 'undefined') {\n\t\t\t\t\t\ttarget[name] = copy;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return the modified object\n\treturn target;\n};\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/cookies.js":"'use strict'\n\nvar tough = require('tough-cookie')\n\nvar Cookie = tough.Cookie\n  , CookieJar = tough.CookieJar\n\n\nexports.parse = function(str) {\n  if (str && str.uri) {\n    str = str.uri\n  }\n  if (typeof str !== 'string') {\n    throw new Error('The cookie function only accepts STRING as param')\n  }\n  return Cookie.parse(str, {loose: true})\n}\n\n// Adapt the sometimes-Async api of tough.CookieJar to our requirements\nfunction RequestJar(store) {\n  var self = this\n  self._jar = new CookieJar(store, {looseMode: true})\n}\nRequestJar.prototype.setCookie = function(cookieOrStr, uri, options) {\n  var self = this\n  return self._jar.setCookieSync(cookieOrStr, uri, options || {})\n}\nRequestJar.prototype.getCookieString = function(uri) {\n  var self = this\n  return self._jar.getCookieStringSync(uri)\n}\nRequestJar.prototype.getCookies = function(uri) {\n  var self = this\n  return self._jar.getCookiesSync(uri)\n}\n\nexports.jar = function(store) {\n  return new RequestJar(store)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/tough-cookie/lib/cookie.js":"/*!\n * Copyright (c) 2015, Salesforce.com, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright notice,\n * this list of conditions and the following disclaimer in the documentation\n * and/or other materials provided with the distribution.\n *\n * 3. Neither the name of Salesforce.com nor the names of its contributors may\n * be used to endorse or promote products derived from this software without\n * specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n'use strict';\nvar net = require('net');\nvar urlParse = require('url').parse;\nvar pubsuffix = require('./pubsuffix');\nvar Store = require('./store').Store;\nvar MemoryCookieStore = require('./memstore').MemoryCookieStore;\nvar pathMatch = require('./pathMatch').pathMatch;\nvar VERSION = require('../package.json').version;\n\nvar punycode;\ntry {\n  punycode = require('punycode');\n} catch(e) {\n  console.warn(\"cookie: can't load punycode; won't use punycode for domain normalization\");\n}\n\nvar DATE_DELIM = /[\\x09\\x20-\\x2F\\x3B-\\x40\\x5B-\\x60\\x7B-\\x7E]/;\n\n// From RFC6265 S4.1.1\n// note that it excludes \\x3B \";\"\nvar COOKIE_OCTET  = /[\\x21\\x23-\\x2B\\x2D-\\x3A\\x3C-\\x5B\\x5D-\\x7E]/;\nvar COOKIE_OCTETS = new RegExp('^'+COOKIE_OCTET.source+'+$');\n\nvar CONTROL_CHARS = /[\\x00-\\x1F]/;\n\n// Double quotes are part of the value (see: S4.1.1).\n// '\\r', '\\n' and '\\0' should be treated as a terminator in the \"relaxed\" mode\n// (see: https://github.com/ChromiumWebApps/chromium/blob/b3d3b4da8bb94c1b2e061600df106d590fda3620/net/cookies/parsed_cookie.cc#L60)\n// '=' and ';' are attribute/values separators\n// (see: https://github.com/ChromiumWebApps/chromium/blob/b3d3b4da8bb94c1b2e061600df106d590fda3620/net/cookies/parsed_cookie.cc#L64)\nvar COOKIE_PAIR = /^(([^=;]+))\\s*=\\s*([^\\n\\r\\0]*)/;\n\n// Used to parse non-RFC-compliant cookies like '=abc' when given the `loose`\n// option in Cookie.parse:\nvar LOOSE_COOKIE_PAIR = /^((?:=)?([^=;]*)\\s*=\\s*)?([^\\n\\r\\0]*)/;\n\n// RFC6265 S4.1.1 defines path value as 'any CHAR except CTLs or \";\"'\n// Note ';' is \\x3B\nvar PATH_VALUE = /[\\x20-\\x3A\\x3C-\\x7E]+/;\n\nvar DAY_OF_MONTH = /^(\\d{1,2})[^\\d]*$/;\nvar TIME = /^(\\d{1,2})[^\\d]*:(\\d{1,2})[^\\d]*:(\\d{1,2})[^\\d]*$/;\nvar MONTH = /^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)/i;\n\nvar MONTH_TO_NUM = {\n  jan:0, feb:1, mar:2, apr:3, may:4, jun:5,\n  jul:6, aug:7, sep:8, oct:9, nov:10, dec:11\n};\nvar NUM_TO_MONTH = [\n  'Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'\n];\nvar NUM_TO_DAY = [\n  'Sun','Mon','Tue','Wed','Thu','Fri','Sat'\n];\n\nvar YEAR = /^(\\d{2}|\\d{4})$/; // 2 to 4 digits\n\nvar MAX_TIME = 2147483647000; // 31-bit max\nvar MIN_TIME = 0; // 31-bit min\n\n\n// RFC6265 S5.1.1 date parser:\nfunction parseDate(str) {\n  if (!str) {\n    return;\n  }\n\n  /* RFC6265 S5.1.1:\n   * 2. Process each date-token sequentially in the order the date-tokens\n   * appear in the cookie-date\n   */\n  var tokens = str.split(DATE_DELIM);\n  if (!tokens) {\n    return;\n  }\n\n  var hour = null;\n  var minutes = null;\n  var seconds = null;\n  var day = null;\n  var month = null;\n  var year = null;\n\n  for (var i=0; i<tokens.length; i++) {\n    var token = tokens[i].trim();\n    if (!token.length) {\n      continue;\n    }\n\n    var result;\n\n    /* 2.1. If the found-time flag is not set and the token matches the time\n     * production, set the found-time flag and set the hour- value,\n     * minute-value, and second-value to the numbers denoted by the digits in\n     * the date-token, respectively.  Skip the remaining sub-steps and continue\n     * to the next date-token.\n     */\n    if (seconds === null) {\n      result = TIME.exec(token);\n      if (result) {\n        hour = parseInt(result[1], 10);\n        minutes = parseInt(result[2], 10);\n        seconds = parseInt(result[3], 10);\n        /* RFC6265 S5.1.1.5:\n         * [fail if]\n         * *  the hour-value is greater than 23,\n         * *  the minute-value is greater than 59, or\n         * *  the second-value is greater than 59.\n         */\n        if(hour > 23 || minutes > 59 || seconds > 59) {\n          return;\n        }\n\n        continue;\n      }\n    }\n\n    /* 2.2. If the found-day-of-month flag is not set and the date-token matches\n     * the day-of-month production, set the found-day-of- month flag and set\n     * the day-of-month-value to the number denoted by the date-token.  Skip\n     * the remaining sub-steps and continue to the next date-token.\n     */\n    if (day === null) {\n      result = DAY_OF_MONTH.exec(token);\n      if (result) {\n        day = parseInt(result, 10);\n        /* RFC6265 S5.1.1.5:\n         * [fail if] the day-of-month-value is less than 1 or greater than 31\n         */\n        if(day < 1 || day > 31) {\n          return;\n        }\n        continue;\n      }\n    }\n\n    /* 2.3. If the found-month flag is not set and the date-token matches the\n     * month production, set the found-month flag and set the month-value to\n     * the month denoted by the date-token.  Skip the remaining sub-steps and\n     * continue to the next date-token.\n     */\n    if (month === null) {\n      result = MONTH.exec(token);\n      if (result) {\n        month = MONTH_TO_NUM[result[1].toLowerCase()];\n        continue;\n      }\n    }\n\n    /* 2.4. If the found-year flag is not set and the date-token matches the year\n     * production, set the found-year flag and set the year-value to the number\n     * denoted by the date-token.  Skip the remaining sub-steps and continue to\n     * the next date-token.\n     */\n    if (year === null) {\n      result = YEAR.exec(token);\n      if (result) {\n        year = parseInt(result[0], 10);\n        /* From S5.1.1:\n         * 3.  If the year-value is greater than or equal to 70 and less\n         * than or equal to 99, increment the year-value by 1900.\n         * 4.  If the year-value is greater than or equal to 0 and less\n         * than or equal to 69, increment the year-value by 2000.\n         */\n        if (70 <= year && year <= 99) {\n          year += 1900;\n        } else if (0 <= year && year <= 69) {\n          year += 2000;\n        }\n\n        if (year < 1601) {\n          return; // 5. ... the year-value is less than 1601\n        }\n      }\n    }\n  }\n\n  if (seconds === null || day === null || month === null || year === null) {\n    return; // 5. ... at least one of the found-day-of-month, found-month, found-\n            // year, or found-time flags is not set,\n  }\n\n  return new Date(Date.UTC(year, month, day, hour, minutes, seconds));\n}\n\nfunction formatDate(date) {\n  var d = date.getUTCDate(); d = d >= 10 ? d : '0'+d;\n  var h = date.getUTCHours(); h = h >= 10 ? h : '0'+h;\n  var m = date.getUTCMinutes(); m = m >= 10 ? m : '0'+m;\n  var s = date.getUTCSeconds(); s = s >= 10 ? s : '0'+s;\n  return NUM_TO_DAY[date.getUTCDay()] + ', ' +\n    d+' '+ NUM_TO_MONTH[date.getUTCMonth()] +' '+ date.getUTCFullYear() +' '+\n    h+':'+m+':'+s+' GMT';\n}\n\n// S5.1.2 Canonicalized Host Names\nfunction canonicalDomain(str) {\n  if (str == null) {\n    return null;\n  }\n  str = str.trim().replace(/^\\./,''); // S4.1.2.3 & S5.2.3: ignore leading .\n\n  // convert to IDN if any non-ASCII characters\n  if (punycode && /[^\\u0001-\\u007f]/.test(str)) {\n    str = punycode.toASCII(str);\n  }\n\n  return str.toLowerCase();\n}\n\n// S5.1.3 Domain Matching\nfunction domainMatch(str, domStr, canonicalize) {\n  if (str == null || domStr == null) {\n    return null;\n  }\n  if (canonicalize !== false) {\n    str = canonicalDomain(str);\n    domStr = canonicalDomain(domStr);\n  }\n\n  /*\n   * \"The domain string and the string are identical. (Note that both the\n   * domain string and the string will have been canonicalized to lower case at\n   * this point)\"\n   */\n  if (str == domStr) {\n    return true;\n  }\n\n  /* \"All of the following [three] conditions hold:\" (order adjusted from the RFC) */\n\n  /* \"* The string is a host name (i.e., not an IP address).\" */\n  if (net.isIP(str)) {\n    return false;\n  }\n\n  /* \"* The domain string is a suffix of the string\" */\n  var idx = str.indexOf(domStr);\n  if (idx <= 0) {\n    return false; // it's a non-match (-1) or prefix (0)\n  }\n\n  // e.g \"a.b.c\".indexOf(\"b.c\") === 2\n  // 5 === 3+2\n  if (str.length !== domStr.length + idx) { // it's not a suffix\n    return false;\n  }\n\n  /* \"* The last character of the string that is not included in the domain\n  * string is a %x2E (\".\") character.\" */\n  if (str.substr(idx-1,1) !== '.') {\n    return false;\n  }\n\n  return true;\n}\n\n\n// RFC6265 S5.1.4 Paths and Path-Match\n\n/*\n * \"The user agent MUST use an algorithm equivalent to the following algorithm\n * to compute the default-path of a cookie:\"\n *\n * Assumption: the path (and not query part or absolute uri) is passed in.\n */\nfunction defaultPath(path) {\n  // \"2. If the uri-path is empty or if the first character of the uri-path is not\n  // a %x2F (\"/\") character, output %x2F (\"/\") and skip the remaining steps.\n  if (!path || path.substr(0,1) !== \"/\") {\n    return \"/\";\n  }\n\n  // \"3. If the uri-path contains no more than one %x2F (\"/\") character, output\n  // %x2F (\"/\") and skip the remaining step.\"\n  if (path === \"/\") {\n    return path;\n  }\n\n  var rightSlash = path.lastIndexOf(\"/\");\n  if (rightSlash === 0) {\n    return \"/\";\n  }\n\n  // \"4. Output the characters of the uri-path from the first character up to,\n  // but not including, the right-most %x2F (\"/\").\"\n  return path.slice(0, rightSlash);\n}\n\n\nfunction parse(str, options) {\n  if (!options || typeof options !== 'object') {\n    options = {};\n  }\n  str = str.trim();\n\n  // We use a regex to parse the \"name-value-pair\" part of S5.2\n  var firstSemi = str.indexOf(';'); // S5.2 step 1\n  var pairRe = options.loose ? LOOSE_COOKIE_PAIR : COOKIE_PAIR;\n  var result = pairRe.exec(firstSemi === -1 ? str : str.substr(0,firstSemi));\n\n  // Rx satisfies the \"the name string is empty\" and \"lacks a %x3D (\"=\")\"\n  // constraints as well as trimming any whitespace.\n  if (!result) {\n    return;\n  }\n\n  var c = new Cookie();\n  if (result[1]) {\n    c.key = result[2].trim();\n  } else {\n    c.key = '';\n  }\n  c.value = result[3].trim();\n  if (CONTROL_CHARS.test(c.key) || CONTROL_CHARS.test(c.value)) {\n    return;\n  }\n\n  if (firstSemi === -1) {\n    return c;\n  }\n\n  // S5.2.3 \"unparsed-attributes consist of the remainder of the set-cookie-string\n  // (including the %x3B (\";\") in question).\" plus later on in the same section\n  // \"discard the first \";\" and trim\".\n  var unparsed = str.slice(firstSemi + 1).trim();\n\n  // \"If the unparsed-attributes string is empty, skip the rest of these\n  // steps.\"\n  if (unparsed.length === 0) {\n    return c;\n  }\n\n  /*\n   * S5.2 says that when looping over the items \"[p]rocess the attribute-name\n   * and attribute-value according to the requirements in the following\n   * subsections\" for every item.  Plus, for many of the individual attributes\n   * in S5.3 it says to use the \"attribute-value of the last attribute in the\n   * cookie-attribute-list\".  Therefore, in this implementation, we overwrite\n   * the previous value.\n   */\n  var cookie_avs = unparsed.split(';');\n  while (cookie_avs.length) {\n    var av = cookie_avs.shift().trim();\n    if (av.length === 0) { // happens if \";;\" appears\n      continue;\n    }\n    var av_sep = av.indexOf('=');\n    var av_key, av_value;\n\n    if (av_sep === -1) {\n      av_key = av;\n      av_value = null;\n    } else {\n      av_key = av.substr(0,av_sep);\n      av_value = av.substr(av_sep+1);\n    }\n\n    av_key = av_key.trim().toLowerCase();\n\n    if (av_value) {\n      av_value = av_value.trim();\n    }\n\n    switch(av_key) {\n    case 'expires': // S5.2.1\n      if (av_value) {\n        var exp = parseDate(av_value);\n        // \"If the attribute-value failed to parse as a cookie date, ignore the\n        // cookie-av.\"\n        if (exp) {\n          // over and underflow not realistically a concern: V8's getTime() seems to\n          // store something larger than a 32-bit time_t (even with 32-bit node)\n          c.expires = exp;\n        }\n      }\n      break;\n\n    case 'max-age': // S5.2.2\n      if (av_value) {\n        // \"If the first character of the attribute-value is not a DIGIT or a \"-\"\n        // character ...[or]... If the remainder of attribute-value contains a\n        // non-DIGIT character, ignore the cookie-av.\"\n        if (/^-?[0-9]+$/.test(av_value)) {\n          var delta = parseInt(av_value, 10);\n          // \"If delta-seconds is less than or equal to zero (0), let expiry-time\n          // be the earliest representable date and time.\"\n          c.setMaxAge(delta);\n        }\n      }\n      break;\n\n    case 'domain': // S5.2.3\n      // \"If the attribute-value is empty, the behavior is undefined.  However,\n      // the user agent SHOULD ignore the cookie-av entirely.\"\n      if (av_value) {\n        // S5.2.3 \"Let cookie-domain be the attribute-value without the leading %x2E\n        // (\".\") character.\"\n        var domain = av_value.trim().replace(/^\\./, '');\n        if (domain) {\n          // \"Convert the cookie-domain to lower case.\"\n          c.domain = domain.toLowerCase();\n        }\n      }\n      break;\n\n    case 'path': // S5.2.4\n      /*\n       * \"If the attribute-value is empty or if the first character of the\n       * attribute-value is not %x2F (\"/\"):\n       *   Let cookie-path be the default-path.\n       * Otherwise:\n       *   Let cookie-path be the attribute-value.\"\n       *\n       * We'll represent the default-path as null since it depends on the\n       * context of the parsing.\n       */\n      c.path = av_value && av_value[0] === \"/\" ? av_value : null;\n      break;\n\n    case 'secure': // S5.2.5\n      /*\n       * \"If the attribute-name case-insensitively matches the string \"Secure\",\n       * the user agent MUST append an attribute to the cookie-attribute-list\n       * with an attribute-name of Secure and an empty attribute-value.\"\n       */\n      c.secure = true;\n      break;\n\n    case 'httponly': // S5.2.6 -- effectively the same as 'secure'\n      c.httpOnly = true;\n      break;\n\n    default:\n      c.extensions = c.extensions || [];\n      c.extensions.push(av);\n      break;\n    }\n  }\n\n  return c;\n}\n\n// avoid the V8 deoptimization monster!\nfunction jsonParse(str) {\n  var obj;\n  try {\n    obj = JSON.parse(str);\n  } catch (e) {\n    return e;\n  }\n  return obj;\n}\n\nfunction fromJSON(str) {\n  if (!str) {\n    return null;\n  }\n\n  var obj;\n  if (typeof str === 'string') {\n    obj = jsonParse(str);\n    if (obj instanceof Error) {\n      return null;\n    }\n  } else {\n    // assume it's an Object\n    obj = str;\n  }\n\n  var c = new Cookie();\n  for (var i=0; i<Cookie.serializableProperties.length; i++) {\n    var prop = Cookie.serializableProperties[i];\n    if (obj[prop] === undefined ||\n        obj[prop] === Cookie.prototype[prop])\n    {\n      continue; // leave as prototype default\n    }\n\n    if (prop === 'expires' ||\n        prop === 'creation' ||\n        prop === 'lastAccessed')\n    {\n      if (obj[prop] === null) {\n        c[prop] = null;\n      } else {\n        c[prop] = obj[prop] == \"Infinity\" ?\n          \"Infinity\" : new Date(obj[prop]);\n      }\n    } else {\n      c[prop] = obj[prop];\n    }\n  }\n\n  return c;\n}\n\n/* Section 5.4 part 2:\n * \"*  Cookies with longer paths are listed before cookies with\n *     shorter paths.\n *\n *  *  Among cookies that have equal-length path fields, cookies with\n *     earlier creation-times are listed before cookies with later\n *     creation-times.\"\n */\n\nfunction cookieCompare(a,b) {\n  var cmp = 0;\n\n  // descending for length: b CMP a\n  var aPathLen = a.path ? a.path.length : 0;\n  var bPathLen = b.path ? b.path.length : 0;\n  cmp = bPathLen - aPathLen;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  // ascending for time: a CMP b\n  var aTime = a.creation ? a.creation.getTime() : MAX_TIME;\n  var bTime = b.creation ? b.creation.getTime() : MAX_TIME;\n  cmp = aTime - bTime;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  // break ties for the same millisecond (precision of JavaScript's clock)\n  cmp = a.creationIndex - b.creationIndex;\n\n  return cmp;\n}\n\n// Gives the permutation of all possible pathMatch()es of a given path. The\n// array is in longest-to-shortest order.  Handy for indexing.\nfunction permutePath(path) {\n  if (path === '/') {\n    return ['/'];\n  }\n  if (path.lastIndexOf('/') === path.length-1) {\n    path = path.substr(0,path.length-1);\n  }\n  var permutations = [path];\n  while (path.length > 1) {\n    var lindex = path.lastIndexOf('/');\n    if (lindex === 0) {\n      break;\n    }\n    path = path.substr(0,lindex);\n    permutations.push(path);\n  }\n  permutations.push('/');\n  return permutations;\n}\n\nfunction getCookieContext(url) {\n  if (url instanceof Object) {\n    return url;\n  }\n  // NOTE: decodeURI will throw on malformed URIs (see GH-32).\n  // Therefore, we will just skip decoding for such URIs.\n  try {\n    url = decodeURI(url);\n  }\n  catch(err) {\n    // Silently swallow error\n  }\n\n  return urlParse(url);\n}\n\nfunction Cookie(options) {\n  options = options || {};\n\n  Object.keys(options).forEach(function(prop) {\n    if (Cookie.prototype.hasOwnProperty(prop) &&\n        Cookie.prototype[prop] !== options[prop] &&\n        prop.substr(0,1) !== '_')\n    {\n      this[prop] = options[prop];\n    }\n  }, this);\n\n  this.creation = this.creation || new Date();\n\n  // used to break creation ties in cookieCompare():\n  Object.defineProperty(this, 'creationIndex', {\n    configurable: false,\n    enumerable: false, // important for assert.deepEqual checks\n    writable: true,\n    value: ++Cookie.cookiesCreated\n  });\n}\n\nCookie.cookiesCreated = 0; // incremented each time a cookie is created\n\nCookie.parse = parse;\nCookie.fromJSON = fromJSON;\n\nCookie.prototype.key = \"\";\nCookie.prototype.value = \"\";\n\n// the order in which the RFC has them:\nCookie.prototype.expires = \"Infinity\"; // coerces to literal Infinity\nCookie.prototype.maxAge = null; // takes precedence over expires for TTL\nCookie.prototype.domain = null;\nCookie.prototype.path = null;\nCookie.prototype.secure = false;\nCookie.prototype.httpOnly = false;\nCookie.prototype.extensions = null;\n\n// set by the CookieJar:\nCookie.prototype.hostOnly = null; // boolean when set\nCookie.prototype.pathIsDefault = null; // boolean when set\nCookie.prototype.creation = null; // Date when set; defaulted by Cookie.parse\nCookie.prototype.lastAccessed = null; // Date when set\nObject.defineProperty(Cookie.prototype, 'creationIndex', {\n  configurable: true,\n  enumerable: false,\n  writable: true,\n  value: 0\n});\n\nCookie.serializableProperties = Object.keys(Cookie.prototype)\n  .filter(function(prop) {\n    return !(\n      Cookie.prototype[prop] instanceof Function ||\n      prop === 'creationIndex' ||\n      prop.substr(0,1) === '_'\n    );\n  });\n\nCookie.prototype.inspect = function inspect() {\n  var now = Date.now();\n  return 'Cookie=\"'+this.toString() +\n    '; hostOnly='+(this.hostOnly != null ? this.hostOnly : '?') +\n    '; aAge='+(this.lastAccessed ? (now-this.lastAccessed.getTime())+'ms' : '?') +\n    '; cAge='+(this.creation ? (now-this.creation.getTime())+'ms' : '?') +\n    '\"';\n};\n\nCookie.prototype.toJSON = function() {\n  var obj = {};\n\n  var props = Cookie.serializableProperties;\n  for (var i=0; i<props.length; i++) {\n    var prop = props[i];\n    if (this[prop] === Cookie.prototype[prop]) {\n      continue; // leave as prototype default\n    }\n\n    if (prop === 'expires' ||\n        prop === 'creation' ||\n        prop === 'lastAccessed')\n    {\n      if (this[prop] === null) {\n        obj[prop] = null;\n      } else {\n        obj[prop] = this[prop] == \"Infinity\" ? // intentionally not ===\n          \"Infinity\" : this[prop].toISOString();\n      }\n    } else if (prop === 'maxAge') {\n      if (this[prop] !== null) {\n        // again, intentionally not ===\n        obj[prop] = (this[prop] == Infinity || this[prop] == -Infinity) ?\n          this[prop].toString() : this[prop];\n      }\n    } else {\n      if (this[prop] !== Cookie.prototype[prop]) {\n        obj[prop] = this[prop];\n      }\n    }\n  }\n\n  return obj;\n};\n\nCookie.prototype.clone = function() {\n  return fromJSON(this.toJSON());\n};\n\nCookie.prototype.validate = function validate() {\n  if (!COOKIE_OCTETS.test(this.value)) {\n    return false;\n  }\n  if (this.expires != Infinity && !(this.expires instanceof Date) && !parseDate(this.expires)) {\n    return false;\n  }\n  if (this.maxAge != null && this.maxAge <= 0) {\n    return false; // \"Max-Age=\" non-zero-digit *DIGIT\n  }\n  if (this.path != null && !PATH_VALUE.test(this.path)) {\n    return false;\n  }\n\n  var cdomain = this.cdomain();\n  if (cdomain) {\n    if (cdomain.match(/\\.$/)) {\n      return false; // S4.1.2.3 suggests that this is bad. domainMatch() tests confirm this\n    }\n    var suffix = pubsuffix.getPublicSuffix(cdomain);\n    if (suffix == null) { // it's a public suffix\n      return false;\n    }\n  }\n  return true;\n};\n\nCookie.prototype.setExpires = function setExpires(exp) {\n  if (exp instanceof Date) {\n    this.expires = exp;\n  } else {\n    this.expires = parseDate(exp) || \"Infinity\";\n  }\n};\n\nCookie.prototype.setMaxAge = function setMaxAge(age) {\n  if (age === Infinity || age === -Infinity) {\n    this.maxAge = age.toString(); // so JSON.stringify() works\n  } else {\n    this.maxAge = age;\n  }\n};\n\n// gives Cookie header format\nCookie.prototype.cookieString = function cookieString() {\n  var val = this.value;\n  if (val == null) {\n    val = '';\n  }\n  if (this.key === '') {\n    return val;\n  }\n  return this.key+'='+val;\n};\n\n// gives Set-Cookie header format\nCookie.prototype.toString = function toString() {\n  var str = this.cookieString();\n\n  if (this.expires != Infinity) {\n    if (this.expires instanceof Date) {\n      str += '; Expires='+formatDate(this.expires);\n    } else {\n      str += '; Expires='+this.expires;\n    }\n  }\n\n  if (this.maxAge != null && this.maxAge != Infinity) {\n    str += '; Max-Age='+this.maxAge;\n  }\n\n  if (this.domain && !this.hostOnly) {\n    str += '; Domain='+this.domain;\n  }\n  if (this.path) {\n    str += '; Path='+this.path;\n  }\n\n  if (this.secure) {\n    str += '; Secure';\n  }\n  if (this.httpOnly) {\n    str += '; HttpOnly';\n  }\n  if (this.extensions) {\n    this.extensions.forEach(function(ext) {\n      str += '; '+ext;\n    });\n  }\n\n  return str;\n};\n\n// TTL() partially replaces the \"expiry-time\" parts of S5.3 step 3 (setCookie()\n// elsewhere)\n// S5.3 says to give the \"latest representable date\" for which we use Infinity\n// For \"expired\" we use 0\nCookie.prototype.TTL = function TTL(now) {\n  /* RFC6265 S4.1.2.2 If a cookie has both the Max-Age and the Expires\n   * attribute, the Max-Age attribute has precedence and controls the\n   * expiration date of the cookie.\n   * (Concurs with S5.3 step 3)\n   */\n  if (this.maxAge != null) {\n    return this.maxAge<=0 ? 0 : this.maxAge*1000;\n  }\n\n  var expires = this.expires;\n  if (expires != Infinity) {\n    if (!(expires instanceof Date)) {\n      expires = parseDate(expires) || Infinity;\n    }\n\n    if (expires == Infinity) {\n      return Infinity;\n    }\n\n    return expires.getTime() - (now || Date.now());\n  }\n\n  return Infinity;\n};\n\n// expiryTime() replaces the \"expiry-time\" parts of S5.3 step 3 (setCookie()\n// elsewhere)\nCookie.prototype.expiryTime = function expiryTime(now) {\n  if (this.maxAge != null) {\n    var relativeTo = now || this.creation || new Date();\n    var age = (this.maxAge <= 0) ? -Infinity : this.maxAge*1000;\n    return relativeTo.getTime() + age;\n  }\n\n  if (this.expires == Infinity) {\n    return Infinity;\n  }\n  return this.expires.getTime();\n};\n\n// expiryDate() replaces the \"expiry-time\" parts of S5.3 step 3 (setCookie()\n// elsewhere), except it returns a Date\nCookie.prototype.expiryDate = function expiryDate(now) {\n  var millisec = this.expiryTime(now);\n  if (millisec == Infinity) {\n    return new Date(MAX_TIME);\n  } else if (millisec == -Infinity) {\n    return new Date(MIN_TIME);\n  } else {\n    return new Date(millisec);\n  }\n};\n\n// This replaces the \"persistent-flag\" parts of S5.3 step 3\nCookie.prototype.isPersistent = function isPersistent() {\n  return (this.maxAge != null || this.expires != Infinity);\n};\n\n// Mostly S5.1.2 and S5.2.3:\nCookie.prototype.cdomain =\nCookie.prototype.canonicalizedDomain = function canonicalizedDomain() {\n  if (this.domain == null) {\n    return null;\n  }\n  return canonicalDomain(this.domain);\n};\n\nfunction CookieJar(store, options) {\n  if (typeof options === \"boolean\") {\n    options = {rejectPublicSuffixes: options};\n  } else if (options == null) {\n    options = {};\n  }\n  if (options.rejectPublicSuffixes != null) {\n    this.rejectPublicSuffixes = options.rejectPublicSuffixes;\n  }\n  if (options.looseMode != null) {\n    this.enableLooseMode = options.looseMode;\n  }\n\n  if (!store) {\n    store = new MemoryCookieStore();\n  }\n  this.store = store;\n}\nCookieJar.prototype.store = null;\nCookieJar.prototype.rejectPublicSuffixes = true;\nCookieJar.prototype.enableLooseMode = false;\nvar CAN_BE_SYNC = [];\n\nCAN_BE_SYNC.push('setCookie');\nCookieJar.prototype.setCookie = function(cookie, url, options, cb) {\n  var err;\n  var context = getCookieContext(url);\n  if (options instanceof Function) {\n    cb = options;\n    options = {};\n  }\n\n  var host = canonicalDomain(context.hostname);\n  var loose = this.enableLooseMode;\n  if (options.loose != null) {\n    loose = options.loose;\n  }\n\n  // S5.3 step 1\n  if (!(cookie instanceof Cookie)) {\n    cookie = Cookie.parse(cookie, { loose: loose });\n  }\n  if (!cookie) {\n    err = new Error(\"Cookie failed to parse\");\n    return cb(options.ignoreError ? null : err);\n  }\n\n  // S5.3 step 2\n  var now = options.now || new Date(); // will assign later to save effort in the face of errors\n\n  // S5.3 step 3: NOOP; persistent-flag and expiry-time is handled by getCookie()\n\n  // S5.3 step 4: NOOP; domain is null by default\n\n  // S5.3 step 5: public suffixes\n  if (this.rejectPublicSuffixes && cookie.domain) {\n    var suffix = pubsuffix.getPublicSuffix(cookie.cdomain());\n    if (suffix == null) { // e.g. \"com\"\n      err = new Error(\"Cookie has domain set to a public suffix\");\n      return cb(options.ignoreError ? null : err);\n    }\n  }\n\n  // S5.3 step 6:\n  if (cookie.domain) {\n    if (!domainMatch(host, cookie.cdomain(), false)) {\n      err = new Error(\"Cookie not in this host's domain. Cookie:\"+cookie.cdomain()+\" Request:\"+host);\n      return cb(options.ignoreError ? null : err);\n    }\n\n    if (cookie.hostOnly == null) { // don't reset if already set\n      cookie.hostOnly = false;\n    }\n\n  } else {\n    cookie.hostOnly = true;\n    cookie.domain = host;\n  }\n\n  //S5.2.4 If the attribute-value is empty or if the first character of the\n  //attribute-value is not %x2F (\"/\"):\n  //Let cookie-path be the default-path.\n  if (!cookie.path || cookie.path[0] !== '/') {\n    cookie.path = defaultPath(context.pathname);\n    cookie.pathIsDefault = true;\n  }\n\n  // S5.3 step 8: NOOP; secure attribute\n  // S5.3 step 9: NOOP; httpOnly attribute\n\n  // S5.3 step 10\n  if (options.http === false && cookie.httpOnly) {\n    err = new Error(\"Cookie is HttpOnly and this isn't an HTTP API\");\n    return cb(options.ignoreError ? null : err);\n  }\n\n  var store = this.store;\n\n  if (!store.updateCookie) {\n    store.updateCookie = function(oldCookie, newCookie, cb) {\n      this.putCookie(newCookie, cb);\n    };\n  }\n\n  function withCookie(err, oldCookie) {\n    if (err) {\n      return cb(err);\n    }\n\n    var next = function(err) {\n      if (err) {\n        return cb(err);\n      } else {\n        cb(null, cookie);\n      }\n    };\n\n    if (oldCookie) {\n      // S5.3 step 11 - \"If the cookie store contains a cookie with the same name,\n      // domain, and path as the newly created cookie:\"\n      if (options.http === false && oldCookie.httpOnly) { // step 11.2\n        err = new Error(\"old Cookie is HttpOnly and this isn't an HTTP API\");\n        return cb(options.ignoreError ? null : err);\n      }\n      cookie.creation = oldCookie.creation; // step 11.3\n      cookie.creationIndex = oldCookie.creationIndex; // preserve tie-breaker\n      cookie.lastAccessed = now;\n      // Step 11.4 (delete cookie) is implied by just setting the new one:\n      store.updateCookie(oldCookie, cookie, next); // step 12\n\n    } else {\n      cookie.creation = cookie.lastAccessed = now;\n      store.putCookie(cookie, next); // step 12\n    }\n  }\n\n  store.findCookie(cookie.domain, cookie.path, cookie.key, withCookie);\n};\n\n// RFC6365 S5.4\nCAN_BE_SYNC.push('getCookies');\nCookieJar.prototype.getCookies = function(url, options, cb) {\n  var context = getCookieContext(url);\n  if (options instanceof Function) {\n    cb = options;\n    options = {};\n  }\n\n  var host = canonicalDomain(context.hostname);\n  var path = context.pathname || '/';\n\n  var secure = options.secure;\n  if (secure == null && context.protocol &&\n      (context.protocol == 'https:' || context.protocol == 'wss:'))\n  {\n    secure = true;\n  }\n\n  var http = options.http;\n  if (http == null) {\n    http = true;\n  }\n\n  var now = options.now || Date.now();\n  var expireCheck = options.expire !== false;\n  var allPaths = !!options.allPaths;\n  var store = this.store;\n\n  function matchingCookie(c) {\n    // \"Either:\n    //   The cookie's host-only-flag is true and the canonicalized\n    //   request-host is identical to the cookie's domain.\n    // Or:\n    //   The cookie's host-only-flag is false and the canonicalized\n    //   request-host domain-matches the cookie's domain.\"\n    if (c.hostOnly) {\n      if (c.domain != host) {\n        return false;\n      }\n    } else {\n      if (!domainMatch(host, c.domain, false)) {\n        return false;\n      }\n    }\n\n    // \"The request-uri's path path-matches the cookie's path.\"\n    if (!allPaths && !pathMatch(path, c.path)) {\n      return false;\n    }\n\n    // \"If the cookie's secure-only-flag is true, then the request-uri's\n    // scheme must denote a \"secure\" protocol\"\n    if (c.secure && !secure) {\n      return false;\n    }\n\n    // \"If the cookie's http-only-flag is true, then exclude the cookie if the\n    // cookie-string is being generated for a \"non-HTTP\" API\"\n    if (c.httpOnly && !http) {\n      return false;\n    }\n\n    // deferred from S5.3\n    // non-RFC: allow retention of expired cookies by choice\n    if (expireCheck && c.expiryTime() <= now) {\n      store.removeCookie(c.domain, c.path, c.key, function(){}); // result ignored\n      return false;\n    }\n\n    return true;\n  }\n\n  store.findCookies(host, allPaths ? null : path, function(err,cookies) {\n    if (err) {\n      return cb(err);\n    }\n\n    cookies = cookies.filter(matchingCookie);\n\n    // sorting of S5.4 part 2\n    if (options.sort !== false) {\n      cookies = cookies.sort(cookieCompare);\n    }\n\n    // S5.4 part 3\n    var now = new Date();\n    cookies.forEach(function(c) {\n      c.lastAccessed = now;\n    });\n    // TODO persist lastAccessed\n\n    cb(null,cookies);\n  });\n};\n\nCAN_BE_SYNC.push('getCookieString');\nCookieJar.prototype.getCookieString = function(/*..., cb*/) {\n  var args = Array.prototype.slice.call(arguments,0);\n  var cb = args.pop();\n  var next = function(err,cookies) {\n    if (err) {\n      cb(err);\n    } else {\n      cb(null, cookies\n        .sort(cookieCompare)\n        .map(function(c){\n          return c.cookieString();\n        })\n        .join('; '));\n    }\n  };\n  args.push(next);\n  this.getCookies.apply(this,args);\n};\n\nCAN_BE_SYNC.push('getSetCookieStrings');\nCookieJar.prototype.getSetCookieStrings = function(/*..., cb*/) {\n  var args = Array.prototype.slice.call(arguments,0);\n  var cb = args.pop();\n  var next = function(err,cookies) {\n    if (err) {\n      cb(err);\n    } else {\n      cb(null, cookies.map(function(c){\n        return c.toString();\n      }));\n    }\n  };\n  args.push(next);\n  this.getCookies.apply(this,args);\n};\n\nCAN_BE_SYNC.push('serialize');\nCookieJar.prototype.serialize = function(cb) {\n  var type = this.store.constructor.name;\n  if (type === 'Object') {\n    type = null;\n  }\n\n  // update README.md \"Serialization Format\" if you change this, please!\n  var serialized = {\n    // The version of tough-cookie that serialized this jar. Generally a good\n    // practice since future versions can make data import decisions based on\n    // known past behavior. When/if this matters, use `semver`.\n    version: 'tough-cookie@'+VERSION,\n\n    // add the store type, to make humans happy:\n    storeType: type,\n\n    // CookieJar configuration:\n    rejectPublicSuffixes: !!this.rejectPublicSuffixes,\n\n    // this gets filled from getAllCookies:\n    cookies: []\n  };\n\n  if (!(this.store.getAllCookies &&\n        typeof this.store.getAllCookies === 'function'))\n  {\n    return cb(new Error('store does not support getAllCookies and cannot be serialized'));\n  }\n\n  this.store.getAllCookies(function(err,cookies) {\n    if (err) {\n      return cb(err);\n    }\n\n    serialized.cookies = cookies.map(function(cookie) {\n      // convert to serialized 'raw' cookies\n      cookie = (cookie instanceof Cookie) ? cookie.toJSON() : cookie;\n\n      // Remove the index so new ones get assigned during deserialization\n      delete cookie.creationIndex;\n\n      return cookie;\n    });\n\n    return cb(null, serialized);\n  });\n};\n\n// well-known name that JSON.stringify calls\nCookieJar.prototype.toJSON = function() {\n  return this.serializeSync();\n};\n\n// use the class method CookieJar.deserialize instead of calling this directly\nCAN_BE_SYNC.push('_importCookies');\nCookieJar.prototype._importCookies = function(serialized, cb) {\n  var jar = this;\n  var cookies = serialized.cookies;\n  if (!cookies || !Array.isArray(cookies)) {\n    return cb(new Error('serialized jar has no cookies array'));\n  }\n\n  function putNext(err) {\n    if (err) {\n      return cb(err);\n    }\n\n    if (!cookies.length) {\n      return cb(err, jar);\n    }\n\n    var cookie;\n    try {\n      cookie = fromJSON(cookies.shift());\n    } catch (e) {\n      return cb(e);\n    }\n\n    if (cookie === null) {\n      return putNext(null); // skip this cookie\n    }\n\n    jar.store.putCookie(cookie, putNext);\n  }\n\n  putNext();\n};\n\nCookieJar.deserialize = function(strOrObj, store, cb) {\n  if (arguments.length !== 3) {\n    // store is optional\n    cb = store;\n    store = null;\n  }\n\n  var serialized;\n  if (typeof strOrObj === 'string') {\n    serialized = jsonParse(strOrObj);\n    if (serialized instanceof Error) {\n      return cb(serialized);\n    }\n  } else {\n    serialized = strOrObj;\n  }\n\n  var jar = new CookieJar(store, serialized.rejectPublicSuffixes);\n  jar._importCookies(serialized, function(err) {\n    if (err) {\n      return cb(err);\n    }\n    cb(null, jar);\n  });\n};\n\nCookieJar.deserializeSync = function(strOrObj, store) {\n  var serialized = typeof strOrObj === 'string' ?\n    JSON.parse(strOrObj) : strOrObj;\n  var jar = new CookieJar(store, serialized.rejectPublicSuffixes);\n\n  // catch this mistake early:\n  if (!jar.store.synchronous) {\n    throw new Error('CookieJar store is not synchronous; use async API instead.');\n  }\n\n  jar._importCookiesSync(serialized);\n  return jar;\n};\nCookieJar.fromJSON = CookieJar.deserializeSync;\n\nCAN_BE_SYNC.push('clone');\nCookieJar.prototype.clone = function(newStore, cb) {\n  if (arguments.length === 1) {\n    cb = newStore;\n    newStore = null;\n  }\n\n  this.serialize(function(err,serialized) {\n    if (err) {\n      return cb(err);\n    }\n    CookieJar.deserialize(newStore, serialized, cb);\n  });\n};\n\n// Use a closure to provide a true imperative API for synchronous stores.\nfunction syncWrap(method) {\n  return function() {\n    if (!this.store.synchronous) {\n      throw new Error('CookieJar store is not synchronous; use async API instead.');\n    }\n\n    var args = Array.prototype.slice.call(arguments);\n    var syncErr, syncResult;\n    args.push(function syncCb(err, result) {\n      syncErr = err;\n      syncResult = result;\n    });\n    this[method].apply(this, args);\n\n    if (syncErr) {\n      throw syncErr;\n    }\n    return syncResult;\n  };\n}\n\n// wrap all declared CAN_BE_SYNC methods in the sync wrapper\nCAN_BE_SYNC.forEach(function(method) {\n  CookieJar.prototype[method+'Sync'] = syncWrap(method);\n});\n\nmodule.exports = {\n  CookieJar: CookieJar,\n  Cookie: Cookie,\n  Store: Store,\n  MemoryCookieStore: MemoryCookieStore,\n  parseDate: parseDate,\n  formatDate: formatDate,\n  parse: parse,\n  fromJSON: fromJSON,\n  domainMatch: domainMatch,\n  defaultPath: defaultPath,\n  pathMatch: pathMatch,\n  getPublicSuffix: pubsuffix.getPublicSuffix,\n  cookieCompare: cookieCompare,\n  permuteDomain: require('./permuteDomain').permuteDomain,\n  permutePath: permutePath,\n  canonicalDomain: canonicalDomain\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/tough-cookie/lib/pubsuffix.js":"/****************************************************\n * AUTOMATICALLY GENERATED by generate-pubsuffix.js *\n *                  DO NOT EDIT!                    *\n ****************************************************/\n\n\"use strict\";\n\nvar punycode = require('punycode');\n\nmodule.exports.getPublicSuffix = function getPublicSuffix(domain) {\n  /*!\n   * Copyright (c) 2015, Salesforce.com, Inc.\n   * All rights reserved.\n   *\n   * Redistribution and use in source and binary forms, with or without\n   * modification, are permitted provided that the following conditions are met:\n   *\n   * 1. Redistributions of source code must retain the above copyright notice,\n   * this list of conditions and the following disclaimer.\n   *\n   * 2. Redistributions in binary form must reproduce the above copyright notice,\n   * this list of conditions and the following disclaimer in the documentation\n   * and/or other materials provided with the distribution.\n   *\n   * 3. Neither the name of Salesforce.com nor the names of its contributors may\n   * be used to endorse or promote products derived from this software without\n   * specific prior written permission.\n   *\n   * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n   * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n   * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n   * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n   * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n   * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n   * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n   * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n   * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n   * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n   * POSSIBILITY OF SUCH DAMAGE.\n   */\n  if (!domain) {\n    return null;\n  }\n  if (domain.match(/^\\./)) {\n    return null;\n  }\n  var asciiDomain = punycode.toASCII(domain);\n  var converted = false;\n  if (asciiDomain !== domain) {\n    domain = asciiDomain;\n    converted = true;\n  }\n  if (index[domain]) {\n    return null;\n  }\n\n  domain = domain.toLowerCase();\n  var parts = domain.split('.').reverse();\n\n  var suffix = '';\n  var suffixLen = 0;\n  for (var i=0; i<parts.length; i++) {\n    var part = parts[i];\n    var starstr = '*'+suffix;\n    var partstr = part+suffix;\n\n    if (index[starstr]) { // star rule matches\n      suffixLen = i+1;\n      if (index[partstr] === false) { // exception rule matches (NB: false, not undefined)\n        suffixLen--;\n      }\n    } else if (index[partstr]) { // exact match, not exception\n      suffixLen = i+1;\n    }\n\n    suffix = '.'+partstr;\n  }\n\n  if (index['*'+suffix]) { // *.domain exists (e.g. *.kyoto.jp for domain='kyoto.jp');\n    return null;\n  }\n\n  suffixLen = suffixLen || 1;\n  if (parts.length > suffixLen) {\n    var publicSuffix = parts.slice(0,suffixLen+1).reverse().join('.');\n    return converted ? punycode.toUnicode(publicSuffix) : publicSuffix;\n  }\n\n  return null;\n};\n\n// The following generated structure is used under the MPL version 2.0\n// See public-suffix.txt for more information\n\nvar index = module.exports.index = Object.freeze(\n{\"ac\":true,\"com.ac\":true,\"edu.ac\":true,\"gov.ac\":true,\"net.ac\":true,\"mil.ac\":true,\"org.ac\":true,\"ad\":true,\"nom.ad\":true,\"ae\":true,\"co.ae\":true,\"net.ae\":true,\"org.ae\":true,\"sch.ae\":true,\"ac.ae\":true,\"gov.ae\":true,\"mil.ae\":true,\"aero\":true,\"accident-investigation.aero\":true,\"accident-prevention.aero\":true,\"aerobatic.aero\":true,\"aeroclub.aero\":true,\"aerodrome.aero\":true,\"agents.aero\":true,\"aircraft.aero\":true,\"airline.aero\":true,\"airport.aero\":true,\"air-surveillance.aero\":true,\"airtraffic.aero\":true,\"air-traffic-control.aero\":true,\"ambulance.aero\":true,\"amusement.aero\":true,\"association.aero\":true,\"author.aero\":true,\"ballooning.aero\":true,\"broker.aero\":true,\"caa.aero\":true,\"cargo.aero\":true,\"catering.aero\":true,\"certification.aero\":true,\"championship.aero\":true,\"charter.aero\":true,\"civilaviation.aero\":true,\"club.aero\":true,\"conference.aero\":true,\"consultant.aero\":true,\"consulting.aero\":true,\"control.aero\":true,\"council.aero\":true,\"crew.aero\":true,\"design.aero\":true,\"dgca.aero\":true,\"educator.aero\":true,\"emergency.aero\":true,\"engine.aero\":true,\"engineer.aero\":true,\"entertainment.aero\":true,\"equipment.aero\":true,\"exchange.aero\":true,\"express.aero\":true,\"federation.aero\":true,\"flight.aero\":true,\"freight.aero\":true,\"fuel.aero\":true,\"gliding.aero\":true,\"government.aero\":true,\"groundhandling.aero\":true,\"group.aero\":true,\"hanggliding.aero\":true,\"homebuilt.aero\":true,\"insurance.aero\":true,\"journal.aero\":true,\"journalist.aero\":true,\"leasing.aero\":true,\"logistics.aero\":true,\"magazine.aero\":true,\"maintenance.aero\":true,\"marketplace.aero\":true,\"media.aero\":true,\"microlight.aero\":true,\"modelling.aero\":true,\"navigation.aero\":true,\"parachuting.aero\":true,\"paragliding.aero\":true,\"passenger-association.aero\":true,\"pilot.aero\":true,\"press.aero\":true,\"production.aero\":true,\"recreation.aero\":true,\"repbody.aero\":true,\"res.aero\":true,\"research.aero\":true,\"rotorcraft.aero\":true,\"safety.aero\":true,\"scientist.aero\":true,\"services.aero\":true,\"show.aero\":true,\"skydiving.aero\":true,\"software.aero\":true,\"student.aero\":true,\"taxi.aero\":true,\"trader.aero\":true,\"trading.aero\":true,\"trainer.aero\":true,\"union.aero\":true,\"workinggroup.aero\":true,\"works.aero\":true,\"af\":true,\"gov.af\":true,\"com.af\":true,\"org.af\":true,\"net.af\":true,\"edu.af\":true,\"ag\":true,\"com.ag\":true,\"org.ag\":true,\"net.ag\":true,\"co.ag\":true,\"nom.ag\":true,\"ai\":true,\"off.ai\":true,\"com.ai\":true,\"net.ai\":true,\"org.ai\":true,\"al\":true,\"com.al\":true,\"edu.al\":true,\"gov.al\":true,\"mil.al\":true,\"net.al\":true,\"org.al\":true,\"am\":true,\"an\":true,\"com.an\":true,\"net.an\":true,\"org.an\":true,\"edu.an\":true,\"ao\":true,\"ed.ao\":true,\"gv.ao\":true,\"og.ao\":true,\"co.ao\":true,\"pb.ao\":true,\"it.ao\":true,\"aq\":true,\"ar\":true,\"com.ar\":true,\"edu.ar\":true,\"gob.ar\":true,\"gov.ar\":true,\"int.ar\":true,\"mil.ar\":true,\"net.ar\":true,\"org.ar\":true,\"tur.ar\":true,\"arpa\":true,\"e164.arpa\":true,\"in-addr.arpa\":true,\"ip6.arpa\":true,\"iris.arpa\":true,\"uri.arpa\":true,\"urn.arpa\":true,\"as\":true,\"gov.as\":true,\"asia\":true,\"at\":true,\"ac.at\":true,\"co.at\":true,\"gv.at\":true,\"or.at\":true,\"au\":true,\"com.au\":true,\"net.au\":true,\"org.au\":true,\"edu.au\":true,\"gov.au\":true,\"asn.au\":true,\"id.au\":true,\"info.au\":true,\"conf.au\":true,\"oz.au\":true,\"act.au\":true,\"nsw.au\":true,\"nt.au\":true,\"qld.au\":true,\"sa.au\":true,\"tas.au\":true,\"vic.au\":true,\"wa.au\":true,\"act.edu.au\":true,\"nsw.edu.au\":true,\"nt.edu.au\":true,\"qld.edu.au\":true,\"sa.edu.au\":true,\"tas.edu.au\":true,\"vic.edu.au\":true,\"wa.edu.au\":true,\"qld.gov.au\":true,\"sa.gov.au\":true,\"tas.gov.au\":true,\"vic.gov.au\":true,\"wa.gov.au\":true,\"aw\":true,\"com.aw\":true,\"ax\":true,\"az\":true,\"com.az\":true,\"net.az\":true,\"int.az\":true,\"gov.az\":true,\"org.az\":true,\"edu.az\":true,\"info.az\":true,\"pp.az\":true,\"mil.az\":true,\"name.az\":true,\"pro.az\":true,\"biz.az\":true,\"ba\":true,\"org.ba\":true,\"net.ba\":true,\"edu.ba\":true,\"gov.ba\":true,\"mil.ba\":true,\"unsa.ba\":true,\"unbi.ba\":true,\"co.ba\":true,\"com.ba\":true,\"rs.ba\":true,\"bb\":true,\"biz.bb\":true,\"co.bb\":true,\"com.bb\":true,\"edu.bb\":true,\"gov.bb\":true,\"info.bb\":true,\"net.bb\":true,\"org.bb\":true,\"store.bb\":true,\"tv.bb\":true,\"*.bd\":true,\"be\":true,\"ac.be\":true,\"bf\":true,\"gov.bf\":true,\"bg\":true,\"a.bg\":true,\"b.bg\":true,\"c.bg\":true,\"d.bg\":true,\"e.bg\":true,\"f.bg\":true,\"g.bg\":true,\"h.bg\":true,\"i.bg\":true,\"j.bg\":true,\"k.bg\":true,\"l.bg\":true,\"m.bg\":true,\"n.bg\":true,\"o.bg\":true,\"p.bg\":true,\"q.bg\":true,\"r.bg\":true,\"s.bg\":true,\"t.bg\":true,\"u.bg\":true,\"v.bg\":true,\"w.bg\":true,\"x.bg\":true,\"y.bg\":true,\"z.bg\":true,\"0.bg\":true,\"1.bg\":true,\"2.bg\":true,\"3.bg\":true,\"4.bg\":true,\"5.bg\":true,\"6.bg\":true,\"7.bg\":true,\"8.bg\":true,\"9.bg\":true,\"bh\":true,\"com.bh\":true,\"edu.bh\":true,\"net.bh\":true,\"org.bh\":true,\"gov.bh\":true,\"bi\":true,\"co.bi\":true,\"com.bi\":true,\"edu.bi\":true,\"or.bi\":true,\"org.bi\":true,\"biz\":true,\"bj\":true,\"asso.bj\":true,\"barreau.bj\":true,\"gouv.bj\":true,\"bm\":true,\"com.bm\":true,\"edu.bm\":true,\"gov.bm\":true,\"net.bm\":true,\"org.bm\":true,\"*.bn\":true,\"bo\":true,\"com.bo\":true,\"edu.bo\":true,\"gov.bo\":true,\"gob.bo\":true,\"int.bo\":true,\"org.bo\":true,\"net.bo\":true,\"mil.bo\":true,\"tv.bo\":true,\"br\":true,\"adm.br\":true,\"adv.br\":true,\"agr.br\":true,\"am.br\":true,\"arq.br\":true,\"art.br\":true,\"ato.br\":true,\"b.br\":true,\"bio.br\":true,\"blog.br\":true,\"bmd.br\":true,\"cim.br\":true,\"cng.br\":true,\"cnt.br\":true,\"com.br\":true,\"coop.br\":true,\"ecn.br\":true,\"eco.br\":true,\"edu.br\":true,\"emp.br\":true,\"eng.br\":true,\"esp.br\":true,\"etc.br\":true,\"eti.br\":true,\"far.br\":true,\"flog.br\":true,\"fm.br\":true,\"fnd.br\":true,\"fot.br\":true,\"fst.br\":true,\"g12.br\":true,\"ggf.br\":true,\"gov.br\":true,\"imb.br\":true,\"ind.br\":true,\"inf.br\":true,\"jor.br\":true,\"jus.br\":true,\"leg.br\":true,\"lel.br\":true,\"mat.br\":true,\"med.br\":true,\"mil.br\":true,\"mp.br\":true,\"mus.br\":true,\"net.br\":true,\"*.nom.br\":true,\"not.br\":true,\"ntr.br\":true,\"odo.br\":true,\"org.br\":true,\"ppg.br\":true,\"pro.br\":true,\"psc.br\":true,\"psi.br\":true,\"qsl.br\":true,\"radio.br\":true,\"rec.br\":true,\"slg.br\":true,\"srv.br\":true,\"taxi.br\":true,\"teo.br\":true,\"tmp.br\":true,\"trd.br\":true,\"tur.br\":true,\"tv.br\":true,\"vet.br\":true,\"vlog.br\":true,\"wiki.br\":true,\"zlg.br\":true,\"bs\":true,\"com.bs\":true,\"net.bs\":true,\"org.bs\":true,\"edu.bs\":true,\"gov.bs\":true,\"bt\":true,\"com.bt\":true,\"edu.bt\":true,\"gov.bt\":true,\"net.bt\":true,\"org.bt\":true,\"bv\":true,\"bw\":true,\"co.bw\":true,\"org.bw\":true,\"by\":true,\"gov.by\":true,\"mil.by\":true,\"com.by\":true,\"of.by\":true,\"bz\":true,\"com.bz\":true,\"net.bz\":true,\"org.bz\":true,\"edu.bz\":true,\"gov.bz\":true,\"ca\":true,\"ab.ca\":true,\"bc.ca\":true,\"mb.ca\":true,\"nb.ca\":true,\"nf.ca\":true,\"nl.ca\":true,\"ns.ca\":true,\"nt.ca\":true,\"nu.ca\":true,\"on.ca\":true,\"pe.ca\":true,\"qc.ca\":true,\"sk.ca\":true,\"yk.ca\":true,\"gc.ca\":true,\"cat\":true,\"cc\":true,\"cd\":true,\"gov.cd\":true,\"cf\":true,\"cg\":true,\"ch\":true,\"ci\":true,\"org.ci\":true,\"or.ci\":true,\"com.ci\":true,\"co.ci\":true,\"edu.ci\":true,\"ed.ci\":true,\"ac.ci\":true,\"net.ci\":true,\"go.ci\":true,\"asso.ci\":true,\"xn--aroport-bya.ci\":true,\"int.ci\":true,\"presse.ci\":true,\"md.ci\":true,\"gouv.ci\":true,\"*.ck\":true,\"www.ck\":false,\"cl\":true,\"gov.cl\":true,\"gob.cl\":true,\"co.cl\":true,\"mil.cl\":true,\"cm\":true,\"co.cm\":true,\"com.cm\":true,\"gov.cm\":true,\"net.cm\":true,\"cn\":true,\"ac.cn\":true,\"com.cn\":true,\"edu.cn\":true,\"gov.cn\":true,\"net.cn\":true,\"org.cn\":true,\"mil.cn\":true,\"xn--55qx5d.cn\":true,\"xn--io0a7i.cn\":true,\"xn--od0alg.cn\":true,\"ah.cn\":true,\"bj.cn\":true,\"cq.cn\":true,\"fj.cn\":true,\"gd.cn\":true,\"gs.cn\":true,\"gz.cn\":true,\"gx.cn\":true,\"ha.cn\":true,\"hb.cn\":true,\"he.cn\":true,\"hi.cn\":true,\"hl.cn\":true,\"hn.cn\":true,\"jl.cn\":true,\"js.cn\":true,\"jx.cn\":true,\"ln.cn\":true,\"nm.cn\":true,\"nx.cn\":true,\"qh.cn\":true,\"sc.cn\":true,\"sd.cn\":true,\"sh.cn\":true,\"sn.cn\":true,\"sx.cn\":true,\"tj.cn\":true,\"xj.cn\":true,\"xz.cn\":true,\"yn.cn\":true,\"zj.cn\":true,\"hk.cn\":true,\"mo.cn\":true,\"tw.cn\":true,\"co\":true,\"arts.co\":true,\"com.co\":true,\"edu.co\":true,\"firm.co\":true,\"gov.co\":true,\"info.co\":true,\"int.co\":true,\"mil.co\":true,\"net.co\":true,\"nom.co\":true,\"org.co\":true,\"rec.co\":true,\"web.co\":true,\"com\":true,\"coop\":true,\"cr\":true,\"ac.cr\":true,\"co.cr\":true,\"ed.cr\":true,\"fi.cr\":true,\"go.cr\":true,\"or.cr\":true,\"sa.cr\":true,\"cu\":true,\"com.cu\":true,\"edu.cu\":true,\"org.cu\":true,\"net.cu\":true,\"gov.cu\":true,\"inf.cu\":true,\"cv\":true,\"cw\":true,\"com.cw\":true,\"edu.cw\":true,\"net.cw\":true,\"org.cw\":true,\"cx\":true,\"gov.cx\":true,\"ac.cy\":true,\"biz.cy\":true,\"com.cy\":true,\"ekloges.cy\":true,\"gov.cy\":true,\"ltd.cy\":true,\"name.cy\":true,\"net.cy\":true,\"org.cy\":true,\"parliament.cy\":true,\"press.cy\":true,\"pro.cy\":true,\"tm.cy\":true,\"cz\":true,\"de\":true,\"dj\":true,\"dk\":true,\"dm\":true,\"com.dm\":true,\"net.dm\":true,\"org.dm\":true,\"edu.dm\":true,\"gov.dm\":true,\"do\":true,\"art.do\":true,\"com.do\":true,\"edu.do\":true,\"gob.do\":true,\"gov.do\":true,\"mil.do\":true,\"net.do\":true,\"org.do\":true,\"sld.do\":true,\"web.do\":true,\"dz\":true,\"com.dz\":true,\"org.dz\":true,\"net.dz\":true,\"gov.dz\":true,\"edu.dz\":true,\"asso.dz\":true,\"pol.dz\":true,\"art.dz\":true,\"ec\":true,\"com.ec\":true,\"info.ec\":true,\"net.ec\":true,\"fin.ec\":true,\"k12.ec\":true,\"med.ec\":true,\"pro.ec\":true,\"org.ec\":true,\"edu.ec\":true,\"gov.ec\":true,\"gob.ec\":true,\"mil.ec\":true,\"edu\":true,\"ee\":true,\"edu.ee\":true,\"gov.ee\":true,\"riik.ee\":true,\"lib.ee\":true,\"med.ee\":true,\"com.ee\":true,\"pri.ee\":true,\"aip.ee\":true,\"org.ee\":true,\"fie.ee\":true,\"eg\":true,\"com.eg\":true,\"edu.eg\":true,\"eun.eg\":true,\"gov.eg\":true,\"mil.eg\":true,\"name.eg\":true,\"net.eg\":true,\"org.eg\":true,\"sci.eg\":true,\"*.er\":true,\"es\":true,\"com.es\":true,\"nom.es\":true,\"org.es\":true,\"gob.es\":true,\"edu.es\":true,\"et\":true,\"com.et\":true,\"gov.et\":true,\"org.et\":true,\"edu.et\":true,\"biz.et\":true,\"name.et\":true,\"info.et\":true,\"net.et\":true,\"eu\":true,\"fi\":true,\"aland.fi\":true,\"*.fj\":true,\"*.fk\":true,\"fm\":true,\"fo\":true,\"fr\":true,\"com.fr\":true,\"asso.fr\":true,\"nom.fr\":true,\"prd.fr\":true,\"presse.fr\":true,\"tm.fr\":true,\"aeroport.fr\":true,\"assedic.fr\":true,\"avocat.fr\":true,\"avoues.fr\":true,\"cci.fr\":true,\"chambagri.fr\":true,\"chirurgiens-dentistes.fr\":true,\"experts-comptables.fr\":true,\"geometre-expert.fr\":true,\"gouv.fr\":true,\"greta.fr\":true,\"huissier-justice.fr\":true,\"medecin.fr\":true,\"notaires.fr\":true,\"pharmacien.fr\":true,\"port.fr\":true,\"veterinaire.fr\":true,\"ga\":true,\"gb\":true,\"gd\":true,\"ge\":true,\"com.ge\":true,\"edu.ge\":true,\"gov.ge\":true,\"org.ge\":true,\"mil.ge\":true,\"net.ge\":true,\"pvt.ge\":true,\"gf\":true,\"gg\":true,\"co.gg\":true,\"net.gg\":true,\"org.gg\":true,\"gh\":true,\"com.gh\":true,\"edu.gh\":true,\"gov.gh\":true,\"org.gh\":true,\"mil.gh\":true,\"gi\":true,\"com.gi\":true,\"ltd.gi\":true,\"gov.gi\":true,\"mod.gi\":true,\"edu.gi\":true,\"org.gi\":true,\"gl\":true,\"co.gl\":true,\"com.gl\":true,\"edu.gl\":true,\"net.gl\":true,\"org.gl\":true,\"gm\":true,\"gn\":true,\"ac.gn\":true,\"com.gn\":true,\"edu.gn\":true,\"gov.gn\":true,\"org.gn\":true,\"net.gn\":true,\"gov\":true,\"gp\":true,\"com.gp\":true,\"net.gp\":true,\"mobi.gp\":true,\"edu.gp\":true,\"org.gp\":true,\"asso.gp\":true,\"gq\":true,\"gr\":true,\"com.gr\":true,\"edu.gr\":true,\"net.gr\":true,\"org.gr\":true,\"gov.gr\":true,\"gs\":true,\"gt\":true,\"com.gt\":true,\"edu.gt\":true,\"gob.gt\":true,\"ind.gt\":true,\"mil.gt\":true,\"net.gt\":true,\"org.gt\":true,\"*.gu\":true,\"gw\":true,\"gy\":true,\"co.gy\":true,\"com.gy\":true,\"net.gy\":true,\"hk\":true,\"com.hk\":true,\"edu.hk\":true,\"gov.hk\":true,\"idv.hk\":true,\"net.hk\":true,\"org.hk\":true,\"xn--55qx5d.hk\":true,\"xn--wcvs22d.hk\":true,\"xn--lcvr32d.hk\":true,\"xn--mxtq1m.hk\":true,\"xn--gmqw5a.hk\":true,\"xn--ciqpn.hk\":true,\"xn--gmq050i.hk\":true,\"xn--zf0avx.hk\":true,\"xn--io0a7i.hk\":true,\"xn--mk0axi.hk\":true,\"xn--od0alg.hk\":true,\"xn--od0aq3b.hk\":true,\"xn--tn0ag.hk\":true,\"xn--uc0atv.hk\":true,\"xn--uc0ay4a.hk\":true,\"hm\":true,\"hn\":true,\"com.hn\":true,\"edu.hn\":true,\"org.hn\":true,\"net.hn\":true,\"mil.hn\":true,\"gob.hn\":true,\"hr\":true,\"iz.hr\":true,\"from.hr\":true,\"name.hr\":true,\"com.hr\":true,\"ht\":true,\"com.ht\":true,\"shop.ht\":true,\"firm.ht\":true,\"info.ht\":true,\"adult.ht\":true,\"net.ht\":true,\"pro.ht\":true,\"org.ht\":true,\"med.ht\":true,\"art.ht\":true,\"coop.ht\":true,\"pol.ht\":true,\"asso.ht\":true,\"edu.ht\":true,\"rel.ht\":true,\"gouv.ht\":true,\"perso.ht\":true,\"hu\":true,\"co.hu\":true,\"info.hu\":true,\"org.hu\":true,\"priv.hu\":true,\"sport.hu\":true,\"tm.hu\":true,\"2000.hu\":true,\"agrar.hu\":true,\"bolt.hu\":true,\"casino.hu\":true,\"city.hu\":true,\"erotica.hu\":true,\"erotika.hu\":true,\"film.hu\":true,\"forum.hu\":true,\"games.hu\":true,\"hotel.hu\":true,\"ingatlan.hu\":true,\"jogasz.hu\":true,\"konyvelo.hu\":true,\"lakas.hu\":true,\"media.hu\":true,\"news.hu\":true,\"reklam.hu\":true,\"sex.hu\":true,\"shop.hu\":true,\"suli.hu\":true,\"szex.hu\":true,\"tozsde.hu\":true,\"utazas.hu\":true,\"video.hu\":true,\"id\":true,\"ac.id\":true,\"biz.id\":true,\"co.id\":true,\"desa.id\":true,\"go.id\":true,\"mil.id\":true,\"my.id\":true,\"net.id\":true,\"or.id\":true,\"sch.id\":true,\"web.id\":true,\"ie\":true,\"gov.ie\":true,\"il\":true,\"ac.il\":true,\"co.il\":true,\"gov.il\":true,\"idf.il\":true,\"k12.il\":true,\"muni.il\":true,\"net.il\":true,\"org.il\":true,\"im\":true,\"ac.im\":true,\"co.im\":true,\"com.im\":true,\"ltd.co.im\":true,\"net.im\":true,\"org.im\":true,\"plc.co.im\":true,\"tt.im\":true,\"tv.im\":true,\"in\":true,\"co.in\":true,\"firm.in\":true,\"net.in\":true,\"org.in\":true,\"gen.in\":true,\"ind.in\":true,\"nic.in\":true,\"ac.in\":true,\"edu.in\":true,\"res.in\":true,\"gov.in\":true,\"mil.in\":true,\"info\":true,\"int\":true,\"eu.int\":true,\"io\":true,\"com.io\":true,\"iq\":true,\"gov.iq\":true,\"edu.iq\":true,\"mil.iq\":true,\"com.iq\":true,\"org.iq\":true,\"net.iq\":true,\"ir\":true,\"ac.ir\":true,\"co.ir\":true,\"gov.ir\":true,\"id.ir\":true,\"net.ir\":true,\"org.ir\":true,\"sch.ir\":true,\"xn--mgba3a4f16a.ir\":true,\"xn--mgba3a4fra.ir\":true,\"is\":true,\"net.is\":true,\"com.is\":true,\"edu.is\":true,\"gov.is\":true,\"org.is\":true,\"int.is\":true,\"it\":true,\"gov.it\":true,\"edu.it\":true,\"abr.it\":true,\"abruzzo.it\":true,\"aosta-valley.it\":true,\"aostavalley.it\":true,\"bas.it\":true,\"basilicata.it\":true,\"cal.it\":true,\"calabria.it\":true,\"cam.it\":true,\"campania.it\":true,\"emilia-romagna.it\":true,\"emiliaromagna.it\":true,\"emr.it\":true,\"friuli-v-giulia.it\":true,\"friuli-ve-giulia.it\":true,\"friuli-vegiulia.it\":true,\"friuli-venezia-giulia.it\":true,\"friuli-veneziagiulia.it\":true,\"friuli-vgiulia.it\":true,\"friuliv-giulia.it\":true,\"friulive-giulia.it\":true,\"friulivegiulia.it\":true,\"friulivenezia-giulia.it\":true,\"friuliveneziagiulia.it\":true,\"friulivgiulia.it\":true,\"fvg.it\":true,\"laz.it\":true,\"lazio.it\":true,\"lig.it\":true,\"liguria.it\":true,\"lom.it\":true,\"lombardia.it\":true,\"lombardy.it\":true,\"lucania.it\":true,\"mar.it\":true,\"marche.it\":true,\"mol.it\":true,\"molise.it\":true,\"piedmont.it\":true,\"piemonte.it\":true,\"pmn.it\":true,\"pug.it\":true,\"puglia.it\":true,\"sar.it\":true,\"sardegna.it\":true,\"sardinia.it\":true,\"sic.it\":true,\"sicilia.it\":true,\"sicily.it\":true,\"taa.it\":true,\"tos.it\":true,\"toscana.it\":true,\"trentino-a-adige.it\":true,\"trentino-aadige.it\":true,\"trentino-alto-adige.it\":true,\"trentino-altoadige.it\":true,\"trentino-s-tirol.it\":true,\"trentino-stirol.it\":true,\"trentino-sud-tirol.it\":true,\"trentino-sudtirol.it\":true,\"trentino-sued-tirol.it\":true,\"trentino-suedtirol.it\":true,\"trentinoa-adige.it\":true,\"trentinoaadige.it\":true,\"trentinoalto-adige.it\":true,\"trentinoaltoadige.it\":true,\"trentinos-tirol.it\":true,\"trentinostirol.it\":true,\"trentinosud-tirol.it\":true,\"trentinosudtirol.it\":true,\"trentinosued-tirol.it\":true,\"trentinosuedtirol.it\":true,\"tuscany.it\":true,\"umb.it\":true,\"umbria.it\":true,\"val-d-aosta.it\":true,\"val-daosta.it\":true,\"vald-aosta.it\":true,\"valdaosta.it\":true,\"valle-aosta.it\":true,\"valle-d-aosta.it\":true,\"valle-daosta.it\":true,\"valleaosta.it\":true,\"valled-aosta.it\":true,\"valledaosta.it\":true,\"vallee-aoste.it\":true,\"valleeaoste.it\":true,\"vao.it\":true,\"vda.it\":true,\"ven.it\":true,\"veneto.it\":true,\"ag.it\":true,\"agrigento.it\":true,\"al.it\":true,\"alessandria.it\":true,\"alto-adige.it\":true,\"altoadige.it\":true,\"an.it\":true,\"ancona.it\":true,\"andria-barletta-trani.it\":true,\"andria-trani-barletta.it\":true,\"andriabarlettatrani.it\":true,\"andriatranibarletta.it\":true,\"ao.it\":true,\"aosta.it\":true,\"aoste.it\":true,\"ap.it\":true,\"aq.it\":true,\"aquila.it\":true,\"ar.it\":true,\"arezzo.it\":true,\"ascoli-piceno.it\":true,\"ascolipiceno.it\":true,\"asti.it\":true,\"at.it\":true,\"av.it\":true,\"avellino.it\":true,\"ba.it\":true,\"balsan.it\":true,\"bari.it\":true,\"barletta-trani-andria.it\":true,\"barlettatraniandria.it\":true,\"belluno.it\":true,\"benevento.it\":true,\"bergamo.it\":true,\"bg.it\":true,\"bi.it\":true,\"biella.it\":true,\"bl.it\":true,\"bn.it\":true,\"bo.it\":true,\"bologna.it\":true,\"bolzano.it\":true,\"bozen.it\":true,\"br.it\":true,\"brescia.it\":true,\"brindisi.it\":true,\"bs.it\":true,\"bt.it\":true,\"bz.it\":true,\"ca.it\":true,\"cagliari.it\":true,\"caltanissetta.it\":true,\"campidano-medio.it\":true,\"campidanomedio.it\":true,\"campobasso.it\":true,\"carbonia-iglesias.it\":true,\"carboniaiglesias.it\":true,\"carrara-massa.it\":true,\"carraramassa.it\":true,\"caserta.it\":true,\"catania.it\":true,\"catanzaro.it\":true,\"cb.it\":true,\"ce.it\":true,\"cesena-forli.it\":true,\"cesenaforli.it\":true,\"ch.it\":true,\"chieti.it\":true,\"ci.it\":true,\"cl.it\":true,\"cn.it\":true,\"co.it\":true,\"como.it\":true,\"cosenza.it\":true,\"cr.it\":true,\"cremona.it\":true,\"crotone.it\":true,\"cs.it\":true,\"ct.it\":true,\"cuneo.it\":true,\"cz.it\":true,\"dell-ogliastra.it\":true,\"dellogliastra.it\":true,\"en.it\":true,\"enna.it\":true,\"fc.it\":true,\"fe.it\":true,\"fermo.it\":true,\"ferrara.it\":true,\"fg.it\":true,\"fi.it\":true,\"firenze.it\":true,\"florence.it\":true,\"fm.it\":true,\"foggia.it\":true,\"forli-cesena.it\":true,\"forlicesena.it\":true,\"fr.it\":true,\"frosinone.it\":true,\"ge.it\":true,\"genoa.it\":true,\"genova.it\":true,\"go.it\":true,\"gorizia.it\":true,\"gr.it\":true,\"grosseto.it\":true,\"iglesias-carbonia.it\":true,\"iglesiascarbonia.it\":true,\"im.it\":true,\"imperia.it\":true,\"is.it\":true,\"isernia.it\":true,\"kr.it\":true,\"la-spezia.it\":true,\"laquila.it\":true,\"laspezia.it\":true,\"latina.it\":true,\"lc.it\":true,\"le.it\":true,\"lecce.it\":true,\"lecco.it\":true,\"li.it\":true,\"livorno.it\":true,\"lo.it\":true,\"lodi.it\":true,\"lt.it\":true,\"lu.it\":true,\"lucca.it\":true,\"macerata.it\":true,\"mantova.it\":true,\"massa-carrara.it\":true,\"massacarrara.it\":true,\"matera.it\":true,\"mb.it\":true,\"mc.it\":true,\"me.it\":true,\"medio-campidano.it\":true,\"mediocampidano.it\":true,\"messina.it\":true,\"mi.it\":true,\"milan.it\":true,\"milano.it\":true,\"mn.it\":true,\"mo.it\":true,\"modena.it\":true,\"monza-brianza.it\":true,\"monza-e-della-brianza.it\":true,\"monza.it\":true,\"monzabrianza.it\":true,\"monzaebrianza.it\":true,\"monzaedellabrianza.it\":true,\"ms.it\":true,\"mt.it\":true,\"na.it\":true,\"naples.it\":true,\"napoli.it\":true,\"no.it\":true,\"novara.it\":true,\"nu.it\":true,\"nuoro.it\":true,\"og.it\":true,\"ogliastra.it\":true,\"olbia-tempio.it\":true,\"olbiatempio.it\":true,\"or.it\":true,\"oristano.it\":true,\"ot.it\":true,\"pa.it\":true,\"padova.it\":true,\"padua.it\":true,\"palermo.it\":true,\"parma.it\":true,\"pavia.it\":true,\"pc.it\":true,\"pd.it\":true,\"pe.it\":true,\"perugia.it\":true,\"pesaro-urbino.it\":true,\"pesarourbino.it\":true,\"pescara.it\":true,\"pg.it\":true,\"pi.it\":true,\"piacenza.it\":true,\"pisa.it\":true,\"pistoia.it\":true,\"pn.it\":true,\"po.it\":true,\"pordenone.it\":true,\"potenza.it\":true,\"pr.it\":true,\"prato.it\":true,\"pt.it\":true,\"pu.it\":true,\"pv.it\":true,\"pz.it\":true,\"ra.it\":true,\"ragusa.it\":true,\"ravenna.it\":true,\"rc.it\":true,\"re.it\":true,\"reggio-calabria.it\":true,\"reggio-emilia.it\":true,\"reggiocalabria.it\":true,\"reggioemilia.it\":true,\"rg.it\":true,\"ri.it\":true,\"rieti.it\":true,\"rimini.it\":true,\"rm.it\":true,\"rn.it\":true,\"ro.it\":true,\"roma.it\":true,\"rome.it\":true,\"rovigo.it\":true,\"sa.it\":true,\"salerno.it\":true,\"sassari.it\":true,\"savona.it\":true,\"si.it\":true,\"siena.it\":true,\"siracusa.it\":true,\"so.it\":true,\"sondrio.it\":true,\"sp.it\":true,\"sr.it\":true,\"ss.it\":true,\"suedtirol.it\":true,\"sv.it\":true,\"ta.it\":true,\"taranto.it\":true,\"te.it\":true,\"tempio-olbia.it\":true,\"tempioolbia.it\":true,\"teramo.it\":true,\"terni.it\":true,\"tn.it\":true,\"to.it\":true,\"torino.it\":true,\"tp.it\":true,\"tr.it\":true,\"trani-andria-barletta.it\":true,\"trani-barletta-andria.it\":true,\"traniandriabarletta.it\":true,\"tranibarlettaandria.it\":true,\"trapani.it\":true,\"trentino.it\":true,\"trento.it\":true,\"treviso.it\":true,\"trieste.it\":true,\"ts.it\":true,\"turin.it\":true,\"tv.it\":true,\"ud.it\":true,\"udine.it\":true,\"urbino-pesaro.it\":true,\"urbinopesaro.it\":true,\"va.it\":true,\"varese.it\":true,\"vb.it\":true,\"vc.it\":true,\"ve.it\":true,\"venezia.it\":true,\"venice.it\":true,\"verbania.it\":true,\"vercelli.it\":true,\"verona.it\":true,\"vi.it\":true,\"vibo-valentia.it\":true,\"vibovalentia.it\":true,\"vicenza.it\":true,\"viterbo.it\":true,\"vr.it\":true,\"vs.it\":true,\"vt.it\":true,\"vv.it\":true,\"je\":true,\"co.je\":true,\"net.je\":true,\"org.je\":true,\"*.jm\":true,\"jo\":true,\"com.jo\":true,\"org.jo\":true,\"net.jo\":true,\"edu.jo\":true,\"sch.jo\":true,\"gov.jo\":true,\"mil.jo\":true,\"name.jo\":true,\"jobs\":true,\"jp\":true,\"ac.jp\":true,\"ad.jp\":true,\"co.jp\":true,\"ed.jp\":true,\"go.jp\":true,\"gr.jp\":true,\"lg.jp\":true,\"ne.jp\":true,\"or.jp\":true,\"aichi.jp\":true,\"akita.jp\":true,\"aomori.jp\":true,\"chiba.jp\":true,\"ehime.jp\":true,\"fukui.jp\":true,\"fukuoka.jp\":true,\"fukushima.jp\":true,\"gifu.jp\":true,\"gunma.jp\":true,\"hiroshima.jp\":true,\"hokkaido.jp\":true,\"hyogo.jp\":true,\"ibaraki.jp\":true,\"ishikawa.jp\":true,\"iwate.jp\":true,\"kagawa.jp\":true,\"kagoshima.jp\":true,\"kanagawa.jp\":true,\"kochi.jp\":true,\"kumamoto.jp\":true,\"kyoto.jp\":true,\"mie.jp\":true,\"miyagi.jp\":true,\"miyazaki.jp\":true,\"nagano.jp\":true,\"nagasaki.jp\":true,\"nara.jp\":true,\"niigata.jp\":true,\"oita.jp\":true,\"okayama.jp\":true,\"okinawa.jp\":true,\"osaka.jp\":true,\"saga.jp\":true,\"saitama.jp\":true,\"shiga.jp\":true,\"shimane.jp\":true,\"shizuoka.jp\":true,\"tochigi.jp\":true,\"tokushima.jp\":true,\"tokyo.jp\":true,\"tottori.jp\":true,\"toyama.jp\":true,\"wakayama.jp\":true,\"yamagata.jp\":true,\"yamaguchi.jp\":true,\"yamanashi.jp\":true,\"xn--4pvxs.jp\":true,\"xn--vgu402c.jp\":true,\"xn--c3s14m.jp\":true,\"xn--f6qx53a.jp\":true,\"xn--8pvr4u.jp\":true,\"xn--uist22h.jp\":true,\"xn--djrs72d6uy.jp\":true,\"xn--mkru45i.jp\":true,\"xn--0trq7p7nn.jp\":true,\"xn--8ltr62k.jp\":true,\"xn--2m4a15e.jp\":true,\"xn--efvn9s.jp\":true,\"xn--32vp30h.jp\":true,\"xn--4it797k.jp\":true,\"xn--1lqs71d.jp\":true,\"xn--5rtp49c.jp\":true,\"xn--5js045d.jp\":true,\"xn--ehqz56n.jp\":true,\"xn--1lqs03n.jp\":true,\"xn--qqqt11m.jp\":true,\"xn--kbrq7o.jp\":true,\"xn--pssu33l.jp\":true,\"xn--ntsq17g.jp\":true,\"xn--uisz3g.jp\":true,\"xn--6btw5a.jp\":true,\"xn--1ctwo.jp\":true,\"xn--6orx2r.jp\":true,\"xn--rht61e.jp\":true,\"xn--rht27z.jp\":true,\"xn--djty4k.jp\":true,\"xn--nit225k.jp\":true,\"xn--rht3d.jp\":true,\"xn--klty5x.jp\":true,\"xn--kltx9a.jp\":true,\"xn--kltp7d.jp\":true,\"xn--uuwu58a.jp\":true,\"xn--zbx025d.jp\":true,\"xn--ntso0iqx3a.jp\":true,\"xn--elqq16h.jp\":true,\"xn--4it168d.jp\":true,\"xn--klt787d.jp\":true,\"xn--rny31h.jp\":true,\"xn--7t0a264c.jp\":true,\"xn--5rtq34k.jp\":true,\"xn--k7yn95e.jp\":true,\"xn--tor131o.jp\":true,\"xn--d5qv7z876c.jp\":true,\"*.kawasaki.jp\":true,\"*.kitakyushu.jp\":true,\"*.kobe.jp\":true,\"*.nagoya.jp\":true,\"*.sapporo.jp\":true,\"*.sendai.jp\":true,\"*.yokohama.jp\":true,\"city.kawasaki.jp\":false,\"city.kitakyushu.jp\":false,\"city.kobe.jp\":false,\"city.nagoya.jp\":false,\"city.sapporo.jp\":false,\"city.sendai.jp\":false,\"city.yokohama.jp\":false,\"aisai.aichi.jp\":true,\"ama.aichi.jp\":true,\"anjo.aichi.jp\":true,\"asuke.aichi.jp\":true,\"chiryu.aichi.jp\":true,\"chita.aichi.jp\":true,\"fuso.aichi.jp\":true,\"gamagori.aichi.jp\":true,\"handa.aichi.jp\":true,\"hazu.aichi.jp\":true,\"hekinan.aichi.jp\":true,\"higashiura.aichi.jp\":true,\"ichinomiya.aichi.jp\":true,\"inazawa.aichi.jp\":true,\"inuyama.aichi.jp\":true,\"isshiki.aichi.jp\":true,\"iwakura.aichi.jp\":true,\"kanie.aichi.jp\":true,\"kariya.aichi.jp\":true,\"kasugai.aichi.jp\":true,\"kira.aichi.jp\":true,\"kiyosu.aichi.jp\":true,\"komaki.aichi.jp\":true,\"konan.aichi.jp\":true,\"kota.aichi.jp\":true,\"mihama.aichi.jp\":true,\"miyoshi.aichi.jp\":true,\"nishio.aichi.jp\":true,\"nisshin.aichi.jp\":true,\"obu.aichi.jp\":true,\"oguchi.aichi.jp\":true,\"oharu.aichi.jp\":true,\"okazaki.aichi.jp\":true,\"owariasahi.aichi.jp\":true,\"seto.aichi.jp\":true,\"shikatsu.aichi.jp\":true,\"shinshiro.aichi.jp\":true,\"shitara.aichi.jp\":true,\"tahara.aichi.jp\":true,\"takahama.aichi.jp\":true,\"tobishima.aichi.jp\":true,\"toei.aichi.jp\":true,\"togo.aichi.jp\":true,\"tokai.aichi.jp\":true,\"tokoname.aichi.jp\":true,\"toyoake.aichi.jp\":true,\"toyohashi.aichi.jp\":true,\"toyokawa.aichi.jp\":true,\"toyone.aichi.jp\":true,\"toyota.aichi.jp\":true,\"tsushima.aichi.jp\":true,\"yatomi.aichi.jp\":true,\"akita.akita.jp\":true,\"daisen.akita.jp\":true,\"fujisato.akita.jp\":true,\"gojome.akita.jp\":true,\"hachirogata.akita.jp\":true,\"happou.akita.jp\":true,\"higashinaruse.akita.jp\":true,\"honjo.akita.jp\":true,\"honjyo.akita.jp\":true,\"ikawa.akita.jp\":true,\"kamikoani.akita.jp\":true,\"kamioka.akita.jp\":true,\"katagami.akita.jp\":true,\"kazuno.akita.jp\":true,\"kitaakita.akita.jp\":true,\"kosaka.akita.jp\":true,\"kyowa.akita.jp\":true,\"misato.akita.jp\":true,\"mitane.akita.jp\":true,\"moriyoshi.akita.jp\":true,\"nikaho.akita.jp\":true,\"noshiro.akita.jp\":true,\"odate.akita.jp\":true,\"oga.akita.jp\":true,\"ogata.akita.jp\":true,\"semboku.akita.jp\":true,\"yokote.akita.jp\":true,\"yurihonjo.akita.jp\":true,\"aomori.aomori.jp\":true,\"gonohe.aomori.jp\":true,\"hachinohe.aomori.jp\":true,\"hashikami.aomori.jp\":true,\"hiranai.aomori.jp\":true,\"hirosaki.aomori.jp\":true,\"itayanagi.aomori.jp\":true,\"kuroishi.aomori.jp\":true,\"misawa.aomori.jp\":true,\"mutsu.aomori.jp\":true,\"nakadomari.aomori.jp\":true,\"noheji.aomori.jp\":true,\"oirase.aomori.jp\":true,\"owani.aomori.jp\":true,\"rokunohe.aomori.jp\":true,\"sannohe.aomori.jp\":true,\"shichinohe.aomori.jp\":true,\"shingo.aomori.jp\":true,\"takko.aomori.jp\":true,\"towada.aomori.jp\":true,\"tsugaru.aomori.jp\":true,\"tsuruta.aomori.jp\":true,\"abiko.chiba.jp\":true,\"asahi.chiba.jp\":true,\"chonan.chiba.jp\":true,\"chosei.chiba.jp\":true,\"choshi.chiba.jp\":true,\"chuo.chiba.jp\":true,\"funabashi.chiba.jp\":true,\"futtsu.chiba.jp\":true,\"hanamigawa.chiba.jp\":true,\"ichihara.chiba.jp\":true,\"ichikawa.chiba.jp\":true,\"ichinomiya.chiba.jp\":true,\"inzai.chiba.jp\":true,\"isumi.chiba.jp\":true,\"kamagaya.chiba.jp\":true,\"kamogawa.chiba.jp\":true,\"kashiwa.chiba.jp\":true,\"katori.chiba.jp\":true,\"katsuura.chiba.jp\":true,\"kimitsu.chiba.jp\":true,\"kisarazu.chiba.jp\":true,\"kozaki.chiba.jp\":true,\"kujukuri.chiba.jp\":true,\"kyonan.chiba.jp\":true,\"matsudo.chiba.jp\":true,\"midori.chiba.jp\":true,\"mihama.chiba.jp\":true,\"minamiboso.chiba.jp\":true,\"mobara.chiba.jp\":true,\"mutsuzawa.chiba.jp\":true,\"nagara.chiba.jp\":true,\"nagareyama.chiba.jp\":true,\"narashino.chiba.jp\":true,\"narita.chiba.jp\":true,\"noda.chiba.jp\":true,\"oamishirasato.chiba.jp\":true,\"omigawa.chiba.jp\":true,\"onjuku.chiba.jp\":true,\"otaki.chiba.jp\":true,\"sakae.chiba.jp\":true,\"sakura.chiba.jp\":true,\"shimofusa.chiba.jp\":true,\"shirako.chiba.jp\":true,\"shiroi.chiba.jp\":true,\"shisui.chiba.jp\":true,\"sodegaura.chiba.jp\":true,\"sosa.chiba.jp\":true,\"tako.chiba.jp\":true,\"tateyama.chiba.jp\":true,\"togane.chiba.jp\":true,\"tohnosho.chiba.jp\":true,\"tomisato.chiba.jp\":true,\"urayasu.chiba.jp\":true,\"yachimata.chiba.jp\":true,\"yachiyo.chiba.jp\":true,\"yokaichiba.chiba.jp\":true,\"yokoshibahikari.chiba.jp\":true,\"yotsukaido.chiba.jp\":true,\"ainan.ehime.jp\":true,\"honai.ehime.jp\":true,\"ikata.ehime.jp\":true,\"imabari.ehime.jp\":true,\"iyo.ehime.jp\":true,\"kamijima.ehime.jp\":true,\"kihoku.ehime.jp\":true,\"kumakogen.ehime.jp\":true,\"masaki.ehime.jp\":true,\"matsuno.ehime.jp\":true,\"matsuyama.ehime.jp\":true,\"namikata.ehime.jp\":true,\"niihama.ehime.jp\":true,\"ozu.ehime.jp\":true,\"saijo.ehime.jp\":true,\"seiyo.ehime.jp\":true,\"shikokuchuo.ehime.jp\":true,\"tobe.ehime.jp\":true,\"toon.ehime.jp\":true,\"uchiko.ehime.jp\":true,\"uwajima.ehime.jp\":true,\"yawatahama.ehime.jp\":true,\"echizen.fukui.jp\":true,\"eiheiji.fukui.jp\":true,\"fukui.fukui.jp\":true,\"ikeda.fukui.jp\":true,\"katsuyama.fukui.jp\":true,\"mihama.fukui.jp\":true,\"minamiechizen.fukui.jp\":true,\"obama.fukui.jp\":true,\"ohi.fukui.jp\":true,\"ono.fukui.jp\":true,\"sabae.fukui.jp\":true,\"sakai.fukui.jp\":true,\"takahama.fukui.jp\":true,\"tsuruga.fukui.jp\":true,\"wakasa.fukui.jp\":true,\"ashiya.fukuoka.jp\":true,\"buzen.fukuoka.jp\":true,\"chikugo.fukuoka.jp\":true,\"chikuho.fukuoka.jp\":true,\"chikujo.fukuoka.jp\":true,\"chikushino.fukuoka.jp\":true,\"chikuzen.fukuoka.jp\":true,\"chuo.fukuoka.jp\":true,\"dazaifu.fukuoka.jp\":true,\"fukuchi.fukuoka.jp\":true,\"hakata.fukuoka.jp\":true,\"higashi.fukuoka.jp\":true,\"hirokawa.fukuoka.jp\":true,\"hisayama.fukuoka.jp\":true,\"iizuka.fukuoka.jp\":true,\"inatsuki.fukuoka.jp\":true,\"kaho.fukuoka.jp\":true,\"kasuga.fukuoka.jp\":true,\"kasuya.fukuoka.jp\":true,\"kawara.fukuoka.jp\":true,\"keisen.fukuoka.jp\":true,\"koga.fukuoka.jp\":true,\"kurate.fukuoka.jp\":true,\"kurogi.fukuoka.jp\":true,\"kurume.fukuoka.jp\":true,\"minami.fukuoka.jp\":true,\"miyako.fukuoka.jp\":true,\"miyama.fukuoka.jp\":true,\"miyawaka.fukuoka.jp\":true,\"mizumaki.fukuoka.jp\":true,\"munakata.fukuoka.jp\":true,\"nakagawa.fukuoka.jp\":true,\"nakama.fukuoka.jp\":true,\"nishi.fukuoka.jp\":true,\"nogata.fukuoka.jp\":true,\"ogori.fukuoka.jp\":true,\"okagaki.fukuoka.jp\":true,\"okawa.fukuoka.jp\":true,\"oki.fukuoka.jp\":true,\"omuta.fukuoka.jp\":true,\"onga.fukuoka.jp\":true,\"onojo.fukuoka.jp\":true,\"oto.fukuoka.jp\":true,\"saigawa.fukuoka.jp\":true,\"sasaguri.fukuoka.jp\":true,\"shingu.fukuoka.jp\":true,\"shinyoshitomi.fukuoka.jp\":true,\"shonai.fukuoka.jp\":true,\"soeda.fukuoka.jp\":true,\"sue.fukuoka.jp\":true,\"tachiarai.fukuoka.jp\":true,\"tagawa.fukuoka.jp\":true,\"takata.fukuoka.jp\":true,\"toho.fukuoka.jp\":true,\"toyotsu.fukuoka.jp\":true,\"tsuiki.fukuoka.jp\":true,\"ukiha.fukuoka.jp\":true,\"umi.fukuoka.jp\":true,\"usui.fukuoka.jp\":true,\"yamada.fukuoka.jp\":true,\"yame.fukuoka.jp\":true,\"yanagawa.fukuoka.jp\":true,\"yukuhashi.fukuoka.jp\":true,\"aizubange.fukushima.jp\":true,\"aizumisato.fukushima.jp\":true,\"aizuwakamatsu.fukushima.jp\":true,\"asakawa.fukushima.jp\":true,\"bandai.fukushima.jp\":true,\"date.fukushima.jp\":true,\"fukushima.fukushima.jp\":true,\"furudono.fukushima.jp\":true,\"futaba.fukushima.jp\":true,\"hanawa.fukushima.jp\":true,\"higashi.fukushima.jp\":true,\"hirata.fukushima.jp\":true,\"hirono.fukushima.jp\":true,\"iitate.fukushima.jp\":true,\"inawashiro.fukushima.jp\":true,\"ishikawa.fukushima.jp\":true,\"iwaki.fukushima.jp\":true,\"izumizaki.fukushima.jp\":true,\"kagamiishi.fukushima.jp\":true,\"kaneyama.fukushima.jp\":true,\"kawamata.fukushima.jp\":true,\"kitakata.fukushima.jp\":true,\"kitashiobara.fukushima.jp\":true,\"koori.fukushima.jp\":true,\"koriyama.fukushima.jp\":true,\"kunimi.fukushima.jp\":true,\"miharu.fukushima.jp\":true,\"mishima.fukushima.jp\":true,\"namie.fukushima.jp\":true,\"nango.fukushima.jp\":true,\"nishiaizu.fukushima.jp\":true,\"nishigo.fukushima.jp\":true,\"okuma.fukushima.jp\":true,\"omotego.fukushima.jp\":true,\"ono.fukushima.jp\":true,\"otama.fukushima.jp\":true,\"samegawa.fukushima.jp\":true,\"shimogo.fukushima.jp\":true,\"shirakawa.fukushima.jp\":true,\"showa.fukushima.jp\":true,\"soma.fukushima.jp\":true,\"sukagawa.fukushima.jp\":true,\"taishin.fukushima.jp\":true,\"tamakawa.fukushima.jp\":true,\"tanagura.fukushima.jp\":true,\"tenei.fukushima.jp\":true,\"yabuki.fukushima.jp\":true,\"yamato.fukushima.jp\":true,\"yamatsuri.fukushima.jp\":true,\"yanaizu.fukushima.jp\":true,\"yugawa.fukushima.jp\":true,\"anpachi.gifu.jp\":true,\"ena.gifu.jp\":true,\"gifu.gifu.jp\":true,\"ginan.gifu.jp\":true,\"godo.gifu.jp\":true,\"gujo.gifu.jp\":true,\"hashima.gifu.jp\":true,\"hichiso.gifu.jp\":true,\"hida.gifu.jp\":true,\"higashishirakawa.gifu.jp\":true,\"ibigawa.gifu.jp\":true,\"ikeda.gifu.jp\":true,\"kakamigahara.gifu.jp\":true,\"kani.gifu.jp\":true,\"kasahara.gifu.jp\":true,\"kasamatsu.gifu.jp\":true,\"kawaue.gifu.jp\":true,\"kitagata.gifu.jp\":true,\"mino.gifu.jp\":true,\"minokamo.gifu.jp\":true,\"mitake.gifu.jp\":true,\"mizunami.gifu.jp\":true,\"motosu.gifu.jp\":true,\"nakatsugawa.gifu.jp\":true,\"ogaki.gifu.jp\":true,\"sakahogi.gifu.jp\":true,\"seki.gifu.jp\":true,\"sekigahara.gifu.jp\":true,\"shirakawa.gifu.jp\":true,\"tajimi.gifu.jp\":true,\"takayama.gifu.jp\":true,\"tarui.gifu.jp\":true,\"toki.gifu.jp\":true,\"tomika.gifu.jp\":true,\"wanouchi.gifu.jp\":true,\"yamagata.gifu.jp\":true,\"yaotsu.gifu.jp\":true,\"yoro.gifu.jp\":true,\"annaka.gunma.jp\":true,\"chiyoda.gunma.jp\":true,\"fujioka.gunma.jp\":true,\"higashiagatsuma.gunma.jp\":true,\"isesaki.gunma.jp\":true,\"itakura.gunma.jp\":true,\"kanna.gunma.jp\":true,\"kanra.gunma.jp\":true,\"katashina.gunma.jp\":true,\"kawaba.gunma.jp\":true,\"kiryu.gunma.jp\":true,\"kusatsu.gunma.jp\":true,\"maebashi.gunma.jp\":true,\"meiwa.gunma.jp\":true,\"midori.gunma.jp\":true,\"minakami.gunma.jp\":true,\"naganohara.gunma.jp\":true,\"nakanojo.gunma.jp\":true,\"nanmoku.gunma.jp\":true,\"numata.gunma.jp\":true,\"oizumi.gunma.jp\":true,\"ora.gunma.jp\":true,\"ota.gunma.jp\":true,\"shibukawa.gunma.jp\":true,\"shimonita.gunma.jp\":true,\"shinto.gunma.jp\":true,\"showa.gunma.jp\":true,\"takasaki.gunma.jp\":true,\"takayama.gunma.jp\":true,\"tamamura.gunma.jp\":true,\"tatebayashi.gunma.jp\":true,\"tomioka.gunma.jp\":true,\"tsukiyono.gunma.jp\":true,\"tsumagoi.gunma.jp\":true,\"ueno.gunma.jp\":true,\"yoshioka.gunma.jp\":true,\"asaminami.hiroshima.jp\":true,\"daiwa.hiroshima.jp\":true,\"etajima.hiroshima.jp\":true,\"fuchu.hiroshima.jp\":true,\"fukuyama.hiroshima.jp\":true,\"hatsukaichi.hiroshima.jp\":true,\"higashihiroshima.hiroshima.jp\":true,\"hongo.hiroshima.jp\":true,\"jinsekikogen.hiroshima.jp\":true,\"kaita.hiroshima.jp\":true,\"kui.hiroshima.jp\":true,\"kumano.hiroshima.jp\":true,\"kure.hiroshima.jp\":true,\"mihara.hiroshima.jp\":true,\"miyoshi.hiroshima.jp\":true,\"naka.hiroshima.jp\":true,\"onomichi.hiroshima.jp\":true,\"osakikamijima.hiroshima.jp\":true,\"otake.hiroshima.jp\":true,\"saka.hiroshima.jp\":true,\"sera.hiroshima.jp\":true,\"seranishi.hiroshima.jp\":true,\"shinichi.hiroshima.jp\":true,\"shobara.hiroshima.jp\":true,\"takehara.hiroshima.jp\":true,\"abashiri.hokkaido.jp\":true,\"abira.hokkaido.jp\":true,\"aibetsu.hokkaido.jp\":true,\"akabira.hokkaido.jp\":true,\"akkeshi.hokkaido.jp\":true,\"asahikawa.hokkaido.jp\":true,\"ashibetsu.hokkaido.jp\":true,\"ashoro.hokkaido.jp\":true,\"assabu.hokkaido.jp\":true,\"atsuma.hokkaido.jp\":true,\"bibai.hokkaido.jp\":true,\"biei.hokkaido.jp\":true,\"bifuka.hokkaido.jp\":true,\"bihoro.hokkaido.jp\":true,\"biratori.hokkaido.jp\":true,\"chippubetsu.hokkaido.jp\":true,\"chitose.hokkaido.jp\":true,\"date.hokkaido.jp\":true,\"ebetsu.hokkaido.jp\":true,\"embetsu.hokkaido.jp\":true,\"eniwa.hokkaido.jp\":true,\"erimo.hokkaido.jp\":true,\"esan.hokkaido.jp\":true,\"esashi.hokkaido.jp\":true,\"fukagawa.hokkaido.jp\":true,\"fukushima.hokkaido.jp\":true,\"furano.hokkaido.jp\":true,\"furubira.hokkaido.jp\":true,\"haboro.hokkaido.jp\":true,\"hakodate.hokkaido.jp\":true,\"hamatonbetsu.hokkaido.jp\":true,\"hidaka.hokkaido.jp\":true,\"higashikagura.hokkaido.jp\":true,\"higashikawa.hokkaido.jp\":true,\"hiroo.hokkaido.jp\":true,\"hokuryu.hokkaido.jp\":true,\"hokuto.hokkaido.jp\":true,\"honbetsu.hokkaido.jp\":true,\"horokanai.hokkaido.jp\":true,\"horonobe.hokkaido.jp\":true,\"ikeda.hokkaido.jp\":true,\"imakane.hokkaido.jp\":true,\"ishikari.hokkaido.jp\":true,\"iwamizawa.hokkaido.jp\":true,\"iwanai.hokkaido.jp\":true,\"kamifurano.hokkaido.jp\":true,\"kamikawa.hokkaido.jp\":true,\"kamishihoro.hokkaido.jp\":true,\"kamisunagawa.hokkaido.jp\":true,\"kamoenai.hokkaido.jp\":true,\"kayabe.hokkaido.jp\":true,\"kembuchi.hokkaido.jp\":true,\"kikonai.hokkaido.jp\":true,\"kimobetsu.hokkaido.jp\":true,\"kitahiroshima.hokkaido.jp\":true,\"kitami.hokkaido.jp\":true,\"kiyosato.hokkaido.jp\":true,\"koshimizu.hokkaido.jp\":true,\"kunneppu.hokkaido.jp\":true,\"kuriyama.hokkaido.jp\":true,\"kuromatsunai.hokkaido.jp\":true,\"kushiro.hokkaido.jp\":true,\"kutchan.hokkaido.jp\":true,\"kyowa.hokkaido.jp\":true,\"mashike.hokkaido.jp\":true,\"matsumae.hokkaido.jp\":true,\"mikasa.hokkaido.jp\":true,\"minamifurano.hokkaido.jp\":true,\"mombetsu.hokkaido.jp\":true,\"moseushi.hokkaido.jp\":true,\"mukawa.hokkaido.jp\":true,\"muroran.hokkaido.jp\":true,\"naie.hokkaido.jp\":true,\"nakagawa.hokkaido.jp\":true,\"nakasatsunai.hokkaido.jp\":true,\"nakatombetsu.hokkaido.jp\":true,\"nanae.hokkaido.jp\":true,\"nanporo.hokkaido.jp\":true,\"nayoro.hokkaido.jp\":true,\"nemuro.hokkaido.jp\":true,\"niikappu.hokkaido.jp\":true,\"niki.hokkaido.jp\":true,\"nishiokoppe.hokkaido.jp\":true,\"noboribetsu.hokkaido.jp\":true,\"numata.hokkaido.jp\":true,\"obihiro.hokkaido.jp\":true,\"obira.hokkaido.jp\":true,\"oketo.hokkaido.jp\":true,\"okoppe.hokkaido.jp\":true,\"otaru.hokkaido.jp\":true,\"otobe.hokkaido.jp\":true,\"otofuke.hokkaido.jp\":true,\"otoineppu.hokkaido.jp\":true,\"oumu.hokkaido.jp\":true,\"ozora.hokkaido.jp\":true,\"pippu.hokkaido.jp\":true,\"rankoshi.hokkaido.jp\":true,\"rebun.hokkaido.jp\":true,\"rikubetsu.hokkaido.jp\":true,\"rishiri.hokkaido.jp\":true,\"rishirifuji.hokkaido.jp\":true,\"saroma.hokkaido.jp\":true,\"sarufutsu.hokkaido.jp\":true,\"shakotan.hokkaido.jp\":true,\"shari.hokkaido.jp\":true,\"shibecha.hokkaido.jp\":true,\"shibetsu.hokkaido.jp\":true,\"shikabe.hokkaido.jp\":true,\"shikaoi.hokkaido.jp\":true,\"shimamaki.hokkaido.jp\":true,\"shimizu.hokkaido.jp\":true,\"shimokawa.hokkaido.jp\":true,\"shinshinotsu.hokkaido.jp\":true,\"shintoku.hokkaido.jp\":true,\"shiranuka.hokkaido.jp\":true,\"shiraoi.hokkaido.jp\":true,\"shiriuchi.hokkaido.jp\":true,\"sobetsu.hokkaido.jp\":true,\"sunagawa.hokkaido.jp\":true,\"taiki.hokkaido.jp\":true,\"takasu.hokkaido.jp\":true,\"takikawa.hokkaido.jp\":true,\"takinoue.hokkaido.jp\":true,\"teshikaga.hokkaido.jp\":true,\"tobetsu.hokkaido.jp\":true,\"tohma.hokkaido.jp\":true,\"tomakomai.hokkaido.jp\":true,\"tomari.hokkaido.jp\":true,\"toya.hokkaido.jp\":true,\"toyako.hokkaido.jp\":true,\"toyotomi.hokkaido.jp\":true,\"toyoura.hokkaido.jp\":true,\"tsubetsu.hokkaido.jp\":true,\"tsukigata.hokkaido.jp\":true,\"urakawa.hokkaido.jp\":true,\"urausu.hokkaido.jp\":true,\"uryu.hokkaido.jp\":true,\"utashinai.hokkaido.jp\":true,\"wakkanai.hokkaido.jp\":true,\"wassamu.hokkaido.jp\":true,\"yakumo.hokkaido.jp\":true,\"yoichi.hokkaido.jp\":true,\"aioi.hyogo.jp\":true,\"akashi.hyogo.jp\":true,\"ako.hyogo.jp\":true,\"amagasaki.hyogo.jp\":true,\"aogaki.hyogo.jp\":true,\"asago.hyogo.jp\":true,\"ashiya.hyogo.jp\":true,\"awaji.hyogo.jp\":true,\"fukusaki.hyogo.jp\":true,\"goshiki.hyogo.jp\":true,\"harima.hyogo.jp\":true,\"himeji.hyogo.jp\":true,\"ichikawa.hyogo.jp\":true,\"inagawa.hyogo.jp\":true,\"itami.hyogo.jp\":true,\"kakogawa.hyogo.jp\":true,\"kamigori.hyogo.jp\":true,\"kamikawa.hyogo.jp\":true,\"kasai.hyogo.jp\":true,\"kasuga.hyogo.jp\":true,\"kawanishi.hyogo.jp\":true,\"miki.hyogo.jp\":true,\"minamiawaji.hyogo.jp\":true,\"nishinomiya.hyogo.jp\":true,\"nishiwaki.hyogo.jp\":true,\"ono.hyogo.jp\":true,\"sanda.hyogo.jp\":true,\"sannan.hyogo.jp\":true,\"sasayama.hyogo.jp\":true,\"sayo.hyogo.jp\":true,\"shingu.hyogo.jp\":true,\"shinonsen.hyogo.jp\":true,\"shiso.hyogo.jp\":true,\"sumoto.hyogo.jp\":true,\"taishi.hyogo.jp\":true,\"taka.hyogo.jp\":true,\"takarazuka.hyogo.jp\":true,\"takasago.hyogo.jp\":true,\"takino.hyogo.jp\":true,\"tamba.hyogo.jp\":true,\"tatsuno.hyogo.jp\":true,\"toyooka.hyogo.jp\":true,\"yabu.hyogo.jp\":true,\"yashiro.hyogo.jp\":true,\"yoka.hyogo.jp\":true,\"yokawa.hyogo.jp\":true,\"ami.ibaraki.jp\":true,\"asahi.ibaraki.jp\":true,\"bando.ibaraki.jp\":true,\"chikusei.ibaraki.jp\":true,\"daigo.ibaraki.jp\":true,\"fujishiro.ibaraki.jp\":true,\"hitachi.ibaraki.jp\":true,\"hitachinaka.ibaraki.jp\":true,\"hitachiomiya.ibaraki.jp\":true,\"hitachiota.ibaraki.jp\":true,\"ibaraki.ibaraki.jp\":true,\"ina.ibaraki.jp\":true,\"inashiki.ibaraki.jp\":true,\"itako.ibaraki.jp\":true,\"iwama.ibaraki.jp\":true,\"joso.ibaraki.jp\":true,\"kamisu.ibaraki.jp\":true,\"kasama.ibaraki.jp\":true,\"kashima.ibaraki.jp\":true,\"kasumigaura.ibaraki.jp\":true,\"koga.ibaraki.jp\":true,\"miho.ibaraki.jp\":true,\"mito.ibaraki.jp\":true,\"moriya.ibaraki.jp\":true,\"naka.ibaraki.jp\":true,\"namegata.ibaraki.jp\":true,\"oarai.ibaraki.jp\":true,\"ogawa.ibaraki.jp\":true,\"omitama.ibaraki.jp\":true,\"ryugasaki.ibaraki.jp\":true,\"sakai.ibaraki.jp\":true,\"sakuragawa.ibaraki.jp\":true,\"shimodate.ibaraki.jp\":true,\"shimotsuma.ibaraki.jp\":true,\"shirosato.ibaraki.jp\":true,\"sowa.ibaraki.jp\":true,\"suifu.ibaraki.jp\":true,\"takahagi.ibaraki.jp\":true,\"tamatsukuri.ibaraki.jp\":true,\"tokai.ibaraki.jp\":true,\"tomobe.ibaraki.jp\":true,\"tone.ibaraki.jp\":true,\"toride.ibaraki.jp\":true,\"tsuchiura.ibaraki.jp\":true,\"tsukuba.ibaraki.jp\":true,\"uchihara.ibaraki.jp\":true,\"ushiku.ibaraki.jp\":true,\"yachiyo.ibaraki.jp\":true,\"yamagata.ibaraki.jp\":true,\"yawara.ibaraki.jp\":true,\"yuki.ibaraki.jp\":true,\"anamizu.ishikawa.jp\":true,\"hakui.ishikawa.jp\":true,\"hakusan.ishikawa.jp\":true,\"kaga.ishikawa.jp\":true,\"kahoku.ishikawa.jp\":true,\"kanazawa.ishikawa.jp\":true,\"kawakita.ishikawa.jp\":true,\"komatsu.ishikawa.jp\":true,\"nakanoto.ishikawa.jp\":true,\"nanao.ishikawa.jp\":true,\"nomi.ishikawa.jp\":true,\"nonoichi.ishikawa.jp\":true,\"noto.ishikawa.jp\":true,\"shika.ishikawa.jp\":true,\"suzu.ishikawa.jp\":true,\"tsubata.ishikawa.jp\":true,\"tsurugi.ishikawa.jp\":true,\"uchinada.ishikawa.jp\":true,\"wajima.ishikawa.jp\":true,\"fudai.iwate.jp\":true,\"fujisawa.iwate.jp\":true,\"hanamaki.iwate.jp\":true,\"hiraizumi.iwate.jp\":true,\"hirono.iwate.jp\":true,\"ichinohe.iwate.jp\":true,\"ichinoseki.iwate.jp\":true,\"iwaizumi.iwate.jp\":true,\"iwate.iwate.jp\":true,\"joboji.iwate.jp\":true,\"kamaishi.iwate.jp\":true,\"kanegasaki.iwate.jp\":true,\"karumai.iwate.jp\":true,\"kawai.iwate.jp\":true,\"kitakami.iwate.jp\":true,\"kuji.iwate.jp\":true,\"kunohe.iwate.jp\":true,\"kuzumaki.iwate.jp\":true,\"miyako.iwate.jp\":true,\"mizusawa.iwate.jp\":true,\"morioka.iwate.jp\":true,\"ninohe.iwate.jp\":true,\"noda.iwate.jp\":true,\"ofunato.iwate.jp\":true,\"oshu.iwate.jp\":true,\"otsuchi.iwate.jp\":true,\"rikuzentakata.iwate.jp\":true,\"shiwa.iwate.jp\":true,\"shizukuishi.iwate.jp\":true,\"sumita.iwate.jp\":true,\"tanohata.iwate.jp\":true,\"tono.iwate.jp\":true,\"yahaba.iwate.jp\":true,\"yamada.iwate.jp\":true,\"ayagawa.kagawa.jp\":true,\"higashikagawa.kagawa.jp\":true,\"kanonji.kagawa.jp\":true,\"kotohira.kagawa.jp\":true,\"manno.kagawa.jp\":true,\"marugame.kagawa.jp\":true,\"mitoyo.kagawa.jp\":true,\"naoshima.kagawa.jp\":true,\"sanuki.kagawa.jp\":true,\"tadotsu.kagawa.jp\":true,\"takamatsu.kagawa.jp\":true,\"tonosho.kagawa.jp\":true,\"uchinomi.kagawa.jp\":true,\"utazu.kagawa.jp\":true,\"zentsuji.kagawa.jp\":true,\"akune.kagoshima.jp\":true,\"amami.kagoshima.jp\":true,\"hioki.kagoshima.jp\":true,\"isa.kagoshima.jp\":true,\"isen.kagoshima.jp\":true,\"izumi.kagoshima.jp\":true,\"kagoshima.kagoshima.jp\":true,\"kanoya.kagoshima.jp\":true,\"kawanabe.kagoshima.jp\":true,\"kinko.kagoshima.jp\":true,\"kouyama.kagoshima.jp\":true,\"makurazaki.kagoshima.jp\":true,\"matsumoto.kagoshima.jp\":true,\"minamitane.kagoshima.jp\":true,\"nakatane.kagoshima.jp\":true,\"nishinoomote.kagoshima.jp\":true,\"satsumasendai.kagoshima.jp\":true,\"soo.kagoshima.jp\":true,\"tarumizu.kagoshima.jp\":true,\"yusui.kagoshima.jp\":true,\"aikawa.kanagawa.jp\":true,\"atsugi.kanagawa.jp\":true,\"ayase.kanagawa.jp\":true,\"chigasaki.kanagawa.jp\":true,\"ebina.kanagawa.jp\":true,\"fujisawa.kanagawa.jp\":true,\"hadano.kanagawa.jp\":true,\"hakone.kanagawa.jp\":true,\"hiratsuka.kanagawa.jp\":true,\"isehara.kanagawa.jp\":true,\"kaisei.kanagawa.jp\":true,\"kamakura.kanagawa.jp\":true,\"kiyokawa.kanagawa.jp\":true,\"matsuda.kanagawa.jp\":true,\"minamiashigara.kanagawa.jp\":true,\"miura.kanagawa.jp\":true,\"nakai.kanagawa.jp\":true,\"ninomiya.kanagawa.jp\":true,\"odawara.kanagawa.jp\":true,\"oi.kanagawa.jp\":true,\"oiso.kanagawa.jp\":true,\"sagamihara.kanagawa.jp\":true,\"samukawa.kanagawa.jp\":true,\"tsukui.kanagawa.jp\":true,\"yamakita.kanagawa.jp\":true,\"yamato.kanagawa.jp\":true,\"yokosuka.kanagawa.jp\":true,\"yugawara.kanagawa.jp\":true,\"zama.kanagawa.jp\":true,\"zushi.kanagawa.jp\":true,\"aki.kochi.jp\":true,\"geisei.kochi.jp\":true,\"hidaka.kochi.jp\":true,\"higashitsuno.kochi.jp\":true,\"ino.kochi.jp\":true,\"kagami.kochi.jp\":true,\"kami.kochi.jp\":true,\"kitagawa.kochi.jp\":true,\"kochi.kochi.jp\":true,\"mihara.kochi.jp\":true,\"motoyama.kochi.jp\":true,\"muroto.kochi.jp\":true,\"nahari.kochi.jp\":true,\"nakamura.kochi.jp\":true,\"nankoku.kochi.jp\":true,\"nishitosa.kochi.jp\":true,\"niyodogawa.kochi.jp\":true,\"ochi.kochi.jp\":true,\"okawa.kochi.jp\":true,\"otoyo.kochi.jp\":true,\"otsuki.kochi.jp\":true,\"sakawa.kochi.jp\":true,\"sukumo.kochi.jp\":true,\"susaki.kochi.jp\":true,\"tosa.kochi.jp\":true,\"tosashimizu.kochi.jp\":true,\"toyo.kochi.jp\":true,\"tsuno.kochi.jp\":true,\"umaji.kochi.jp\":true,\"yasuda.kochi.jp\":true,\"yusuhara.kochi.jp\":true,\"amakusa.kumamoto.jp\":true,\"arao.kumamoto.jp\":true,\"aso.kumamoto.jp\":true,\"choyo.kumamoto.jp\":true,\"gyokuto.kumamoto.jp\":true,\"hitoyoshi.kumamoto.jp\":true,\"kamiamakusa.kumamoto.jp\":true,\"kashima.kumamoto.jp\":true,\"kikuchi.kumamoto.jp\":true,\"kosa.kumamoto.jp\":true,\"kumamoto.kumamoto.jp\":true,\"mashiki.kumamoto.jp\":true,\"mifune.kumamoto.jp\":true,\"minamata.kumamoto.jp\":true,\"minamioguni.kumamoto.jp\":true,\"nagasu.kumamoto.jp\":true,\"nishihara.kumamoto.jp\":true,\"oguni.kumamoto.jp\":true,\"ozu.kumamoto.jp\":true,\"sumoto.kumamoto.jp\":true,\"takamori.kumamoto.jp\":true,\"uki.kumamoto.jp\":true,\"uto.kumamoto.jp\":true,\"yamaga.kumamoto.jp\":true,\"yamato.kumamoto.jp\":true,\"yatsushiro.kumamoto.jp\":true,\"ayabe.kyoto.jp\":true,\"fukuchiyama.kyoto.jp\":true,\"higashiyama.kyoto.jp\":true,\"ide.kyoto.jp\":true,\"ine.kyoto.jp\":true,\"joyo.kyoto.jp\":true,\"kameoka.kyoto.jp\":true,\"kamo.kyoto.jp\":true,\"kita.kyoto.jp\":true,\"kizu.kyoto.jp\":true,\"kumiyama.kyoto.jp\":true,\"kyotamba.kyoto.jp\":true,\"kyotanabe.kyoto.jp\":true,\"kyotango.kyoto.jp\":true,\"maizuru.kyoto.jp\":true,\"minami.kyoto.jp\":true,\"minamiyamashiro.kyoto.jp\":true,\"miyazu.kyoto.jp\":true,\"muko.kyoto.jp\":true,\"nagaokakyo.kyoto.jp\":true,\"nakagyo.kyoto.jp\":true,\"nantan.kyoto.jp\":true,\"oyamazaki.kyoto.jp\":true,\"sakyo.kyoto.jp\":true,\"seika.kyoto.jp\":true,\"tanabe.kyoto.jp\":true,\"uji.kyoto.jp\":true,\"ujitawara.kyoto.jp\":true,\"wazuka.kyoto.jp\":true,\"yamashina.kyoto.jp\":true,\"yawata.kyoto.jp\":true,\"asahi.mie.jp\":true,\"inabe.mie.jp\":true,\"ise.mie.jp\":true,\"kameyama.mie.jp\":true,\"kawagoe.mie.jp\":true,\"kiho.mie.jp\":true,\"kisosaki.mie.jp\":true,\"kiwa.mie.jp\":true,\"komono.mie.jp\":true,\"kumano.mie.jp\":true,\"kuwana.mie.jp\":true,\"matsusaka.mie.jp\":true,\"meiwa.mie.jp\":true,\"mihama.mie.jp\":true,\"minamiise.mie.jp\":true,\"misugi.mie.jp\":true,\"miyama.mie.jp\":true,\"nabari.mie.jp\":true,\"shima.mie.jp\":true,\"suzuka.mie.jp\":true,\"tado.mie.jp\":true,\"taiki.mie.jp\":true,\"taki.mie.jp\":true,\"tamaki.mie.jp\":true,\"toba.mie.jp\":true,\"tsu.mie.jp\":true,\"udono.mie.jp\":true,\"ureshino.mie.jp\":true,\"watarai.mie.jp\":true,\"yokkaichi.mie.jp\":true,\"furukawa.miyagi.jp\":true,\"higashimatsushima.miyagi.jp\":true,\"ishinomaki.miyagi.jp\":true,\"iwanuma.miyagi.jp\":true,\"kakuda.miyagi.jp\":true,\"kami.miyagi.jp\":true,\"kawasaki.miyagi.jp\":true,\"kesennuma.miyagi.jp\":true,\"marumori.miyagi.jp\":true,\"matsushima.miyagi.jp\":true,\"minamisanriku.miyagi.jp\":true,\"misato.miyagi.jp\":true,\"murata.miyagi.jp\":true,\"natori.miyagi.jp\":true,\"ogawara.miyagi.jp\":true,\"ohira.miyagi.jp\":true,\"onagawa.miyagi.jp\":true,\"osaki.miyagi.jp\":true,\"rifu.miyagi.jp\":true,\"semine.miyagi.jp\":true,\"shibata.miyagi.jp\":true,\"shichikashuku.miyagi.jp\":true,\"shikama.miyagi.jp\":true,\"shiogama.miyagi.jp\":true,\"shiroishi.miyagi.jp\":true,\"tagajo.miyagi.jp\":true,\"taiwa.miyagi.jp\":true,\"tome.miyagi.jp\":true,\"tomiya.miyagi.jp\":true,\"wakuya.miyagi.jp\":true,\"watari.miyagi.jp\":true,\"yamamoto.miyagi.jp\":true,\"zao.miyagi.jp\":true,\"aya.miyazaki.jp\":true,\"ebino.miyazaki.jp\":true,\"gokase.miyazaki.jp\":true,\"hyuga.miyazaki.jp\":true,\"kadogawa.miyazaki.jp\":true,\"kawaminami.miyazaki.jp\":true,\"kijo.miyazaki.jp\":true,\"kitagawa.miyazaki.jp\":true,\"kitakata.miyazaki.jp\":true,\"kitaura.miyazaki.jp\":true,\"kobayashi.miyazaki.jp\":true,\"kunitomi.miyazaki.jp\":true,\"kushima.miyazaki.jp\":true,\"mimata.miyazaki.jp\":true,\"miyakonojo.miyazaki.jp\":true,\"miyazaki.miyazaki.jp\":true,\"morotsuka.miyazaki.jp\":true,\"nichinan.miyazaki.jp\":true,\"nishimera.miyazaki.jp\":true,\"nobeoka.miyazaki.jp\":true,\"saito.miyazaki.jp\":true,\"shiiba.miyazaki.jp\":true,\"shintomi.miyazaki.jp\":true,\"takaharu.miyazaki.jp\":true,\"takanabe.miyazaki.jp\":true,\"takazaki.miyazaki.jp\":true,\"tsuno.miyazaki.jp\":true,\"achi.nagano.jp\":true,\"agematsu.nagano.jp\":true,\"anan.nagano.jp\":true,\"aoki.nagano.jp\":true,\"asahi.nagano.jp\":true,\"azumino.nagano.jp\":true,\"chikuhoku.nagano.jp\":true,\"chikuma.nagano.jp\":true,\"chino.nagano.jp\":true,\"fujimi.nagano.jp\":true,\"hakuba.nagano.jp\":true,\"hara.nagano.jp\":true,\"hiraya.nagano.jp\":true,\"iida.nagano.jp\":true,\"iijima.nagano.jp\":true,\"iiyama.nagano.jp\":true,\"iizuna.nagano.jp\":true,\"ikeda.nagano.jp\":true,\"ikusaka.nagano.jp\":true,\"ina.nagano.jp\":true,\"karuizawa.nagano.jp\":true,\"kawakami.nagano.jp\":true,\"kiso.nagano.jp\":true,\"kisofukushima.nagano.jp\":true,\"kitaaiki.nagano.jp\":true,\"komagane.nagano.jp\":true,\"komoro.nagano.jp\":true,\"matsukawa.nagano.jp\":true,\"matsumoto.nagano.jp\":true,\"miasa.nagano.jp\":true,\"minamiaiki.nagano.jp\":true,\"minamimaki.nagano.jp\":true,\"minamiminowa.nagano.jp\":true,\"minowa.nagano.jp\":true,\"miyada.nagano.jp\":true,\"miyota.nagano.jp\":true,\"mochizuki.nagano.jp\":true,\"nagano.nagano.jp\":true,\"nagawa.nagano.jp\":true,\"nagiso.nagano.jp\":true,\"nakagawa.nagano.jp\":true,\"nakano.nagano.jp\":true,\"nozawaonsen.nagano.jp\":true,\"obuse.nagano.jp\":true,\"ogawa.nagano.jp\":true,\"okaya.nagano.jp\":true,\"omachi.nagano.jp\":true,\"omi.nagano.jp\":true,\"ookuwa.nagano.jp\":true,\"ooshika.nagano.jp\":true,\"otaki.nagano.jp\":true,\"otari.nagano.jp\":true,\"sakae.nagano.jp\":true,\"sakaki.nagano.jp\":true,\"saku.nagano.jp\":true,\"sakuho.nagano.jp\":true,\"shimosuwa.nagano.jp\":true,\"shinanomachi.nagano.jp\":true,\"shiojiri.nagano.jp\":true,\"suwa.nagano.jp\":true,\"suzaka.nagano.jp\":true,\"takagi.nagano.jp\":true,\"takamori.nagano.jp\":true,\"takayama.nagano.jp\":true,\"tateshina.nagano.jp\":true,\"tatsuno.nagano.jp\":true,\"togakushi.nagano.jp\":true,\"togura.nagano.jp\":true,\"tomi.nagano.jp\":true,\"ueda.nagano.jp\":true,\"wada.nagano.jp\":true,\"yamagata.nagano.jp\":true,\"yamanouchi.nagano.jp\":true,\"yasaka.nagano.jp\":true,\"yasuoka.nagano.jp\":true,\"chijiwa.nagasaki.jp\":true,\"futsu.nagasaki.jp\":true,\"goto.nagasaki.jp\":true,\"hasami.nagasaki.jp\":true,\"hirado.nagasaki.jp\":true,\"iki.nagasaki.jp\":true,\"isahaya.nagasaki.jp\":true,\"kawatana.nagasaki.jp\":true,\"kuchinotsu.nagasaki.jp\":true,\"matsuura.nagasaki.jp\":true,\"nagasaki.nagasaki.jp\":true,\"obama.nagasaki.jp\":true,\"omura.nagasaki.jp\":true,\"oseto.nagasaki.jp\":true,\"saikai.nagasaki.jp\":true,\"sasebo.nagasaki.jp\":true,\"seihi.nagasaki.jp\":true,\"shimabara.nagasaki.jp\":true,\"shinkamigoto.nagasaki.jp\":true,\"togitsu.nagasaki.jp\":true,\"tsushima.nagasaki.jp\":true,\"unzen.nagasaki.jp\":true,\"ando.nara.jp\":true,\"gose.nara.jp\":true,\"heguri.nara.jp\":true,\"higashiyoshino.nara.jp\":true,\"ikaruga.nara.jp\":true,\"ikoma.nara.jp\":true,\"kamikitayama.nara.jp\":true,\"kanmaki.nara.jp\":true,\"kashiba.nara.jp\":true,\"kashihara.nara.jp\":true,\"katsuragi.nara.jp\":true,\"kawai.nara.jp\":true,\"kawakami.nara.jp\":true,\"kawanishi.nara.jp\":true,\"koryo.nara.jp\":true,\"kurotaki.nara.jp\":true,\"mitsue.nara.jp\":true,\"miyake.nara.jp\":true,\"nara.nara.jp\":true,\"nosegawa.nara.jp\":true,\"oji.nara.jp\":true,\"ouda.nara.jp\":true,\"oyodo.nara.jp\":true,\"sakurai.nara.jp\":true,\"sango.nara.jp\":true,\"shimoichi.nara.jp\":true,\"shimokitayama.nara.jp\":true,\"shinjo.nara.jp\":true,\"soni.nara.jp\":true,\"takatori.nara.jp\":true,\"tawaramoto.nara.jp\":true,\"tenkawa.nara.jp\":true,\"tenri.nara.jp\":true,\"uda.nara.jp\":true,\"yamatokoriyama.nara.jp\":true,\"yamatotakada.nara.jp\":true,\"yamazoe.nara.jp\":true,\"yoshino.nara.jp\":true,\"aga.niigata.jp\":true,\"agano.niigata.jp\":true,\"gosen.niigata.jp\":true,\"itoigawa.niigata.jp\":true,\"izumozaki.niigata.jp\":true,\"joetsu.niigata.jp\":true,\"kamo.niigata.jp\":true,\"kariwa.niigata.jp\":true,\"kashiwazaki.niigata.jp\":true,\"minamiuonuma.niigata.jp\":true,\"mitsuke.niigata.jp\":true,\"muika.niigata.jp\":true,\"murakami.niigata.jp\":true,\"myoko.niigata.jp\":true,\"nagaoka.niigata.jp\":true,\"niigata.niigata.jp\":true,\"ojiya.niigata.jp\":true,\"omi.niigata.jp\":true,\"sado.niigata.jp\":true,\"sanjo.niigata.jp\":true,\"seiro.niigata.jp\":true,\"seirou.niigata.jp\":true,\"sekikawa.niigata.jp\":true,\"shibata.niigata.jp\":true,\"tagami.niigata.jp\":true,\"tainai.niigata.jp\":true,\"tochio.niigata.jp\":true,\"tokamachi.niigata.jp\":true,\"tsubame.niigata.jp\":true,\"tsunan.niigata.jp\":true,\"uonuma.niigata.jp\":true,\"yahiko.niigata.jp\":true,\"yoita.niigata.jp\":true,\"yuzawa.niigata.jp\":true,\"beppu.oita.jp\":true,\"bungoono.oita.jp\":true,\"bungotakada.oita.jp\":true,\"hasama.oita.jp\":true,\"hiji.oita.jp\":true,\"himeshima.oita.jp\":true,\"hita.oita.jp\":true,\"kamitsue.oita.jp\":true,\"kokonoe.oita.jp\":true,\"kuju.oita.jp\":true,\"kunisaki.oita.jp\":true,\"kusu.oita.jp\":true,\"oita.oita.jp\":true,\"saiki.oita.jp\":true,\"taketa.oita.jp\":true,\"tsukumi.oita.jp\":true,\"usa.oita.jp\":true,\"usuki.oita.jp\":true,\"yufu.oita.jp\":true,\"akaiwa.okayama.jp\":true,\"asakuchi.okayama.jp\":true,\"bizen.okayama.jp\":true,\"hayashima.okayama.jp\":true,\"ibara.okayama.jp\":true,\"kagamino.okayama.jp\":true,\"kasaoka.okayama.jp\":true,\"kibichuo.okayama.jp\":true,\"kumenan.okayama.jp\":true,\"kurashiki.okayama.jp\":true,\"maniwa.okayama.jp\":true,\"misaki.okayama.jp\":true,\"nagi.okayama.jp\":true,\"niimi.okayama.jp\":true,\"nishiawakura.okayama.jp\":true,\"okayama.okayama.jp\":true,\"satosho.okayama.jp\":true,\"setouchi.okayama.jp\":true,\"shinjo.okayama.jp\":true,\"shoo.okayama.jp\":true,\"soja.okayama.jp\":true,\"takahashi.okayama.jp\":true,\"tamano.okayama.jp\":true,\"tsuyama.okayama.jp\":true,\"wake.okayama.jp\":true,\"yakage.okayama.jp\":true,\"aguni.okinawa.jp\":true,\"ginowan.okinawa.jp\":true,\"ginoza.okinawa.jp\":true,\"gushikami.okinawa.jp\":true,\"haebaru.okinawa.jp\":true,\"higashi.okinawa.jp\":true,\"hirara.okinawa.jp\":true,\"iheya.okinawa.jp\":true,\"ishigaki.okinawa.jp\":true,\"ishikawa.okinawa.jp\":true,\"itoman.okinawa.jp\":true,\"izena.okinawa.jp\":true,\"kadena.okinawa.jp\":true,\"kin.okinawa.jp\":true,\"kitadaito.okinawa.jp\":true,\"kitanakagusuku.okinawa.jp\":true,\"kumejima.okinawa.jp\":true,\"kunigami.okinawa.jp\":true,\"minamidaito.okinawa.jp\":true,\"motobu.okinawa.jp\":true,\"nago.okinawa.jp\":true,\"naha.okinawa.jp\":true,\"nakagusuku.okinawa.jp\":true,\"nakijin.okinawa.jp\":true,\"nanjo.okinawa.jp\":true,\"nishihara.okinawa.jp\":true,\"ogimi.okinawa.jp\":true,\"okinawa.okinawa.jp\":true,\"onna.okinawa.jp\":true,\"shimoji.okinawa.jp\":true,\"taketomi.okinawa.jp\":true,\"tarama.okinawa.jp\":true,\"tokashiki.okinawa.jp\":true,\"tomigusuku.okinawa.jp\":true,\"tonaki.okinawa.jp\":true,\"urasoe.okinawa.jp\":true,\"uruma.okinawa.jp\":true,\"yaese.okinawa.jp\":true,\"yomitan.okinawa.jp\":true,\"yonabaru.okinawa.jp\":true,\"yonaguni.okinawa.jp\":true,\"zamami.okinawa.jp\":true,\"abeno.osaka.jp\":true,\"chihayaakasaka.osaka.jp\":true,\"chuo.osaka.jp\":true,\"daito.osaka.jp\":true,\"fujiidera.osaka.jp\":true,\"habikino.osaka.jp\":true,\"hannan.osaka.jp\":true,\"higashiosaka.osaka.jp\":true,\"higashisumiyoshi.osaka.jp\":true,\"higashiyodogawa.osaka.jp\":true,\"hirakata.osaka.jp\":true,\"ibaraki.osaka.jp\":true,\"ikeda.osaka.jp\":true,\"izumi.osaka.jp\":true,\"izumiotsu.osaka.jp\":true,\"izumisano.osaka.jp\":true,\"kadoma.osaka.jp\":true,\"kaizuka.osaka.jp\":true,\"kanan.osaka.jp\":true,\"kashiwara.osaka.jp\":true,\"katano.osaka.jp\":true,\"kawachinagano.osaka.jp\":true,\"kishiwada.osaka.jp\":true,\"kita.osaka.jp\":true,\"kumatori.osaka.jp\":true,\"matsubara.osaka.jp\":true,\"minato.osaka.jp\":true,\"minoh.osaka.jp\":true,\"misaki.osaka.jp\":true,\"moriguchi.osaka.jp\":true,\"neyagawa.osaka.jp\":true,\"nishi.osaka.jp\":true,\"nose.osaka.jp\":true,\"osakasayama.osaka.jp\":true,\"sakai.osaka.jp\":true,\"sayama.osaka.jp\":true,\"sennan.osaka.jp\":true,\"settsu.osaka.jp\":true,\"shijonawate.osaka.jp\":true,\"shimamoto.osaka.jp\":true,\"suita.osaka.jp\":true,\"tadaoka.osaka.jp\":true,\"taishi.osaka.jp\":true,\"tajiri.osaka.jp\":true,\"takaishi.osaka.jp\":true,\"takatsuki.osaka.jp\":true,\"tondabayashi.osaka.jp\":true,\"toyonaka.osaka.jp\":true,\"toyono.osaka.jp\":true,\"yao.osaka.jp\":true,\"ariake.saga.jp\":true,\"arita.saga.jp\":true,\"fukudomi.saga.jp\":true,\"genkai.saga.jp\":true,\"hamatama.saga.jp\":true,\"hizen.saga.jp\":true,\"imari.saga.jp\":true,\"kamimine.saga.jp\":true,\"kanzaki.saga.jp\":true,\"karatsu.saga.jp\":true,\"kashima.saga.jp\":true,\"kitagata.saga.jp\":true,\"kitahata.saga.jp\":true,\"kiyama.saga.jp\":true,\"kouhoku.saga.jp\":true,\"kyuragi.saga.jp\":true,\"nishiarita.saga.jp\":true,\"ogi.saga.jp\":true,\"omachi.saga.jp\":true,\"ouchi.saga.jp\":true,\"saga.saga.jp\":true,\"shiroishi.saga.jp\":true,\"taku.saga.jp\":true,\"tara.saga.jp\":true,\"tosu.saga.jp\":true,\"yoshinogari.saga.jp\":true,\"arakawa.saitama.jp\":true,\"asaka.saitama.jp\":true,\"chichibu.saitama.jp\":true,\"fujimi.saitama.jp\":true,\"fujimino.saitama.jp\":true,\"fukaya.saitama.jp\":true,\"hanno.saitama.jp\":true,\"hanyu.saitama.jp\":true,\"hasuda.saitama.jp\":true,\"hatogaya.saitama.jp\":true,\"hatoyama.saitama.jp\":true,\"hidaka.saitama.jp\":true,\"higashichichibu.saitama.jp\":true,\"higashimatsuyama.saitama.jp\":true,\"honjo.saitama.jp\":true,\"ina.saitama.jp\":true,\"iruma.saitama.jp\":true,\"iwatsuki.saitama.jp\":true,\"kamiizumi.saitama.jp\":true,\"kamikawa.saitama.jp\":true,\"kamisato.saitama.jp\":true,\"kasukabe.saitama.jp\":true,\"kawagoe.saitama.jp\":true,\"kawaguchi.saitama.jp\":true,\"kawajima.saitama.jp\":true,\"kazo.saitama.jp\":true,\"kitamoto.saitama.jp\":true,\"koshigaya.saitama.jp\":true,\"kounosu.saitama.jp\":true,\"kuki.saitama.jp\":true,\"kumagaya.saitama.jp\":true,\"matsubushi.saitama.jp\":true,\"minano.saitama.jp\":true,\"misato.saitama.jp\":true,\"miyashiro.saitama.jp\":true,\"miyoshi.saitama.jp\":true,\"moroyama.saitama.jp\":true,\"nagatoro.saitama.jp\":true,\"namegawa.saitama.jp\":true,\"niiza.saitama.jp\":true,\"ogano.saitama.jp\":true,\"ogawa.saitama.jp\":true,\"ogose.saitama.jp\":true,\"okegawa.saitama.jp\":true,\"omiya.saitama.jp\":true,\"otaki.saitama.jp\":true,\"ranzan.saitama.jp\":true,\"ryokami.saitama.jp\":true,\"saitama.saitama.jp\":true,\"sakado.saitama.jp\":true,\"satte.saitama.jp\":true,\"sayama.saitama.jp\":true,\"shiki.saitama.jp\":true,\"shiraoka.saitama.jp\":true,\"soka.saitama.jp\":true,\"sugito.saitama.jp\":true,\"toda.saitama.jp\":true,\"tokigawa.saitama.jp\":true,\"tokorozawa.saitama.jp\":true,\"tsurugashima.saitama.jp\":true,\"urawa.saitama.jp\":true,\"warabi.saitama.jp\":true,\"yashio.saitama.jp\":true,\"yokoze.saitama.jp\":true,\"yono.saitama.jp\":true,\"yorii.saitama.jp\":true,\"yoshida.saitama.jp\":true,\"yoshikawa.saitama.jp\":true,\"yoshimi.saitama.jp\":true,\"aisho.shiga.jp\":true,\"gamo.shiga.jp\":true,\"higashiomi.shiga.jp\":true,\"hikone.shiga.jp\":true,\"koka.shiga.jp\":true,\"konan.shiga.jp\":true,\"kosei.shiga.jp\":true,\"koto.shiga.jp\":true,\"kusatsu.shiga.jp\":true,\"maibara.shiga.jp\":true,\"moriyama.shiga.jp\":true,\"nagahama.shiga.jp\":true,\"nishiazai.shiga.jp\":true,\"notogawa.shiga.jp\":true,\"omihachiman.shiga.jp\":true,\"otsu.shiga.jp\":true,\"ritto.shiga.jp\":true,\"ryuoh.shiga.jp\":true,\"takashima.shiga.jp\":true,\"takatsuki.shiga.jp\":true,\"torahime.shiga.jp\":true,\"toyosato.shiga.jp\":true,\"yasu.shiga.jp\":true,\"akagi.shimane.jp\":true,\"ama.shimane.jp\":true,\"gotsu.shimane.jp\":true,\"hamada.shimane.jp\":true,\"higashiizumo.shimane.jp\":true,\"hikawa.shimane.jp\":true,\"hikimi.shimane.jp\":true,\"izumo.shimane.jp\":true,\"kakinoki.shimane.jp\":true,\"masuda.shimane.jp\":true,\"matsue.shimane.jp\":true,\"misato.shimane.jp\":true,\"nishinoshima.shimane.jp\":true,\"ohda.shimane.jp\":true,\"okinoshima.shimane.jp\":true,\"okuizumo.shimane.jp\":true,\"shimane.shimane.jp\":true,\"tamayu.shimane.jp\":true,\"tsuwano.shimane.jp\":true,\"unnan.shimane.jp\":true,\"yakumo.shimane.jp\":true,\"yasugi.shimane.jp\":true,\"yatsuka.shimane.jp\":true,\"arai.shizuoka.jp\":true,\"atami.shizuoka.jp\":true,\"fuji.shizuoka.jp\":true,\"fujieda.shizuoka.jp\":true,\"fujikawa.shizuoka.jp\":true,\"fujinomiya.shizuoka.jp\":true,\"fukuroi.shizuoka.jp\":true,\"gotemba.shizuoka.jp\":true,\"haibara.shizuoka.jp\":true,\"hamamatsu.shizuoka.jp\":true,\"higashiizu.shizuoka.jp\":true,\"ito.shizuoka.jp\":true,\"iwata.shizuoka.jp\":true,\"izu.shizuoka.jp\":true,\"izunokuni.shizuoka.jp\":true,\"kakegawa.shizuoka.jp\":true,\"kannami.shizuoka.jp\":true,\"kawanehon.shizuoka.jp\":true,\"kawazu.shizuoka.jp\":true,\"kikugawa.shizuoka.jp\":true,\"kosai.shizuoka.jp\":true,\"makinohara.shizuoka.jp\":true,\"matsuzaki.shizuoka.jp\":true,\"minamiizu.shizuoka.jp\":true,\"mishima.shizuoka.jp\":true,\"morimachi.shizuoka.jp\":true,\"nishiizu.shizuoka.jp\":true,\"numazu.shizuoka.jp\":true,\"omaezaki.shizuoka.jp\":true,\"shimada.shizuoka.jp\":true,\"shimizu.shizuoka.jp\":true,\"shimoda.shizuoka.jp\":true,\"shizuoka.shizuoka.jp\":true,\"susono.shizuoka.jp\":true,\"yaizu.shizuoka.jp\":true,\"yoshida.shizuoka.jp\":true,\"ashikaga.tochigi.jp\":true,\"bato.tochigi.jp\":true,\"haga.tochigi.jp\":true,\"ichikai.tochigi.jp\":true,\"iwafune.tochigi.jp\":true,\"kaminokawa.tochigi.jp\":true,\"kanuma.tochigi.jp\":true,\"karasuyama.tochigi.jp\":true,\"kuroiso.tochigi.jp\":true,\"mashiko.tochigi.jp\":true,\"mibu.tochigi.jp\":true,\"moka.tochigi.jp\":true,\"motegi.tochigi.jp\":true,\"nasu.tochigi.jp\":true,\"nasushiobara.tochigi.jp\":true,\"nikko.tochigi.jp\":true,\"nishikata.tochigi.jp\":true,\"nogi.tochigi.jp\":true,\"ohira.tochigi.jp\":true,\"ohtawara.tochigi.jp\":true,\"oyama.tochigi.jp\":true,\"sakura.tochigi.jp\":true,\"sano.tochigi.jp\":true,\"shimotsuke.tochigi.jp\":true,\"shioya.tochigi.jp\":true,\"takanezawa.tochigi.jp\":true,\"tochigi.tochigi.jp\":true,\"tsuga.tochigi.jp\":true,\"ujiie.tochigi.jp\":true,\"utsunomiya.tochigi.jp\":true,\"yaita.tochigi.jp\":true,\"aizumi.tokushima.jp\":true,\"anan.tokushima.jp\":true,\"ichiba.tokushima.jp\":true,\"itano.tokushima.jp\":true,\"kainan.tokushima.jp\":true,\"komatsushima.tokushima.jp\":true,\"matsushige.tokushima.jp\":true,\"mima.tokushima.jp\":true,\"minami.tokushima.jp\":true,\"miyoshi.tokushima.jp\":true,\"mugi.tokushima.jp\":true,\"nakagawa.tokushima.jp\":true,\"naruto.tokushima.jp\":true,\"sanagochi.tokushima.jp\":true,\"shishikui.tokushima.jp\":true,\"tokushima.tokushima.jp\":true,\"wajiki.tokushima.jp\":true,\"adachi.tokyo.jp\":true,\"akiruno.tokyo.jp\":true,\"akishima.tokyo.jp\":true,\"aogashima.tokyo.jp\":true,\"arakawa.tokyo.jp\":true,\"bunkyo.tokyo.jp\":true,\"chiyoda.tokyo.jp\":true,\"chofu.tokyo.jp\":true,\"chuo.tokyo.jp\":true,\"edogawa.tokyo.jp\":true,\"fuchu.tokyo.jp\":true,\"fussa.tokyo.jp\":true,\"hachijo.tokyo.jp\":true,\"hachioji.tokyo.jp\":true,\"hamura.tokyo.jp\":true,\"higashikurume.tokyo.jp\":true,\"higashimurayama.tokyo.jp\":true,\"higashiyamato.tokyo.jp\":true,\"hino.tokyo.jp\":true,\"hinode.tokyo.jp\":true,\"hinohara.tokyo.jp\":true,\"inagi.tokyo.jp\":true,\"itabashi.tokyo.jp\":true,\"katsushika.tokyo.jp\":true,\"kita.tokyo.jp\":true,\"kiyose.tokyo.jp\":true,\"kodaira.tokyo.jp\":true,\"koganei.tokyo.jp\":true,\"kokubunji.tokyo.jp\":true,\"komae.tokyo.jp\":true,\"koto.tokyo.jp\":true,\"kouzushima.tokyo.jp\":true,\"kunitachi.tokyo.jp\":true,\"machida.tokyo.jp\":true,\"meguro.tokyo.jp\":true,\"minato.tokyo.jp\":true,\"mitaka.tokyo.jp\":true,\"mizuho.tokyo.jp\":true,\"musashimurayama.tokyo.jp\":true,\"musashino.tokyo.jp\":true,\"nakano.tokyo.jp\":true,\"nerima.tokyo.jp\":true,\"ogasawara.tokyo.jp\":true,\"okutama.tokyo.jp\":true,\"ome.tokyo.jp\":true,\"oshima.tokyo.jp\":true,\"ota.tokyo.jp\":true,\"setagaya.tokyo.jp\":true,\"shibuya.tokyo.jp\":true,\"shinagawa.tokyo.jp\":true,\"shinjuku.tokyo.jp\":true,\"suginami.tokyo.jp\":true,\"sumida.tokyo.jp\":true,\"tachikawa.tokyo.jp\":true,\"taito.tokyo.jp\":true,\"tama.tokyo.jp\":true,\"toshima.tokyo.jp\":true,\"chizu.tottori.jp\":true,\"hino.tottori.jp\":true,\"kawahara.tottori.jp\":true,\"koge.tottori.jp\":true,\"kotoura.tottori.jp\":true,\"misasa.tottori.jp\":true,\"nanbu.tottori.jp\":true,\"nichinan.tottori.jp\":true,\"sakaiminato.tottori.jp\":true,\"tottori.tottori.jp\":true,\"wakasa.tottori.jp\":true,\"yazu.tottori.jp\":true,\"yonago.tottori.jp\":true,\"asahi.toyama.jp\":true,\"fuchu.toyama.jp\":true,\"fukumitsu.toyama.jp\":true,\"funahashi.toyama.jp\":true,\"himi.toyama.jp\":true,\"imizu.toyama.jp\":true,\"inami.toyama.jp\":true,\"johana.toyama.jp\":true,\"kamiichi.toyama.jp\":true,\"kurobe.toyama.jp\":true,\"nakaniikawa.toyama.jp\":true,\"namerikawa.toyama.jp\":true,\"nanto.toyama.jp\":true,\"nyuzen.toyama.jp\":true,\"oyabe.toyama.jp\":true,\"taira.toyama.jp\":true,\"takaoka.toyama.jp\":true,\"tateyama.toyama.jp\":true,\"toga.toyama.jp\":true,\"tonami.toyama.jp\":true,\"toyama.toyama.jp\":true,\"unazuki.toyama.jp\":true,\"uozu.toyama.jp\":true,\"yamada.toyama.jp\":true,\"arida.wakayama.jp\":true,\"aridagawa.wakayama.jp\":true,\"gobo.wakayama.jp\":true,\"hashimoto.wakayama.jp\":true,\"hidaka.wakayama.jp\":true,\"hirogawa.wakayama.jp\":true,\"inami.wakayama.jp\":true,\"iwade.wakayama.jp\":true,\"kainan.wakayama.jp\":true,\"kamitonda.wakayama.jp\":true,\"katsuragi.wakayama.jp\":true,\"kimino.wakayama.jp\":true,\"kinokawa.wakayama.jp\":true,\"kitayama.wakayama.jp\":true,\"koya.wakayama.jp\":true,\"koza.wakayama.jp\":true,\"kozagawa.wakayama.jp\":true,\"kudoyama.wakayama.jp\":true,\"kushimoto.wakayama.jp\":true,\"mihama.wakayama.jp\":true,\"misato.wakayama.jp\":true,\"nachikatsuura.wakayama.jp\":true,\"shingu.wakayama.jp\":true,\"shirahama.wakayama.jp\":true,\"taiji.wakayama.jp\":true,\"tanabe.wakayama.jp\":true,\"wakayama.wakayama.jp\":true,\"yuasa.wakayama.jp\":true,\"yura.wakayama.jp\":true,\"asahi.yamagata.jp\":true,\"funagata.yamagata.jp\":true,\"higashine.yamagata.jp\":true,\"iide.yamagata.jp\":true,\"kahoku.yamagata.jp\":true,\"kaminoyama.yamagata.jp\":true,\"kaneyama.yamagata.jp\":true,\"kawanishi.yamagata.jp\":true,\"mamurogawa.yamagata.jp\":true,\"mikawa.yamagata.jp\":true,\"murayama.yamagata.jp\":true,\"nagai.yamagata.jp\":true,\"nakayama.yamagata.jp\":true,\"nanyo.yamagata.jp\":true,\"nishikawa.yamagata.jp\":true,\"obanazawa.yamagata.jp\":true,\"oe.yamagata.jp\":true,\"oguni.yamagata.jp\":true,\"ohkura.yamagata.jp\":true,\"oishida.yamagata.jp\":true,\"sagae.yamagata.jp\":true,\"sakata.yamagata.jp\":true,\"sakegawa.yamagata.jp\":true,\"shinjo.yamagata.jp\":true,\"shirataka.yamagata.jp\":true,\"shonai.yamagata.jp\":true,\"takahata.yamagata.jp\":true,\"tendo.yamagata.jp\":true,\"tozawa.yamagata.jp\":true,\"tsuruoka.yamagata.jp\":true,\"yamagata.yamagata.jp\":true,\"yamanobe.yamagata.jp\":true,\"yonezawa.yamagata.jp\":true,\"yuza.yamagata.jp\":true,\"abu.yamaguchi.jp\":true,\"hagi.yamaguchi.jp\":true,\"hikari.yamaguchi.jp\":true,\"hofu.yamaguchi.jp\":true,\"iwakuni.yamaguchi.jp\":true,\"kudamatsu.yamaguchi.jp\":true,\"mitou.yamaguchi.jp\":true,\"nagato.yamaguchi.jp\":true,\"oshima.yamaguchi.jp\":true,\"shimonoseki.yamaguchi.jp\":true,\"shunan.yamaguchi.jp\":true,\"tabuse.yamaguchi.jp\":true,\"tokuyama.yamaguchi.jp\":true,\"toyota.yamaguchi.jp\":true,\"ube.yamaguchi.jp\":true,\"yuu.yamaguchi.jp\":true,\"chuo.yamanashi.jp\":true,\"doshi.yamanashi.jp\":true,\"fuefuki.yamanashi.jp\":true,\"fujikawa.yamanashi.jp\":true,\"fujikawaguchiko.yamanashi.jp\":true,\"fujiyoshida.yamanashi.jp\":true,\"hayakawa.yamanashi.jp\":true,\"hokuto.yamanashi.jp\":true,\"ichikawamisato.yamanashi.jp\":true,\"kai.yamanashi.jp\":true,\"kofu.yamanashi.jp\":true,\"koshu.yamanashi.jp\":true,\"kosuge.yamanashi.jp\":true,\"minami-alps.yamanashi.jp\":true,\"minobu.yamanashi.jp\":true,\"nakamichi.yamanashi.jp\":true,\"nanbu.yamanashi.jp\":true,\"narusawa.yamanashi.jp\":true,\"nirasaki.yamanashi.jp\":true,\"nishikatsura.yamanashi.jp\":true,\"oshino.yamanashi.jp\":true,\"otsuki.yamanashi.jp\":true,\"showa.yamanashi.jp\":true,\"tabayama.yamanashi.jp\":true,\"tsuru.yamanashi.jp\":true,\"uenohara.yamanashi.jp\":true,\"yamanakako.yamanashi.jp\":true,\"yamanashi.yamanashi.jp\":true,\"*.ke\":true,\"kg\":true,\"org.kg\":true,\"net.kg\":true,\"com.kg\":true,\"edu.kg\":true,\"gov.kg\":true,\"mil.kg\":true,\"*.kh\":true,\"ki\":true,\"edu.ki\":true,\"biz.ki\":true,\"net.ki\":true,\"org.ki\":true,\"gov.ki\":true,\"info.ki\":true,\"com.ki\":true,\"km\":true,\"org.km\":true,\"nom.km\":true,\"gov.km\":true,\"prd.km\":true,\"tm.km\":true,\"edu.km\":true,\"mil.km\":true,\"ass.km\":true,\"com.km\":true,\"coop.km\":true,\"asso.km\":true,\"presse.km\":true,\"medecin.km\":true,\"notaires.km\":true,\"pharmaciens.km\":true,\"veterinaire.km\":true,\"gouv.km\":true,\"kn\":true,\"net.kn\":true,\"org.kn\":true,\"edu.kn\":true,\"gov.kn\":true,\"kp\":true,\"com.kp\":true,\"edu.kp\":true,\"gov.kp\":true,\"org.kp\":true,\"rep.kp\":true,\"tra.kp\":true,\"kr\":true,\"ac.kr\":true,\"co.kr\":true,\"es.kr\":true,\"go.kr\":true,\"hs.kr\":true,\"kg.kr\":true,\"mil.kr\":true,\"ms.kr\":true,\"ne.kr\":true,\"or.kr\":true,\"pe.kr\":true,\"re.kr\":true,\"sc.kr\":true,\"busan.kr\":true,\"chungbuk.kr\":true,\"chungnam.kr\":true,\"daegu.kr\":true,\"daejeon.kr\":true,\"gangwon.kr\":true,\"gwangju.kr\":true,\"gyeongbuk.kr\":true,\"gyeonggi.kr\":true,\"gyeongnam.kr\":true,\"incheon.kr\":true,\"jeju.kr\":true,\"jeonbuk.kr\":true,\"jeonnam.kr\":true,\"seoul.kr\":true,\"ulsan.kr\":true,\"*.kw\":true,\"ky\":true,\"edu.ky\":true,\"gov.ky\":true,\"com.ky\":true,\"org.ky\":true,\"net.ky\":true,\"kz\":true,\"org.kz\":true,\"edu.kz\":true,\"net.kz\":true,\"gov.kz\":true,\"mil.kz\":true,\"com.kz\":true,\"la\":true,\"int.la\":true,\"net.la\":true,\"info.la\":true,\"edu.la\":true,\"gov.la\":true,\"per.la\":true,\"com.la\":true,\"org.la\":true,\"lb\":true,\"com.lb\":true,\"edu.lb\":true,\"gov.lb\":true,\"net.lb\":true,\"org.lb\":true,\"lc\":true,\"com.lc\":true,\"net.lc\":true,\"co.lc\":true,\"org.lc\":true,\"edu.lc\":true,\"gov.lc\":true,\"li\":true,\"lk\":true,\"gov.lk\":true,\"sch.lk\":true,\"net.lk\":true,\"int.lk\":true,\"com.lk\":true,\"org.lk\":true,\"edu.lk\":true,\"ngo.lk\":true,\"soc.lk\":true,\"web.lk\":true,\"ltd.lk\":true,\"assn.lk\":true,\"grp.lk\":true,\"hotel.lk\":true,\"ac.lk\":true,\"lr\":true,\"com.lr\":true,\"edu.lr\":true,\"gov.lr\":true,\"org.lr\":true,\"net.lr\":true,\"ls\":true,\"co.ls\":true,\"org.ls\":true,\"lt\":true,\"gov.lt\":true,\"lu\":true,\"lv\":true,\"com.lv\":true,\"edu.lv\":true,\"gov.lv\":true,\"org.lv\":true,\"mil.lv\":true,\"id.lv\":true,\"net.lv\":true,\"asn.lv\":true,\"conf.lv\":true,\"ly\":true,\"com.ly\":true,\"net.ly\":true,\"gov.ly\":true,\"plc.ly\":true,\"edu.ly\":true,\"sch.ly\":true,\"med.ly\":true,\"org.ly\":true,\"id.ly\":true,\"ma\":true,\"co.ma\":true,\"net.ma\":true,\"gov.ma\":true,\"org.ma\":true,\"ac.ma\":true,\"press.ma\":true,\"mc\":true,\"tm.mc\":true,\"asso.mc\":true,\"md\":true,\"me\":true,\"co.me\":true,\"net.me\":true,\"org.me\":true,\"edu.me\":true,\"ac.me\":true,\"gov.me\":true,\"its.me\":true,\"priv.me\":true,\"mg\":true,\"org.mg\":true,\"nom.mg\":true,\"gov.mg\":true,\"prd.mg\":true,\"tm.mg\":true,\"edu.mg\":true,\"mil.mg\":true,\"com.mg\":true,\"co.mg\":true,\"mh\":true,\"mil\":true,\"mk\":true,\"com.mk\":true,\"org.mk\":true,\"net.mk\":true,\"edu.mk\":true,\"gov.mk\":true,\"inf.mk\":true,\"name.mk\":true,\"ml\":true,\"com.ml\":true,\"edu.ml\":true,\"gouv.ml\":true,\"gov.ml\":true,\"net.ml\":true,\"org.ml\":true,\"presse.ml\":true,\"*.mm\":true,\"mn\":true,\"gov.mn\":true,\"edu.mn\":true,\"org.mn\":true,\"mo\":true,\"com.mo\":true,\"net.mo\":true,\"org.mo\":true,\"edu.mo\":true,\"gov.mo\":true,\"mobi\":true,\"mp\":true,\"mq\":true,\"mr\":true,\"gov.mr\":true,\"ms\":true,\"com.ms\":true,\"edu.ms\":true,\"gov.ms\":true,\"net.ms\":true,\"org.ms\":true,\"mt\":true,\"com.mt\":true,\"edu.mt\":true,\"net.mt\":true,\"org.mt\":true,\"mu\":true,\"com.mu\":true,\"net.mu\":true,\"org.mu\":true,\"gov.mu\":true,\"ac.mu\":true,\"co.mu\":true,\"or.mu\":true,\"museum\":true,\"academy.museum\":true,\"agriculture.museum\":true,\"air.museum\":true,\"airguard.museum\":true,\"alabama.museum\":true,\"alaska.museum\":true,\"amber.museum\":true,\"ambulance.museum\":true,\"american.museum\":true,\"americana.museum\":true,\"americanantiques.museum\":true,\"americanart.museum\":true,\"amsterdam.museum\":true,\"and.museum\":true,\"annefrank.museum\":true,\"anthro.museum\":true,\"anthropology.museum\":true,\"antiques.museum\":true,\"aquarium.museum\":true,\"arboretum.museum\":true,\"archaeological.museum\":true,\"archaeology.museum\":true,\"architecture.museum\":true,\"art.museum\":true,\"artanddesign.museum\":true,\"artcenter.museum\":true,\"artdeco.museum\":true,\"arteducation.museum\":true,\"artgallery.museum\":true,\"arts.museum\":true,\"artsandcrafts.museum\":true,\"asmatart.museum\":true,\"assassination.museum\":true,\"assisi.museum\":true,\"association.museum\":true,\"astronomy.museum\":true,\"atlanta.museum\":true,\"austin.museum\":true,\"australia.museum\":true,\"automotive.museum\":true,\"aviation.museum\":true,\"axis.museum\":true,\"badajoz.museum\":true,\"baghdad.museum\":true,\"bahn.museum\":true,\"bale.museum\":true,\"baltimore.museum\":true,\"barcelona.museum\":true,\"baseball.museum\":true,\"basel.museum\":true,\"baths.museum\":true,\"bauern.museum\":true,\"beauxarts.museum\":true,\"beeldengeluid.museum\":true,\"bellevue.museum\":true,\"bergbau.museum\":true,\"berkeley.museum\":true,\"berlin.museum\":true,\"bern.museum\":true,\"bible.museum\":true,\"bilbao.museum\":true,\"bill.museum\":true,\"birdart.museum\":true,\"birthplace.museum\":true,\"bonn.museum\":true,\"boston.museum\":true,\"botanical.museum\":true,\"botanicalgarden.museum\":true,\"botanicgarden.museum\":true,\"botany.museum\":true,\"brandywinevalley.museum\":true,\"brasil.museum\":true,\"bristol.museum\":true,\"british.museum\":true,\"britishcolumbia.museum\":true,\"broadcast.museum\":true,\"brunel.museum\":true,\"brussel.museum\":true,\"brussels.museum\":true,\"bruxelles.museum\":true,\"building.museum\":true,\"burghof.museum\":true,\"bus.museum\":true,\"bushey.museum\":true,\"cadaques.museum\":true,\"california.museum\":true,\"cambridge.museum\":true,\"can.museum\":true,\"canada.museum\":true,\"capebreton.museum\":true,\"carrier.museum\":true,\"cartoonart.museum\":true,\"casadelamoneda.museum\":true,\"castle.museum\":true,\"castres.museum\":true,\"celtic.museum\":true,\"center.museum\":true,\"chattanooga.museum\":true,\"cheltenham.museum\":true,\"chesapeakebay.museum\":true,\"chicago.museum\":true,\"children.museum\":true,\"childrens.museum\":true,\"childrensgarden.museum\":true,\"chiropractic.museum\":true,\"chocolate.museum\":true,\"christiansburg.museum\":true,\"cincinnati.museum\":true,\"cinema.museum\":true,\"circus.museum\":true,\"civilisation.museum\":true,\"civilization.museum\":true,\"civilwar.museum\":true,\"clinton.museum\":true,\"clock.museum\":true,\"coal.museum\":true,\"coastaldefence.museum\":true,\"cody.museum\":true,\"coldwar.museum\":true,\"collection.museum\":true,\"colonialwilliamsburg.museum\":true,\"coloradoplateau.museum\":true,\"columbia.museum\":true,\"columbus.museum\":true,\"communication.museum\":true,\"communications.museum\":true,\"community.museum\":true,\"computer.museum\":true,\"computerhistory.museum\":true,\"xn--comunicaes-v6a2o.museum\":true,\"contemporary.museum\":true,\"contemporaryart.museum\":true,\"convent.museum\":true,\"copenhagen.museum\":true,\"corporation.museum\":true,\"xn--correios-e-telecomunicaes-ghc29a.museum\":true,\"corvette.museum\":true,\"costume.museum\":true,\"countryestate.museum\":true,\"county.museum\":true,\"crafts.museum\":true,\"cranbrook.museum\":true,\"creation.museum\":true,\"cultural.museum\":true,\"culturalcenter.museum\":true,\"culture.museum\":true,\"cyber.museum\":true,\"cymru.museum\":true,\"dali.museum\":true,\"dallas.museum\":true,\"database.museum\":true,\"ddr.museum\":true,\"decorativearts.museum\":true,\"delaware.museum\":true,\"delmenhorst.museum\":true,\"denmark.museum\":true,\"depot.museum\":true,\"design.museum\":true,\"detroit.museum\":true,\"dinosaur.museum\":true,\"discovery.museum\":true,\"dolls.museum\":true,\"donostia.museum\":true,\"durham.museum\":true,\"eastafrica.museum\":true,\"eastcoast.museum\":true,\"education.museum\":true,\"educational.museum\":true,\"egyptian.museum\":true,\"eisenbahn.museum\":true,\"elburg.museum\":true,\"elvendrell.museum\":true,\"embroidery.museum\":true,\"encyclopedic.museum\":true,\"england.museum\":true,\"entomology.museum\":true,\"environment.museum\":true,\"environmentalconservation.museum\":true,\"epilepsy.museum\":true,\"essex.museum\":true,\"estate.museum\":true,\"ethnology.museum\":true,\"exeter.museum\":true,\"exhibition.museum\":true,\"family.museum\":true,\"farm.museum\":true,\"farmequipment.museum\":true,\"farmers.museum\":true,\"farmstead.museum\":true,\"field.museum\":true,\"figueres.museum\":true,\"filatelia.museum\":true,\"film.museum\":true,\"fineart.museum\":true,\"finearts.museum\":true,\"finland.museum\":true,\"flanders.museum\":true,\"florida.museum\":true,\"force.museum\":true,\"fortmissoula.museum\":true,\"fortworth.museum\":true,\"foundation.museum\":true,\"francaise.museum\":true,\"frankfurt.museum\":true,\"franziskaner.museum\":true,\"freemasonry.museum\":true,\"freiburg.museum\":true,\"fribourg.museum\":true,\"frog.museum\":true,\"fundacio.museum\":true,\"furniture.museum\":true,\"gallery.museum\":true,\"garden.museum\":true,\"gateway.museum\":true,\"geelvinck.museum\":true,\"gemological.museum\":true,\"geology.museum\":true,\"georgia.museum\":true,\"giessen.museum\":true,\"glas.museum\":true,\"glass.museum\":true,\"gorge.museum\":true,\"grandrapids.museum\":true,\"graz.museum\":true,\"guernsey.museum\":true,\"halloffame.museum\":true,\"hamburg.museum\":true,\"handson.museum\":true,\"harvestcelebration.museum\":true,\"hawaii.museum\":true,\"health.museum\":true,\"heimatunduhren.museum\":true,\"hellas.museum\":true,\"helsinki.museum\":true,\"hembygdsforbund.museum\":true,\"heritage.museum\":true,\"histoire.museum\":true,\"historical.museum\":true,\"historicalsociety.museum\":true,\"historichouses.museum\":true,\"historisch.museum\":true,\"historisches.museum\":true,\"history.museum\":true,\"historyofscience.museum\":true,\"horology.museum\":true,\"house.museum\":true,\"humanities.museum\":true,\"illustration.museum\":true,\"imageandsound.museum\":true,\"indian.museum\":true,\"indiana.museum\":true,\"indianapolis.museum\":true,\"indianmarket.museum\":true,\"intelligence.museum\":true,\"interactive.museum\":true,\"iraq.museum\":true,\"iron.museum\":true,\"isleofman.museum\":true,\"jamison.museum\":true,\"jefferson.museum\":true,\"jerusalem.museum\":true,\"jewelry.museum\":true,\"jewish.museum\":true,\"jewishart.museum\":true,\"jfk.museum\":true,\"journalism.museum\":true,\"judaica.museum\":true,\"judygarland.museum\":true,\"juedisches.museum\":true,\"juif.museum\":true,\"karate.museum\":true,\"karikatur.museum\":true,\"kids.museum\":true,\"koebenhavn.museum\":true,\"koeln.museum\":true,\"kunst.museum\":true,\"kunstsammlung.museum\":true,\"kunstunddesign.museum\":true,\"labor.museum\":true,\"labour.museum\":true,\"lajolla.museum\":true,\"lancashire.museum\":true,\"landes.museum\":true,\"lans.museum\":true,\"xn--lns-qla.museum\":true,\"larsson.museum\":true,\"lewismiller.museum\":true,\"lincoln.museum\":true,\"linz.museum\":true,\"living.museum\":true,\"livinghistory.museum\":true,\"localhistory.museum\":true,\"london.museum\":true,\"losangeles.museum\":true,\"louvre.museum\":true,\"loyalist.museum\":true,\"lucerne.museum\":true,\"luxembourg.museum\":true,\"luzern.museum\":true,\"mad.museum\":true,\"madrid.museum\":true,\"mallorca.museum\":true,\"manchester.museum\":true,\"mansion.museum\":true,\"mansions.museum\":true,\"manx.museum\":true,\"marburg.museum\":true,\"maritime.museum\":true,\"maritimo.museum\":true,\"maryland.museum\":true,\"marylhurst.museum\":true,\"media.museum\":true,\"medical.museum\":true,\"medizinhistorisches.museum\":true,\"meeres.museum\":true,\"memorial.museum\":true,\"mesaverde.museum\":true,\"michigan.museum\":true,\"midatlantic.museum\":true,\"military.museum\":true,\"mill.museum\":true,\"miners.museum\":true,\"mining.museum\":true,\"minnesota.museum\":true,\"missile.museum\":true,\"missoula.museum\":true,\"modern.museum\":true,\"moma.museum\":true,\"money.museum\":true,\"monmouth.museum\":true,\"monticello.museum\":true,\"montreal.museum\":true,\"moscow.museum\":true,\"motorcycle.museum\":true,\"muenchen.museum\":true,\"muenster.museum\":true,\"mulhouse.museum\":true,\"muncie.museum\":true,\"museet.museum\":true,\"museumcenter.museum\":true,\"museumvereniging.museum\":true,\"music.museum\":true,\"national.museum\":true,\"nationalfirearms.museum\":true,\"nationalheritage.museum\":true,\"nativeamerican.museum\":true,\"naturalhistory.museum\":true,\"naturalhistorymuseum.museum\":true,\"naturalsciences.museum\":true,\"nature.museum\":true,\"naturhistorisches.museum\":true,\"natuurwetenschappen.museum\":true,\"naumburg.museum\":true,\"naval.museum\":true,\"nebraska.museum\":true,\"neues.museum\":true,\"newhampshire.museum\":true,\"newjersey.museum\":true,\"newmexico.museum\":true,\"newport.museum\":true,\"newspaper.museum\":true,\"newyork.museum\":true,\"niepce.museum\":true,\"norfolk.museum\":true,\"north.museum\":true,\"nrw.museum\":true,\"nuernberg.museum\":true,\"nuremberg.museum\":true,\"nyc.museum\":true,\"nyny.museum\":true,\"oceanographic.museum\":true,\"oceanographique.museum\":true,\"omaha.museum\":true,\"online.museum\":true,\"ontario.museum\":true,\"openair.museum\":true,\"oregon.museum\":true,\"oregontrail.museum\":true,\"otago.museum\":true,\"oxford.museum\":true,\"pacific.museum\":true,\"paderborn.museum\":true,\"palace.museum\":true,\"paleo.museum\":true,\"palmsprings.museum\":true,\"panama.museum\":true,\"paris.museum\":true,\"pasadena.museum\":true,\"pharmacy.museum\":true,\"philadelphia.museum\":true,\"philadelphiaarea.museum\":true,\"philately.museum\":true,\"phoenix.museum\":true,\"photography.museum\":true,\"pilots.museum\":true,\"pittsburgh.museum\":true,\"planetarium.museum\":true,\"plantation.museum\":true,\"plants.museum\":true,\"plaza.museum\":true,\"portal.museum\":true,\"portland.museum\":true,\"portlligat.museum\":true,\"posts-and-telecommunications.museum\":true,\"preservation.museum\":true,\"presidio.museum\":true,\"press.museum\":true,\"project.museum\":true,\"public.museum\":true,\"pubol.museum\":true,\"quebec.museum\":true,\"railroad.museum\":true,\"railway.museum\":true,\"research.museum\":true,\"resistance.museum\":true,\"riodejaneiro.museum\":true,\"rochester.museum\":true,\"rockart.museum\":true,\"roma.museum\":true,\"russia.museum\":true,\"saintlouis.museum\":true,\"salem.museum\":true,\"salvadordali.museum\":true,\"salzburg.museum\":true,\"sandiego.museum\":true,\"sanfrancisco.museum\":true,\"santabarbara.museum\":true,\"santacruz.museum\":true,\"santafe.museum\":true,\"saskatchewan.museum\":true,\"satx.museum\":true,\"savannahga.museum\":true,\"schlesisches.museum\":true,\"schoenbrunn.museum\":true,\"schokoladen.museum\":true,\"school.museum\":true,\"schweiz.museum\":true,\"science.museum\":true,\"scienceandhistory.museum\":true,\"scienceandindustry.museum\":true,\"sciencecenter.museum\":true,\"sciencecenters.museum\":true,\"science-fiction.museum\":true,\"sciencehistory.museum\":true,\"sciences.museum\":true,\"sciencesnaturelles.museum\":true,\"scotland.museum\":true,\"seaport.museum\":true,\"settlement.museum\":true,\"settlers.museum\":true,\"shell.museum\":true,\"sherbrooke.museum\":true,\"sibenik.museum\":true,\"silk.museum\":true,\"ski.museum\":true,\"skole.museum\":true,\"society.museum\":true,\"sologne.museum\":true,\"soundandvision.museum\":true,\"southcarolina.museum\":true,\"southwest.museum\":true,\"space.museum\":true,\"spy.museum\":true,\"square.museum\":true,\"stadt.museum\":true,\"stalbans.museum\":true,\"starnberg.museum\":true,\"state.museum\":true,\"stateofdelaware.museum\":true,\"station.museum\":true,\"steam.museum\":true,\"steiermark.museum\":true,\"stjohn.museum\":true,\"stockholm.museum\":true,\"stpetersburg.museum\":true,\"stuttgart.museum\":true,\"suisse.museum\":true,\"surgeonshall.museum\":true,\"surrey.museum\":true,\"svizzera.museum\":true,\"sweden.museum\":true,\"sydney.museum\":true,\"tank.museum\":true,\"tcm.museum\":true,\"technology.museum\":true,\"telekommunikation.museum\":true,\"television.museum\":true,\"texas.museum\":true,\"textile.museum\":true,\"theater.museum\":true,\"time.museum\":true,\"timekeeping.museum\":true,\"topology.museum\":true,\"torino.museum\":true,\"touch.museum\":true,\"town.museum\":true,\"transport.museum\":true,\"tree.museum\":true,\"trolley.museum\":true,\"trust.museum\":true,\"trustee.museum\":true,\"uhren.museum\":true,\"ulm.museum\":true,\"undersea.museum\":true,\"university.museum\":true,\"usa.museum\":true,\"usantiques.museum\":true,\"usarts.museum\":true,\"uscountryestate.museum\":true,\"usculture.museum\":true,\"usdecorativearts.museum\":true,\"usgarden.museum\":true,\"ushistory.museum\":true,\"ushuaia.museum\":true,\"uslivinghistory.museum\":true,\"utah.museum\":true,\"uvic.museum\":true,\"valley.museum\":true,\"vantaa.museum\":true,\"versailles.museum\":true,\"viking.museum\":true,\"village.museum\":true,\"virginia.museum\":true,\"virtual.museum\":true,\"virtuel.museum\":true,\"vlaanderen.museum\":true,\"volkenkunde.museum\":true,\"wales.museum\":true,\"wallonie.museum\":true,\"war.museum\":true,\"washingtondc.museum\":true,\"watchandclock.museum\":true,\"watch-and-clock.museum\":true,\"western.museum\":true,\"westfalen.museum\":true,\"whaling.museum\":true,\"wildlife.museum\":true,\"williamsburg.museum\":true,\"windmill.museum\":true,\"workshop.museum\":true,\"york.museum\":true,\"yorkshire.museum\":true,\"yosemite.museum\":true,\"youth.museum\":true,\"zoological.museum\":true,\"zoology.museum\":true,\"xn--9dbhblg6di.museum\":true,\"xn--h1aegh.museum\":true,\"mv\":true,\"aero.mv\":true,\"biz.mv\":true,\"com.mv\":true,\"coop.mv\":true,\"edu.mv\":true,\"gov.mv\":true,\"info.mv\":true,\"int.mv\":true,\"mil.mv\":true,\"museum.mv\":true,\"name.mv\":true,\"net.mv\":true,\"org.mv\":true,\"pro.mv\":true,\"mw\":true,\"ac.mw\":true,\"biz.mw\":true,\"co.mw\":true,\"com.mw\":true,\"coop.mw\":true,\"edu.mw\":true,\"gov.mw\":true,\"int.mw\":true,\"museum.mw\":true,\"net.mw\":true,\"org.mw\":true,\"mx\":true,\"com.mx\":true,\"org.mx\":true,\"gob.mx\":true,\"edu.mx\":true,\"net.mx\":true,\"my\":true,\"com.my\":true,\"net.my\":true,\"org.my\":true,\"gov.my\":true,\"edu.my\":true,\"mil.my\":true,\"name.my\":true,\"*.mz\":true,\"teledata.mz\":false,\"na\":true,\"info.na\":true,\"pro.na\":true,\"name.na\":true,\"school.na\":true,\"or.na\":true,\"dr.na\":true,\"us.na\":true,\"mx.na\":true,\"ca.na\":true,\"in.na\":true,\"cc.na\":true,\"tv.na\":true,\"ws.na\":true,\"mobi.na\":true,\"co.na\":true,\"com.na\":true,\"org.na\":true,\"name\":true,\"nc\":true,\"asso.nc\":true,\"ne\":true,\"net\":true,\"nf\":true,\"com.nf\":true,\"net.nf\":true,\"per.nf\":true,\"rec.nf\":true,\"web.nf\":true,\"arts.nf\":true,\"firm.nf\":true,\"info.nf\":true,\"other.nf\":true,\"store.nf\":true,\"ng\":true,\"com.ng\":true,\"edu.ng\":true,\"name.ng\":true,\"net.ng\":true,\"org.ng\":true,\"sch.ng\":true,\"gov.ng\":true,\"mil.ng\":true,\"mobi.ng\":true,\"*.ni\":true,\"nl\":true,\"bv.nl\":true,\"no\":true,\"fhs.no\":true,\"vgs.no\":true,\"fylkesbibl.no\":true,\"folkebibl.no\":true,\"museum.no\":true,\"idrett.no\":true,\"priv.no\":true,\"mil.no\":true,\"stat.no\":true,\"dep.no\":true,\"kommune.no\":true,\"herad.no\":true,\"aa.no\":true,\"ah.no\":true,\"bu.no\":true,\"fm.no\":true,\"hl.no\":true,\"hm.no\":true,\"jan-mayen.no\":true,\"mr.no\":true,\"nl.no\":true,\"nt.no\":true,\"of.no\":true,\"ol.no\":true,\"oslo.no\":true,\"rl.no\":true,\"sf.no\":true,\"st.no\":true,\"svalbard.no\":true,\"tm.no\":true,\"tr.no\":true,\"va.no\":true,\"vf.no\":true,\"gs.aa.no\":true,\"gs.ah.no\":true,\"gs.bu.no\":true,\"gs.fm.no\":true,\"gs.hl.no\":true,\"gs.hm.no\":true,\"gs.jan-mayen.no\":true,\"gs.mr.no\":true,\"gs.nl.no\":true,\"gs.nt.no\":true,\"gs.of.no\":true,\"gs.ol.no\":true,\"gs.oslo.no\":true,\"gs.rl.no\":true,\"gs.sf.no\":true,\"gs.st.no\":true,\"gs.svalbard.no\":true,\"gs.tm.no\":true,\"gs.tr.no\":true,\"gs.va.no\":true,\"gs.vf.no\":true,\"akrehamn.no\":true,\"xn--krehamn-dxa.no\":true,\"algard.no\":true,\"xn--lgrd-poac.no\":true,\"arna.no\":true,\"brumunddal.no\":true,\"bryne.no\":true,\"bronnoysund.no\":true,\"xn--brnnysund-m8ac.no\":true,\"drobak.no\":true,\"xn--drbak-wua.no\":true,\"egersund.no\":true,\"fetsund.no\":true,\"floro.no\":true,\"xn--flor-jra.no\":true,\"fredrikstad.no\":true,\"hokksund.no\":true,\"honefoss.no\":true,\"xn--hnefoss-q1a.no\":true,\"jessheim.no\":true,\"jorpeland.no\":true,\"xn--jrpeland-54a.no\":true,\"kirkenes.no\":true,\"kopervik.no\":true,\"krokstadelva.no\":true,\"langevag.no\":true,\"xn--langevg-jxa.no\":true,\"leirvik.no\":true,\"mjondalen.no\":true,\"xn--mjndalen-64a.no\":true,\"mo-i-rana.no\":true,\"mosjoen.no\":true,\"xn--mosjen-eya.no\":true,\"nesoddtangen.no\":true,\"orkanger.no\":true,\"osoyro.no\":true,\"xn--osyro-wua.no\":true,\"raholt.no\":true,\"xn--rholt-mra.no\":true,\"sandnessjoen.no\":true,\"xn--sandnessjen-ogb.no\":true,\"skedsmokorset.no\":true,\"slattum.no\":true,\"spjelkavik.no\":true,\"stathelle.no\":true,\"stavern.no\":true,\"stjordalshalsen.no\":true,\"xn--stjrdalshalsen-sqb.no\":true,\"tananger.no\":true,\"tranby.no\":true,\"vossevangen.no\":true,\"afjord.no\":true,\"xn--fjord-lra.no\":true,\"agdenes.no\":true,\"al.no\":true,\"xn--l-1fa.no\":true,\"alesund.no\":true,\"xn--lesund-hua.no\":true,\"alstahaug.no\":true,\"alta.no\":true,\"xn--lt-liac.no\":true,\"alaheadju.no\":true,\"xn--laheadju-7ya.no\":true,\"alvdal.no\":true,\"amli.no\":true,\"xn--mli-tla.no\":true,\"amot.no\":true,\"xn--mot-tla.no\":true,\"andebu.no\":true,\"andoy.no\":true,\"xn--andy-ira.no\":true,\"andasuolo.no\":true,\"ardal.no\":true,\"xn--rdal-poa.no\":true,\"aremark.no\":true,\"arendal.no\":true,\"xn--s-1fa.no\":true,\"aseral.no\":true,\"xn--seral-lra.no\":true,\"asker.no\":true,\"askim.no\":true,\"askvoll.no\":true,\"askoy.no\":true,\"xn--asky-ira.no\":true,\"asnes.no\":true,\"xn--snes-poa.no\":true,\"audnedaln.no\":true,\"aukra.no\":true,\"aure.no\":true,\"aurland.no\":true,\"aurskog-holand.no\":true,\"xn--aurskog-hland-jnb.no\":true,\"austevoll.no\":true,\"austrheim.no\":true,\"averoy.no\":true,\"xn--avery-yua.no\":true,\"balestrand.no\":true,\"ballangen.no\":true,\"balat.no\":true,\"xn--blt-elab.no\":true,\"balsfjord.no\":true,\"bahccavuotna.no\":true,\"xn--bhccavuotna-k7a.no\":true,\"bamble.no\":true,\"bardu.no\":true,\"beardu.no\":true,\"beiarn.no\":true,\"bajddar.no\":true,\"xn--bjddar-pta.no\":true,\"baidar.no\":true,\"xn--bidr-5nac.no\":true,\"berg.no\":true,\"bergen.no\":true,\"berlevag.no\":true,\"xn--berlevg-jxa.no\":true,\"bearalvahki.no\":true,\"xn--bearalvhki-y4a.no\":true,\"bindal.no\":true,\"birkenes.no\":true,\"bjarkoy.no\":true,\"xn--bjarky-fya.no\":true,\"bjerkreim.no\":true,\"bjugn.no\":true,\"bodo.no\":true,\"xn--bod-2na.no\":true,\"badaddja.no\":true,\"xn--bdddj-mrabd.no\":true,\"budejju.no\":true,\"bokn.no\":true,\"bremanger.no\":true,\"bronnoy.no\":true,\"xn--brnny-wuac.no\":true,\"bygland.no\":true,\"bykle.no\":true,\"barum.no\":true,\"xn--brum-voa.no\":true,\"bo.telemark.no\":true,\"xn--b-5ga.telemark.no\":true,\"bo.nordland.no\":true,\"xn--b-5ga.nordland.no\":true,\"bievat.no\":true,\"xn--bievt-0qa.no\":true,\"bomlo.no\":true,\"xn--bmlo-gra.no\":true,\"batsfjord.no\":true,\"xn--btsfjord-9za.no\":true,\"bahcavuotna.no\":true,\"xn--bhcavuotna-s4a.no\":true,\"dovre.no\":true,\"drammen.no\":true,\"drangedal.no\":true,\"dyroy.no\":true,\"xn--dyry-ira.no\":true,\"donna.no\":true,\"xn--dnna-gra.no\":true,\"eid.no\":true,\"eidfjord.no\":true,\"eidsberg.no\":true,\"eidskog.no\":true,\"eidsvoll.no\":true,\"eigersund.no\":true,\"elverum.no\":true,\"enebakk.no\":true,\"engerdal.no\":true,\"etne.no\":true,\"etnedal.no\":true,\"evenes.no\":true,\"evenassi.no\":true,\"xn--eveni-0qa01ga.no\":true,\"evje-og-hornnes.no\":true,\"farsund.no\":true,\"fauske.no\":true,\"fuossko.no\":true,\"fuoisku.no\":true,\"fedje.no\":true,\"fet.no\":true,\"finnoy.no\":true,\"xn--finny-yua.no\":true,\"fitjar.no\":true,\"fjaler.no\":true,\"fjell.no\":true,\"flakstad.no\":true,\"flatanger.no\":true,\"flekkefjord.no\":true,\"flesberg.no\":true,\"flora.no\":true,\"fla.no\":true,\"xn--fl-zia.no\":true,\"folldal.no\":true,\"forsand.no\":true,\"fosnes.no\":true,\"frei.no\":true,\"frogn.no\":true,\"froland.no\":true,\"frosta.no\":true,\"frana.no\":true,\"xn--frna-woa.no\":true,\"froya.no\":true,\"xn--frya-hra.no\":true,\"fusa.no\":true,\"fyresdal.no\":true,\"forde.no\":true,\"xn--frde-gra.no\":true,\"gamvik.no\":true,\"gangaviika.no\":true,\"xn--ggaviika-8ya47h.no\":true,\"gaular.no\":true,\"gausdal.no\":true,\"gildeskal.no\":true,\"xn--gildeskl-g0a.no\":true,\"giske.no\":true,\"gjemnes.no\":true,\"gjerdrum.no\":true,\"gjerstad.no\":true,\"gjesdal.no\":true,\"gjovik.no\":true,\"xn--gjvik-wua.no\":true,\"gloppen.no\":true,\"gol.no\":true,\"gran.no\":true,\"grane.no\":true,\"granvin.no\":true,\"gratangen.no\":true,\"grimstad.no\":true,\"grong.no\":true,\"kraanghke.no\":true,\"xn--kranghke-b0a.no\":true,\"grue.no\":true,\"gulen.no\":true,\"hadsel.no\":true,\"halden.no\":true,\"halsa.no\":true,\"hamar.no\":true,\"hamaroy.no\":true,\"habmer.no\":true,\"xn--hbmer-xqa.no\":true,\"hapmir.no\":true,\"xn--hpmir-xqa.no\":true,\"hammerfest.no\":true,\"hammarfeasta.no\":true,\"xn--hmmrfeasta-s4ac.no\":true,\"haram.no\":true,\"hareid.no\":true,\"harstad.no\":true,\"hasvik.no\":true,\"aknoluokta.no\":true,\"xn--koluokta-7ya57h.no\":true,\"hattfjelldal.no\":true,\"aarborte.no\":true,\"haugesund.no\":true,\"hemne.no\":true,\"hemnes.no\":true,\"hemsedal.no\":true,\"heroy.more-og-romsdal.no\":true,\"xn--hery-ira.xn--mre-og-romsdal-qqb.no\":true,\"heroy.nordland.no\":true,\"xn--hery-ira.nordland.no\":true,\"hitra.no\":true,\"hjartdal.no\":true,\"hjelmeland.no\":true,\"hobol.no\":true,\"xn--hobl-ira.no\":true,\"hof.no\":true,\"hol.no\":true,\"hole.no\":true,\"holmestrand.no\":true,\"holtalen.no\":true,\"xn--holtlen-hxa.no\":true,\"hornindal.no\":true,\"horten.no\":true,\"hurdal.no\":true,\"hurum.no\":true,\"hvaler.no\":true,\"hyllestad.no\":true,\"hagebostad.no\":true,\"xn--hgebostad-g3a.no\":true,\"hoyanger.no\":true,\"xn--hyanger-q1a.no\":true,\"hoylandet.no\":true,\"xn--hylandet-54a.no\":true,\"ha.no\":true,\"xn--h-2fa.no\":true,\"ibestad.no\":true,\"inderoy.no\":true,\"xn--indery-fya.no\":true,\"iveland.no\":true,\"jevnaker.no\":true,\"jondal.no\":true,\"jolster.no\":true,\"xn--jlster-bya.no\":true,\"karasjok.no\":true,\"karasjohka.no\":true,\"xn--krjohka-hwab49j.no\":true,\"karlsoy.no\":true,\"galsa.no\":true,\"xn--gls-elac.no\":true,\"karmoy.no\":true,\"xn--karmy-yua.no\":true,\"kautokeino.no\":true,\"guovdageaidnu.no\":true,\"klepp.no\":true,\"klabu.no\":true,\"xn--klbu-woa.no\":true,\"kongsberg.no\":true,\"kongsvinger.no\":true,\"kragero.no\":true,\"xn--krager-gya.no\":true,\"kristiansand.no\":true,\"kristiansund.no\":true,\"krodsherad.no\":true,\"xn--krdsherad-m8a.no\":true,\"kvalsund.no\":true,\"rahkkeravju.no\":true,\"xn--rhkkervju-01af.no\":true,\"kvam.no\":true,\"kvinesdal.no\":true,\"kvinnherad.no\":true,\"kviteseid.no\":true,\"kvitsoy.no\":true,\"xn--kvitsy-fya.no\":true,\"kvafjord.no\":true,\"xn--kvfjord-nxa.no\":true,\"giehtavuoatna.no\":true,\"kvanangen.no\":true,\"xn--kvnangen-k0a.no\":true,\"navuotna.no\":true,\"xn--nvuotna-hwa.no\":true,\"kafjord.no\":true,\"xn--kfjord-iua.no\":true,\"gaivuotna.no\":true,\"xn--givuotna-8ya.no\":true,\"larvik.no\":true,\"lavangen.no\":true,\"lavagis.no\":true,\"loabat.no\":true,\"xn--loabt-0qa.no\":true,\"lebesby.no\":true,\"davvesiida.no\":true,\"leikanger.no\":true,\"leirfjord.no\":true,\"leka.no\":true,\"leksvik.no\":true,\"lenvik.no\":true,\"leangaviika.no\":true,\"xn--leagaviika-52b.no\":true,\"lesja.no\":true,\"levanger.no\":true,\"lier.no\":true,\"lierne.no\":true,\"lillehammer.no\":true,\"lillesand.no\":true,\"lindesnes.no\":true,\"lindas.no\":true,\"xn--linds-pra.no\":true,\"lom.no\":true,\"loppa.no\":true,\"lahppi.no\":true,\"xn--lhppi-xqa.no\":true,\"lund.no\":true,\"lunner.no\":true,\"luroy.no\":true,\"xn--lury-ira.no\":true,\"luster.no\":true,\"lyngdal.no\":true,\"lyngen.no\":true,\"ivgu.no\":true,\"lardal.no\":true,\"lerdal.no\":true,\"xn--lrdal-sra.no\":true,\"lodingen.no\":true,\"xn--ldingen-q1a.no\":true,\"lorenskog.no\":true,\"xn--lrenskog-54a.no\":true,\"loten.no\":true,\"xn--lten-gra.no\":true,\"malvik.no\":true,\"masoy.no\":true,\"xn--msy-ula0h.no\":true,\"muosat.no\":true,\"xn--muost-0qa.no\":true,\"mandal.no\":true,\"marker.no\":true,\"marnardal.no\":true,\"masfjorden.no\":true,\"meland.no\":true,\"meldal.no\":true,\"melhus.no\":true,\"meloy.no\":true,\"xn--mely-ira.no\":true,\"meraker.no\":true,\"xn--merker-kua.no\":true,\"moareke.no\":true,\"xn--moreke-jua.no\":true,\"midsund.no\":true,\"midtre-gauldal.no\":true,\"modalen.no\":true,\"modum.no\":true,\"molde.no\":true,\"moskenes.no\":true,\"moss.no\":true,\"mosvik.no\":true,\"malselv.no\":true,\"xn--mlselv-iua.no\":true,\"malatvuopmi.no\":true,\"xn--mlatvuopmi-s4a.no\":true,\"namdalseid.no\":true,\"aejrie.no\":true,\"namsos.no\":true,\"namsskogan.no\":true,\"naamesjevuemie.no\":true,\"xn--nmesjevuemie-tcba.no\":true,\"laakesvuemie.no\":true,\"nannestad.no\":true,\"narvik.no\":true,\"narviika.no\":true,\"naustdal.no\":true,\"nedre-eiker.no\":true,\"nes.akershus.no\":true,\"nes.buskerud.no\":true,\"nesna.no\":true,\"nesodden.no\":true,\"nesseby.no\":true,\"unjarga.no\":true,\"xn--unjrga-rta.no\":true,\"nesset.no\":true,\"nissedal.no\":true,\"nittedal.no\":true,\"nord-aurdal.no\":true,\"nord-fron.no\":true,\"nord-odal.no\":true,\"norddal.no\":true,\"nordkapp.no\":true,\"davvenjarga.no\":true,\"xn--davvenjrga-y4a.no\":true,\"nordre-land.no\":true,\"nordreisa.no\":true,\"raisa.no\":true,\"xn--risa-5na.no\":true,\"nore-og-uvdal.no\":true,\"notodden.no\":true,\"naroy.no\":true,\"xn--nry-yla5g.no\":true,\"notteroy.no\":true,\"xn--nttery-byae.no\":true,\"odda.no\":true,\"oksnes.no\":true,\"xn--ksnes-uua.no\":true,\"oppdal.no\":true,\"oppegard.no\":true,\"xn--oppegrd-ixa.no\":true,\"orkdal.no\":true,\"orland.no\":true,\"xn--rland-uua.no\":true,\"orskog.no\":true,\"xn--rskog-uua.no\":true,\"orsta.no\":true,\"xn--rsta-fra.no\":true,\"os.hedmark.no\":true,\"os.hordaland.no\":true,\"osen.no\":true,\"osteroy.no\":true,\"xn--ostery-fya.no\":true,\"ostre-toten.no\":true,\"xn--stre-toten-zcb.no\":true,\"overhalla.no\":true,\"ovre-eiker.no\":true,\"xn--vre-eiker-k8a.no\":true,\"oyer.no\":true,\"xn--yer-zna.no\":true,\"oygarden.no\":true,\"xn--ygarden-p1a.no\":true,\"oystre-slidre.no\":true,\"xn--ystre-slidre-ujb.no\":true,\"porsanger.no\":true,\"porsangu.no\":true,\"xn--porsgu-sta26f.no\":true,\"porsgrunn.no\":true,\"radoy.no\":true,\"xn--rady-ira.no\":true,\"rakkestad.no\":true,\"rana.no\":true,\"ruovat.no\":true,\"randaberg.no\":true,\"rauma.no\":true,\"rendalen.no\":true,\"rennebu.no\":true,\"rennesoy.no\":true,\"xn--rennesy-v1a.no\":true,\"rindal.no\":true,\"ringebu.no\":true,\"ringerike.no\":true,\"ringsaker.no\":true,\"rissa.no\":true,\"risor.no\":true,\"xn--risr-ira.no\":true,\"roan.no\":true,\"rollag.no\":true,\"rygge.no\":true,\"ralingen.no\":true,\"xn--rlingen-mxa.no\":true,\"rodoy.no\":true,\"xn--rdy-0nab.no\":true,\"romskog.no\":true,\"xn--rmskog-bya.no\":true,\"roros.no\":true,\"xn--rros-gra.no\":true,\"rost.no\":true,\"xn--rst-0na.no\":true,\"royken.no\":true,\"xn--ryken-vua.no\":true,\"royrvik.no\":true,\"xn--ryrvik-bya.no\":true,\"rade.no\":true,\"xn--rde-ula.no\":true,\"salangen.no\":true,\"siellak.no\":true,\"saltdal.no\":true,\"salat.no\":true,\"xn--slt-elab.no\":true,\"xn--slat-5na.no\":true,\"samnanger.no\":true,\"sande.more-og-romsdal.no\":true,\"sande.xn--mre-og-romsdal-qqb.no\":true,\"sande.vestfold.no\":true,\"sandefjord.no\":true,\"sandnes.no\":true,\"sandoy.no\":true,\"xn--sandy-yua.no\":true,\"sarpsborg.no\":true,\"sauda.no\":true,\"sauherad.no\":true,\"sel.no\":true,\"selbu.no\":true,\"selje.no\":true,\"seljord.no\":true,\"sigdal.no\":true,\"siljan.no\":true,\"sirdal.no\":true,\"skaun.no\":true,\"skedsmo.no\":true,\"ski.no\":true,\"skien.no\":true,\"skiptvet.no\":true,\"skjervoy.no\":true,\"xn--skjervy-v1a.no\":true,\"skierva.no\":true,\"xn--skierv-uta.no\":true,\"skjak.no\":true,\"xn--skjk-soa.no\":true,\"skodje.no\":true,\"skanland.no\":true,\"xn--sknland-fxa.no\":true,\"skanit.no\":true,\"xn--sknit-yqa.no\":true,\"smola.no\":true,\"xn--smla-hra.no\":true,\"snillfjord.no\":true,\"snasa.no\":true,\"xn--snsa-roa.no\":true,\"snoasa.no\":true,\"snaase.no\":true,\"xn--snase-nra.no\":true,\"sogndal.no\":true,\"sokndal.no\":true,\"sola.no\":true,\"solund.no\":true,\"songdalen.no\":true,\"sortland.no\":true,\"spydeberg.no\":true,\"stange.no\":true,\"stavanger.no\":true,\"steigen.no\":true,\"steinkjer.no\":true,\"stjordal.no\":true,\"xn--stjrdal-s1a.no\":true,\"stokke.no\":true,\"stor-elvdal.no\":true,\"stord.no\":true,\"stordal.no\":true,\"storfjord.no\":true,\"omasvuotna.no\":true,\"strand.no\":true,\"stranda.no\":true,\"stryn.no\":true,\"sula.no\":true,\"suldal.no\":true,\"sund.no\":true,\"sunndal.no\":true,\"surnadal.no\":true,\"sveio.no\":true,\"svelvik.no\":true,\"sykkylven.no\":true,\"sogne.no\":true,\"xn--sgne-gra.no\":true,\"somna.no\":true,\"xn--smna-gra.no\":true,\"sondre-land.no\":true,\"xn--sndre-land-0cb.no\":true,\"sor-aurdal.no\":true,\"xn--sr-aurdal-l8a.no\":true,\"sor-fron.no\":true,\"xn--sr-fron-q1a.no\":true,\"sor-odal.no\":true,\"xn--sr-odal-q1a.no\":true,\"sor-varanger.no\":true,\"xn--sr-varanger-ggb.no\":true,\"matta-varjjat.no\":true,\"xn--mtta-vrjjat-k7af.no\":true,\"sorfold.no\":true,\"xn--srfold-bya.no\":true,\"sorreisa.no\":true,\"xn--srreisa-q1a.no\":true,\"sorum.no\":true,\"xn--srum-gra.no\":true,\"tana.no\":true,\"deatnu.no\":true,\"time.no\":true,\"tingvoll.no\":true,\"tinn.no\":true,\"tjeldsund.no\":true,\"dielddanuorri.no\":true,\"tjome.no\":true,\"xn--tjme-hra.no\":true,\"tokke.no\":true,\"tolga.no\":true,\"torsken.no\":true,\"tranoy.no\":true,\"xn--trany-yua.no\":true,\"tromso.no\":true,\"xn--troms-zua.no\":true,\"tromsa.no\":true,\"romsa.no\":true,\"trondheim.no\":true,\"troandin.no\":true,\"trysil.no\":true,\"trana.no\":true,\"xn--trna-woa.no\":true,\"trogstad.no\":true,\"xn--trgstad-r1a.no\":true,\"tvedestrand.no\":true,\"tydal.no\":true,\"tynset.no\":true,\"tysfjord.no\":true,\"divtasvuodna.no\":true,\"divttasvuotna.no\":true,\"tysnes.no\":true,\"tysvar.no\":true,\"xn--tysvr-vra.no\":true,\"tonsberg.no\":true,\"xn--tnsberg-q1a.no\":true,\"ullensaker.no\":true,\"ullensvang.no\":true,\"ulvik.no\":true,\"utsira.no\":true,\"vadso.no\":true,\"xn--vads-jra.no\":true,\"cahcesuolo.no\":true,\"xn--hcesuolo-7ya35b.no\":true,\"vaksdal.no\":true,\"valle.no\":true,\"vang.no\":true,\"vanylven.no\":true,\"vardo.no\":true,\"xn--vard-jra.no\":true,\"varggat.no\":true,\"xn--vrggt-xqad.no\":true,\"vefsn.no\":true,\"vaapste.no\":true,\"vega.no\":true,\"vegarshei.no\":true,\"xn--vegrshei-c0a.no\":true,\"vennesla.no\":true,\"verdal.no\":true,\"verran.no\":true,\"vestby.no\":true,\"vestnes.no\":true,\"vestre-slidre.no\":true,\"vestre-toten.no\":true,\"vestvagoy.no\":true,\"xn--vestvgy-ixa6o.no\":true,\"vevelstad.no\":true,\"vik.no\":true,\"vikna.no\":true,\"vindafjord.no\":true,\"volda.no\":true,\"voss.no\":true,\"varoy.no\":true,\"xn--vry-yla5g.no\":true,\"vagan.no\":true,\"xn--vgan-qoa.no\":true,\"voagat.no\":true,\"vagsoy.no\":true,\"xn--vgsy-qoa0j.no\":true,\"vaga.no\":true,\"xn--vg-yiab.no\":true,\"valer.ostfold.no\":true,\"xn--vler-qoa.xn--stfold-9xa.no\":true,\"valer.hedmark.no\":true,\"xn--vler-qoa.hedmark.no\":true,\"*.np\":true,\"nr\":true,\"biz.nr\":true,\"info.nr\":true,\"gov.nr\":true,\"edu.nr\":true,\"org.nr\":true,\"net.nr\":true,\"com.nr\":true,\"nu\":true,\"nz\":true,\"ac.nz\":true,\"co.nz\":true,\"cri.nz\":true,\"geek.nz\":true,\"gen.nz\":true,\"govt.nz\":true,\"health.nz\":true,\"iwi.nz\":true,\"kiwi.nz\":true,\"maori.nz\":true,\"mil.nz\":true,\"xn--mori-qsa.nz\":true,\"net.nz\":true,\"org.nz\":true,\"parliament.nz\":true,\"school.nz\":true,\"om\":true,\"co.om\":true,\"com.om\":true,\"edu.om\":true,\"gov.om\":true,\"med.om\":true,\"museum.om\":true,\"net.om\":true,\"org.om\":true,\"pro.om\":true,\"org\":true,\"pa\":true,\"ac.pa\":true,\"gob.pa\":true,\"com.pa\":true,\"org.pa\":true,\"sld.pa\":true,\"edu.pa\":true,\"net.pa\":true,\"ing.pa\":true,\"abo.pa\":true,\"med.pa\":true,\"nom.pa\":true,\"pe\":true,\"edu.pe\":true,\"gob.pe\":true,\"nom.pe\":true,\"mil.pe\":true,\"org.pe\":true,\"com.pe\":true,\"net.pe\":true,\"pf\":true,\"com.pf\":true,\"org.pf\":true,\"edu.pf\":true,\"*.pg\":true,\"ph\":true,\"com.ph\":true,\"net.ph\":true,\"org.ph\":true,\"gov.ph\":true,\"edu.ph\":true,\"ngo.ph\":true,\"mil.ph\":true,\"i.ph\":true,\"pk\":true,\"com.pk\":true,\"net.pk\":true,\"edu.pk\":true,\"org.pk\":true,\"fam.pk\":true,\"biz.pk\":true,\"web.pk\":true,\"gov.pk\":true,\"gob.pk\":true,\"gok.pk\":true,\"gon.pk\":true,\"gop.pk\":true,\"gos.pk\":true,\"info.pk\":true,\"pl\":true,\"com.pl\":true,\"net.pl\":true,\"org.pl\":true,\"aid.pl\":true,\"agro.pl\":true,\"atm.pl\":true,\"auto.pl\":true,\"biz.pl\":true,\"edu.pl\":true,\"gmina.pl\":true,\"gsm.pl\":true,\"info.pl\":true,\"mail.pl\":true,\"miasta.pl\":true,\"media.pl\":true,\"mil.pl\":true,\"nieruchomosci.pl\":true,\"nom.pl\":true,\"pc.pl\":true,\"powiat.pl\":true,\"priv.pl\":true,\"realestate.pl\":true,\"rel.pl\":true,\"sex.pl\":true,\"shop.pl\":true,\"sklep.pl\":true,\"sos.pl\":true,\"szkola.pl\":true,\"targi.pl\":true,\"tm.pl\":true,\"tourism.pl\":true,\"travel.pl\":true,\"turystyka.pl\":true,\"gov.pl\":true,\"ap.gov.pl\":true,\"ic.gov.pl\":true,\"is.gov.pl\":true,\"us.gov.pl\":true,\"kmpsp.gov.pl\":true,\"kppsp.gov.pl\":true,\"kwpsp.gov.pl\":true,\"psp.gov.pl\":true,\"wskr.gov.pl\":true,\"kwp.gov.pl\":true,\"mw.gov.pl\":true,\"ug.gov.pl\":true,\"um.gov.pl\":true,\"umig.gov.pl\":true,\"ugim.gov.pl\":true,\"upow.gov.pl\":true,\"uw.gov.pl\":true,\"starostwo.gov.pl\":true,\"pa.gov.pl\":true,\"po.gov.pl\":true,\"psse.gov.pl\":true,\"pup.gov.pl\":true,\"rzgw.gov.pl\":true,\"sa.gov.pl\":true,\"so.gov.pl\":true,\"sr.gov.pl\":true,\"wsa.gov.pl\":true,\"sko.gov.pl\":true,\"uzs.gov.pl\":true,\"wiih.gov.pl\":true,\"winb.gov.pl\":true,\"pinb.gov.pl\":true,\"wios.gov.pl\":true,\"witd.gov.pl\":true,\"wzmiuw.gov.pl\":true,\"piw.gov.pl\":true,\"wiw.gov.pl\":true,\"griw.gov.pl\":true,\"wif.gov.pl\":true,\"oum.gov.pl\":true,\"sdn.gov.pl\":true,\"zp.gov.pl\":true,\"uppo.gov.pl\":true,\"mup.gov.pl\":true,\"wuoz.gov.pl\":true,\"konsulat.gov.pl\":true,\"oirm.gov.pl\":true,\"augustow.pl\":true,\"babia-gora.pl\":true,\"bedzin.pl\":true,\"beskidy.pl\":true,\"bialowieza.pl\":true,\"bialystok.pl\":true,\"bielawa.pl\":true,\"bieszczady.pl\":true,\"boleslawiec.pl\":true,\"bydgoszcz.pl\":true,\"bytom.pl\":true,\"cieszyn.pl\":true,\"czeladz.pl\":true,\"czest.pl\":true,\"dlugoleka.pl\":true,\"elblag.pl\":true,\"elk.pl\":true,\"glogow.pl\":true,\"gniezno.pl\":true,\"gorlice.pl\":true,\"grajewo.pl\":true,\"ilawa.pl\":true,\"jaworzno.pl\":true,\"jelenia-gora.pl\":true,\"jgora.pl\":true,\"kalisz.pl\":true,\"kazimierz-dolny.pl\":true,\"karpacz.pl\":true,\"kartuzy.pl\":true,\"kaszuby.pl\":true,\"katowice.pl\":true,\"kepno.pl\":true,\"ketrzyn.pl\":true,\"klodzko.pl\":true,\"kobierzyce.pl\":true,\"kolobrzeg.pl\":true,\"konin.pl\":true,\"konskowola.pl\":true,\"kutno.pl\":true,\"lapy.pl\":true,\"lebork.pl\":true,\"legnica.pl\":true,\"lezajsk.pl\":true,\"limanowa.pl\":true,\"lomza.pl\":true,\"lowicz.pl\":true,\"lubin.pl\":true,\"lukow.pl\":true,\"malbork.pl\":true,\"malopolska.pl\":true,\"mazowsze.pl\":true,\"mazury.pl\":true,\"mielec.pl\":true,\"mielno.pl\":true,\"mragowo.pl\":true,\"naklo.pl\":true,\"nowaruda.pl\":true,\"nysa.pl\":true,\"olawa.pl\":true,\"olecko.pl\":true,\"olkusz.pl\":true,\"olsztyn.pl\":true,\"opoczno.pl\":true,\"opole.pl\":true,\"ostroda.pl\":true,\"ostroleka.pl\":true,\"ostrowiec.pl\":true,\"ostrowwlkp.pl\":true,\"pila.pl\":true,\"pisz.pl\":true,\"podhale.pl\":true,\"podlasie.pl\":true,\"polkowice.pl\":true,\"pomorze.pl\":true,\"pomorskie.pl\":true,\"prochowice.pl\":true,\"pruszkow.pl\":true,\"przeworsk.pl\":true,\"pulawy.pl\":true,\"radom.pl\":true,\"rawa-maz.pl\":true,\"rybnik.pl\":true,\"rzeszow.pl\":true,\"sanok.pl\":true,\"sejny.pl\":true,\"slask.pl\":true,\"slupsk.pl\":true,\"sosnowiec.pl\":true,\"stalowa-wola.pl\":true,\"skoczow.pl\":true,\"starachowice.pl\":true,\"stargard.pl\":true,\"suwalki.pl\":true,\"swidnica.pl\":true,\"swiebodzin.pl\":true,\"swinoujscie.pl\":true,\"szczecin.pl\":true,\"szczytno.pl\":true,\"tarnobrzeg.pl\":true,\"tgory.pl\":true,\"turek.pl\":true,\"tychy.pl\":true,\"ustka.pl\":true,\"walbrzych.pl\":true,\"warmia.pl\":true,\"warszawa.pl\":true,\"waw.pl\":true,\"wegrow.pl\":true,\"wielun.pl\":true,\"wlocl.pl\":true,\"wloclawek.pl\":true,\"wodzislaw.pl\":true,\"wolomin.pl\":true,\"wroclaw.pl\":true,\"zachpomor.pl\":true,\"zagan.pl\":true,\"zarow.pl\":true,\"zgora.pl\":true,\"zgorzelec.pl\":true,\"pm\":true,\"pn\":true,\"gov.pn\":true,\"co.pn\":true,\"org.pn\":true,\"edu.pn\":true,\"net.pn\":true,\"post\":true,\"pr\":true,\"com.pr\":true,\"net.pr\":true,\"org.pr\":true,\"gov.pr\":true,\"edu.pr\":true,\"isla.pr\":true,\"pro.pr\":true,\"biz.pr\":true,\"info.pr\":true,\"name.pr\":true,\"est.pr\":true,\"prof.pr\":true,\"ac.pr\":true,\"pro\":true,\"aca.pro\":true,\"bar.pro\":true,\"cpa.pro\":true,\"jur.pro\":true,\"law.pro\":true,\"med.pro\":true,\"eng.pro\":true,\"ps\":true,\"edu.ps\":true,\"gov.ps\":true,\"sec.ps\":true,\"plo.ps\":true,\"com.ps\":true,\"org.ps\":true,\"net.ps\":true,\"pt\":true,\"net.pt\":true,\"gov.pt\":true,\"org.pt\":true,\"edu.pt\":true,\"int.pt\":true,\"publ.pt\":true,\"com.pt\":true,\"nome.pt\":true,\"pw\":true,\"co.pw\":true,\"ne.pw\":true,\"or.pw\":true,\"ed.pw\":true,\"go.pw\":true,\"belau.pw\":true,\"py\":true,\"com.py\":true,\"coop.py\":true,\"edu.py\":true,\"gov.py\":true,\"mil.py\":true,\"net.py\":true,\"org.py\":true,\"qa\":true,\"com.qa\":true,\"edu.qa\":true,\"gov.qa\":true,\"mil.qa\":true,\"name.qa\":true,\"net.qa\":true,\"org.qa\":true,\"sch.qa\":true,\"re\":true,\"com.re\":true,\"asso.re\":true,\"nom.re\":true,\"ro\":true,\"com.ro\":true,\"org.ro\":true,\"tm.ro\":true,\"nt.ro\":true,\"nom.ro\":true,\"info.ro\":true,\"rec.ro\":true,\"arts.ro\":true,\"firm.ro\":true,\"store.ro\":true,\"www.ro\":true,\"rs\":true,\"co.rs\":true,\"org.rs\":true,\"edu.rs\":true,\"ac.rs\":true,\"gov.rs\":true,\"in.rs\":true,\"ru\":true,\"ac.ru\":true,\"com.ru\":true,\"edu.ru\":true,\"int.ru\":true,\"net.ru\":true,\"org.ru\":true,\"pp.ru\":true,\"adygeya.ru\":true,\"altai.ru\":true,\"amur.ru\":true,\"arkhangelsk.ru\":true,\"astrakhan.ru\":true,\"bashkiria.ru\":true,\"belgorod.ru\":true,\"bir.ru\":true,\"bryansk.ru\":true,\"buryatia.ru\":true,\"cbg.ru\":true,\"chel.ru\":true,\"chelyabinsk.ru\":true,\"chita.ru\":true,\"chukotka.ru\":true,\"chuvashia.ru\":true,\"dagestan.ru\":true,\"dudinka.ru\":true,\"e-burg.ru\":true,\"grozny.ru\":true,\"irkutsk.ru\":true,\"ivanovo.ru\":true,\"izhevsk.ru\":true,\"jar.ru\":true,\"joshkar-ola.ru\":true,\"kalmykia.ru\":true,\"kaluga.ru\":true,\"kamchatka.ru\":true,\"karelia.ru\":true,\"kazan.ru\":true,\"kchr.ru\":true,\"kemerovo.ru\":true,\"khabarovsk.ru\":true,\"khakassia.ru\":true,\"khv.ru\":true,\"kirov.ru\":true,\"koenig.ru\":true,\"komi.ru\":true,\"kostroma.ru\":true,\"krasnoyarsk.ru\":true,\"kuban.ru\":true,\"kurgan.ru\":true,\"kursk.ru\":true,\"lipetsk.ru\":true,\"magadan.ru\":true,\"mari.ru\":true,\"mari-el.ru\":true,\"marine.ru\":true,\"mordovia.ru\":true,\"msk.ru\":true,\"murmansk.ru\":true,\"nalchik.ru\":true,\"nnov.ru\":true,\"nov.ru\":true,\"novosibirsk.ru\":true,\"nsk.ru\":true,\"omsk.ru\":true,\"orenburg.ru\":true,\"oryol.ru\":true,\"palana.ru\":true,\"penza.ru\":true,\"perm.ru\":true,\"ptz.ru\":true,\"rnd.ru\":true,\"ryazan.ru\":true,\"sakhalin.ru\":true,\"samara.ru\":true,\"saratov.ru\":true,\"simbirsk.ru\":true,\"smolensk.ru\":true,\"spb.ru\":true,\"stavropol.ru\":true,\"stv.ru\":true,\"surgut.ru\":true,\"tambov.ru\":true,\"tatarstan.ru\":true,\"tom.ru\":true,\"tomsk.ru\":true,\"tsaritsyn.ru\":true,\"tsk.ru\":true,\"tula.ru\":true,\"tuva.ru\":true,\"tver.ru\":true,\"tyumen.ru\":true,\"udm.ru\":true,\"udmurtia.ru\":true,\"ulan-ude.ru\":true,\"vladikavkaz.ru\":true,\"vladimir.ru\":true,\"vladivostok.ru\":true,\"volgograd.ru\":true,\"vologda.ru\":true,\"voronezh.ru\":true,\"vrn.ru\":true,\"vyatka.ru\":true,\"yakutia.ru\":true,\"yamal.ru\":true,\"yaroslavl.ru\":true,\"yekaterinburg.ru\":true,\"yuzhno-sakhalinsk.ru\":true,\"amursk.ru\":true,\"baikal.ru\":true,\"cmw.ru\":true,\"fareast.ru\":true,\"jamal.ru\":true,\"kms.ru\":true,\"k-uralsk.ru\":true,\"kustanai.ru\":true,\"kuzbass.ru\":true,\"magnitka.ru\":true,\"mytis.ru\":true,\"nakhodka.ru\":true,\"nkz.ru\":true,\"norilsk.ru\":true,\"oskol.ru\":true,\"pyatigorsk.ru\":true,\"rubtsovsk.ru\":true,\"snz.ru\":true,\"syzran.ru\":true,\"vdonsk.ru\":true,\"zgrad.ru\":true,\"gov.ru\":true,\"mil.ru\":true,\"test.ru\":true,\"rw\":true,\"gov.rw\":true,\"net.rw\":true,\"edu.rw\":true,\"ac.rw\":true,\"com.rw\":true,\"co.rw\":true,\"int.rw\":true,\"mil.rw\":true,\"gouv.rw\":true,\"sa\":true,\"com.sa\":true,\"net.sa\":true,\"org.sa\":true,\"gov.sa\":true,\"med.sa\":true,\"pub.sa\":true,\"edu.sa\":true,\"sch.sa\":true,\"sb\":true,\"com.sb\":true,\"edu.sb\":true,\"gov.sb\":true,\"net.sb\":true,\"org.sb\":true,\"sc\":true,\"com.sc\":true,\"gov.sc\":true,\"net.sc\":true,\"org.sc\":true,\"edu.sc\":true,\"sd\":true,\"com.sd\":true,\"net.sd\":true,\"org.sd\":true,\"edu.sd\":true,\"med.sd\":true,\"tv.sd\":true,\"gov.sd\":true,\"info.sd\":true,\"se\":true,\"a.se\":true,\"ac.se\":true,\"b.se\":true,\"bd.se\":true,\"brand.se\":true,\"c.se\":true,\"d.se\":true,\"e.se\":true,\"f.se\":true,\"fh.se\":true,\"fhsk.se\":true,\"fhv.se\":true,\"g.se\":true,\"h.se\":true,\"i.se\":true,\"k.se\":true,\"komforb.se\":true,\"kommunalforbund.se\":true,\"komvux.se\":true,\"l.se\":true,\"lanbib.se\":true,\"m.se\":true,\"n.se\":true,\"naturbruksgymn.se\":true,\"o.se\":true,\"org.se\":true,\"p.se\":true,\"parti.se\":true,\"pp.se\":true,\"press.se\":true,\"r.se\":true,\"s.se\":true,\"t.se\":true,\"tm.se\":true,\"u.se\":true,\"w.se\":true,\"x.se\":true,\"y.se\":true,\"z.se\":true,\"sg\":true,\"com.sg\":true,\"net.sg\":true,\"org.sg\":true,\"gov.sg\":true,\"edu.sg\":true,\"per.sg\":true,\"sh\":true,\"com.sh\":true,\"net.sh\":true,\"gov.sh\":true,\"org.sh\":true,\"mil.sh\":true,\"si\":true,\"sj\":true,\"sk\":true,\"sl\":true,\"com.sl\":true,\"net.sl\":true,\"edu.sl\":true,\"gov.sl\":true,\"org.sl\":true,\"sm\":true,\"sn\":true,\"art.sn\":true,\"com.sn\":true,\"edu.sn\":true,\"gouv.sn\":true,\"org.sn\":true,\"perso.sn\":true,\"univ.sn\":true,\"so\":true,\"com.so\":true,\"net.so\":true,\"org.so\":true,\"sr\":true,\"st\":true,\"co.st\":true,\"com.st\":true,\"consulado.st\":true,\"edu.st\":true,\"embaixada.st\":true,\"gov.st\":true,\"mil.st\":true,\"net.st\":true,\"org.st\":true,\"principe.st\":true,\"saotome.st\":true,\"store.st\":true,\"su\":true,\"adygeya.su\":true,\"arkhangelsk.su\":true,\"balashov.su\":true,\"bashkiria.su\":true,\"bryansk.su\":true,\"dagestan.su\":true,\"grozny.su\":true,\"ivanovo.su\":true,\"kalmykia.su\":true,\"kaluga.su\":true,\"karelia.su\":true,\"khakassia.su\":true,\"krasnodar.su\":true,\"kurgan.su\":true,\"lenug.su\":true,\"mordovia.su\":true,\"msk.su\":true,\"murmansk.su\":true,\"nalchik.su\":true,\"nov.su\":true,\"obninsk.su\":true,\"penza.su\":true,\"pokrovsk.su\":true,\"sochi.su\":true,\"spb.su\":true,\"togliatti.su\":true,\"troitsk.su\":true,\"tula.su\":true,\"tuva.su\":true,\"vladikavkaz.su\":true,\"vladimir.su\":true,\"vologda.su\":true,\"sv\":true,\"com.sv\":true,\"edu.sv\":true,\"gob.sv\":true,\"org.sv\":true,\"red.sv\":true,\"sx\":true,\"gov.sx\":true,\"sy\":true,\"edu.sy\":true,\"gov.sy\":true,\"net.sy\":true,\"mil.sy\":true,\"com.sy\":true,\"org.sy\":true,\"sz\":true,\"co.sz\":true,\"ac.sz\":true,\"org.sz\":true,\"tc\":true,\"td\":true,\"tel\":true,\"tf\":true,\"tg\":true,\"th\":true,\"ac.th\":true,\"co.th\":true,\"go.th\":true,\"in.th\":true,\"mi.th\":true,\"net.th\":true,\"or.th\":true,\"tj\":true,\"ac.tj\":true,\"biz.tj\":true,\"co.tj\":true,\"com.tj\":true,\"edu.tj\":true,\"go.tj\":true,\"gov.tj\":true,\"int.tj\":true,\"mil.tj\":true,\"name.tj\":true,\"net.tj\":true,\"nic.tj\":true,\"org.tj\":true,\"test.tj\":true,\"web.tj\":true,\"tk\":true,\"tl\":true,\"gov.tl\":true,\"tm\":true,\"com.tm\":true,\"co.tm\":true,\"org.tm\":true,\"net.tm\":true,\"nom.tm\":true,\"gov.tm\":true,\"mil.tm\":true,\"edu.tm\":true,\"tn\":true,\"com.tn\":true,\"ens.tn\":true,\"fin.tn\":true,\"gov.tn\":true,\"ind.tn\":true,\"intl.tn\":true,\"nat.tn\":true,\"net.tn\":true,\"org.tn\":true,\"info.tn\":true,\"perso.tn\":true,\"tourism.tn\":true,\"edunet.tn\":true,\"rnrt.tn\":true,\"rns.tn\":true,\"rnu.tn\":true,\"mincom.tn\":true,\"agrinet.tn\":true,\"defense.tn\":true,\"turen.tn\":true,\"to\":true,\"com.to\":true,\"gov.to\":true,\"net.to\":true,\"org.to\":true,\"edu.to\":true,\"mil.to\":true,\"tp\":true,\"tr\":true,\"com.tr\":true,\"info.tr\":true,\"biz.tr\":true,\"net.tr\":true,\"org.tr\":true,\"web.tr\":true,\"gen.tr\":true,\"tv.tr\":true,\"av.tr\":true,\"dr.tr\":true,\"bbs.tr\":true,\"name.tr\":true,\"tel.tr\":true,\"gov.tr\":true,\"bel.tr\":true,\"pol.tr\":true,\"mil.tr\":true,\"k12.tr\":true,\"edu.tr\":true,\"kep.tr\":true,\"nc.tr\":true,\"gov.nc.tr\":true,\"travel\":true,\"tt\":true,\"co.tt\":true,\"com.tt\":true,\"org.tt\":true,\"net.tt\":true,\"biz.tt\":true,\"info.tt\":true,\"pro.tt\":true,\"int.tt\":true,\"coop.tt\":true,\"jobs.tt\":true,\"mobi.tt\":true,\"travel.tt\":true,\"museum.tt\":true,\"aero.tt\":true,\"name.tt\":true,\"gov.tt\":true,\"edu.tt\":true,\"tv\":true,\"tw\":true,\"edu.tw\":true,\"gov.tw\":true,\"mil.tw\":true,\"com.tw\":true,\"net.tw\":true,\"org.tw\":true,\"idv.tw\":true,\"game.tw\":true,\"ebiz.tw\":true,\"club.tw\":true,\"xn--zf0ao64a.tw\":true,\"xn--uc0atv.tw\":true,\"xn--czrw28b.tw\":true,\"tz\":true,\"ac.tz\":true,\"co.tz\":true,\"go.tz\":true,\"hotel.tz\":true,\"info.tz\":true,\"me.tz\":true,\"mil.tz\":true,\"mobi.tz\":true,\"ne.tz\":true,\"or.tz\":true,\"sc.tz\":true,\"tv.tz\":true,\"ua\":true,\"com.ua\":true,\"edu.ua\":true,\"gov.ua\":true,\"in.ua\":true,\"net.ua\":true,\"org.ua\":true,\"cherkassy.ua\":true,\"cherkasy.ua\":true,\"chernigov.ua\":true,\"chernihiv.ua\":true,\"chernivtsi.ua\":true,\"chernovtsy.ua\":true,\"ck.ua\":true,\"cn.ua\":true,\"cr.ua\":true,\"crimea.ua\":true,\"cv.ua\":true,\"dn.ua\":true,\"dnepropetrovsk.ua\":true,\"dnipropetrovsk.ua\":true,\"dominic.ua\":true,\"donetsk.ua\":true,\"dp.ua\":true,\"if.ua\":true,\"ivano-frankivsk.ua\":true,\"kh.ua\":true,\"kharkiv.ua\":true,\"kharkov.ua\":true,\"kherson.ua\":true,\"khmelnitskiy.ua\":true,\"khmelnytskyi.ua\":true,\"kiev.ua\":true,\"kirovograd.ua\":true,\"km.ua\":true,\"kr.ua\":true,\"krym.ua\":true,\"ks.ua\":true,\"kv.ua\":true,\"kyiv.ua\":true,\"lg.ua\":true,\"lt.ua\":true,\"lugansk.ua\":true,\"lutsk.ua\":true,\"lv.ua\":true,\"lviv.ua\":true,\"mk.ua\":true,\"mykolaiv.ua\":true,\"nikolaev.ua\":true,\"od.ua\":true,\"odesa.ua\":true,\"odessa.ua\":true,\"pl.ua\":true,\"poltava.ua\":true,\"rivne.ua\":true,\"rovno.ua\":true,\"rv.ua\":true,\"sb.ua\":true,\"sebastopol.ua\":true,\"sevastopol.ua\":true,\"sm.ua\":true,\"sumy.ua\":true,\"te.ua\":true,\"ternopil.ua\":true,\"uz.ua\":true,\"uzhgorod.ua\":true,\"vinnica.ua\":true,\"vinnytsia.ua\":true,\"vn.ua\":true,\"volyn.ua\":true,\"yalta.ua\":true,\"zaporizhzhe.ua\":true,\"zaporizhzhia.ua\":true,\"zhitomir.ua\":true,\"zhytomyr.ua\":true,\"zp.ua\":true,\"zt.ua\":true,\"ug\":true,\"co.ug\":true,\"or.ug\":true,\"ac.ug\":true,\"sc.ug\":true,\"go.ug\":true,\"ne.ug\":true,\"com.ug\":true,\"org.ug\":true,\"uk\":true,\"ac.uk\":true,\"co.uk\":true,\"gov.uk\":true,\"ltd.uk\":true,\"me.uk\":true,\"net.uk\":true,\"nhs.uk\":true,\"org.uk\":true,\"plc.uk\":true,\"police.uk\":true,\"*.sch.uk\":true,\"us\":true,\"dni.us\":true,\"fed.us\":true,\"isa.us\":true,\"kids.us\":true,\"nsn.us\":true,\"ak.us\":true,\"al.us\":true,\"ar.us\":true,\"as.us\":true,\"az.us\":true,\"ca.us\":true,\"co.us\":true,\"ct.us\":true,\"dc.us\":true,\"de.us\":true,\"fl.us\":true,\"ga.us\":true,\"gu.us\":true,\"hi.us\":true,\"ia.us\":true,\"id.us\":true,\"il.us\":true,\"in.us\":true,\"ks.us\":true,\"ky.us\":true,\"la.us\":true,\"ma.us\":true,\"md.us\":true,\"me.us\":true,\"mi.us\":true,\"mn.us\":true,\"mo.us\":true,\"ms.us\":true,\"mt.us\":true,\"nc.us\":true,\"nd.us\":true,\"ne.us\":true,\"nh.us\":true,\"nj.us\":true,\"nm.us\":true,\"nv.us\":true,\"ny.us\":true,\"oh.us\":true,\"ok.us\":true,\"or.us\":true,\"pa.us\":true,\"pr.us\":true,\"ri.us\":true,\"sc.us\":true,\"sd.us\":true,\"tn.us\":true,\"tx.us\":true,\"ut.us\":true,\"vi.us\":true,\"vt.us\":true,\"va.us\":true,\"wa.us\":true,\"wi.us\":true,\"wv.us\":true,\"wy.us\":true,\"k12.ak.us\":true,\"k12.al.us\":true,\"k12.ar.us\":true,\"k12.as.us\":true,\"k12.az.us\":true,\"k12.ca.us\":true,\"k12.co.us\":true,\"k12.ct.us\":true,\"k12.dc.us\":true,\"k12.de.us\":true,\"k12.fl.us\":true,\"k12.ga.us\":true,\"k12.gu.us\":true,\"k12.ia.us\":true,\"k12.id.us\":true,\"k12.il.us\":true,\"k12.in.us\":true,\"k12.ks.us\":true,\"k12.ky.us\":true,\"k12.la.us\":true,\"k12.ma.us\":true,\"k12.md.us\":true,\"k12.me.us\":true,\"k12.mi.us\":true,\"k12.mn.us\":true,\"k12.mo.us\":true,\"k12.ms.us\":true,\"k12.mt.us\":true,\"k12.nc.us\":true,\"k12.ne.us\":true,\"k12.nh.us\":true,\"k12.nj.us\":true,\"k12.nm.us\":true,\"k12.nv.us\":true,\"k12.ny.us\":true,\"k12.oh.us\":true,\"k12.ok.us\":true,\"k12.or.us\":true,\"k12.pa.us\":true,\"k12.pr.us\":true,\"k12.ri.us\":true,\"k12.sc.us\":true,\"k12.tn.us\":true,\"k12.tx.us\":true,\"k12.ut.us\":true,\"k12.vi.us\":true,\"k12.vt.us\":true,\"k12.va.us\":true,\"k12.wa.us\":true,\"k12.wi.us\":true,\"k12.wy.us\":true,\"cc.ak.us\":true,\"cc.al.us\":true,\"cc.ar.us\":true,\"cc.as.us\":true,\"cc.az.us\":true,\"cc.ca.us\":true,\"cc.co.us\":true,\"cc.ct.us\":true,\"cc.dc.us\":true,\"cc.de.us\":true,\"cc.fl.us\":true,\"cc.ga.us\":true,\"cc.gu.us\":true,\"cc.hi.us\":true,\"cc.ia.us\":true,\"cc.id.us\":true,\"cc.il.us\":true,\"cc.in.us\":true,\"cc.ks.us\":true,\"cc.ky.us\":true,\"cc.la.us\":true,\"cc.ma.us\":true,\"cc.md.us\":true,\"cc.me.us\":true,\"cc.mi.us\":true,\"cc.mn.us\":true,\"cc.mo.us\":true,\"cc.ms.us\":true,\"cc.mt.us\":true,\"cc.nc.us\":true,\"cc.nd.us\":true,\"cc.ne.us\":true,\"cc.nh.us\":true,\"cc.nj.us\":true,\"cc.nm.us\":true,\"cc.nv.us\":true,\"cc.ny.us\":true,\"cc.oh.us\":true,\"cc.ok.us\":true,\"cc.or.us\":true,\"cc.pa.us\":true,\"cc.pr.us\":true,\"cc.ri.us\":true,\"cc.sc.us\":true,\"cc.sd.us\":true,\"cc.tn.us\":true,\"cc.tx.us\":true,\"cc.ut.us\":true,\"cc.vi.us\":true,\"cc.vt.us\":true,\"cc.va.us\":true,\"cc.wa.us\":true,\"cc.wi.us\":true,\"cc.wv.us\":true,\"cc.wy.us\":true,\"lib.ak.us\":true,\"lib.al.us\":true,\"lib.ar.us\":true,\"lib.as.us\":true,\"lib.az.us\":true,\"lib.ca.us\":true,\"lib.co.us\":true,\"lib.ct.us\":true,\"lib.dc.us\":true,\"lib.de.us\":true,\"lib.fl.us\":true,\"lib.ga.us\":true,\"lib.gu.us\":true,\"lib.hi.us\":true,\"lib.ia.us\":true,\"lib.id.us\":true,\"lib.il.us\":true,\"lib.in.us\":true,\"lib.ks.us\":true,\"lib.ky.us\":true,\"lib.la.us\":true,\"lib.ma.us\":true,\"lib.md.us\":true,\"lib.me.us\":true,\"lib.mi.us\":true,\"lib.mn.us\":true,\"lib.mo.us\":true,\"lib.ms.us\":true,\"lib.mt.us\":true,\"lib.nc.us\":true,\"lib.nd.us\":true,\"lib.ne.us\":true,\"lib.nh.us\":true,\"lib.nj.us\":true,\"lib.nm.us\":true,\"lib.nv.us\":true,\"lib.ny.us\":true,\"lib.oh.us\":true,\"lib.ok.us\":true,\"lib.or.us\":true,\"lib.pa.us\":true,\"lib.pr.us\":true,\"lib.ri.us\":true,\"lib.sc.us\":true,\"lib.sd.us\":true,\"lib.tn.us\":true,\"lib.tx.us\":true,\"lib.ut.us\":true,\"lib.vi.us\":true,\"lib.vt.us\":true,\"lib.va.us\":true,\"lib.wa.us\":true,\"lib.wi.us\":true,\"lib.wy.us\":true,\"pvt.k12.ma.us\":true,\"chtr.k12.ma.us\":true,\"paroch.k12.ma.us\":true,\"uy\":true,\"com.uy\":true,\"edu.uy\":true,\"gub.uy\":true,\"mil.uy\":true,\"net.uy\":true,\"org.uy\":true,\"uz\":true,\"co.uz\":true,\"com.uz\":true,\"net.uz\":true,\"org.uz\":true,\"va\":true,\"vc\":true,\"com.vc\":true,\"net.vc\":true,\"org.vc\":true,\"gov.vc\":true,\"mil.vc\":true,\"edu.vc\":true,\"ve\":true,\"arts.ve\":true,\"co.ve\":true,\"com.ve\":true,\"e12.ve\":true,\"edu.ve\":true,\"firm.ve\":true,\"gob.ve\":true,\"gov.ve\":true,\"info.ve\":true,\"int.ve\":true,\"mil.ve\":true,\"net.ve\":true,\"org.ve\":true,\"rec.ve\":true,\"store.ve\":true,\"tec.ve\":true,\"web.ve\":true,\"vg\":true,\"vi\":true,\"co.vi\":true,\"com.vi\":true,\"k12.vi\":true,\"net.vi\":true,\"org.vi\":true,\"vn\":true,\"com.vn\":true,\"net.vn\":true,\"org.vn\":true,\"edu.vn\":true,\"gov.vn\":true,\"int.vn\":true,\"ac.vn\":true,\"biz.vn\":true,\"info.vn\":true,\"name.vn\":true,\"pro.vn\":true,\"health.vn\":true,\"vu\":true,\"com.vu\":true,\"edu.vu\":true,\"net.vu\":true,\"org.vu\":true,\"wf\":true,\"ws\":true,\"com.ws\":true,\"net.ws\":true,\"org.ws\":true,\"gov.ws\":true,\"edu.ws\":true,\"yt\":true,\"xn--mgbaam7a8h\":true,\"xn--y9a3aq\":true,\"xn--54b7fta0cc\":true,\"xn--90ais\":true,\"xn--fiqs8s\":true,\"xn--fiqz9s\":true,\"xn--lgbbat1ad8j\":true,\"xn--wgbh1c\":true,\"xn--node\":true,\"xn--qxam\":true,\"xn--j6w193g\":true,\"xn--h2brj9c\":true,\"xn--mgbbh1a71e\":true,\"xn--fpcrj9c3d\":true,\"xn--gecrj9c\":true,\"xn--s9brj9c\":true,\"xn--45brj9c\":true,\"xn--xkc2dl3a5ee0h\":true,\"xn--mgba3a4f16a\":true,\"xn--mgba3a4fra\":true,\"xn--mgbtx2b\":true,\"xn--mgbayh7gpa\":true,\"xn--3e0b707e\":true,\"xn--80ao21a\":true,\"xn--fzc2c9e2c\":true,\"xn--xkc2al3hye2a\":true,\"xn--mgbc0a9azcg\":true,\"xn--d1alf\":true,\"xn--l1acc\":true,\"xn--mix891f\":true,\"xn--mix082f\":true,\"xn--mgbx4cd0ab\":true,\"xn--mgb9awbf\":true,\"xn--mgbai9azgqp6j\":true,\"xn--mgbai9a5eva00b\":true,\"xn--ygbi2ammx\":true,\"xn--90a3ac\":true,\"xn--o1ac.xn--90a3ac\":true,\"xn--c1avg.xn--90a3ac\":true,\"xn--90azh.xn--90a3ac\":true,\"xn--d1at.xn--90a3ac\":true,\"xn--o1ach.xn--90a3ac\":true,\"xn--80au.xn--90a3ac\":true,\"xn--p1ai\":true,\"xn--wgbl6a\":true,\"xn--mgberp4a5d4ar\":true,\"xn--mgberp4a5d4a87g\":true,\"xn--mgbqly7c0a67fbc\":true,\"xn--mgbqly7cvafr\":true,\"xn--mgbpl2fh\":true,\"xn--yfro4i67o\":true,\"xn--clchc0ea0b2g2a9gcd\":true,\"xn--ogbpf8fl\":true,\"xn--mgbtf8fl\":true,\"xn--o3cw4h\":true,\"xn--pgbs0dh\":true,\"xn--kpry57d\":true,\"xn--kprw13d\":true,\"xn--nnx388a\":true,\"xn--j1amh\":true,\"xn--mgb2ddes\":true,\"xxx\":true,\"*.ye\":true,\"ac.za\":true,\"agrica.za\":true,\"alt.za\":true,\"co.za\":true,\"edu.za\":true,\"gov.za\":true,\"grondar.za\":true,\"law.za\":true,\"mil.za\":true,\"net.za\":true,\"ngo.za\":true,\"nis.za\":true,\"nom.za\":true,\"org.za\":true,\"school.za\":true,\"tm.za\":true,\"web.za\":true,\"*.zm\":true,\"*.zw\":true,\"aaa\":true,\"aarp\":true,\"abarth\":true,\"abb\":true,\"abbott\":true,\"abbvie\":true,\"abc\":true,\"able\":true,\"abogado\":true,\"abudhabi\":true,\"academy\":true,\"accenture\":true,\"accountant\":true,\"accountants\":true,\"aco\":true,\"active\":true,\"actor\":true,\"adac\":true,\"ads\":true,\"adult\":true,\"aeg\":true,\"aetna\":true,\"afamilycompany\":true,\"afl\":true,\"africa\":true,\"africamagic\":true,\"agakhan\":true,\"agency\":true,\"aig\":true,\"aigo\":true,\"airbus\":true,\"airforce\":true,\"airtel\":true,\"akdn\":true,\"alfaromeo\":true,\"alibaba\":true,\"alipay\":true,\"allfinanz\":true,\"allstate\":true,\"ally\":true,\"alsace\":true,\"alstom\":true,\"americanexpress\":true,\"americanfamily\":true,\"amex\":true,\"amfam\":true,\"amica\":true,\"amsterdam\":true,\"analytics\":true,\"android\":true,\"anquan\":true,\"anz\":true,\"aol\":true,\"apartments\":true,\"app\":true,\"apple\":true,\"aquarelle\":true,\"aramco\":true,\"archi\":true,\"army\":true,\"arte\":true,\"asda\":true,\"associates\":true,\"athleta\":true,\"attorney\":true,\"auction\":true,\"audi\":true,\"audible\":true,\"audio\":true,\"auspost\":true,\"author\":true,\"auto\":true,\"autos\":true,\"avianca\":true,\"aws\":true,\"axa\":true,\"azure\":true,\"baby\":true,\"baidu\":true,\"banamex\":true,\"bananarepublic\":true,\"band\":true,\"bank\":true,\"bar\":true,\"barcelona\":true,\"barclaycard\":true,\"barclays\":true,\"barefoot\":true,\"bargains\":true,\"basketball\":true,\"bauhaus\":true,\"bayern\":true,\"bbc\":true,\"bbt\":true,\"bbva\":true,\"bcg\":true,\"bcn\":true,\"beats\":true,\"beer\":true,\"bentley\":true,\"berlin\":true,\"best\":true,\"bestbuy\":true,\"bet\":true,\"bharti\":true,\"bible\":true,\"bid\":true,\"bike\":true,\"bing\":true,\"bingo\":true,\"bio\":true,\"black\":true,\"blackfriday\":true,\"blanco\":true,\"blockbuster\":true,\"blog\":true,\"bloomberg\":true,\"blue\":true,\"bms\":true,\"bmw\":true,\"bnl\":true,\"bnpparibas\":true,\"boats\":true,\"boehringer\":true,\"bofa\":true,\"bom\":true,\"bond\":true,\"boo\":true,\"book\":true,\"booking\":true,\"boots\":true,\"bosch\":true,\"bostik\":true,\"bot\":true,\"boutique\":true,\"bradesco\":true,\"bridgestone\":true,\"broadway\":true,\"broker\":true,\"brother\":true,\"brussels\":true,\"budapest\":true,\"bugatti\":true,\"build\":true,\"builders\":true,\"business\":true,\"buy\":true,\"buzz\":true,\"bzh\":true,\"cab\":true,\"cafe\":true,\"cal\":true,\"call\":true,\"calvinklein\":true,\"camera\":true,\"camp\":true,\"cancerresearch\":true,\"canon\":true,\"capetown\":true,\"capital\":true,\"capitalone\":true,\"car\":true,\"caravan\":true,\"cards\":true,\"care\":true,\"career\":true,\"careers\":true,\"cars\":true,\"cartier\":true,\"casa\":true,\"case\":true,\"caseih\":true,\"cash\":true,\"casino\":true,\"catering\":true,\"cba\":true,\"cbn\":true,\"cbre\":true,\"cbs\":true,\"ceb\":true,\"center\":true,\"ceo\":true,\"cern\":true,\"cfa\":true,\"cfd\":true,\"chanel\":true,\"channel\":true,\"chase\":true,\"chat\":true,\"cheap\":true,\"chintai\":true,\"chloe\":true,\"christmas\":true,\"chrome\":true,\"chrysler\":true,\"church\":true,\"cipriani\":true,\"circle\":true,\"cisco\":true,\"citadel\":true,\"citi\":true,\"citic\":true,\"city\":true,\"cityeats\":true,\"claims\":true,\"cleaning\":true,\"click\":true,\"clinic\":true,\"clothing\":true,\"cloud\":true,\"club\":true,\"clubmed\":true,\"coach\":true,\"codes\":true,\"coffee\":true,\"college\":true,\"cologne\":true,\"comcast\":true,\"commbank\":true,\"community\":true,\"company\":true,\"computer\":true,\"comsec\":true,\"condos\":true,\"construction\":true,\"consulting\":true,\"contact\":true,\"contractors\":true,\"cooking\":true,\"cookingchannel\":true,\"cool\":true,\"corsica\":true,\"country\":true,\"coupon\":true,\"coupons\":true,\"courses\":true,\"credit\":true,\"creditcard\":true,\"creditunion\":true,\"cricket\":true,\"crown\":true,\"crs\":true,\"cruises\":true,\"csc\":true,\"cuisinella\":true,\"cymru\":true,\"cyou\":true,\"dabur\":true,\"dad\":true,\"dance\":true,\"date\":true,\"dating\":true,\"datsun\":true,\"day\":true,\"dclk\":true,\"dds\":true,\"deal\":true,\"dealer\":true,\"deals\":true,\"degree\":true,\"delivery\":true,\"dell\":true,\"deloitte\":true,\"delta\":true,\"democrat\":true,\"dental\":true,\"dentist\":true,\"desi\":true,\"design\":true,\"dev\":true,\"dhl\":true,\"diamonds\":true,\"diet\":true,\"digital\":true,\"direct\":true,\"directory\":true,\"discount\":true,\"discover\":true,\"dish\":true,\"dnp\":true,\"docs\":true,\"dodge\":true,\"dog\":true,\"doha\":true,\"domains\":true,\"doosan\":true,\"dot\":true,\"download\":true,\"drive\":true,\"dstv\":true,\"dtv\":true,\"dubai\":true,\"duck\":true,\"dunlop\":true,\"duns\":true,\"dupont\":true,\"durban\":true,\"dvag\":true,\"dwg\":true,\"earth\":true,\"eat\":true,\"edeka\":true,\"education\":true,\"email\":true,\"emerck\":true,\"emerson\":true,\"energy\":true,\"engineer\":true,\"engineering\":true,\"enterprises\":true,\"epost\":true,\"epson\":true,\"equipment\":true,\"ericsson\":true,\"erni\":true,\"esq\":true,\"estate\":true,\"esurance\":true,\"etisalat\":true,\"eurovision\":true,\"eus\":true,\"events\":true,\"everbank\":true,\"exchange\":true,\"expert\":true,\"exposed\":true,\"express\":true,\"extraspace\":true,\"fage\":true,\"fail\":true,\"fairwinds\":true,\"faith\":true,\"family\":true,\"fan\":true,\"fans\":true,\"farm\":true,\"farmers\":true,\"fashion\":true,\"fast\":true,\"fedex\":true,\"feedback\":true,\"ferrari\":true,\"ferrero\":true,\"fiat\":true,\"fidelity\":true,\"fido\":true,\"film\":true,\"final\":true,\"finance\":true,\"financial\":true,\"fire\":true,\"firestone\":true,\"firmdale\":true,\"fish\":true,\"fishing\":true,\"fit\":true,\"fitness\":true,\"flickr\":true,\"flights\":true,\"flir\":true,\"florist\":true,\"flowers\":true,\"flsmidth\":true,\"fly\":true,\"foo\":true,\"foodnetwork\":true,\"football\":true,\"ford\":true,\"forex\":true,\"forsale\":true,\"forum\":true,\"foundation\":true,\"fox\":true,\"fresenius\":true,\"frl\":true,\"frogans\":true,\"frontdoor\":true,\"frontier\":true,\"ftr\":true,\"fujitsu\":true,\"fujixerox\":true,\"fund\":true,\"furniture\":true,\"futbol\":true,\"fyi\":true,\"gal\":true,\"gallery\":true,\"gallo\":true,\"gallup\":true,\"game\":true,\"games\":true,\"gap\":true,\"garden\":true,\"gbiz\":true,\"gdn\":true,\"gea\":true,\"gent\":true,\"genting\":true,\"george\":true,\"ggee\":true,\"gift\":true,\"gifts\":true,\"gives\":true,\"giving\":true,\"glade\":true,\"glass\":true,\"gle\":true,\"global\":true,\"globo\":true,\"gmail\":true,\"gmo\":true,\"gmx\":true,\"godaddy\":true,\"gold\":true,\"goldpoint\":true,\"golf\":true,\"goo\":true,\"goodhands\":true,\"goodyear\":true,\"goog\":true,\"google\":true,\"gop\":true,\"got\":true,\"gotv\":true,\"grainger\":true,\"graphics\":true,\"gratis\":true,\"green\":true,\"gripe\":true,\"group\":true,\"guardian\":true,\"gucci\":true,\"guge\":true,\"guide\":true,\"guitars\":true,\"guru\":true,\"hamburg\":true,\"hangout\":true,\"haus\":true,\"hbo\":true,\"hdfc\":true,\"hdfcbank\":true,\"health\":true,\"healthcare\":true,\"help\":true,\"helsinki\":true,\"here\":true,\"hermes\":true,\"hgtv\":true,\"hiphop\":true,\"hisamitsu\":true,\"hitachi\":true,\"hiv\":true,\"hkt\":true,\"hockey\":true,\"holdings\":true,\"holiday\":true,\"homedepot\":true,\"homegoods\":true,\"homes\":true,\"homesense\":true,\"honda\":true,\"honeywell\":true,\"horse\":true,\"host\":true,\"hosting\":true,\"hot\":true,\"hoteles\":true,\"hotmail\":true,\"house\":true,\"how\":true,\"hsbc\":true,\"htc\":true,\"hughes\":true,\"hyatt\":true,\"hyundai\":true,\"ibm\":true,\"icbc\":true,\"ice\":true,\"icu\":true,\"ieee\":true,\"ifm\":true,\"iinet\":true,\"ikano\":true,\"imamat\":true,\"imdb\":true,\"immo\":true,\"immobilien\":true,\"industries\":true,\"infiniti\":true,\"ing\":true,\"ink\":true,\"institute\":true,\"insurance\":true,\"insure\":true,\"intel\":true,\"international\":true,\"intuit\":true,\"investments\":true,\"ipiranga\":true,\"irish\":true,\"iselect\":true,\"ismaili\":true,\"ist\":true,\"istanbul\":true,\"itau\":true,\"itv\":true,\"iveco\":true,\"iwc\":true,\"jaguar\":true,\"java\":true,\"jcb\":true,\"jcp\":true,\"jeep\":true,\"jetzt\":true,\"jewelry\":true,\"jio\":true,\"jlc\":true,\"jll\":true,\"jmp\":true,\"jnj\":true,\"joburg\":true,\"jot\":true,\"joy\":true,\"jpmorgan\":true,\"jprs\":true,\"juegos\":true,\"juniper\":true,\"kaufen\":true,\"kddi\":true,\"kerryhotels\":true,\"kerrylogistics\":true,\"kerryproperties\":true,\"kfh\":true,\"kia\":true,\"kim\":true,\"kinder\":true,\"kindle\":true,\"kitchen\":true,\"kiwi\":true,\"koeln\":true,\"komatsu\":true,\"kosher\":true,\"kpmg\":true,\"kpn\":true,\"krd\":true,\"kred\":true,\"kuokgroup\":true,\"kyknet\":true,\"kyoto\":true,\"lacaixa\":true,\"ladbrokes\":true,\"lamborghini\":true,\"lancaster\":true,\"lancia\":true,\"lancome\":true,\"land\":true,\"landrover\":true,\"lanxess\":true,\"lasalle\":true,\"lat\":true,\"latino\":true,\"latrobe\":true,\"law\":true,\"lawyer\":true,\"lds\":true,\"lease\":true,\"leclerc\":true,\"lefrak\":true,\"legal\":true,\"lego\":true,\"lexus\":true,\"lgbt\":true,\"liaison\":true,\"lidl\":true,\"life\":true,\"lifeinsurance\":true,\"lifestyle\":true,\"lighting\":true,\"like\":true,\"lilly\":true,\"limited\":true,\"limo\":true,\"lincoln\":true,\"linde\":true,\"link\":true,\"lipsy\":true,\"live\":true,\"living\":true,\"lixil\":true,\"loan\":true,\"loans\":true,\"locker\":true,\"locus\":true,\"loft\":true,\"lol\":true,\"london\":true,\"lotte\":true,\"lotto\":true,\"love\":true,\"lpl\":true,\"lplfinancial\":true,\"ltd\":true,\"ltda\":true,\"lundbeck\":true,\"lupin\":true,\"luxe\":true,\"luxury\":true,\"macys\":true,\"madrid\":true,\"maif\":true,\"maison\":true,\"makeup\":true,\"man\":true,\"management\":true,\"mango\":true,\"market\":true,\"marketing\":true,\"markets\":true,\"marriott\":true,\"marshalls\":true,\"maserati\":true,\"mattel\":true,\"mba\":true,\"mcd\":true,\"mcdonalds\":true,\"mckinsey\":true,\"med\":true,\"media\":true,\"meet\":true,\"melbourne\":true,\"meme\":true,\"memorial\":true,\"men\":true,\"menu\":true,\"meo\":true,\"metlife\":true,\"miami\":true,\"microsoft\":true,\"mini\":true,\"mint\":true,\"mit\":true,\"mitsubishi\":true,\"mlb\":true,\"mls\":true,\"mma\":true,\"mnet\":true,\"mobily\":true,\"moda\":true,\"moe\":true,\"moi\":true,\"mom\":true,\"monash\":true,\"money\":true,\"monster\":true,\"montblanc\":true,\"mopar\":true,\"mormon\":true,\"mortgage\":true,\"moscow\":true,\"moto\":true,\"motorcycles\":true,\"mov\":true,\"movie\":true,\"movistar\":true,\"msd\":true,\"mtn\":true,\"mtpc\":true,\"mtr\":true,\"multichoice\":true,\"mutual\":true,\"mutuelle\":true,\"mzansimagic\":true,\"nab\":true,\"nadex\":true,\"nagoya\":true,\"naspers\":true,\"nationwide\":true,\"natura\":true,\"navy\":true,\"nba\":true,\"nec\":true,\"netbank\":true,\"netflix\":true,\"network\":true,\"neustar\":true,\"new\":true,\"newholland\":true,\"news\":true,\"next\":true,\"nextdirect\":true,\"nexus\":true,\"nfl\":true,\"ngo\":true,\"nhk\":true,\"nico\":true,\"nike\":true,\"nikon\":true,\"ninja\":true,\"nissan\":true,\"nokia\":true,\"northwesternmutual\":true,\"norton\":true,\"now\":true,\"nowruz\":true,\"nowtv\":true,\"nra\":true,\"nrw\":true,\"ntt\":true,\"nyc\":true,\"obi\":true,\"observer\":true,\"off\":true,\"office\":true,\"okinawa\":true,\"olayan\":true,\"olayangroup\":true,\"oldnavy\":true,\"ollo\":true,\"omega\":true,\"one\":true,\"ong\":true,\"onl\":true,\"online\":true,\"onyourside\":true,\"ooo\":true,\"open\":true,\"oracle\":true,\"orange\":true,\"organic\":true,\"orientexpress\":true,\"osaka\":true,\"otsuka\":true,\"ott\":true,\"ovh\":true,\"page\":true,\"pamperedchef\":true,\"panasonic\":true,\"panerai\":true,\"paris\":true,\"pars\":true,\"partners\":true,\"parts\":true,\"party\":true,\"passagens\":true,\"pay\":true,\"payu\":true,\"pccw\":true,\"pet\":true,\"pfizer\":true,\"pharmacy\":true,\"philips\":true,\"photo\":true,\"photography\":true,\"photos\":true,\"physio\":true,\"piaget\":true,\"pics\":true,\"pictet\":true,\"pictures\":true,\"pid\":true,\"pin\":true,\"ping\":true,\"pink\":true,\"pioneer\":true,\"pizza\":true,\"place\":true,\"play\":true,\"playstation\":true,\"plumbing\":true,\"plus\":true,\"pnc\":true,\"pohl\":true,\"poker\":true,\"politie\":true,\"porn\":true,\"pramerica\":true,\"praxi\":true,\"press\":true,\"prime\":true,\"prod\":true,\"productions\":true,\"prof\":true,\"progressive\":true,\"promo\":true,\"properties\":true,\"property\":true,\"protection\":true,\"pru\":true,\"prudential\":true,\"pub\":true,\"qpon\":true,\"quebec\":true,\"quest\":true,\"qvc\":true,\"racing\":true,\"raid\":true,\"read\":true,\"realestate\":true,\"realtor\":true,\"realty\":true,\"recipes\":true,\"red\":true,\"redstone\":true,\"redumbrella\":true,\"rehab\":true,\"reise\":true,\"reisen\":true,\"reit\":true,\"reliance\":true,\"ren\":true,\"rent\":true,\"rentals\":true,\"repair\":true,\"report\":true,\"republican\":true,\"rest\":true,\"restaurant\":true,\"review\":true,\"reviews\":true,\"rexroth\":true,\"rich\":true,\"richardli\":true,\"ricoh\":true,\"rightathome\":true,\"ril\":true,\"rio\":true,\"rip\":true,\"rocher\":true,\"rocks\":true,\"rodeo\":true,\"rogers\":true,\"room\":true,\"rsvp\":true,\"ruhr\":true,\"run\":true,\"rwe\":true,\"ryukyu\":true,\"saarland\":true,\"safe\":true,\"safety\":true,\"sakura\":true,\"sale\":true,\"salon\":true,\"samsclub\":true,\"samsung\":true,\"sandvik\":true,\"sandvikcoromant\":true,\"sanofi\":true,\"sap\":true,\"sapo\":true,\"sarl\":true,\"sas\":true,\"save\":true,\"saxo\":true,\"sbi\":true,\"sbs\":true,\"sca\":true,\"scb\":true,\"schaeffler\":true,\"schmidt\":true,\"scholarships\":true,\"school\":true,\"schule\":true,\"schwarz\":true,\"science\":true,\"scjohnson\":true,\"scor\":true,\"scot\":true,\"seat\":true,\"secure\":true,\"security\":true,\"seek\":true,\"sener\":true,\"services\":true,\"ses\":true,\"seven\":true,\"sew\":true,\"sex\":true,\"sexy\":true,\"sfr\":true,\"shangrila\":true,\"sharp\":true,\"shaw\":true,\"shell\":true,\"shia\":true,\"shiksha\":true,\"shoes\":true,\"shouji\":true,\"show\":true,\"showtime\":true,\"shriram\":true,\"silk\":true,\"sina\":true,\"singles\":true,\"site\":true,\"ski\":true,\"skin\":true,\"sky\":true,\"skype\":true,\"sling\":true,\"smart\":true,\"smile\":true,\"sncf\":true,\"soccer\":true,\"social\":true,\"softbank\":true,\"software\":true,\"sohu\":true,\"solar\":true,\"solutions\":true,\"song\":true,\"sony\":true,\"soy\":true,\"space\":true,\"spiegel\":true,\"spot\":true,\"spreadbetting\":true,\"srl\":true,\"srt\":true,\"stada\":true,\"staples\":true,\"star\":true,\"starhub\":true,\"statebank\":true,\"statefarm\":true,\"statoil\":true,\"stc\":true,\"stcgroup\":true,\"stockholm\":true,\"storage\":true,\"store\":true,\"studio\":true,\"study\":true,\"style\":true,\"sucks\":true,\"supersport\":true,\"supplies\":true,\"supply\":true,\"support\":true,\"surf\":true,\"surgery\":true,\"suzuki\":true,\"swatch\":true,\"swiftcover\":true,\"swiss\":true,\"sydney\":true,\"symantec\":true,\"systems\":true,\"tab\":true,\"taipei\":true,\"talk\":true,\"taobao\":true,\"target\":true,\"tatamotors\":true,\"tatar\":true,\"tattoo\":true,\"tax\":true,\"taxi\":true,\"tci\":true,\"tdk\":true,\"team\":true,\"tech\":true,\"technology\":true,\"telecity\":true,\"telefonica\":true,\"temasek\":true,\"tennis\":true,\"teva\":true,\"thd\":true,\"theater\":true,\"theatre\":true,\"theguardian\":true,\"tiaa\":true,\"tickets\":true,\"tienda\":true,\"tiffany\":true,\"tips\":true,\"tires\":true,\"tirol\":true,\"tjmaxx\":true,\"tjx\":true,\"tkmaxx\":true,\"tmall\":true,\"today\":true,\"tokyo\":true,\"tools\":true,\"top\":true,\"toray\":true,\"toshiba\":true,\"total\":true,\"tours\":true,\"town\":true,\"toyota\":true,\"toys\":true,\"trade\":true,\"trading\":true,\"training\":true,\"travelchannel\":true,\"travelers\":true,\"travelersinsurance\":true,\"trust\":true,\"trv\":true,\"tube\":true,\"tui\":true,\"tunes\":true,\"tushu\":true,\"tvs\":true,\"ubank\":true,\"ubs\":true,\"uconnect\":true,\"university\":true,\"uno\":true,\"uol\":true,\"ups\":true,\"vacations\":true,\"vana\":true,\"vanguard\":true,\"vegas\":true,\"ventures\":true,\"verisign\":true,\"versicherung\":true,\"vet\":true,\"viajes\":true,\"video\":true,\"vig\":true,\"viking\":true,\"villas\":true,\"vin\":true,\"vip\":true,\"virgin\":true,\"visa\":true,\"vision\":true,\"vista\":true,\"vistaprint\":true,\"viva\":true,\"vivo\":true,\"vlaanderen\":true,\"vodka\":true,\"volkswagen\":true,\"vote\":true,\"voting\":true,\"voto\":true,\"voyage\":true,\"vuelos\":true,\"wales\":true,\"walmart\":true,\"walter\":true,\"wang\":true,\"wanggou\":true,\"warman\":true,\"watch\":true,\"watches\":true,\"weather\":true,\"weatherchannel\":true,\"webcam\":true,\"weber\":true,\"website\":true,\"wed\":true,\"wedding\":true,\"weibo\":true,\"weir\":true,\"whoswho\":true,\"wien\":true,\"wiki\":true,\"williamhill\":true,\"win\":true,\"windows\":true,\"wine\":true,\"winners\":true,\"wme\":true,\"wolterskluwer\":true,\"woodside\":true,\"work\":true,\"works\":true,\"world\":true,\"wtc\":true,\"wtf\":true,\"xbox\":true,\"xerox\":true,\"xfinity\":true,\"xihuan\":true,\"xin\":true,\"xn--11b4c3d\":true,\"xn--1ck2e1b\":true,\"xn--1qqw23a\":true,\"xn--30rr7y\":true,\"xn--3bst00m\":true,\"xn--3ds443g\":true,\"xn--3oq18vl8pn36a\":true,\"xn--3pxu8k\":true,\"xn--42c2d9a\":true,\"xn--45q11c\":true,\"xn--4gbrim\":true,\"xn--4gq48lf9j\":true,\"xn--55qw42g\":true,\"xn--55qx5d\":true,\"xn--5su34j936bgsg\":true,\"xn--5tzm5g\":true,\"xn--6frz82g\":true,\"xn--6qq986b3xl\":true,\"xn--80adxhks\":true,\"xn--80asehdb\":true,\"xn--80aswg\":true,\"xn--8y0a063a\":true,\"xn--9dbq2a\":true,\"xn--9et52u\":true,\"xn--9krt00a\":true,\"xn--b4w605ferd\":true,\"xn--bck1b9a5dre4c\":true,\"xn--c1avg\":true,\"xn--c2br7g\":true,\"xn--cck2b3b\":true,\"xn--cg4bki\":true,\"xn--czr694b\":true,\"xn--czrs0t\":true,\"xn--czru2d\":true,\"xn--d1acj3b\":true,\"xn--eckvdtc9d\":true,\"xn--efvy88h\":true,\"xn--estv75g\":true,\"xn--fct429k\":true,\"xn--fhbei\":true,\"xn--fiq228c5hs\":true,\"xn--fiq64b\":true,\"xn--fjq720a\":true,\"xn--flw351e\":true,\"xn--fzys8d69uvgm\":true,\"xn--g2xx48c\":true,\"xn--gckr3f0f\":true,\"xn--hxt814e\":true,\"xn--i1b6b1a6a2e\":true,\"xn--imr513n\":true,\"xn--io0a7i\":true,\"xn--j1aef\":true,\"xn--jlq61u9w7b\":true,\"xn--jvr189m\":true,\"xn--kcrx77d1x4a\":true,\"xn--kpu716f\":true,\"xn--kput3i\":true,\"xn--mgba3a3ejt\":true,\"xn--mgba7c0bbn0a\":true,\"xn--mgbaakc7dvf\":true,\"xn--mgbab2bd\":true,\"xn--mgbb9fbpob\":true,\"xn--mgbca7dzdo\":true,\"xn--mgbt3dhd\":true,\"xn--mk1bu44c\":true,\"xn--mxtq1m\":true,\"xn--ngbc5azd\":true,\"xn--ngbe9e0a\":true,\"xn--nqv7f\":true,\"xn--nqv7fs00ema\":true,\"xn--nyqy26a\":true,\"xn--p1acf\":true,\"xn--pbt977c\":true,\"xn--pssy2u\":true,\"xn--q9jyb4c\":true,\"xn--qcka1pmc\":true,\"xn--rhqv96g\":true,\"xn--rovu88b\":true,\"xn--ses554g\":true,\"xn--t60b56a\":true,\"xn--tckwe\":true,\"xn--unup4y\":true,\"xn--vermgensberater-ctb\":true,\"xn--vermgensberatung-pwb\":true,\"xn--vhquv\":true,\"xn--vuq861b\":true,\"xn--w4r85el8fhu5dnra\":true,\"xn--w4rs40l\":true,\"xn--xhq521b\":true,\"xn--zfr164b\":true,\"xperia\":true,\"xyz\":true,\"yachts\":true,\"yahoo\":true,\"yamaxun\":true,\"yandex\":true,\"yodobashi\":true,\"yoga\":true,\"yokohama\":true,\"you\":true,\"youtube\":true,\"yun\":true,\"zappos\":true,\"zara\":true,\"zero\":true,\"zip\":true,\"zippo\":true,\"zone\":true,\"zuerich\":true,\"cloudfront.net\":true,\"ap-northeast-1.compute.amazonaws.com\":true,\"ap-southeast-1.compute.amazonaws.com\":true,\"ap-southeast-2.compute.amazonaws.com\":true,\"cn-north-1.compute.amazonaws.cn\":true,\"compute.amazonaws.cn\":true,\"compute.amazonaws.com\":true,\"compute-1.amazonaws.com\":true,\"eu-west-1.compute.amazonaws.com\":true,\"eu-central-1.compute.amazonaws.com\":true,\"sa-east-1.compute.amazonaws.com\":true,\"us-east-1.amazonaws.com\":true,\"us-gov-west-1.compute.amazonaws.com\":true,\"us-west-1.compute.amazonaws.com\":true,\"us-west-2.compute.amazonaws.com\":true,\"z-1.compute-1.amazonaws.com\":true,\"z-2.compute-1.amazonaws.com\":true,\"elasticbeanstalk.com\":true,\"elb.amazonaws.com\":true,\"s3.amazonaws.com\":true,\"s3-ap-northeast-1.amazonaws.com\":true,\"s3-ap-southeast-1.amazonaws.com\":true,\"s3-ap-southeast-2.amazonaws.com\":true,\"s3-external-1.amazonaws.com\":true,\"s3-external-2.amazonaws.com\":true,\"s3-fips-us-gov-west-1.amazonaws.com\":true,\"s3-eu-central-1.amazonaws.com\":true,\"s3-eu-west-1.amazonaws.com\":true,\"s3-sa-east-1.amazonaws.com\":true,\"s3-us-gov-west-1.amazonaws.com\":true,\"s3-us-west-1.amazonaws.com\":true,\"s3-us-west-2.amazonaws.com\":true,\"s3.cn-north-1.amazonaws.com.cn\":true,\"s3.eu-central-1.amazonaws.com\":true,\"betainabox.com\":true,\"ae.org\":true,\"ar.com\":true,\"br.com\":true,\"cn.com\":true,\"com.de\":true,\"com.se\":true,\"de.com\":true,\"eu.com\":true,\"gb.com\":true,\"gb.net\":true,\"hu.com\":true,\"hu.net\":true,\"jp.net\":true,\"jpn.com\":true,\"kr.com\":true,\"mex.com\":true,\"no.com\":true,\"qc.com\":true,\"ru.com\":true,\"sa.com\":true,\"se.com\":true,\"se.net\":true,\"uk.com\":true,\"uk.net\":true,\"us.com\":true,\"uy.com\":true,\"za.bz\":true,\"za.com\":true,\"africa.com\":true,\"gr.com\":true,\"in.net\":true,\"us.org\":true,\"co.com\":true,\"c.la\":true,\"cloudcontrolled.com\":true,\"cloudcontrolapp.com\":true,\"co.ca\":true,\"c.cdn77.org\":true,\"cdn77-ssl.net\":true,\"r.cdn77.net\":true,\"rsc.cdn77.org\":true,\"ssl.origin.cdn77-secure.org\":true,\"co.nl\":true,\"co.no\":true,\"*.platform.sh\":true,\"cupcake.is\":true,\"dreamhosters.com\":true,\"duckdns.org\":true,\"dyndns-at-home.com\":true,\"dyndns-at-work.com\":true,\"dyndns-blog.com\":true,\"dyndns-free.com\":true,\"dyndns-home.com\":true,\"dyndns-ip.com\":true,\"dyndns-mail.com\":true,\"dyndns-office.com\":true,\"dyndns-pics.com\":true,\"dyndns-remote.com\":true,\"dyndns-server.com\":true,\"dyndns-web.com\":true,\"dyndns-wiki.com\":true,\"dyndns-work.com\":true,\"dyndns.biz\":true,\"dyndns.info\":true,\"dyndns.org\":true,\"dyndns.tv\":true,\"at-band-camp.net\":true,\"ath.cx\":true,\"barrel-of-knowledge.info\":true,\"barrell-of-knowledge.info\":true,\"better-than.tv\":true,\"blogdns.com\":true,\"blogdns.net\":true,\"blogdns.org\":true,\"blogsite.org\":true,\"boldlygoingnowhere.org\":true,\"broke-it.net\":true,\"buyshouses.net\":true,\"cechire.com\":true,\"dnsalias.com\":true,\"dnsalias.net\":true,\"dnsalias.org\":true,\"dnsdojo.com\":true,\"dnsdojo.net\":true,\"dnsdojo.org\":true,\"does-it.net\":true,\"doesntexist.com\":true,\"doesntexist.org\":true,\"dontexist.com\":true,\"dontexist.net\":true,\"dontexist.org\":true,\"doomdns.com\":true,\"doomdns.org\":true,\"dvrdns.org\":true,\"dyn-o-saur.com\":true,\"dynalias.com\":true,\"dynalias.net\":true,\"dynalias.org\":true,\"dynathome.net\":true,\"dyndns.ws\":true,\"endofinternet.net\":true,\"endofinternet.org\":true,\"endoftheinternet.org\":true,\"est-a-la-maison.com\":true,\"est-a-la-masion.com\":true,\"est-le-patron.com\":true,\"est-mon-blogueur.com\":true,\"for-better.biz\":true,\"for-more.biz\":true,\"for-our.info\":true,\"for-some.biz\":true,\"for-the.biz\":true,\"forgot.her.name\":true,\"forgot.his.name\":true,\"from-ak.com\":true,\"from-al.com\":true,\"from-ar.com\":true,\"from-az.net\":true,\"from-ca.com\":true,\"from-co.net\":true,\"from-ct.com\":true,\"from-dc.com\":true,\"from-de.com\":true,\"from-fl.com\":true,\"from-ga.com\":true,\"from-hi.com\":true,\"from-ia.com\":true,\"from-id.com\":true,\"from-il.com\":true,\"from-in.com\":true,\"from-ks.com\":true,\"from-ky.com\":true,\"from-la.net\":true,\"from-ma.com\":true,\"from-md.com\":true,\"from-me.org\":true,\"from-mi.com\":true,\"from-mn.com\":true,\"from-mo.com\":true,\"from-ms.com\":true,\"from-mt.com\":true,\"from-nc.com\":true,\"from-nd.com\":true,\"from-ne.com\":true,\"from-nh.com\":true,\"from-nj.com\":true,\"from-nm.com\":true,\"from-nv.com\":true,\"from-ny.net\":true,\"from-oh.com\":true,\"from-ok.com\":true,\"from-or.com\":true,\"from-pa.com\":true,\"from-pr.com\":true,\"from-ri.com\":true,\"from-sc.com\":true,\"from-sd.com\":true,\"from-tn.com\":true,\"from-tx.com\":true,\"from-ut.com\":true,\"from-va.com\":true,\"from-vt.com\":true,\"from-wa.com\":true,\"from-wi.com\":true,\"from-wv.com\":true,\"from-wy.com\":true,\"ftpaccess.cc\":true,\"fuettertdasnetz.de\":true,\"game-host.org\":true,\"game-server.cc\":true,\"getmyip.com\":true,\"gets-it.net\":true,\"go.dyndns.org\":true,\"gotdns.com\":true,\"gotdns.org\":true,\"groks-the.info\":true,\"groks-this.info\":true,\"ham-radio-op.net\":true,\"here-for-more.info\":true,\"hobby-site.com\":true,\"hobby-site.org\":true,\"home.dyndns.org\":true,\"homedns.org\":true,\"homeftp.net\":true,\"homeftp.org\":true,\"homeip.net\":true,\"homelinux.com\":true,\"homelinux.net\":true,\"homelinux.org\":true,\"homeunix.com\":true,\"homeunix.net\":true,\"homeunix.org\":true,\"iamallama.com\":true,\"in-the-band.net\":true,\"is-a-anarchist.com\":true,\"is-a-blogger.com\":true,\"is-a-bookkeeper.com\":true,\"is-a-bruinsfan.org\":true,\"is-a-bulls-fan.com\":true,\"is-a-candidate.org\":true,\"is-a-caterer.com\":true,\"is-a-celticsfan.org\":true,\"is-a-chef.com\":true,\"is-a-chef.net\":true,\"is-a-chef.org\":true,\"is-a-conservative.com\":true,\"is-a-cpa.com\":true,\"is-a-cubicle-slave.com\":true,\"is-a-democrat.com\":true,\"is-a-designer.com\":true,\"is-a-doctor.com\":true,\"is-a-financialadvisor.com\":true,\"is-a-geek.com\":true,\"is-a-geek.net\":true,\"is-a-geek.org\":true,\"is-a-green.com\":true,\"is-a-guru.com\":true,\"is-a-hard-worker.com\":true,\"is-a-hunter.com\":true,\"is-a-knight.org\":true,\"is-a-landscaper.com\":true,\"is-a-lawyer.com\":true,\"is-a-liberal.com\":true,\"is-a-libertarian.com\":true,\"is-a-linux-user.org\":true,\"is-a-llama.com\":true,\"is-a-musician.com\":true,\"is-a-nascarfan.com\":true,\"is-a-nurse.com\":true,\"is-a-painter.com\":true,\"is-a-patsfan.org\":true,\"is-a-personaltrainer.com\":true,\"is-a-photographer.com\":true,\"is-a-player.com\":true,\"is-a-republican.com\":true,\"is-a-rockstar.com\":true,\"is-a-socialist.com\":true,\"is-a-soxfan.org\":true,\"is-a-student.com\":true,\"is-a-teacher.com\":true,\"is-a-techie.com\":true,\"is-a-therapist.com\":true,\"is-an-accountant.com\":true,\"is-an-actor.com\":true,\"is-an-actress.com\":true,\"is-an-anarchist.com\":true,\"is-an-artist.com\":true,\"is-an-engineer.com\":true,\"is-an-entertainer.com\":true,\"is-by.us\":true,\"is-certified.com\":true,\"is-found.org\":true,\"is-gone.com\":true,\"is-into-anime.com\":true,\"is-into-cars.com\":true,\"is-into-cartoons.com\":true,\"is-into-games.com\":true,\"is-leet.com\":true,\"is-lost.org\":true,\"is-not-certified.com\":true,\"is-saved.org\":true,\"is-slick.com\":true,\"is-uberleet.com\":true,\"is-very-bad.org\":true,\"is-very-evil.org\":true,\"is-very-good.org\":true,\"is-very-nice.org\":true,\"is-very-sweet.org\":true,\"is-with-theband.com\":true,\"isa-geek.com\":true,\"isa-geek.net\":true,\"isa-geek.org\":true,\"isa-hockeynut.com\":true,\"issmarterthanyou.com\":true,\"isteingeek.de\":true,\"istmein.de\":true,\"kicks-ass.net\":true,\"kicks-ass.org\":true,\"knowsitall.info\":true,\"land-4-sale.us\":true,\"lebtimnetz.de\":true,\"leitungsen.de\":true,\"likes-pie.com\":true,\"likescandy.com\":true,\"merseine.nu\":true,\"mine.nu\":true,\"misconfused.org\":true,\"mypets.ws\":true,\"myphotos.cc\":true,\"neat-url.com\":true,\"office-on-the.net\":true,\"on-the-web.tv\":true,\"podzone.net\":true,\"podzone.org\":true,\"readmyblog.org\":true,\"saves-the-whales.com\":true,\"scrapper-site.net\":true,\"scrapping.cc\":true,\"selfip.biz\":true,\"selfip.com\":true,\"selfip.info\":true,\"selfip.net\":true,\"selfip.org\":true,\"sells-for-less.com\":true,\"sells-for-u.com\":true,\"sells-it.net\":true,\"sellsyourhome.org\":true,\"servebbs.com\":true,\"servebbs.net\":true,\"servebbs.org\":true,\"serveftp.net\":true,\"serveftp.org\":true,\"servegame.org\":true,\"shacknet.nu\":true,\"simple-url.com\":true,\"space-to-rent.com\":true,\"stuff-4-sale.org\":true,\"stuff-4-sale.us\":true,\"teaches-yoga.com\":true,\"thruhere.net\":true,\"traeumtgerade.de\":true,\"webhop.biz\":true,\"webhop.info\":true,\"webhop.net\":true,\"webhop.org\":true,\"worse-than.tv\":true,\"writesthisblog.com\":true,\"eu.org\":true,\"al.eu.org\":true,\"asso.eu.org\":true,\"at.eu.org\":true,\"au.eu.org\":true,\"be.eu.org\":true,\"bg.eu.org\":true,\"ca.eu.org\":true,\"cd.eu.org\":true,\"ch.eu.org\":true,\"cn.eu.org\":true,\"cy.eu.org\":true,\"cz.eu.org\":true,\"de.eu.org\":true,\"dk.eu.org\":true,\"edu.eu.org\":true,\"ee.eu.org\":true,\"es.eu.org\":true,\"fi.eu.org\":true,\"fr.eu.org\":true,\"gr.eu.org\":true,\"hr.eu.org\":true,\"hu.eu.org\":true,\"ie.eu.org\":true,\"il.eu.org\":true,\"in.eu.org\":true,\"int.eu.org\":true,\"is.eu.org\":true,\"it.eu.org\":true,\"jp.eu.org\":true,\"kr.eu.org\":true,\"lt.eu.org\":true,\"lu.eu.org\":true,\"lv.eu.org\":true,\"mc.eu.org\":true,\"me.eu.org\":true,\"mk.eu.org\":true,\"mt.eu.org\":true,\"my.eu.org\":true,\"net.eu.org\":true,\"ng.eu.org\":true,\"nl.eu.org\":true,\"no.eu.org\":true,\"nz.eu.org\":true,\"paris.eu.org\":true,\"pl.eu.org\":true,\"pt.eu.org\":true,\"q-a.eu.org\":true,\"ro.eu.org\":true,\"ru.eu.org\":true,\"se.eu.org\":true,\"si.eu.org\":true,\"sk.eu.org\":true,\"tr.eu.org\":true,\"uk.eu.org\":true,\"us.eu.org\":true,\"a.ssl.fastly.net\":true,\"b.ssl.fastly.net\":true,\"global.ssl.fastly.net\":true,\"a.prod.fastly.net\":true,\"global.prod.fastly.net\":true,\"firebaseapp.com\":true,\"flynnhub.com\":true,\"service.gov.uk\":true,\"github.io\":true,\"githubusercontent.com\":true,\"ro.com\":true,\"appspot.com\":true,\"blogspot.ae\":true,\"blogspot.al\":true,\"blogspot.am\":true,\"blogspot.ba\":true,\"blogspot.be\":true,\"blogspot.bg\":true,\"blogspot.bj\":true,\"blogspot.ca\":true,\"blogspot.cf\":true,\"blogspot.ch\":true,\"blogspot.cl\":true,\"blogspot.co.at\":true,\"blogspot.co.id\":true,\"blogspot.co.il\":true,\"blogspot.co.ke\":true,\"blogspot.co.nz\":true,\"blogspot.co.uk\":true,\"blogspot.co.za\":true,\"blogspot.com\":true,\"blogspot.com.ar\":true,\"blogspot.com.au\":true,\"blogspot.com.br\":true,\"blogspot.com.by\":true,\"blogspot.com.co\":true,\"blogspot.com.cy\":true,\"blogspot.com.ee\":true,\"blogspot.com.eg\":true,\"blogspot.com.es\":true,\"blogspot.com.mt\":true,\"blogspot.com.ng\":true,\"blogspot.com.tr\":true,\"blogspot.com.uy\":true,\"blogspot.cv\":true,\"blogspot.cz\":true,\"blogspot.de\":true,\"blogspot.dk\":true,\"blogspot.fi\":true,\"blogspot.fr\":true,\"blogspot.gr\":true,\"blogspot.hk\":true,\"blogspot.hr\":true,\"blogspot.hu\":true,\"blogspot.ie\":true,\"blogspot.in\":true,\"blogspot.is\":true,\"blogspot.it\":true,\"blogspot.jp\":true,\"blogspot.kr\":true,\"blogspot.li\":true,\"blogspot.lt\":true,\"blogspot.lu\":true,\"blogspot.md\":true,\"blogspot.mk\":true,\"blogspot.mr\":true,\"blogspot.mx\":true,\"blogspot.my\":true,\"blogspot.nl\":true,\"blogspot.no\":true,\"blogspot.pe\":true,\"blogspot.pt\":true,\"blogspot.qa\":true,\"blogspot.re\":true,\"blogspot.ro\":true,\"blogspot.rs\":true,\"blogspot.ru\":true,\"blogspot.se\":true,\"blogspot.sg\":true,\"blogspot.si\":true,\"blogspot.sk\":true,\"blogspot.sn\":true,\"blogspot.td\":true,\"blogspot.tw\":true,\"blogspot.ug\":true,\"blogspot.vn\":true,\"codespot.com\":true,\"googleapis.com\":true,\"googlecode.com\":true,\"pagespeedmobilizer.com\":true,\"withgoogle.com\":true,\"withyoutube.com\":true,\"herokuapp.com\":true,\"herokussl.com\":true,\"iki.fi\":true,\"biz.at\":true,\"info.at\":true,\"co.pl\":true,\"azurewebsites.net\":true,\"azure-mobile.net\":true,\"cloudapp.net\":true,\"bmoattachments.org\":true,\"4u.com\":true,\"nfshost.com\":true,\"nyc.mn\":true,\"nid.io\":true,\"operaunite.com\":true,\"outsystemscloud.com\":true,\"art.pl\":true,\"gliwice.pl\":true,\"krakow.pl\":true,\"poznan.pl\":true,\"wroc.pl\":true,\"zakopane.pl\":true,\"pantheon.io\":true,\"gotpantheon.com\":true,\"priv.at\":true,\"qa2.com\":true,\"rhcloud.com\":true,\"sandcats.io\":true,\"biz.ua\":true,\"co.ua\":true,\"pp.ua\":true,\"sinaapp.com\":true,\"vipsinaapp.com\":true,\"1kapp.com\":true,\"gda.pl\":true,\"gdansk.pl\":true,\"gdynia.pl\":true,\"med.pl\":true,\"sopot.pl\":true,\"hk.com\":true,\"hk.org\":true,\"ltd.hk\":true,\"inc.hk\":true,\"yolasite.com\":true,\"za.net\":true,\"za.org\":true});\n\n// END of automatically generated file\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/tough-cookie/lib/store.js":"/*!\n * Copyright (c) 2015, Salesforce.com, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright notice,\n * this list of conditions and the following disclaimer in the documentation\n * and/or other materials provided with the distribution.\n *\n * 3. Neither the name of Salesforce.com nor the names of its contributors may\n * be used to endorse or promote products derived from this software without\n * specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n'use strict';\n/*jshint unused:false */\n\nfunction Store() {\n}\nexports.Store = Store;\n\n// Stores may be synchronous, but are still required to use a\n// Continuation-Passing Style API.  The CookieJar itself will expose a \"*Sync\"\n// API that converts from synchronous-callbacks to imperative style.\nStore.prototype.synchronous = false;\n\nStore.prototype.findCookie = function(domain, path, key, cb) {\n  throw new Error('findCookie is not implemented');\n};\n\nStore.prototype.findCookies = function(domain, path, cb) {\n  throw new Error('findCookies is not implemented');\n};\n\nStore.prototype.putCookie = function(cookie, cb) {\n  throw new Error('putCookie is not implemented');\n};\n\nStore.prototype.updateCookie = function(oldCookie, newCookie, cb) {\n  // recommended default implementation:\n  // return this.putCookie(newCookie, cb);\n  throw new Error('updateCookie is not implemented');\n};\n\nStore.prototype.removeCookie = function(domain, path, key, cb) {\n  throw new Error('removeCookie is not implemented');\n};\n\nStore.prototype.removeCookies = function(domain, path, cb) {\n  throw new Error('removeCookies is not implemented');\n};\n\nStore.prototype.getAllCookies = function(cb) {\n  throw new Error('getAllCookies is not implemented (therefore jar cannot be serialized)');\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/tough-cookie/lib/memstore.js":"/*!\n * Copyright (c) 2015, Salesforce.com, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright notice,\n * this list of conditions and the following disclaimer in the documentation\n * and/or other materials provided with the distribution.\n *\n * 3. Neither the name of Salesforce.com nor the names of its contributors may\n * be used to endorse or promote products derived from this software without\n * specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n'use strict';\nvar Store = require('./store').Store;\nvar permuteDomain = require('./permuteDomain').permuteDomain;\nvar pathMatch = require('./pathMatch').pathMatch;\nvar util = require('util');\n\nfunction MemoryCookieStore() {\n  Store.call(this);\n  this.idx = {};\n}\nutil.inherits(MemoryCookieStore, Store);\nexports.MemoryCookieStore = MemoryCookieStore;\nMemoryCookieStore.prototype.idx = null;\n\n// Since it's just a struct in RAM, this Store is synchronous\nMemoryCookieStore.prototype.synchronous = true;\n\n// force a default depth:\nMemoryCookieStore.prototype.inspect = function() {\n  return \"{ idx: \"+util.inspect(this.idx, false, 2)+' }';\n};\n\nMemoryCookieStore.prototype.findCookie = function(domain, path, key, cb) {\n  if (!this.idx[domain]) {\n    return cb(null,undefined);\n  }\n  if (!this.idx[domain][path]) {\n    return cb(null,undefined);\n  }\n  return cb(null,this.idx[domain][path][key]||null);\n};\n\nMemoryCookieStore.prototype.findCookies = function(domain, path, cb) {\n  var results = [];\n  if (!domain) {\n    return cb(null,[]);\n  }\n\n  var pathMatcher;\n  if (!path) {\n    // null means \"all paths\"\n    pathMatcher = function matchAll(domainIndex) {\n      for (var curPath in domainIndex) {\n        var pathIndex = domainIndex[curPath];\n        for (var key in pathIndex) {\n          results.push(pathIndex[key]);\n        }\n      }\n    };\n\n  } else {\n    pathMatcher = function matchRFC(domainIndex) {\n       //NOTE: we should use path-match algorithm from S5.1.4 here\n       //(see : https://github.com/ChromiumWebApps/chromium/blob/b3d3b4da8bb94c1b2e061600df106d590fda3620/net/cookies/canonical_cookie.cc#L299)\n       Object.keys(domainIndex).forEach(function (cookiePath) {\n         if (pathMatch(path, cookiePath)) {\n           var pathIndex = domainIndex[cookiePath];\n\n           for (var key in pathIndex) {\n             results.push(pathIndex[key]);\n           }\n         }\n       });\n     };\n  }\n\n  var domains = permuteDomain(domain) || [domain];\n  var idx = this.idx;\n  domains.forEach(function(curDomain) {\n    var domainIndex = idx[curDomain];\n    if (!domainIndex) {\n      return;\n    }\n    pathMatcher(domainIndex);\n  });\n\n  cb(null,results);\n};\n\nMemoryCookieStore.prototype.putCookie = function(cookie, cb) {\n  if (!this.idx[cookie.domain]) {\n    this.idx[cookie.domain] = {};\n  }\n  if (!this.idx[cookie.domain][cookie.path]) {\n    this.idx[cookie.domain][cookie.path] = {};\n  }\n  this.idx[cookie.domain][cookie.path][cookie.key] = cookie;\n  cb(null);\n};\n\nMemoryCookieStore.prototype.updateCookie = function(oldCookie, newCookie, cb) {\n  // updateCookie() may avoid updating cookies that are identical.  For example,\n  // lastAccessed may not be important to some stores and an equality\n  // comparison could exclude that field.\n  this.putCookie(newCookie,cb);\n};\n\nMemoryCookieStore.prototype.removeCookie = function(domain, path, key, cb) {\n  if (this.idx[domain] && this.idx[domain][path] && this.idx[domain][path][key]) {\n    delete this.idx[domain][path][key];\n  }\n  cb(null);\n};\n\nMemoryCookieStore.prototype.removeCookies = function(domain, path, cb) {\n  if (this.idx[domain]) {\n    if (path) {\n      delete this.idx[domain][path];\n    } else {\n      delete this.idx[domain];\n    }\n  }\n  return cb(null);\n};\n\nMemoryCookieStore.prototype.getAllCookies = function(cb) {\n  var cookies = [];\n  var idx = this.idx;\n\n  var domains = Object.keys(idx);\n  domains.forEach(function(domain) {\n    var paths = Object.keys(idx[domain]);\n    paths.forEach(function(path) {\n      var keys = Object.keys(idx[domain][path]);\n      keys.forEach(function(key) {\n        if (key !== null) {\n          cookies.push(idx[domain][path][key]);\n        }\n      });\n    });\n  });\n\n  // Sort by creationIndex so deserializing retains the creation order.\n  // When implementing your own store, this SHOULD retain the order too\n  cookies.sort(function(a,b) {\n    return (a.creationIndex||0) - (b.creationIndex||0);\n  });\n\n  cb(null, cookies);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/tough-cookie/lib/permuteDomain.js":"/*!\n * Copyright (c) 2015, Salesforce.com, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright notice,\n * this list of conditions and the following disclaimer in the documentation\n * and/or other materials provided with the distribution.\n *\n * 3. Neither the name of Salesforce.com nor the names of its contributors may\n * be used to endorse or promote products derived from this software without\n * specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\"use strict\";\nvar pubsuffix = require('./pubsuffix');\n\n// Gives the permutation of all possible domainMatch()es of a given domain. The\n// array is in shortest-to-longest order.  Handy for indexing.\nfunction permuteDomain (domain) {\n  var pubSuf = pubsuffix.getPublicSuffix(domain);\n  if (!pubSuf) {\n    return null;\n  }\n  if (pubSuf == domain) {\n    return [domain];\n  }\n\n  var prefix = domain.slice(0, -(pubSuf.length + 1)); // \".example.com\"\n  var parts = prefix.split('.').reverse();\n  var cur = pubSuf;\n  var permutations = [cur];\n  while (parts.length) {\n    cur = parts.shift() + '.' + cur;\n    permutations.push(cur);\n  }\n  return permutations;\n}\n\nexports.permuteDomain = permuteDomain;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/tough-cookie/lib/pathMatch.js":"/*!\n * Copyright (c) 2015, Salesforce.com, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright notice,\n * this list of conditions and the following disclaimer in the documentation\n * and/or other materials provided with the distribution.\n *\n * 3. Neither the name of Salesforce.com nor the names of its contributors may\n * be used to endorse or promote products derived from this software without\n * specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\"use strict\";\n/*\n * \"A request-path path-matches a given cookie-path if at least one of the\n * following conditions holds:\"\n */\nfunction pathMatch (reqPath, cookiePath) {\n  // \"o  The cookie-path and the request-path are identical.\"\n  if (cookiePath === reqPath) {\n    return true;\n  }\n\n  var idx = reqPath.indexOf(cookiePath);\n  if (idx === 0) {\n    // \"o  The cookie-path is a prefix of the request-path, and the last\n    // character of the cookie-path is %x2F (\"/\").\"\n    if (cookiePath.substr(-1) === \"/\") {\n      return true;\n    }\n\n    // \" o  The cookie-path is a prefix of the request-path, and the first\n    // character of the request-path that is not included in the cookie- path\n    // is a %x2F (\"/\") character.\"\n    if (reqPath.substr(cookiePath.length, 1) === \"/\") {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nexports.pathMatch = pathMatch;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/helpers.js":"'use strict'\n\nvar jsonSafeStringify = require('json-stringify-safe')\n  , crypto = require('crypto')\n  , Buffer = require('safe-buffer').Buffer\n\nvar defer = typeof setImmediate === 'undefined'\n  ? process.nextTick\n  : setImmediate\n\nfunction paramsHaveRequestBody(params) {\n  return (\n    params.body ||\n    params.requestBodyStream ||\n    (params.json && typeof params.json !== 'boolean') ||\n    params.multipart\n  )\n}\n\nfunction safeStringify (obj, replacer) {\n  var ret\n  try {\n    ret = JSON.stringify(obj, replacer)\n  } catch (e) {\n    ret = jsonSafeStringify(obj, replacer)\n  }\n  return ret\n}\n\nfunction md5 (str) {\n  return crypto.createHash('md5').update(str).digest('hex')\n}\n\nfunction isReadStream (rs) {\n  return rs.readable && rs.path && rs.mode\n}\n\nfunction toBase64 (str) {\n  return Buffer.from(str || '', 'utf8').toString('base64')\n}\n\nfunction copy (obj) {\n  var o = {}\n  Object.keys(obj).forEach(function (i) {\n    o[i] = obj[i]\n  })\n  return o\n}\n\nfunction version () {\n  var numbers = process.version.replace('v', '').split('.')\n  return {\n    major: parseInt(numbers[0], 10),\n    minor: parseInt(numbers[1], 10),\n    patch: parseInt(numbers[2], 10)\n  }\n}\n\nexports.paramsHaveRequestBody = paramsHaveRequestBody\nexports.safeStringify         = safeStringify\nexports.md5                   = md5\nexports.isReadStream          = isReadStream\nexports.toBase64              = toBase64\nexports.copy                  = copy\nexports.version               = version\nexports.defer                 = defer\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/json-stringify-safe/stringify.js":"exports = module.exports = stringify\nexports.getSerialize = serializer\n\nfunction stringify(obj, replacer, spaces, cycleReplacer) {\n  return JSON.stringify(obj, serializer(replacer, cycleReplacer), spaces)\n}\n\nfunction serializer(replacer, cycleReplacer) {\n  var stack = [], keys = []\n\n  if (cycleReplacer == null) cycleReplacer = function(key, value) {\n    if (stack[0] === value) return \"[Circular ~]\"\n    return \"[Circular ~.\" + keys.slice(0, stack.indexOf(value)).join(\".\") + \"]\"\n  }\n\n  return function(key, value) {\n    if (stack.length > 0) {\n      var thisPos = stack.indexOf(this)\n      ~thisPos ? stack.splice(thisPos + 1) : stack.push(this)\n      ~thisPos ? keys.splice(thisPos, Infinity, key) : keys.push(key)\n      if (~stack.indexOf(value)) value = cycleReplacer.call(this, key, value)\n    }\n    else stack.push(value)\n\n    return replacer == null ? value : replacer.call(this, key, value)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/safe-buffer/index.js":"var buffer = require('buffer')\n\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  Object.keys(buffer).forEach(function (prop) {\n    exports[prop] = buffer[prop]\n  })\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\nObject.keys(Buffer).forEach(function (prop) {\n  SafeBuffer[prop] = Buffer[prop]\n})\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/request.js":"'use strict'\n\nvar http = require('http')\n  , https = require('https')\n  , url = require('url')\n  , util = require('util')\n  , stream = require('stream')\n  , zlib = require('zlib')\n  , hawk = require('hawk')\n  , aws2 = require('aws-sign2')\n  , aws4 = require('aws4')\n  , httpSignature = require('http-signature')\n  , mime = require('mime-types')\n  , stringstream = require('stringstream')\n  , caseless = require('caseless')\n  , ForeverAgent = require('forever-agent')\n  , FormData = require('form-data')\n  , extend = require('extend')\n  , isstream = require('isstream')\n  , isTypedArray = require('is-typedarray').strict\n  , helpers = require('./lib/helpers')\n  , cookies = require('./lib/cookies')\n  , getProxyFromURI = require('./lib/getProxyFromURI')\n  , Querystring = require('./lib/querystring').Querystring\n  , Har = require('./lib/har').Har\n  , Auth = require('./lib/auth').Auth\n  , OAuth = require('./lib/oauth').OAuth\n  , Multipart = require('./lib/multipart').Multipart\n  , Redirect = require('./lib/redirect').Redirect\n  , Tunnel = require('./lib/tunnel').Tunnel\n  , now = require('performance-now')\n  , Buffer = require('safe-buffer').Buffer\n\nvar safeStringify = helpers.safeStringify\n  , isReadStream = helpers.isReadStream\n  , toBase64 = helpers.toBase64\n  , defer = helpers.defer\n  , copy = helpers.copy\n  , version = helpers.version\n  , globalCookieJar = cookies.jar()\n\n\nvar globalPool = {}\n\nfunction filterForNonReserved(reserved, options) {\n  // Filter out properties that are not reserved.\n  // Reserved values are passed in at call site.\n\n  var object = {}\n  for (var i in options) {\n    var notReserved = (reserved.indexOf(i) === -1)\n    if (notReserved) {\n      object[i] = options[i]\n    }\n  }\n  return object\n}\n\nfunction filterOutReservedFunctions(reserved, options) {\n  // Filter out properties that are functions and are reserved.\n  // Reserved values are passed in at call site.\n\n  var object = {}\n  for (var i in options) {\n    var isReserved = !(reserved.indexOf(i) === -1)\n    var isFunction = (typeof options[i] === 'function')\n    if (!(isReserved && isFunction)) {\n      object[i] = options[i]\n    }\n  }\n  return object\n\n}\n\n// Return a simpler request object to allow serialization\nfunction requestToJSON() {\n  var self = this\n  return {\n    uri: self.uri,\n    method: self.method,\n    headers: self.headers\n  }\n}\n\n// Return a simpler response object to allow serialization\nfunction responseToJSON() {\n  var self = this\n  return {\n    statusCode: self.statusCode,\n    body: self.body,\n    headers: self.headers,\n    request: requestToJSON.call(self.request)\n  }\n}\n\nfunction Request (options) {\n  // if given the method property in options, set property explicitMethod to true\n\n  // extend the Request instance with any non-reserved properties\n  // remove any reserved functions from the options object\n  // set Request instance to be readable and writable\n  // call init\n\n  var self = this\n\n  // start with HAR, then override with additional options\n  if (options.har) {\n    self._har = new Har(self)\n    options = self._har.options(options)\n  }\n\n  stream.Stream.call(self)\n  var reserved = Object.keys(Request.prototype)\n  var nonReserved = filterForNonReserved(reserved, options)\n\n  extend(self, nonReserved)\n  options = filterOutReservedFunctions(reserved, options)\n\n  self.readable = true\n  self.writable = true\n  if (options.method) {\n    self.explicitMethod = true\n  }\n  self._qs = new Querystring(self)\n  self._auth = new Auth(self)\n  self._oauth = new OAuth(self)\n  self._multipart = new Multipart(self)\n  self._redirect = new Redirect(self)\n  self._tunnel = new Tunnel(self)\n  self.init(options)\n}\n\nutil.inherits(Request, stream.Stream)\n\n// Debugging\nRequest.debug = process.env.NODE_DEBUG && /\\brequest\\b/.test(process.env.NODE_DEBUG)\nfunction debug() {\n  if (Request.debug) {\n    console.error('REQUEST %s', util.format.apply(util, arguments))\n  }\n}\nRequest.prototype.debug = debug\n\nRequest.prototype.init = function (options) {\n  // init() contains all the code to setup the request object.\n  // the actual outgoing request is not started until start() is called\n  // this function is called from both the constructor and on redirect.\n  var self = this\n  if (!options) {\n    options = {}\n  }\n  self.headers = self.headers ? copy(self.headers) : {}\n\n  // Delete headers with value undefined since they break\n  // ClientRequest.OutgoingMessage.setHeader in node 0.12\n  for (var headerName in self.headers) {\n    if (typeof self.headers[headerName] === 'undefined') {\n      delete self.headers[headerName]\n    }\n  }\n\n  caseless.httpify(self, self.headers)\n\n  if (!self.method) {\n    self.method = options.method || 'GET'\n  }\n  if (!self.localAddress) {\n    self.localAddress = options.localAddress\n  }\n\n  self._qs.init(options)\n\n  debug(options)\n  if (!self.pool && self.pool !== false) {\n    self.pool = globalPool\n  }\n  self.dests = self.dests || []\n  self.__isRequestRequest = true\n\n  // Protect against double callback\n  if (!self._callback && self.callback) {\n    self._callback = self.callback\n    self.callback = function () {\n      if (self._callbackCalled) {\n        return // Print a warning maybe?\n      }\n      self._callbackCalled = true\n      self._callback.apply(self, arguments)\n    }\n    self.on('error', self.callback.bind())\n    self.on('complete', self.callback.bind(self, null))\n  }\n\n  // People use this property instead all the time, so support it\n  if (!self.uri && self.url) {\n    self.uri = self.url\n    delete self.url\n  }\n\n  // If there's a baseUrl, then use it as the base URL (i.e. uri must be\n  // specified as a relative path and is appended to baseUrl).\n  if (self.baseUrl) {\n    if (typeof self.baseUrl !== 'string') {\n      return self.emit('error', new Error('options.baseUrl must be a string'))\n    }\n\n    if (typeof self.uri !== 'string') {\n      return self.emit('error', new Error('options.uri must be a string when using options.baseUrl'))\n    }\n\n    if (self.uri.indexOf('//') === 0 || self.uri.indexOf('://') !== -1) {\n      return self.emit('error', new Error('options.uri must be a path when using options.baseUrl'))\n    }\n\n    // Handle all cases to make sure that there's only one slash between\n    // baseUrl and uri.\n    var baseUrlEndsWithSlash = self.baseUrl.lastIndexOf('/') === self.baseUrl.length - 1\n    var uriStartsWithSlash = self.uri.indexOf('/') === 0\n\n    if (baseUrlEndsWithSlash && uriStartsWithSlash) {\n      self.uri = self.baseUrl + self.uri.slice(1)\n    } else if (baseUrlEndsWithSlash || uriStartsWithSlash) {\n      self.uri = self.baseUrl + self.uri\n    } else if (self.uri === '') {\n      self.uri = self.baseUrl\n    } else {\n      self.uri = self.baseUrl + '/' + self.uri\n    }\n    delete self.baseUrl\n  }\n\n  // A URI is needed by this point, emit error if we haven't been able to get one\n  if (!self.uri) {\n    return self.emit('error', new Error('options.uri is a required argument'))\n  }\n\n  // If a string URI/URL was given, parse it into a URL object\n  if (typeof self.uri === 'string') {\n    self.uri = url.parse(self.uri)\n  }\n\n  // Some URL objects are not from a URL parsed string and need href added\n  if (!self.uri.href) {\n    self.uri.href = url.format(self.uri)\n  }\n\n  // DEPRECATED: Warning for users of the old Unix Sockets URL Scheme\n  if (self.uri.protocol === 'unix:') {\n    return self.emit('error', new Error('`unix://` URL scheme is no longer supported. Please use the format `http://unix:SOCKET:PATH`'))\n  }\n\n  // Support Unix Sockets\n  if (self.uri.host === 'unix') {\n    self.enableUnixSocket()\n  }\n\n  if (self.strictSSL === false) {\n    self.rejectUnauthorized = false\n  }\n\n  if (!self.uri.pathname) {self.uri.pathname = '/'}\n\n  if (!(self.uri.host || (self.uri.hostname && self.uri.port)) && !self.uri.isUnix) {\n    // Invalid URI: it may generate lot of bad errors, like 'TypeError: Cannot call method `indexOf` of undefined' in CookieJar\n    // Detect and reject it as soon as possible\n    var faultyUri = url.format(self.uri)\n    var message = 'Invalid URI \"' + faultyUri + '\"'\n    if (Object.keys(options).length === 0) {\n      // No option ? This can be the sign of a redirect\n      // As this is a case where the user cannot do anything (they didn't call request directly with this URL)\n      // they should be warned that it can be caused by a redirection (can save some hair)\n      message += '. This can be caused by a crappy redirection.'\n    }\n    // This error was fatal\n    self.abort()\n    return self.emit('error', new Error(message))\n  }\n\n  if (!self.hasOwnProperty('proxy')) {\n    self.proxy = getProxyFromURI(self.uri)\n  }\n\n  self.tunnel = self._tunnel.isEnabled()\n  if (self.proxy) {\n    self._tunnel.setup(options)\n  }\n\n  self._redirect.onRequest(options)\n\n  self.setHost = false\n  if (!self.hasHeader('host')) {\n    var hostHeaderName = self.originalHostHeaderName || 'host'\n    // When used with an IPv6 address, `host` will provide\n    // the correct bracketed format, unlike using `hostname` and\n    // optionally adding the `port` when necessary.\n    self.setHeader(hostHeaderName, self.uri.host)\n    self.setHost = true\n  }\n\n  self.jar(self._jar || options.jar)\n\n  if (!self.uri.port) {\n    if (self.uri.protocol === 'http:') {self.uri.port = 80}\n    else if (self.uri.protocol === 'https:') {self.uri.port = 443}\n  }\n\n  if (self.proxy && !self.tunnel) {\n    self.port = self.proxy.port\n    self.host = self.proxy.hostname\n  } else {\n    self.port = self.uri.port\n    self.host = self.uri.hostname\n  }\n\n  if (options.form) {\n    self.form(options.form)\n  }\n\n  if (options.formData) {\n    var formData = options.formData\n    var requestForm = self.form()\n    var appendFormValue = function (key, value) {\n      if (value && value.hasOwnProperty('value') && value.hasOwnProperty('options')) {\n        requestForm.append(key, value.value, value.options)\n      } else {\n        requestForm.append(key, value)\n      }\n    }\n    for (var formKey in formData) {\n      if (formData.hasOwnProperty(formKey)) {\n        var formValue = formData[formKey]\n        if (formValue instanceof Array) {\n          for (var j = 0; j < formValue.length; j++) {\n            appendFormValue(formKey, formValue[j])\n          }\n        } else {\n          appendFormValue(formKey, formValue)\n        }\n      }\n    }\n  }\n\n  if (options.qs) {\n    self.qs(options.qs)\n  }\n\n  if (self.uri.path) {\n    self.path = self.uri.path\n  } else {\n    self.path = self.uri.pathname + (self.uri.search || '')\n  }\n\n  if (self.path.length === 0) {\n    self.path = '/'\n  }\n\n  // Auth must happen last in case signing is dependent on other headers\n  if (options.aws) {\n    self.aws(options.aws)\n  }\n\n  if (options.hawk) {\n    self.hawk(options.hawk)\n  }\n\n  if (options.httpSignature) {\n    self.httpSignature(options.httpSignature)\n  }\n\n  if (options.auth) {\n    if (Object.prototype.hasOwnProperty.call(options.auth, 'username')) {\n      options.auth.user = options.auth.username\n    }\n    if (Object.prototype.hasOwnProperty.call(options.auth, 'password')) {\n      options.auth.pass = options.auth.password\n    }\n\n    self.auth(\n      options.auth.user,\n      options.auth.pass,\n      options.auth.sendImmediately,\n      options.auth.bearer\n    )\n  }\n\n  if (self.gzip && !self.hasHeader('accept-encoding')) {\n    self.setHeader('accept-encoding', 'gzip, deflate')\n  }\n\n  if (self.uri.auth && !self.hasHeader('authorization')) {\n    var uriAuthPieces = self.uri.auth.split(':').map(function(item) {return self._qs.unescape(item)})\n    self.auth(uriAuthPieces[0], uriAuthPieces.slice(1).join(':'), true)\n  }\n\n  if (!self.tunnel && self.proxy && self.proxy.auth && !self.hasHeader('proxy-authorization')) {\n    var proxyAuthPieces = self.proxy.auth.split(':').map(function(item) {return self._qs.unescape(item)})\n    var authHeader = 'Basic ' + toBase64(proxyAuthPieces.join(':'))\n    self.setHeader('proxy-authorization', authHeader)\n  }\n\n  if (self.proxy && !self.tunnel) {\n    self.path = (self.uri.protocol + '//' + self.uri.host + self.path)\n  }\n\n  if (options.json) {\n    self.json(options.json)\n  }\n  if (options.multipart) {\n    self.multipart(options.multipart)\n  }\n\n  if (options.time) {\n    self.timing = true\n\n    // NOTE: elapsedTime is deprecated in favor of .timings\n    self.elapsedTime = self.elapsedTime || 0\n  }\n\n  function setContentLength () {\n    if (isTypedArray(self.body)) {\n      self.body = Buffer.from(self.body)\n    }\n\n    if (!self.hasHeader('content-length')) {\n      var length\n      if (typeof self.body === 'string') {\n        length = Buffer.byteLength(self.body)\n      }\n      else if (Array.isArray(self.body)) {\n        length = self.body.reduce(function (a, b) {return a + b.length}, 0)\n      }\n      else {\n        length = self.body.length\n      }\n\n      if (length) {\n        self.setHeader('content-length', length)\n      } else {\n        self.emit('error', new Error('Argument error, options.body.'))\n      }\n    }\n  }\n  if (self.body && !isstream(self.body)) {\n    setContentLength()\n  }\n\n  if (options.oauth) {\n    self.oauth(options.oauth)\n  } else if (self._oauth.params && self.hasHeader('authorization')) {\n    self.oauth(self._oauth.params)\n  }\n\n  var protocol = self.proxy && !self.tunnel ? self.proxy.protocol : self.uri.protocol\n    , defaultModules = {'http:':http, 'https:':https}\n    , httpModules = self.httpModules || {}\n\n  self.httpModule = httpModules[protocol] || defaultModules[protocol]\n\n  if (!self.httpModule) {\n    return self.emit('error', new Error('Invalid protocol: ' + protocol))\n  }\n\n  if (options.ca) {\n    self.ca = options.ca\n  }\n\n  if (!self.agent) {\n    if (options.agentOptions) {\n      self.agentOptions = options.agentOptions\n    }\n\n    if (options.agentClass) {\n      self.agentClass = options.agentClass\n    } else if (options.forever) {\n      var v = version()\n      // use ForeverAgent in node 0.10- only\n      if (v.major === 0 && v.minor <= 10) {\n        self.agentClass = protocol === 'http:' ? ForeverAgent : ForeverAgent.SSL\n      } else {\n        self.agentClass = self.httpModule.Agent\n        self.agentOptions = self.agentOptions || {}\n        self.agentOptions.keepAlive = true\n      }\n    } else {\n      self.agentClass = self.httpModule.Agent\n    }\n  }\n\n  if (self.pool === false) {\n    self.agent = false\n  } else {\n    self.agent = self.agent || self.getNewAgent()\n  }\n\n  self.on('pipe', function (src) {\n    if (self.ntick && self._started) {\n      self.emit('error', new Error('You cannot pipe to this stream after the outbound request has started.'))\n    }\n    self.src = src\n    if (isReadStream(src)) {\n      if (!self.hasHeader('content-type')) {\n        self.setHeader('content-type', mime.lookup(src.path))\n      }\n    } else {\n      if (src.headers) {\n        for (var i in src.headers) {\n          if (!self.hasHeader(i)) {\n            self.setHeader(i, src.headers[i])\n          }\n        }\n      }\n      if (self._json && !self.hasHeader('content-type')) {\n        self.setHeader('content-type', 'application/json')\n      }\n      if (src.method && !self.explicitMethod) {\n        self.method = src.method\n      }\n    }\n\n    // self.on('pipe', function () {\n    //   console.error('You have already piped to this stream. Pipeing twice is likely to break the request.')\n    // })\n  })\n\n  defer(function () {\n    if (self._aborted) {\n      return\n    }\n\n    var end = function () {\n      if (self._form) {\n        if (!self._auth.hasAuth) {\n          self._form.pipe(self)\n        }\n        else if (self._auth.hasAuth && self._auth.sentAuth) {\n          self._form.pipe(self)\n        }\n      }\n      if (self._multipart && self._multipart.chunked) {\n        self._multipart.body.pipe(self)\n      }\n      if (self.body) {\n        if (isstream(self.body)) {\n          self.body.pipe(self)\n        } else {\n          setContentLength()\n          if (Array.isArray(self.body)) {\n            self.body.forEach(function (part) {\n              self.write(part)\n            })\n          } else {\n            self.write(self.body)\n          }\n          self.end()\n        }\n      } else if (self.requestBodyStream) {\n        console.warn('options.requestBodyStream is deprecated, please pass the request object to stream.pipe.')\n        self.requestBodyStream.pipe(self)\n      } else if (!self.src) {\n        if (self._auth.hasAuth && !self._auth.sentAuth) {\n          self.end()\n          return\n        }\n        if (self.method !== 'GET' && typeof self.method !== 'undefined') {\n          self.setHeader('content-length', 0)\n        }\n        self.end()\n      }\n    }\n\n    if (self._form && !self.hasHeader('content-length')) {\n      // Before ending the request, we had to compute the length of the whole form, asyncly\n      self.setHeader(self._form.getHeaders(), true)\n      self._form.getLength(function (err, length) {\n        if (!err && !isNaN(length)) {\n          self.setHeader('content-length', length)\n        }\n        end()\n      })\n    } else {\n      end()\n    }\n\n    self.ntick = true\n  })\n\n}\n\nRequest.prototype.getNewAgent = function () {\n  var self = this\n  var Agent = self.agentClass\n  var options = {}\n  if (self.agentOptions) {\n    for (var i in self.agentOptions) {\n      options[i] = self.agentOptions[i]\n    }\n  }\n  if (self.ca) {\n    options.ca = self.ca\n  }\n  if (self.ciphers) {\n    options.ciphers = self.ciphers\n  }\n  if (self.secureProtocol) {\n    options.secureProtocol = self.secureProtocol\n  }\n  if (self.secureOptions) {\n    options.secureOptions = self.secureOptions\n  }\n  if (typeof self.rejectUnauthorized !== 'undefined') {\n    options.rejectUnauthorized = self.rejectUnauthorized\n  }\n\n  if (self.cert && self.key) {\n    options.key = self.key\n    options.cert = self.cert\n  }\n\n  if (self.pfx) {\n    options.pfx = self.pfx\n  }\n\n  if (self.passphrase) {\n    options.passphrase = self.passphrase\n  }\n\n  var poolKey = ''\n\n  // different types of agents are in different pools\n  if (Agent !== self.httpModule.Agent) {\n    poolKey += Agent.name\n  }\n\n  // ca option is only relevant if proxy or destination are https\n  var proxy = self.proxy\n  if (typeof proxy === 'string') {\n    proxy = url.parse(proxy)\n  }\n  var isHttps = (proxy && proxy.protocol === 'https:') || this.uri.protocol === 'https:'\n\n  if (isHttps) {\n    if (options.ca) {\n      if (poolKey) {\n        poolKey += ':'\n      }\n      poolKey += options.ca\n    }\n\n    if (typeof options.rejectUnauthorized !== 'undefined') {\n      if (poolKey) {\n        poolKey += ':'\n      }\n      poolKey += options.rejectUnauthorized\n    }\n\n    if (options.cert) {\n      if (poolKey) {\n        poolKey += ':'\n      }\n      poolKey += options.cert.toString('ascii') + options.key.toString('ascii')\n    }\n\n    if (options.pfx) {\n      if (poolKey) {\n        poolKey += ':'\n      }\n      poolKey += options.pfx.toString('ascii')\n    }\n\n    if (options.ciphers) {\n      if (poolKey) {\n        poolKey += ':'\n      }\n      poolKey += options.ciphers\n    }\n\n    if (options.secureProtocol) {\n      if (poolKey) {\n        poolKey += ':'\n      }\n      poolKey += options.secureProtocol\n    }\n\n    if (options.secureOptions) {\n      if (poolKey) {\n        poolKey += ':'\n      }\n      poolKey += options.secureOptions\n    }\n  }\n\n  if (self.pool === globalPool && !poolKey && Object.keys(options).length === 0 && self.httpModule.globalAgent) {\n    // not doing anything special.  Use the globalAgent\n    return self.httpModule.globalAgent\n  }\n\n  // we're using a stored agent.  Make sure it's protocol-specific\n  poolKey = self.uri.protocol + poolKey\n\n  // generate a new agent for this setting if none yet exists\n  if (!self.pool[poolKey]) {\n    self.pool[poolKey] = new Agent(options)\n    // properly set maxSockets on new agents\n    if (self.pool.maxSockets) {\n      self.pool[poolKey].maxSockets = self.pool.maxSockets\n    }\n  }\n\n  return self.pool[poolKey]\n}\n\nRequest.prototype.start = function () {\n  // start() is called once we are ready to send the outgoing HTTP request.\n  // this is usually called on the first write(), end() or on nextTick()\n  var self = this\n\n  if (self.timing) {\n    // All timings will be relative to this request's startTime.  In order to do this,\n    // we need to capture the wall-clock start time (via Date), immediately followed\n    // by the high-resolution timer (via now()).  While these two won't be set\n    // at the _exact_ same time, they should be close enough to be able to calculate\n    // high-resolution, monotonically non-decreasing timestamps relative to startTime.\n    var startTime = new Date().getTime()\n    var startTimeNow = now()\n  }\n\n  if (self._aborted) {\n    return\n  }\n\n  self._started = true\n  self.method = self.method || 'GET'\n  self.href = self.uri.href\n\n  if (self.src && self.src.stat && self.src.stat.size && !self.hasHeader('content-length')) {\n    self.setHeader('content-length', self.src.stat.size)\n  }\n  if (self._aws) {\n    self.aws(self._aws, true)\n  }\n\n  // We have a method named auth, which is completely different from the http.request\n  // auth option.  If we don't remove it, we're gonna have a bad time.\n  var reqOptions = copy(self)\n  delete reqOptions.auth\n\n  debug('make request', self.uri.href)\n\n  // node v6.8.0 now supports a `timeout` value in `http.request()`, but we\n  // should delete it for now since we handle timeouts manually for better\n  // consistency with node versions before v6.8.0\n  delete reqOptions.timeout\n\n  try {\n    self.req = self.httpModule.request(reqOptions)\n  } catch (err) {\n    self.emit('error', err)\n    return\n  }\n\n  if (self.timing) {\n    self.startTime = startTime\n    self.startTimeNow = startTimeNow\n\n    // Timing values will all be relative to startTime (by comparing to startTimeNow\n    // so we have an accurate clock)\n    self.timings = {}\n  }\n\n  var timeout\n  if (self.timeout && !self.timeoutTimer) {\n    if (self.timeout < 0) {\n      timeout = 0\n    } else if (typeof self.timeout === 'number' && isFinite(self.timeout)) {\n      timeout = self.timeout\n    }\n  }\n\n  self.req.on('response', self.onRequestResponse.bind(self))\n  self.req.on('error', self.onRequestError.bind(self))\n  self.req.on('drain', function() {\n    self.emit('drain')\n  })\n  self.req.on('socket', function(socket) {\n    // `._connecting` was the old property which was made public in node v6.1.0\n    var isConnecting = socket._connecting || socket.connecting\n    if (self.timing) {\n      self.timings.socket = now() - self.startTimeNow\n\n      if (isConnecting) {\n        var onLookupTiming = function() {\n          self.timings.lookup = now() - self.startTimeNow\n        }\n\n        var onConnectTiming = function() {\n          self.timings.connect = now() - self.startTimeNow\n        }\n\n        socket.once('lookup', onLookupTiming)\n        socket.once('connect', onConnectTiming)\n\n        // clean up timing event listeners if needed on error\n        self.req.once('error', function() {\n          socket.removeListener('lookup', onLookupTiming)\n          socket.removeListener('connect', onConnectTiming)\n        })\n      }\n    }\n\n    var setReqTimeout = function() {\n      // This timeout sets the amount of time to wait *between* bytes sent\n      // from the server once connected.\n      //\n      // In particular, it's useful for erroring if the server fails to send\n      // data halfway through streaming a response.\n      self.req.setTimeout(timeout, function () {\n        if (self.req) {\n          self.abort()\n          var e = new Error('ESOCKETTIMEDOUT')\n          e.code = 'ESOCKETTIMEDOUT'\n          e.connect = false\n          self.emit('error', e)\n        }\n      })\n    }\n    if (timeout !== undefined) {\n      // Only start the connection timer if we're actually connecting a new\n      // socket, otherwise if we're already connected (because this is a\n      // keep-alive connection) do not bother. This is important since we won't\n      // get a 'connect' event for an already connected socket.\n      if (isConnecting) {\n        var onReqSockConnect = function() {\n          socket.removeListener('connect', onReqSockConnect)\n          clearTimeout(self.timeoutTimer)\n          self.timeoutTimer = null\n          setReqTimeout()\n        }\n\n        socket.on('connect', onReqSockConnect)\n\n        self.req.on('error', function(err) {\n          socket.removeListener('connect', onReqSockConnect)\n        })\n\n        // Set a timeout in memory - this block will throw if the server takes more\n        // than `timeout` to write the HTTP status and headers (corresponding to\n        // the on('response') event on the client). NB: this measures wall-clock\n        // time, not the time between bytes sent by the server.\n        self.timeoutTimer = setTimeout(function () {\n          socket.removeListener('connect', onReqSockConnect)\n          self.abort()\n          var e = new Error('ETIMEDOUT')\n          e.code = 'ETIMEDOUT'\n          e.connect = true\n          self.emit('error', e)\n        }, timeout)\n      } else {\n        // We're already connected\n        setReqTimeout()\n      }\n    }\n    self.emit('socket', socket)\n  })\n\n  self.emit('request', self.req)\n}\n\nRequest.prototype.onRequestError = function (error) {\n  var self = this\n  if (self._aborted) {\n    return\n  }\n  if (self.req && self.req._reusedSocket && error.code === 'ECONNRESET'\n      && self.agent.addRequestNoreuse) {\n    self.agent = { addRequest: self.agent.addRequestNoreuse.bind(self.agent) }\n    self.start()\n    self.req.end()\n    return\n  }\n  if (self.timeout && self.timeoutTimer) {\n    clearTimeout(self.timeoutTimer)\n    self.timeoutTimer = null\n  }\n  self.emit('error', error)\n}\n\nRequest.prototype.onRequestResponse = function (response) {\n  var self = this\n\n  if (self.timing) {\n    self.timings.response = now() - self.startTimeNow\n  }\n\n  debug('onRequestResponse', self.uri.href, response.statusCode, response.headers)\n  response.on('end', function() {\n    if (self.timing) {\n      self.timings.end = now() - self.startTimeNow\n      response.timingStart = self.startTime\n\n      // fill in the blanks for any periods that didn't trigger, such as\n      // no lookup or connect due to keep alive\n      if (!self.timings.socket) {\n        self.timings.socket = 0\n      }\n      if (!self.timings.lookup) {\n        self.timings.lookup = self.timings.socket\n      }\n      if (!self.timings.connect) {\n        self.timings.connect = self.timings.lookup\n      }\n      if (!self.timings.response) {\n        self.timings.response = self.timings.connect\n      }\n\n      debug('elapsed time', self.timings.end)\n\n      // elapsedTime includes all redirects\n      self.elapsedTime += Math.round(self.timings.end)\n\n      // NOTE: elapsedTime is deprecated in favor of .timings\n      response.elapsedTime = self.elapsedTime\n\n      // timings is just for the final fetch\n      response.timings = self.timings\n\n      // pre-calculate phase timings as well\n      response.timingPhases = {\n        wait: self.timings.socket,\n        dns: self.timings.lookup - self.timings.socket,\n        tcp: self.timings.connect - self.timings.lookup,\n        firstByte: self.timings.response - self.timings.connect,\n        download: self.timings.end - self.timings.response,\n        total: self.timings.end\n      }\n    }\n    debug('response end', self.uri.href, response.statusCode, response.headers)\n  })\n\n  if (self._aborted) {\n    debug('aborted', self.uri.href)\n    response.resume()\n    return\n  }\n\n  self.response = response\n  response.request = self\n  response.toJSON = responseToJSON\n\n  // XXX This is different on 0.10, because SSL is strict by default\n  if (self.httpModule === https &&\n      self.strictSSL && (!response.hasOwnProperty('socket') ||\n      !response.socket.authorized)) {\n    debug('strict ssl error', self.uri.href)\n    var sslErr = response.hasOwnProperty('socket') ? response.socket.authorizationError : self.uri.href + ' does not support SSL'\n    self.emit('error', new Error('SSL Error: ' + sslErr))\n    return\n  }\n\n  // Save the original host before any redirect (if it changes, we need to\n  // remove any authorization headers).  Also remember the case of the header\n  // name because lots of broken servers expect Host instead of host and we\n  // want the caller to be able to specify this.\n  self.originalHost = self.getHeader('host')\n  if (!self.originalHostHeaderName) {\n    self.originalHostHeaderName = self.hasHeader('host')\n  }\n  if (self.setHost) {\n    self.removeHeader('host')\n  }\n  if (self.timeout && self.timeoutTimer) {\n    clearTimeout(self.timeoutTimer)\n    self.timeoutTimer = null\n  }\n\n  var targetCookieJar = (self._jar && self._jar.setCookie) ? self._jar : globalCookieJar\n  var addCookie = function (cookie) {\n    //set the cookie if it's domain in the href's domain.\n    try {\n      targetCookieJar.setCookie(cookie, self.uri.href, {ignoreError: true})\n    } catch (e) {\n      self.emit('error', e)\n    }\n  }\n\n  response.caseless = caseless(response.headers)\n\n  if (response.caseless.has('set-cookie') && (!self._disableCookies)) {\n    var headerName = response.caseless.has('set-cookie')\n    if (Array.isArray(response.headers[headerName])) {\n      response.headers[headerName].forEach(addCookie)\n    } else {\n      addCookie(response.headers[headerName])\n    }\n  }\n\n  if (self._redirect.onResponse(response)) {\n    return // Ignore the rest of the response\n  } else {\n    // Be a good stream and emit end when the response is finished.\n    // Hack to emit end on close because of a core bug that never fires end\n    response.on('close', function () {\n      if (!self._ended) {\n        self.response.emit('end')\n      }\n    })\n\n    response.once('end', function () {\n      self._ended = true\n    })\n\n    var noBody = function (code) {\n      return (\n        self.method === 'HEAD'\n        // Informational\n        || (code >= 100 && code < 200)\n        // No Content\n        || code === 204\n        // Not Modified\n        || code === 304\n      )\n    }\n\n    var responseContent\n    if (self.gzip && !noBody(response.statusCode)) {\n      var contentEncoding = response.headers['content-encoding'] || 'identity'\n      contentEncoding = contentEncoding.trim().toLowerCase()\n\n      // Be more lenient with decoding compressed responses, since (very rarely)\n      // servers send slightly invalid gzip responses that are still accepted\n      // by common browsers.\n      // Always using Z_SYNC_FLUSH is what cURL does.\n      var zlibOptions = {\n        flush: zlib.Z_SYNC_FLUSH\n      , finishFlush: zlib.Z_SYNC_FLUSH\n      }\n\n      if (contentEncoding === 'gzip') {\n        responseContent = zlib.createGunzip(zlibOptions)\n        response.pipe(responseContent)\n      } else if (contentEncoding === 'deflate') {\n        responseContent = zlib.createInflate(zlibOptions)\n        response.pipe(responseContent)\n      } else {\n        // Since previous versions didn't check for Content-Encoding header,\n        // ignore any invalid values to preserve backwards-compatibility\n        if (contentEncoding !== 'identity') {\n          debug('ignoring unrecognized Content-Encoding ' + contentEncoding)\n        }\n        responseContent = response\n      }\n    } else {\n      responseContent = response\n    }\n\n    if (self.encoding) {\n      if (self.dests.length !== 0) {\n        console.error('Ignoring encoding parameter as this stream is being piped to another stream which makes the encoding option invalid.')\n      } else if (responseContent.setEncoding) {\n        responseContent.setEncoding(self.encoding)\n      } else {\n        // Should only occur on node pre-v0.9.4 (joyent/node@9b5abe5) with\n        // zlib streams.\n        // If/When support for 0.9.4 is dropped, this should be unnecessary.\n        responseContent = responseContent.pipe(stringstream(self.encoding))\n      }\n    }\n\n    if (self._paused) {\n      responseContent.pause()\n    }\n\n    self.responseContent = responseContent\n\n    self.emit('response', response)\n\n    self.dests.forEach(function (dest) {\n      self.pipeDest(dest)\n    })\n\n    responseContent.on('data', function (chunk) {\n      if (self.timing && !self.responseStarted) {\n        self.responseStartTime = (new Date()).getTime()\n\n        // NOTE: responseStartTime is deprecated in favor of .timings\n        response.responseStartTime = self.responseStartTime\n      }\n      self._destdata = true\n      self.emit('data', chunk)\n    })\n    responseContent.once('end', function (chunk) {\n      self.emit('end', chunk)\n    })\n    responseContent.on('error', function (error) {\n      self.emit('error', error)\n    })\n    responseContent.on('close', function () {self.emit('close')})\n\n    if (self.callback) {\n      self.readResponseBody(response)\n    }\n    //if no callback\n    else {\n      self.on('end', function () {\n        if (self._aborted) {\n          debug('aborted', self.uri.href)\n          return\n        }\n        self.emit('complete', response)\n      })\n    }\n  }\n  debug('finish init function', self.uri.href)\n}\n\nRequest.prototype.readResponseBody = function (response) {\n  var self = this\n  debug('reading response\\'s body')\n  var buffers = []\n    , bufferLength = 0\n    , strings = []\n\n  self.on('data', function (chunk) {\n    if (!Buffer.isBuffer(chunk)) {\n      strings.push(chunk)\n    } else if (chunk.length) {\n      bufferLength += chunk.length\n      buffers.push(chunk)\n    }\n  })\n  self.on('end', function () {\n    debug('end event', self.uri.href)\n    if (self._aborted) {\n      debug('aborted', self.uri.href)\n      // `buffer` is defined in the parent scope and used in a closure it exists for the life of the request.\n      // This can lead to leaky behavior if the user retains a reference to the request object.\n      buffers = []\n      bufferLength = 0\n      return\n    }\n\n    if (bufferLength) {\n      debug('has body', self.uri.href, bufferLength)\n      response.body = Buffer.concat(buffers, bufferLength)\n      if (self.encoding !== null) {\n        response.body = response.body.toString(self.encoding)\n      }\n      // `buffer` is defined in the parent scope and used in a closure it exists for the life of the Request.\n      // This can lead to leaky behavior if the user retains a reference to the request object.\n      buffers = []\n      bufferLength = 0\n    } else if (strings.length) {\n      // The UTF8 BOM [0xEF,0xBB,0xBF] is converted to [0xFE,0xFF] in the JS UTC16/UCS2 representation.\n      // Strip this value out when the encoding is set to 'utf8', as upstream consumers won't expect it and it breaks JSON.parse().\n      if (self.encoding === 'utf8' && strings[0].length > 0 && strings[0][0] === '\\uFEFF') {\n        strings[0] = strings[0].substring(1)\n      }\n      response.body = strings.join('')\n    }\n\n    if (self._json) {\n      try {\n        response.body = JSON.parse(response.body, self._jsonReviver)\n      } catch (e) {\n        debug('invalid JSON received', self.uri.href)\n      }\n    }\n    debug('emitting complete', self.uri.href)\n    if (typeof response.body === 'undefined' && !self._json) {\n      response.body = self.encoding === null ? Buffer.alloc(0) : ''\n    }\n    self.emit('complete', response, response.body)\n  })\n}\n\nRequest.prototype.abort = function () {\n  var self = this\n  self._aborted = true\n\n  if (self.req) {\n    self.req.abort()\n  }\n  else if (self.response) {\n    self.response.destroy()\n  }\n\n  self.emit('abort')\n}\n\nRequest.prototype.pipeDest = function (dest) {\n  var self = this\n  var response = self.response\n  // Called after the response is received\n  if (dest.headers && !dest.headersSent) {\n    if (response.caseless.has('content-type')) {\n      var ctname = response.caseless.has('content-type')\n      if (dest.setHeader) {\n        dest.setHeader(ctname, response.headers[ctname])\n      }\n      else {\n        dest.headers[ctname] = response.headers[ctname]\n      }\n    }\n\n    if (response.caseless.has('content-length')) {\n      var clname = response.caseless.has('content-length')\n      if (dest.setHeader) {\n        dest.setHeader(clname, response.headers[clname])\n      } else {\n        dest.headers[clname] = response.headers[clname]\n      }\n    }\n  }\n  if (dest.setHeader && !dest.headersSent) {\n    for (var i in response.headers) {\n      // If the response content is being decoded, the Content-Encoding header\n      // of the response doesn't represent the piped content, so don't pass it.\n      if (!self.gzip || i !== 'content-encoding') {\n        dest.setHeader(i, response.headers[i])\n      }\n    }\n    dest.statusCode = response.statusCode\n  }\n  if (self.pipefilter) {\n    self.pipefilter(response, dest)\n  }\n}\n\nRequest.prototype.qs = function (q, clobber) {\n  var self = this\n  var base\n  if (!clobber && self.uri.query) {\n    base = self._qs.parse(self.uri.query)\n  } else {\n    base = {}\n  }\n\n  for (var i in q) {\n    base[i] = q[i]\n  }\n\n  var qs = self._qs.stringify(base)\n\n  if (qs === '') {\n    return self\n  }\n\n  self.uri = url.parse(self.uri.href.split('?')[0] + '?' + qs)\n  self.url = self.uri\n  self.path = self.uri.path\n\n  if (self.uri.host === 'unix') {\n    self.enableUnixSocket()\n  }\n\n  return self\n}\nRequest.prototype.form = function (form) {\n  var self = this\n  if (form) {\n    if (!/^application\\/x-www-form-urlencoded\\b/.test(self.getHeader('content-type'))) {\n      self.setHeader('content-type', 'application/x-www-form-urlencoded')\n    }\n    self.body = (typeof form === 'string')\n      ? self._qs.rfc3986(form.toString('utf8'))\n      : self._qs.stringify(form).toString('utf8')\n    return self\n  }\n  // create form-data object\n  self._form = new FormData()\n  self._form.on('error', function(err) {\n    err.message = 'form-data: ' + err.message\n    self.emit('error', err)\n    self.abort()\n  })\n  return self._form\n}\nRequest.prototype.multipart = function (multipart) {\n  var self = this\n\n  self._multipart.onRequest(multipart)\n\n  if (!self._multipart.chunked) {\n    self.body = self._multipart.body\n  }\n\n  return self\n}\nRequest.prototype.json = function (val) {\n  var self = this\n\n  if (!self.hasHeader('accept')) {\n    self.setHeader('accept', 'application/json')\n  }\n\n  if (typeof self.jsonReplacer === 'function') {\n    self._jsonReplacer = self.jsonReplacer\n  }\n\n  self._json = true\n  if (typeof val === 'boolean') {\n    if (self.body !== undefined) {\n      if (!/^application\\/x-www-form-urlencoded\\b/.test(self.getHeader('content-type'))) {\n        self.body = safeStringify(self.body, self._jsonReplacer)\n      } else {\n        self.body = self._qs.rfc3986(self.body)\n      }\n      if (!self.hasHeader('content-type')) {\n        self.setHeader('content-type', 'application/json')\n      }\n    }\n  } else {\n    self.body = safeStringify(val, self._jsonReplacer)\n    if (!self.hasHeader('content-type')) {\n      self.setHeader('content-type', 'application/json')\n    }\n  }\n\n  if (typeof self.jsonReviver === 'function') {\n    self._jsonReviver = self.jsonReviver\n  }\n\n  return self\n}\nRequest.prototype.getHeader = function (name, headers) {\n  var self = this\n  var result, re, match\n  if (!headers) {\n    headers = self.headers\n  }\n  Object.keys(headers).forEach(function (key) {\n    if (key.length !== name.length) {\n      return\n    }\n    re = new RegExp(name, 'i')\n    match = key.match(re)\n    if (match) {\n      result = headers[key]\n    }\n  })\n  return result\n}\nRequest.prototype.enableUnixSocket = function () {\n  // Get the socket & request paths from the URL\n  var unixParts = this.uri.path.split(':')\n    , host = unixParts[0]\n    , path = unixParts[1]\n  // Apply unix properties to request\n  this.socketPath = host\n  this.uri.pathname = path\n  this.uri.path = path\n  this.uri.host = host\n  this.uri.hostname = host\n  this.uri.isUnix = true\n}\n\n\nRequest.prototype.auth = function (user, pass, sendImmediately, bearer) {\n  var self = this\n\n  self._auth.onRequest(user, pass, sendImmediately, bearer)\n\n  return self\n}\nRequest.prototype.aws = function (opts, now) {\n  var self = this\n\n  if (!now) {\n    self._aws = opts\n    return self\n  }\n\n  if (opts.sign_version == 4 || opts.sign_version == '4') {\n    // use aws4\n    var options = {\n      host: self.uri.host,\n      path: self.uri.path,\n      method: self.method,\n      headers: {\n        'content-type': self.getHeader('content-type') || ''\n      },\n      body: self.body\n    }\n    var signRes = aws4.sign(options, {\n      accessKeyId: opts.key,\n      secretAccessKey: opts.secret,\n      sessionToken: opts.session\n    })\n    self.setHeader('authorization', signRes.headers.Authorization)\n    self.setHeader('x-amz-date', signRes.headers['X-Amz-Date'])\n    if (signRes.headers['X-Amz-Security-Token']) {\n      self.setHeader('x-amz-security-token', signRes.headers['X-Amz-Security-Token'])\n    }\n  }\n  else {\n    // default: use aws-sign2\n    var date = new Date()\n    self.setHeader('date', date.toUTCString())\n    var auth =\n      { key: opts.key\n      , secret: opts.secret\n      , verb: self.method.toUpperCase()\n      , date: date\n      , contentType: self.getHeader('content-type') || ''\n      , md5: self.getHeader('content-md5') || ''\n      , amazonHeaders: aws2.canonicalizeHeaders(self.headers)\n      }\n    var path = self.uri.path\n    if (opts.bucket && path) {\n      auth.resource = '/' + opts.bucket + path\n    } else if (opts.bucket && !path) {\n      auth.resource = '/' + opts.bucket\n    } else if (!opts.bucket && path) {\n      auth.resource = path\n    } else if (!opts.bucket && !path) {\n      auth.resource = '/'\n    }\n    auth.resource = aws2.canonicalizeResource(auth.resource)\n    self.setHeader('authorization', aws2.authorization(auth))\n  }\n\n  return self\n}\nRequest.prototype.httpSignature = function (opts) {\n  var self = this\n  httpSignature.signRequest({\n    getHeader: function(header) {\n      return self.getHeader(header, self.headers)\n    },\n    setHeader: function(header, value) {\n      self.setHeader(header, value)\n    },\n    method: self.method,\n    path: self.path\n  }, opts)\n  debug('httpSignature authorization', self.getHeader('authorization'))\n\n  return self\n}\nRequest.prototype.hawk = function (opts) {\n  var self = this\n  self.setHeader('Authorization', hawk.client.header(self.uri, self.method, opts).field)\n}\nRequest.prototype.oauth = function (_oauth) {\n  var self = this\n\n  self._oauth.onRequest(_oauth)\n\n  return self\n}\n\nRequest.prototype.jar = function (jar) {\n  var self = this\n  var cookies\n\n  if (self._redirect.redirectsFollowed === 0) {\n    self.originalCookieHeader = self.getHeader('cookie')\n  }\n\n  if (!jar) {\n    // disable cookies\n    cookies = false\n    self._disableCookies = true\n  } else {\n    var targetCookieJar = (jar && jar.getCookieString) ? jar : globalCookieJar\n    var urihref = self.uri.href\n    //fetch cookie in the Specified host\n    if (targetCookieJar) {\n      cookies = targetCookieJar.getCookieString(urihref)\n    }\n  }\n\n  //if need cookie and cookie is not empty\n  if (cookies && cookies.length) {\n    if (self.originalCookieHeader) {\n      // Don't overwrite existing Cookie header\n      self.setHeader('cookie', self.originalCookieHeader + '; ' + cookies)\n    } else {\n      self.setHeader('cookie', cookies)\n    }\n  }\n  self._jar = jar\n  return self\n}\n\n\n// Stream API\nRequest.prototype.pipe = function (dest, opts) {\n  var self = this\n\n  if (self.response) {\n    if (self._destdata) {\n      self.emit('error', new Error('You cannot pipe after data has been emitted from the response.'))\n    } else if (self._ended) {\n      self.emit('error', new Error('You cannot pipe after the response has been ended.'))\n    } else {\n      stream.Stream.prototype.pipe.call(self, dest, opts)\n      self.pipeDest(dest)\n      return dest\n    }\n  } else {\n    self.dests.push(dest)\n    stream.Stream.prototype.pipe.call(self, dest, opts)\n    return dest\n  }\n}\nRequest.prototype.write = function () {\n  var self = this\n  if (self._aborted) {return}\n\n  if (!self._started) {\n    self.start()\n  }\n  if (self.req) {\n    return self.req.write.apply(self.req, arguments)\n  }\n}\nRequest.prototype.end = function (chunk) {\n  var self = this\n  if (self._aborted) {return}\n\n  if (chunk) {\n    self.write(chunk)\n  }\n  if (!self._started) {\n    self.start()\n  }\n  if (self.req) {\n    self.req.end()\n  }\n}\nRequest.prototype.pause = function () {\n  var self = this\n  if (!self.responseContent) {\n    self._paused = true\n  } else {\n    self.responseContent.pause.apply(self.responseContent, arguments)\n  }\n}\nRequest.prototype.resume = function () {\n  var self = this\n  if (!self.responseContent) {\n    self._paused = false\n  } else {\n    self.responseContent.resume.apply(self.responseContent, arguments)\n  }\n}\nRequest.prototype.destroy = function () {\n  var self = this\n  if (!self._ended) {\n    self.end()\n  } else if (self.response) {\n    self.response.destroy()\n  }\n}\n\nRequest.defaultProxyHeaderWhiteList =\n  Tunnel.defaultProxyHeaderWhiteList.slice()\n\nRequest.defaultProxyHeaderExclusiveList =\n  Tunnel.defaultProxyHeaderExclusiveList.slice()\n\n// Exports\n\nRequest.prototype.toJSON = requestToJSON\nmodule.exports = Request\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/lib/index.js":"// Export sub-modules\r\n\r\nexports.error = exports.Error = require('boom');\r\nexports.sntp = require('sntp');\r\n\r\nexports.server = require('./server');\r\nexports.client = require('./client');\r\nexports.crypto = require('./crypto');\r\nexports.utils = require('./utils');\r\n\r\nexports.uri = {\r\n    authenticate: exports.server.authenticateBewit,\r\n    getBewit: exports.client.getBewit\r\n};\r\n\r\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/node_modules/boom/lib/index.js":"// Load modules\n\nvar Http = require('http');\nvar Hoek = require('hoek');\n\n\n// Declare internals\n\nvar internals = {};\n\nexports.wrap = function (error, statusCode, message) {\n\n    Hoek.assert(error instanceof Error, 'Cannot wrap non-Error object');\n    return (error.isBoom ? error : internals.initialize(error, statusCode || 500, message));\n};\n\n\nexports.create = function (statusCode, message, data) {\n\n    return internals.create(statusCode, message, data, exports.create);\n};\n\ninternals.create = function (statusCode, message, data, ctor) {\n\n    var error = new Error(message ? message : undefined);       // Avoids settings null message\n    Error.captureStackTrace(error, ctor);                       // Filter the stack to our external API\n    error.data = data || null;\n    internals.initialize(error, statusCode);\n    return error;\n};\n\ninternals.initialize = function (error, statusCode, message) {\n\n    var numberCode = parseInt(statusCode, 10);\n    Hoek.assert(!isNaN(numberCode) && numberCode >= 400, 'First argument must be a number (400+):', statusCode);\n\n    error.isBoom = true;\n    error.isServer = numberCode >= 500;\n\n    if (!error.hasOwnProperty('data')) {\n        error.data = null;\n    }\n\n    error.output = {\n        statusCode: numberCode,\n        payload: {},\n        headers: {}\n    };\n\n    error.reformat = internals.reformat;\n    error.reformat();\n\n    if (!message &&\n        !error.message) {\n\n        message = error.output.payload.error;\n    }\n\n    if (message) {\n        error.message = (message + (error.message ? ': ' + error.message : ''));\n    }\n\n    return error;\n};\n\n\ninternals.reformat = function () {\n\n    this.output.payload.statusCode = this.output.statusCode;\n    this.output.payload.error = Http.STATUS_CODES[this.output.statusCode] || 'Unknown';\n\n    if (this.output.statusCode === 500) {\n        this.output.payload.message = 'An internal server error occurred';              // Hide actual error from user\n    }\n    else if (this.message) {\n        this.output.payload.message = this.message;\n    }\n};\n\n\n// 4xx Client Errors\n\nexports.badRequest = function (message, data) {\n\n    return internals.create(400, message, data, exports.badRequest);\n};\n\n\nexports.unauthorized = function (message, scheme, attributes) {          // Or function (message, wwwAuthenticate[])\n\n    var err = internals.create(401, message, undefined, exports.unauthorized);\n\n    if (!scheme) {\n        return err;\n    }\n\n    var wwwAuthenticate = '';\n    var i = 0;\n    var il = 0;\n\n    if (typeof scheme === 'string') {\n\n        // function (message, scheme, attributes)\n\n        wwwAuthenticate = scheme;\n\n        if (attributes || message) {\n            err.output.payload.attributes = {};\n        }\n\n        if (attributes) {\n            var names = Object.keys(attributes);\n            for (i = 0, il = names.length; i < il; ++i) {\n                var name = names[i];\n                if (i) {\n                    wwwAuthenticate += ',';\n                }\n\n                var value = attributes[name];\n                if (value === null ||\n                    value === undefined) {              // Value can be zero\n\n                    value = '';\n                }\n                wwwAuthenticate += ' ' + name + '=\"' + Hoek.escapeHeaderAttribute(value.toString()) + '\"';\n                err.output.payload.attributes[name] = value;\n            }\n        }\n\n        if (message) {\n            if (attributes) {\n                wwwAuthenticate += ',';\n            }\n            wwwAuthenticate += ' error=\"' + Hoek.escapeHeaderAttribute(message) + '\"';\n            err.output.payload.attributes.error = message;\n        }\n        else {\n            err.isMissing = true;\n        }\n    }\n    else {\n\n        // function (message, wwwAuthenticate[])\n\n        var wwwArray = scheme;\n        for (i = 0, il = wwwArray.length; i < il; ++i) {\n            if (i) {\n                wwwAuthenticate += ', ';\n            }\n\n            wwwAuthenticate += wwwArray[i];\n        }\n    }\n\n    err.output.headers['WWW-Authenticate'] = wwwAuthenticate;\n\n    return err;\n};\n\n\nexports.forbidden = function (message, data) {\n\n    return internals.create(403, message, data, exports.forbidden);\n};\n\n\nexports.notFound = function (message, data) {\n\n    return internals.create(404, message, data, exports.notFound);\n};\n\n\nexports.methodNotAllowed = function (message, data) {\n\n    return internals.create(405, message, data, exports.methodNotAllowed);\n};\n\n\nexports.notAcceptable = function (message, data) {\n\n    return internals.create(406, message, data, exports.notAcceptable);\n};\n\n\nexports.proxyAuthRequired = function (message, data) {\n\n    return internals.create(407, message, data, exports.proxyAuthRequired);\n};\n\n\nexports.clientTimeout = function (message, data) {\n\n    return internals.create(408, message, data, exports.clientTimeout);\n};\n\n\nexports.conflict = function (message, data) {\n\n    return internals.create(409, message, data, exports.conflict);\n};\n\n\nexports.resourceGone = function (message, data) {\n\n    return internals.create(410, message, data, exports.resourceGone);\n};\n\n\nexports.lengthRequired = function (message, data) {\n\n    return internals.create(411, message, data, exports.lengthRequired);\n};\n\n\nexports.preconditionFailed = function (message, data) {\n\n    return internals.create(412, message, data, exports.preconditionFailed);\n};\n\n\nexports.entityTooLarge = function (message, data) {\n\n    return internals.create(413, message, data, exports.entityTooLarge);\n};\n\n\nexports.uriTooLong = function (message, data) {\n\n    return internals.create(414, message, data, exports.uriTooLong);\n};\n\n\nexports.unsupportedMediaType = function (message, data) {\n\n    return internals.create(415, message, data, exports.unsupportedMediaType);\n};\n\n\nexports.rangeNotSatisfiable = function (message, data) {\n\n    return internals.create(416, message, data, exports.rangeNotSatisfiable);\n};\n\n\nexports.expectationFailed = function (message, data) {\n\n    return internals.create(417, message, data, exports.expectationFailed);\n};\n\nexports.badData = function (message, data) {\n\n    return internals.create(422, message, data, exports.badData);\n};\n\n\nexports.preconditionRequired = function (message, data) {\n\n    return internals.create(428, message, data, exports.preconditionRequired);\n};\n\n\nexports.tooManyRequests = function (message, data) {\n\n    return internals.create(429, message, data, exports.tooManyRequests);\n};\n\n\n// 5xx Server Errors\n\nexports.internal = function (message, data, statusCode) {\n\n    return internals.serverError(message, data, statusCode, exports.internal);\n};\n\ninternals.serverError = function (message, data, statusCode, ctor) {\n\n    var error;\n    if (data instanceof Error) {\n        error = exports.wrap(data, statusCode, message);\n    } else {\n        error = internals.create(statusCode || 500, message, undefined, ctor);\n        error.data = data;\n    }\n\n    return error;\n};\n\n\nexports.notImplemented = function (message, data) {\n\n    return internals.serverError(message, data, 501, exports.notImplemented);\n};\n\n\nexports.badGateway = function (message, data) {\n\n    return internals.serverError(message, data, 502, exports.badGateway);\n};\n\n\nexports.serverTimeout = function (message, data) {\n\n    return internals.serverError(message, data, 503, exports.serverTimeout);\n};\n\n\nexports.gatewayTimeout = function (message, data) {\n\n    return internals.serverError(message, data, 504, exports.gatewayTimeout);\n};\n\n\nexports.badImplementation = function (message, data) {\n\n    var err = internals.serverError(message, data, 500, exports.badImplementation);\n    err.isDeveloperError = true;\n    return err;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/node_modules/hoek/lib/index.js":"// Load modules\n\nvar Crypto = require('crypto');\nvar Path = require('path');\nvar Util = require('util');\nvar Escape = require('./escape');\n\n\n// Declare internals\n\nvar internals = {};\n\n\n// Clone object or array\n\nexports.clone = function (obj, seen) {\n\n    if (typeof obj !== 'object' ||\n        obj === null) {\n\n        return obj;\n    }\n\n    seen = seen || { orig: [], copy: [] };\n\n    var lookup = seen.orig.indexOf(obj);\n    if (lookup !== -1) {\n        return seen.copy[lookup];\n    }\n\n    var newObj;\n    var cloneDeep = false;\n\n    if (!Array.isArray(obj)) {\n        if (Buffer.isBuffer(obj)) {\n            newObj = new Buffer(obj);\n        }\n        else if (obj instanceof Date) {\n            newObj = new Date(obj.getTime());\n        }\n        else if (obj instanceof RegExp) {\n            newObj = new RegExp(obj);\n        }\n        else {\n            var proto = Object.getPrototypeOf(obj);\n            if (proto &&\n                proto.isImmutable) {\n\n                newObj = obj;\n            }\n            else {\n                newObj = Object.create(proto);\n                cloneDeep = true;\n            }\n        }\n    }\n    else {\n        newObj = [];\n        cloneDeep = true;\n    }\n\n    seen.orig.push(obj);\n    seen.copy.push(newObj);\n\n    if (cloneDeep) {\n        var keys = Object.getOwnPropertyNames(obj);\n        for (var i = 0, il = keys.length; i < il; ++i) {\n            var key = keys[i];\n            var descriptor = Object.getOwnPropertyDescriptor(obj, key);\n            if (descriptor &&\n                (descriptor.get ||\n                 descriptor.set)) {\n\n                Object.defineProperty(newObj, key, descriptor);\n            }\n            else {\n                newObj[key] = exports.clone(obj[key], seen);\n            }\n        }\n    }\n\n    return newObj;\n};\n\n\n// Merge all the properties of source into target, source wins in conflict, and by default null and undefined from source are applied\n/*eslint-disable */\nexports.merge = function (target, source, isNullOverride /* = true */, isMergeArrays /* = true */) {\n/*eslint-enable */\n    exports.assert(target && typeof target === 'object', 'Invalid target value: must be an object');\n    exports.assert(source === null || source === undefined || typeof source === 'object', 'Invalid source value: must be null, undefined, or an object');\n\n    if (!source) {\n        return target;\n    }\n\n    if (Array.isArray(source)) {\n        exports.assert(Array.isArray(target), 'Cannot merge array onto an object');\n        if (isMergeArrays === false) {                                                  // isMergeArrays defaults to true\n            target.length = 0;                                                          // Must not change target assignment\n        }\n\n        for (var i = 0, il = source.length; i < il; ++i) {\n            target.push(exports.clone(source[i]));\n        }\n\n        return target;\n    }\n\n    var keys = Object.keys(source);\n    for (var k = 0, kl = keys.length; k < kl; ++k) {\n        var key = keys[k];\n        var value = source[key];\n        if (value &&\n            typeof value === 'object') {\n\n            if (!target[key] ||\n                typeof target[key] !== 'object' ||\n                (Array.isArray(target[key]) ^ Array.isArray(value)) ||\n                value instanceof Date ||\n                Buffer.isBuffer(value) ||\n                value instanceof RegExp) {\n\n                target[key] = exports.clone(value);\n            }\n            else {\n                exports.merge(target[key], value, isNullOverride, isMergeArrays);\n            }\n        }\n        else {\n            if (value !== null &&\n                value !== undefined) {                              // Explicit to preserve empty strings\n\n                target[key] = value;\n            }\n            else if (isNullOverride !== false) {                    // Defaults to true\n                target[key] = value;\n            }\n        }\n    }\n\n    return target;\n};\n\n\n// Apply options to a copy of the defaults\n\nexports.applyToDefaults = function (defaults, options, isNullOverride) {\n\n    exports.assert(defaults && typeof defaults === 'object', 'Invalid defaults value: must be an object');\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\n\n    if (!options) {                                                 // If no options, return null\n        return null;\n    }\n\n    var copy = exports.clone(defaults);\n\n    if (options === true) {                                         // If options is set to true, use defaults\n        return copy;\n    }\n\n    return exports.merge(copy, options, isNullOverride === true, false);\n};\n\n\n// Clone an object except for the listed keys which are shallow copied\n\nexports.cloneWithShallow = function (source, keys) {\n\n    if (!source ||\n        typeof source !== 'object') {\n\n        return source;\n    }\n\n    var storage = internals.store(source, keys);    // Move shallow copy items to storage\n    var copy = exports.clone(source);               // Deep copy the rest\n    internals.restore(copy, source, storage);       // Shallow copy the stored items and restore\n    return copy;\n};\n\n\ninternals.store = function (source, keys) {\n\n    var storage = {};\n    for (var i = 0, il = keys.length; i < il; ++i) {\n        var key = keys[i];\n        var value = exports.reach(source, key);\n        if (value !== undefined) {\n            storage[key] = value;\n            internals.reachSet(source, key, undefined);\n        }\n    }\n\n    return storage;\n};\n\n\ninternals.restore = function (copy, source, storage) {\n\n    var keys = Object.keys(storage);\n    for (var i = 0, il = keys.length; i < il; ++i) {\n        var key = keys[i];\n        internals.reachSet(copy, key, storage[key]);\n        internals.reachSet(source, key, storage[key]);\n    }\n};\n\n\ninternals.reachSet = function (obj, key, value) {\n\n    var path = key.split('.');\n    var ref = obj;\n    for (var i = 0, il = path.length; i < il; ++i) {\n        var segment = path[i];\n        if (i + 1 === il) {\n            ref[segment] = value;\n        }\n\n        ref = ref[segment];\n    }\n};\n\n\n// Apply options to defaults except for the listed keys which are shallow copied from option without merging\n\nexports.applyToDefaultsWithShallow = function (defaults, options, keys) {\n\n    exports.assert(defaults && typeof defaults === 'object', 'Invalid defaults value: must be an object');\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\n    exports.assert(keys && Array.isArray(keys), 'Invalid keys');\n\n    if (!options) {                                                 // If no options, return null\n        return null;\n    }\n\n    var copy = exports.cloneWithShallow(defaults, keys);\n\n    if (options === true) {                                         // If options is set to true, use defaults\n        return copy;\n    }\n\n    var storage = internals.store(options, keys);   // Move shallow copy items to storage\n    exports.merge(copy, options, false, false);     // Deep copy the rest\n    internals.restore(copy, options, storage);      // Shallow copy the stored items and restore\n    return copy;\n};\n\n\n// Deep object or array comparison\n\nexports.deepEqual = function (obj, ref, options, seen) {\n\n    options = options || { prototype: true };\n\n    var type = typeof obj;\n\n    if (type !== typeof ref) {\n        return false;\n    }\n\n    if (type !== 'object' ||\n        obj === null ||\n        ref === null) {\n\n        if (obj === ref) {                                                      // Copied from Deep-eql, copyright(c) 2013 Jake Luer, jake@alogicalparadox.com, MIT Licensed, https://github.com/chaijs/deep-eql\n            return obj !== 0 || 1 / obj === 1 / ref;        // -0 / +0\n        }\n\n        return obj !== obj && ref !== ref;                  // NaN\n    }\n\n    seen = seen || [];\n    if (seen.indexOf(obj) !== -1) {\n        return true;                            // If previous comparison failed, it would have stopped execution\n    }\n\n    seen.push(obj);\n\n    if (Array.isArray(obj)) {\n        if (!Array.isArray(ref)) {\n            return false;\n        }\n\n        if (!options.part && obj.length !== ref.length) {\n            return false;\n        }\n\n        for (var i = 0, il = obj.length; i < il; ++i) {\n            if (options.part) {\n                var found = false;\n                for (var r = 0, rl = ref.length; r < rl; ++r) {\n                    if (exports.deepEqual(obj[i], ref[r], options, seen)) {\n                        found = true;\n                        break;\n                    }\n                }\n\n                return found;\n            }\n\n            if (!exports.deepEqual(obj[i], ref[i], options, seen)) {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    if (Buffer.isBuffer(obj)) {\n        if (!Buffer.isBuffer(ref)) {\n            return false;\n        }\n\n        if (obj.length !== ref.length) {\n            return false;\n        }\n\n        for (var j = 0, jl = obj.length; j < jl; ++j) {\n            if (obj[j] !== ref[j]) {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    if (obj instanceof Date) {\n        return (ref instanceof Date && obj.getTime() === ref.getTime());\n    }\n\n    if (obj instanceof RegExp) {\n        return (ref instanceof RegExp && obj.toString() === ref.toString());\n    }\n\n    if (options.prototype) {\n        if (Object.getPrototypeOf(obj) !== Object.getPrototypeOf(ref)) {\n            return false;\n        }\n    }\n\n    var keys = Object.getOwnPropertyNames(obj);\n\n    if (!options.part && keys.length !== Object.getOwnPropertyNames(ref).length) {\n        return false;\n    }\n\n    for (var k = 0, kl = keys.length; k < kl; ++k) {\n        var key = keys[k];\n        var descriptor = Object.getOwnPropertyDescriptor(obj, key);\n        if (descriptor.get) {\n            if (!exports.deepEqual(descriptor, Object.getOwnPropertyDescriptor(ref, key), options, seen)) {\n                return false;\n            }\n        }\n        else if (!exports.deepEqual(obj[key], ref[key], options, seen)) {\n            return false;\n        }\n    }\n\n    return true;\n};\n\n\n// Remove duplicate items from array\n\nexports.unique = function (array, key) {\n\n    var index = {};\n    var result = [];\n\n    for (var i = 0, il = array.length; i < il; ++i) {\n        var id = (key ? array[i][key] : array[i]);\n        if (index[id] !== true) {\n\n            result.push(array[i]);\n            index[id] = true;\n        }\n    }\n\n    return result;\n};\n\n\n// Convert array into object\n\nexports.mapToObject = function (array, key) {\n\n    if (!array) {\n        return null;\n    }\n\n    var obj = {};\n    for (var i = 0, il = array.length; i < il; ++i) {\n        if (key) {\n            if (array[i][key]) {\n                obj[array[i][key]] = true;\n            }\n        }\n        else {\n            obj[array[i]] = true;\n        }\n    }\n\n    return obj;\n};\n\n\n// Find the common unique items in two arrays\n\nexports.intersect = function (array1, array2, justFirst) {\n\n    if (!array1 || !array2) {\n        return [];\n    }\n\n    var common = [];\n    var hash = (Array.isArray(array1) ? exports.mapToObject(array1) : array1);\n    var found = {};\n    for (var i = 0, il = array2.length; i < il; ++i) {\n        if (hash[array2[i]] && !found[array2[i]]) {\n            if (justFirst) {\n                return array2[i];\n            }\n\n            common.push(array2[i]);\n            found[array2[i]] = true;\n        }\n    }\n\n    return (justFirst ? null : common);\n};\n\n\n// Test if the reference contains the values\n\nexports.contain = function (ref, values, options) {\n\n    /*\n        string -> string(s)\n        array -> item(s)\n        object -> key(s)\n        object -> object (key:value)\n    */\n\n    var valuePairs = null;\n    if (typeof ref === 'object' &&\n        typeof values === 'object' &&\n        !Array.isArray(ref) &&\n        !Array.isArray(values)) {\n\n        valuePairs = values;\n        values = Object.keys(values);\n    }\n    else {\n        values = [].concat(values);\n    }\n\n    options = options || {};            // deep, once, only, part\n\n    exports.assert(arguments.length >= 2, 'Insufficient arguments');\n    exports.assert(typeof ref === 'string' || typeof ref === 'object', 'Reference must be string or an object');\n    exports.assert(values.length, 'Values array cannot be empty');\n\n    var compare, compareFlags;\n    if (options.deep) {\n        compare = exports.deepEqual;\n\n        var hasOnly = options.hasOwnProperty('only'), hasPart = options.hasOwnProperty('part');\n\n        compareFlags = {\n            prototype: hasOnly ? options.only : hasPart ? !options.part : false,\n            part: hasOnly ? !options.only : hasPart ? options.part : true\n        };\n    }\n    else {\n        compare = function (a, b) {\n\n            return a === b;\n        };\n    }\n\n    var misses = false;\n    var matches = new Array(values.length);\n    for (var i = 0, il = matches.length; i < il; ++i) {\n        matches[i] = 0;\n    }\n\n    if (typeof ref === 'string') {\n        var pattern = '(';\n        for (i = 0, il = values.length; i < il; ++i) {\n            var value = values[i];\n            exports.assert(typeof value === 'string', 'Cannot compare string reference to non-string value');\n            pattern += (i ? '|' : '') + exports.escapeRegex(value);\n        }\n\n        var regex = new RegExp(pattern + ')', 'g');\n        var leftovers = ref.replace(regex, function ($0, $1) {\n\n            var index = values.indexOf($1);\n            ++matches[index];\n            return '';          // Remove from string\n        });\n\n        misses = !!leftovers;\n    }\n    else if (Array.isArray(ref)) {\n        for (i = 0, il = ref.length; i < il; ++i) {\n            for (var j = 0, jl = values.length, matched = false; j < jl && matched === false; ++j) {\n                matched = compare(values[j], ref[i], compareFlags) && j;\n            }\n\n            if (matched !== false) {\n                ++matches[matched];\n            }\n            else {\n                misses = true;\n            }\n        }\n    }\n    else {\n        var keys = Object.keys(ref);\n        for (i = 0, il = keys.length; i < il; ++i) {\n            var key = keys[i];\n            var pos = values.indexOf(key);\n            if (pos !== -1) {\n                if (valuePairs &&\n                    !compare(valuePairs[key], ref[key], compareFlags)) {\n\n                    return false;\n                }\n\n                ++matches[pos];\n            }\n            else {\n                misses = true;\n            }\n        }\n    }\n\n    var result = false;\n    for (i = 0, il = matches.length; i < il; ++i) {\n        result = result || !!matches[i];\n        if ((options.once && matches[i] > 1) ||\n            (!options.part && !matches[i])) {\n\n            return false;\n        }\n    }\n\n    if (options.only &&\n        misses) {\n\n        return false;\n    }\n\n    return result;\n};\n\n\n// Flatten array\n\nexports.flatten = function (array, target) {\n\n    var result = target || [];\n\n    for (var i = 0, il = array.length; i < il; ++i) {\n        if (Array.isArray(array[i])) {\n            exports.flatten(array[i], result);\n        }\n        else {\n            result.push(array[i]);\n        }\n    }\n\n    return result;\n};\n\n\n// Convert an object key chain string ('a.b.c') to reference (object[a][b][c])\n\nexports.reach = function (obj, chain, options) {\n\n    if (chain === false ||\n        chain === null ||\n        typeof chain === 'undefined') {\n\n        return obj;\n    }\n\n    options = options || {};\n    if (typeof options === 'string') {\n        options = { separator: options };\n    }\n\n    var path = chain.split(options.separator || '.');\n    var ref = obj;\n    for (var i = 0, il = path.length; i < il; ++i) {\n        var key = path[i];\n        if (key[0] === '-' && Array.isArray(ref)) {\n            key = key.slice(1, key.length);\n            key = ref.length - key;\n        }\n\n        if (!ref ||\n            !ref.hasOwnProperty(key) ||\n            (typeof ref !== 'object' && options.functions === false)) {         // Only object and function can have properties\n\n            exports.assert(!options.strict || i + 1 === il, 'Missing segment', key, 'in reach path ', chain);\n            exports.assert(typeof ref === 'object' || options.functions === true || typeof ref !== 'function', 'Invalid segment', key, 'in reach path ', chain);\n            ref = options.default;\n            break;\n        }\n\n        ref = ref[key];\n    }\n\n    return ref;\n};\n\n\nexports.reachTemplate = function (obj, template, options) {\n\n    return template.replace(/{([^}]+)}/g, function ($0, chain) {\n\n        var value = exports.reach(obj, chain, options);\n        return (value === undefined || value === null ? '' : value);\n    });\n};\n\n\nexports.formatStack = function (stack) {\n\n    var trace = [];\n    for (var i = 0, il = stack.length; i < il; ++i) {\n        var item = stack[i];\n        trace.push([item.getFileName(), item.getLineNumber(), item.getColumnNumber(), item.getFunctionName(), item.isConstructor()]);\n    }\n\n    return trace;\n};\n\n\nexports.formatTrace = function (trace) {\n\n    var display = [];\n\n    for (var i = 0, il = trace.length; i < il; ++i) {\n        var row = trace[i];\n        display.push((row[4] ? 'new ' : '') + row[3] + ' (' + row[0] + ':' + row[1] + ':' + row[2] + ')');\n    }\n\n    return display;\n};\n\n\nexports.callStack = function (slice) {\n\n    // http://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\n\n    var v8 = Error.prepareStackTrace;\n    Error.prepareStackTrace = function (err, stack) {\n\n        return stack;\n    };\n\n    var capture = {};\n    Error.captureStackTrace(capture, arguments.callee);     /*eslint no-caller:0 */\n    var stack = capture.stack;\n\n    Error.prepareStackTrace = v8;\n\n    var trace = exports.formatStack(stack);\n\n    if (slice) {\n        return trace.slice(slice);\n    }\n\n    return trace;\n};\n\n\nexports.displayStack = function (slice) {\n\n    var trace = exports.callStack(slice === undefined ? 1 : slice + 1);\n\n    return exports.formatTrace(trace);\n};\n\n\nexports.abortThrow = false;\n\n\nexports.abort = function (message, hideStack) {\n\n    if (process.env.NODE_ENV === 'test' || exports.abortThrow === true) {\n        throw new Error(message || 'Unknown error');\n    }\n\n    var stack = '';\n    if (!hideStack) {\n        stack = exports.displayStack(1).join('\\n\\t');\n    }\n    console.log('ABORT: ' + message + '\\n\\t' + stack);\n    process.exit(1);\n};\n\n\nexports.assert = function (condition /*, msg1, msg2, msg3 */) {\n\n    if (condition) {\n        return;\n    }\n\n    if (arguments.length === 2 && arguments[1] instanceof Error) {\n        throw arguments[1];\n    }\n\n    var msgs = [];\n    for (var i = 1, il = arguments.length; i < il; ++i) {\n        if (arguments[i] !== '') {\n            msgs.push(arguments[i]);            // Avoids Array.slice arguments leak, allowing for V8 optimizations\n        }\n    }\n\n    msgs = msgs.map(function (msg) {\n\n        return typeof msg === 'string' ? msg : msg instanceof Error ? msg.message : exports.stringify(msg);\n    });\n    throw new Error(msgs.join(' ') || 'Unknown error');\n};\n\n\nexports.Timer = function () {\n\n    this.ts = 0;\n    this.reset();\n};\n\n\nexports.Timer.prototype.reset = function () {\n\n    this.ts = Date.now();\n};\n\n\nexports.Timer.prototype.elapsed = function () {\n\n    return Date.now() - this.ts;\n};\n\n\nexports.Bench = function () {\n\n    this.ts = 0;\n    this.reset();\n};\n\n\nexports.Bench.prototype.reset = function () {\n\n    this.ts = exports.Bench.now();\n};\n\n\nexports.Bench.prototype.elapsed = function () {\n\n    return exports.Bench.now() - this.ts;\n};\n\n\nexports.Bench.now = function () {\n\n    var ts = process.hrtime();\n    return (ts[0] * 1e3) + (ts[1] / 1e6);\n};\n\n\n// Escape string for Regex construction\n\nexports.escapeRegex = function (string) {\n\n    // Escape ^$.*+-?=!:|\\/()[]{},\n    return string.replace(/[\\^\\$\\.\\*\\+\\-\\?\\=\\!\\:\\|\\\\\\/\\(\\)\\[\\]\\{\\}\\,]/g, '\\\\$&');\n};\n\n\n// Base64url (RFC 4648) encode\n\nexports.base64urlEncode = function (value, encoding) {\n\n    var buf = (Buffer.isBuffer(value) ? value : new Buffer(value, encoding || 'binary'));\n    return buf.toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\n};\n\n\n// Base64url (RFC 4648) decode\n\nexports.base64urlDecode = function (value, encoding) {\n\n    if (value &&\n        !/^[\\w\\-]*$/.test(value)) {\n\n        return new Error('Invalid character');\n    }\n\n    try {\n        var buf = new Buffer(value, 'base64');\n        return (encoding === 'buffer' ? buf : buf.toString(encoding || 'binary'));\n    }\n    catch (err) {\n        return err;\n    }\n};\n\n\n// Escape attribute value for use in HTTP header\n\nexports.escapeHeaderAttribute = function (attribute) {\n\n    // Allowed value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9, \\, \"\n\n    exports.assert(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~\\\"\\\\]*$/.test(attribute), 'Bad attribute value (' + attribute + ')');\n\n    return attribute.replace(/\\\\/g, '\\\\\\\\').replace(/\\\"/g, '\\\\\"');                             // Escape quotes and slash\n};\n\n\nexports.escapeHtml = function (string) {\n\n    return Escape.escapeHtml(string);\n};\n\n\nexports.escapeJavaScript = function (string) {\n\n    return Escape.escapeJavaScript(string);\n};\n\n\nexports.nextTick = function (callback) {\n\n    return function () {\n\n        var args = arguments;\n        process.nextTick(function () {\n\n            callback.apply(null, args);\n        });\n    };\n};\n\n\nexports.once = function (method) {\n\n    if (method._hoekOnce) {\n        return method;\n    }\n\n    var once = false;\n    var wrapped = function () {\n\n        if (!once) {\n            once = true;\n            method.apply(null, arguments);\n        }\n    };\n\n    wrapped._hoekOnce = true;\n\n    return wrapped;\n};\n\n\nexports.isAbsolutePath = function (path, platform) {\n\n    if (!path) {\n        return false;\n    }\n\n    if (Path.isAbsolute) {                      // node >= 0.11\n        return Path.isAbsolute(path);\n    }\n\n    platform = platform || process.platform;\n\n    // Unix\n\n    if (platform !== 'win32') {\n        return path[0] === '/';\n    }\n\n    // Windows\n\n    return !!/^(?:[a-zA-Z]:[\\\\\\/])|(?:[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/])/.test(path);        // C:\\ or \\\\something\\something\n};\n\n\nexports.isInteger = function (value) {\n\n    return (typeof value === 'number' &&\n            parseFloat(value) === parseInt(value, 10) &&\n            !isNaN(value));\n};\n\n\nexports.ignore = function () { };\n\n\nexports.inherits = Util.inherits;\n\n\nexports.format = Util.format;\n\n\nexports.transform = function (source, transform, options) {\n\n    exports.assert(source === null || source === undefined || typeof source === 'object' || Array.isArray(source), 'Invalid source object: must be null, undefined, an object, or an array');\n\n    if (Array.isArray(source)) {\n        var results = [];\n        for (var i = 0, il = source.length; i < il; ++i) {\n            results.push(exports.transform(source[i], transform, options));\n        }\n        return results;\n    }\n\n    var result = {};\n    var keys = Object.keys(transform);\n\n    for (var k = 0, kl = keys.length; k < kl; ++k) {\n        var key = keys[k];\n        var path = key.split('.');\n        var sourcePath = transform[key];\n\n        exports.assert(typeof sourcePath === 'string', 'All mappings must be \".\" delineated strings');\n\n        var segment;\n        var res = result;\n\n        while (path.length > 1) {\n            segment = path.shift();\n            if (!res[segment]) {\n                res[segment] = {};\n            }\n            res = res[segment];\n        }\n        segment = path.shift();\n        res[segment] = exports.reach(source, sourcePath, options);\n    }\n\n    return result;\n};\n\n\nexports.uniqueFilename = function (path, extension) {\n\n    if (extension) {\n        extension = extension[0] !== '.' ? '.' + extension : extension;\n    }\n    else {\n        extension = '';\n    }\n\n    path = Path.resolve(path);\n    var name = [Date.now(), process.pid, Crypto.randomBytes(8).toString('hex')].join('-') + extension;\n    return Path.join(path, name);\n};\n\n\nexports.stringify = function () {\n\n    try {\n        return JSON.stringify.apply(null, arguments);\n    }\n    catch (err) {\n        return '[Cannot display object: ' + err.message + ']';\n    }\n};\n\n\nexports.shallow = function (source) {\n\n    var target = {};\n    var keys = Object.keys(source);\n    for (var i = 0, il = keys.length; i < il; ++i) {\n        var key = keys[i];\n        target[key] = source[key];\n    }\n\n    return target;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/node_modules/hoek/lib/escape.js":"// Declare internals\n\nvar internals = {};\n\n\nexports.escapeJavaScript = function (input) {\n\n    if (!input) {\n        return '';\n    }\n\n    var escaped = '';\n\n    for (var i = 0, il = input.length; i < il; ++i) {\n\n        var charCode = input.charCodeAt(i);\n\n        if (internals.isSafe(charCode)) {\n            escaped += input[i];\n        }\n        else {\n            escaped += internals.escapeJavaScriptChar(charCode);\n        }\n    }\n\n    return escaped;\n};\n\n\nexports.escapeHtml = function (input) {\n\n    if (!input) {\n        return '';\n    }\n\n    var escaped = '';\n\n    for (var i = 0, il = input.length; i < il; ++i) {\n\n        var charCode = input.charCodeAt(i);\n\n        if (internals.isSafe(charCode)) {\n            escaped += input[i];\n        }\n        else {\n            escaped += internals.escapeHtmlChar(charCode);\n        }\n    }\n\n    return escaped;\n};\n\n\ninternals.escapeJavaScriptChar = function (charCode) {\n\n    if (charCode >= 256) {\n        return '\\\\u' + internals.padLeft('' + charCode, 4);\n    }\n\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\n    return '\\\\x' + internals.padLeft(hexValue, 2);\n};\n\n\ninternals.escapeHtmlChar = function (charCode) {\n\n    var namedEscape = internals.namedHtml[charCode];\n    if (typeof namedEscape !== 'undefined') {\n        return namedEscape;\n    }\n\n    if (charCode >= 256) {\n        return '&#' + charCode + ';';\n    }\n\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\n    return '&#x' + internals.padLeft(hexValue, 2) + ';';\n};\n\n\ninternals.padLeft = function (str, len) {\n\n    while (str.length < len) {\n        str = '0' + str;\n    }\n\n    return str;\n};\n\n\ninternals.isSafe = function (charCode) {\n\n    return (typeof internals.safeCharCodes[charCode] !== 'undefined');\n};\n\n\ninternals.namedHtml = {\n    '38': '&amp;',\n    '60': '&lt;',\n    '62': '&gt;',\n    '34': '&quot;',\n    '160': '&nbsp;',\n    '162': '&cent;',\n    '163': '&pound;',\n    '164': '&curren;',\n    '169': '&copy;',\n    '174': '&reg;'\n};\n\n\ninternals.safeCharCodes = (function () {\n\n    var safe = {};\n\n    for (var i = 32; i < 123; ++i) {\n\n        if ((i >= 97) ||                    // a-z\n            (i >= 65 && i <= 90) ||         // A-Z\n            (i >= 48 && i <= 57) ||         // 0-9\n            i === 32 ||                     // space\n            i === 46 ||                     // .\n            i === 44 ||                     // ,\n            i === 45 ||                     // -\n            i === 58 ||                     // :\n            i === 95) {                     // _\n\n            safe[i] = null;\n        }\n    }\n\n    return safe;\n}());\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/node_modules/sntp/index.js":"module.exports = require('./lib');","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/node_modules/sntp/lib/index.js":"// Load modules\n\nvar Dgram = require('dgram');\nvar Dns = require('dns');\nvar Hoek = require('hoek');\n\n\n// Declare internals\n\nvar internals = {};\n\n\nexports.time = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    var settings = Hoek.clone(options);\n    settings.host = settings.host || 'pool.ntp.org';\n    settings.port = settings.port || 123;\n    settings.resolveReference = settings.resolveReference || false;\n\n    // Declare variables used by callback\n\n    var timeoutId = 0;\n    var sent = 0;\n\n    // Ensure callback is only called once\n\n    var finish = function (err, result) {\n\n        if (timeoutId) {\n            clearTimeout(timeoutId);\n            timeoutId = 0;\n        }\n\n        socket.removeAllListeners();\n        socket.once('error', internals.ignore);\n        socket.close();\n        return callback(err, result);\n    };\n\n    finish = Hoek.once(finish);\n\n    // Create UDP socket\n\n    var socket = Dgram.createSocket('udp4');\n\n    socket.once('error', function (err) {\n\n        return finish(err);\n    });\n\n    // Listen to incoming messages\n\n    socket.on('message', function (buffer, rinfo) {\n\n        var received = Date.now();\n\n        var message = new internals.NtpMessage(buffer);\n        if (!message.isValid) {\n            return finish(new Error('Invalid server response'), message);\n        }\n\n        if (message.originateTimestamp !== sent) {\n            return finish(new Error('Wrong originate timestamp'), message);\n        }\n\n        // Timestamp Name          ID   When Generated\n        // ------------------------------------------------------------\n        // Originate Timestamp     T1   time request sent by client\n        // Receive Timestamp       T2   time request received by server\n        // Transmit Timestamp      T3   time reply sent by server\n        // Destination Timestamp   T4   time reply received by client\n        //\n        // The roundtrip delay d and system clock offset t are defined as:\n        //\n        // d = (T4 - T1) - (T3 - T2)     t = ((T2 - T1) + (T3 - T4)) / 2\n\n        var T1 = message.originateTimestamp;\n        var T2 = message.receiveTimestamp;\n        var T3 = message.transmitTimestamp;\n        var T4 = received;\n\n        message.d = (T4 - T1) - (T3 - T2);\n        message.t = ((T2 - T1) + (T3 - T4)) / 2;\n        message.receivedLocally = received;\n\n        if (!settings.resolveReference ||\n            message.stratum !== 'secondary') {\n\n            return finish(null, message);\n        }\n\n        // Resolve reference IP address\n\n        Dns.reverse(message.referenceId, function (err, domains) {\n\n            if (/* $lab:coverage:off$ */ !err /* $lab:coverage:on$ */) {\n                message.referenceHost = domains[0];\n            }\n\n            return finish(null, message);\n        });\n    });\n\n    // Set timeout\n\n    if (settings.timeout) {\n        timeoutId = setTimeout(function () {\n\n            timeoutId = 0;\n            return finish(new Error('Timeout'));\n        }, settings.timeout);\n    }\n\n    // Construct NTP message\n\n    var message = new Buffer(48);\n    for (var i = 0; i < 48; i++) {                      // Zero message\n        message[i] = 0;\n    }\n\n    message[0] = (0 << 6) + (4 << 3) + (3 << 0)         // Set version number to 4 and Mode to 3 (client)\n    sent = Date.now();\n    internals.fromMsecs(sent, message, 40);               // Set transmit timestamp (returns as originate)\n\n    // Send NTP request\n\n    socket.send(message, 0, message.length, settings.port, settings.host, function (err, bytes) {\n\n        if (err ||\n            bytes !== 48) {\n\n            return finish(err || new Error('Could not send entire message'));\n        }\n    });\n};\n\n\ninternals.NtpMessage = function (buffer) {\n\n    this.isValid = false;\n\n    // Validate\n\n    if (buffer.length !== 48) {\n        return;\n    }\n\n    // Leap indicator\n\n    var li = (buffer[0] >> 6);\n    switch (li) {\n        case 0: this.leapIndicator = 'no-warning'; break;\n        case 1: this.leapIndicator = 'last-minute-61'; break;\n        case 2: this.leapIndicator = 'last-minute-59'; break;\n        case 3: this.leapIndicator = 'alarm'; break;\n    }\n\n    // Version\n\n    var vn = ((buffer[0] & 0x38) >> 3);\n    this.version = vn;\n\n    // Mode\n\n    var mode = (buffer[0] & 0x7);\n    switch (mode) {\n        case 1: this.mode = 'symmetric-active'; break;\n        case 2: this.mode = 'symmetric-passive'; break;\n        case 3: this.mode = 'client'; break;\n        case 4: this.mode = 'server'; break;\n        case 5: this.mode = 'broadcast'; break;\n        case 0:\n        case 6:\n        case 7: this.mode = 'reserved'; break;\n    }\n\n    // Stratum\n\n    var stratum = buffer[1];\n    if (stratum === 0) {\n        this.stratum = 'death';\n    }\n    else if (stratum === 1) {\n        this.stratum = 'primary';\n    }\n    else if (stratum <= 15) {\n        this.stratum = 'secondary';\n    }\n    else {\n        this.stratum = 'reserved';\n    }\n\n    // Poll interval (msec)\n\n    this.pollInterval = Math.round(Math.pow(2, buffer[2])) * 1000;\n\n    // Precision (msecs)\n\n    this.precision = Math.pow(2, buffer[3]) * 1000;\n\n    // Root delay (msecs)\n\n    var rootDelay = 256 * (256 * (256 * buffer[4] + buffer[5]) + buffer[6]) + buffer[7];\n    this.rootDelay = 1000 * (rootDelay / 0x10000);\n\n    // Root dispersion (msecs)\n\n    this.rootDispersion = ((buffer[8] << 8) + buffer[9] + ((buffer[10] << 8) + buffer[11]) / Math.pow(2, 16)) * 1000;\n\n    // Reference identifier\n\n    this.referenceId = '';\n    switch (this.stratum) {\n        case 'death':\n        case 'primary':\n            this.referenceId = String.fromCharCode(buffer[12]) + String.fromCharCode(buffer[13]) + String.fromCharCode(buffer[14]) + String.fromCharCode(buffer[15]);\n            break;\n        case 'secondary':\n            this.referenceId = '' + buffer[12] + '.' + buffer[13] + '.' + buffer[14] + '.' + buffer[15];\n            break;\n    }\n\n    // Reference timestamp\n\n    this.referenceTimestamp = internals.toMsecs(buffer, 16);\n\n    // Originate timestamp\n\n    this.originateTimestamp = internals.toMsecs(buffer, 24);\n\n    // Receive timestamp\n\n    this.receiveTimestamp = internals.toMsecs(buffer, 32);\n\n    // Transmit timestamp\n\n    this.transmitTimestamp = internals.toMsecs(buffer, 40);\n\n    // Validate\n\n    if (this.version === 4 &&\n        this.stratum !== 'reserved' &&\n        this.mode === 'server' &&\n        this.originateTimestamp &&\n        this.receiveTimestamp &&\n        this.transmitTimestamp) {\n\n        this.isValid = true;\n    }\n\n    return this;\n};\n\n\ninternals.toMsecs = function (buffer, offset) {\n\n    var seconds = 0;\n    var fraction = 0;\n\n    for (var i = 0; i < 4; ++i) {\n        seconds = (seconds * 256) + buffer[offset + i];\n    }\n\n    for (i = 4; i < 8; ++i) {\n        fraction = (fraction * 256) + buffer[offset + i];\n    }\n\n    return ((seconds - 2208988800 + (fraction / Math.pow(2, 32))) * 1000);\n};\n\n\ninternals.fromMsecs = function (ts, buffer, offset) {\n\n    var seconds = Math.floor(ts / 1000) + 2208988800;\n    var fraction = Math.round((ts % 1000) / 1000 * Math.pow(2, 32));\n\n    buffer[offset + 0] = (seconds & 0xFF000000) >> 24;\n    buffer[offset + 1] = (seconds & 0x00FF0000) >> 16;\n    buffer[offset + 2] = (seconds & 0x0000FF00) >> 8;\n    buffer[offset + 3] = (seconds & 0x000000FF);\n\n    buffer[offset + 4] = (fraction & 0xFF000000) >> 24;\n    buffer[offset + 5] = (fraction & 0x00FF0000) >> 16;\n    buffer[offset + 6] = (fraction & 0x0000FF00) >> 8;\n    buffer[offset + 7] = (fraction & 0x000000FF);\n};\n\n\n// Offset singleton\n\ninternals.last = {\n    offset: 0,\n    expires: 0,\n    host: '',\n    port: 0\n};\n\n\nexports.offset = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    var now = Date.now();\n    var clockSyncRefresh = options.clockSyncRefresh || 24 * 60 * 60 * 1000;                    // Daily\n\n    if (internals.last.offset &&\n        internals.last.host === options.host &&\n        internals.last.port === options.port &&\n        now < internals.last.expires) {\n\n        process.nextTick(function () {\n\n            callback(null, internals.last.offset);\n        });\n\n        return;\n    }\n\n    exports.time(options, function (err, time) {\n\n        if (err) {\n            return callback(err, 0);\n        }\n\n        internals.last = {\n            offset: Math.round(time.t),\n            expires: now + clockSyncRefresh,\n            host: options.host,\n            port: options.port\n        };\n\n        return callback(null, internals.last.offset);\n    });\n};\n\n\n// Now singleton\n\ninternals.now = {\n    intervalId: 0\n};\n\n\nexports.start = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    if (internals.now.intervalId) {\n        process.nextTick(function () {\n\n            callback();\n        });\n\n        return;\n    }\n\n    exports.offset(options, function (err, offset) {\n\n        internals.now.intervalId = setInterval(function () {\n\n            exports.offset(options, function () { });\n        }, options.clockSyncRefresh || 24 * 60 * 60 * 1000);                                // Daily\n\n        return callback();\n    });\n};\n\n\nexports.stop = function () {\n\n    if (!internals.now.intervalId) {\n        return;\n    }\n\n    clearInterval(internals.now.intervalId);\n    internals.now.intervalId = 0;\n};\n\n\nexports.isLive = function () {\n\n    return !!internals.now.intervalId;\n};\n\n\nexports.now = function () {\n\n    var now = Date.now();\n    if (!exports.isLive() ||\n        now >= internals.last.expires) {\n\n        return now;\n    }\n\n    return now + internals.last.offset;\n};\n\n\ninternals.ignore = function () {\n\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/lib/server.js":"// Load modules\r\n\r\nvar Boom = require('boom');\r\nvar Hoek = require('hoek');\r\nvar Cryptiles = require('cryptiles');\r\nvar Crypto = require('./crypto');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Hawk authentication\r\n\r\n/*\r\n   req:                 node's HTTP request object or an object as follows:\r\n\r\n                        var request = {\r\n                            method: 'GET',\r\n                            url: '/resource/4?a=1&b=2',\r\n                            host: 'example.com',\r\n                            port: 8080,\r\n                            authorization: 'Hawk id=\"dh37fgj492je\", ts=\"1353832234\", nonce=\"j4h3g2\", ext=\"some-app-ext-data\", mac=\"6R4rV5iE+NPoym+WwjeHzjAGXUtLNIxmo1vpMofpLAE=\"'\r\n                        };\r\n\r\n   credentialsFunc:     required function to lookup the set of Hawk credentials based on the provided credentials id.\r\n                        The credentials include the MAC key, MAC algorithm, and other attributes (such as username)\r\n                        needed by the application. This function is the equivalent of verifying the username and\r\n                        password in Basic authentication.\r\n\r\n                        var credentialsFunc = function (id, callback) {\r\n\r\n                            // Lookup credentials in database\r\n                            db.lookup(id, function (err, item) {\r\n\r\n                                if (err || !item) {\r\n                                    return callback(err);\r\n                                }\r\n\r\n                                var credentials = {\r\n                                    // Required\r\n                                    key: item.key,\r\n                                    algorithm: item.algorithm,\r\n                                    // Application specific\r\n                                    user: item.user\r\n                                };\r\n\r\n                                return callback(null, credentials);\r\n                            });\r\n                        };\r\n\r\n   options: {\r\n\r\n        hostHeaderName:        optional header field name, used to override the default 'Host' header when used\r\n                               behind a cache of a proxy. Apache2 changes the value of the 'Host' header while preserving\r\n                               the original (which is what the module must verify) in the 'x-forwarded-host' header field.\r\n                               Only used when passed a node Http.ServerRequest object.\r\n\r\n        nonceFunc:             optional nonce validation function. The function signature is function(key, nonce, ts, callback)\r\n                               where 'callback' must be called using the signature function(err).\r\n\r\n        timestampSkewSec:      optional number of seconds of permitted clock skew for incoming timestamps. Defaults to 60 seconds.\r\n                               Provides a +/- skew which means actual allowed window is double the number of seconds.\r\n\r\n        localtimeOffsetMsec:   optional local clock time offset express in a number of milliseconds (positive or negative).\r\n                               Defaults to 0.\r\n\r\n        payload:               optional payload for validation. The client calculates the hash value and includes it via the 'hash'\r\n                               header attribute. The server always ensures the value provided has been included in the request\r\n                               MAC. When this option is provided, it validates the hash value itself. Validation is done by calculating\r\n                               a hash value over the entire payload (assuming it has already be normalized to the same format and\r\n                               encoding used by the client to calculate the hash on request). If the payload is not available at the time\r\n                               of authentication, the authenticatePayload() method can be used by passing it the credentials and\r\n                               attributes.hash returned in the authenticate callback.\r\n\r\n        host:                  optional host name override. Only used when passed a node request object.\r\n        port:                  optional port override. Only used when passed a node request object.\r\n    }\r\n\r\n    callback: function (err, credentials, artifacts) { }\r\n */\r\n\r\nexports.authenticate = function (req, credentialsFunc, options, callback) {\r\n\r\n    callback = Hoek.nextTick(callback);\r\n\r\n    // Default options\r\n\r\n    options.nonceFunc = options.nonceFunc || internals.nonceFunc;\r\n    options.timestampSkewSec = options.timestampSkewSec || 60;                                                  // 60 seconds\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now(options.localtimeOffsetMsec);                           // Measure now before any other processing\r\n\r\n    // Convert node Http request object to a request configuration object\r\n\r\n    var request = Utils.parseRequest(req, options);\r\n    if (request instanceof Error) {\r\n        return callback(Boom.badRequest(request.message));\r\n    }\r\n\r\n    // Parse HTTP Authorization header\r\n\r\n    var attributes = Utils.parseAuthorizationHeader(request.authorization);\r\n    if (attributes instanceof Error) {\r\n        return callback(attributes);\r\n    }\r\n\r\n    // Construct artifacts container\r\n\r\n    var artifacts = {\r\n        method: request.method,\r\n        host: request.host,\r\n        port: request.port,\r\n        resource: request.url,\r\n        ts: attributes.ts,\r\n        nonce: attributes.nonce,\r\n        hash: attributes.hash,\r\n        ext: attributes.ext,\r\n        app: attributes.app,\r\n        dlg: attributes.dlg,\r\n        mac: attributes.mac,\r\n        id: attributes.id\r\n    };\r\n\r\n    // Verify required header attributes\r\n\r\n    if (!attributes.id ||\r\n        !attributes.ts ||\r\n        !attributes.nonce ||\r\n        !attributes.mac) {\r\n\r\n        return callback(Boom.badRequest('Missing attributes'), null, artifacts);\r\n    }\r\n\r\n    // Fetch Hawk credentials\r\n\r\n    credentialsFunc(attributes.id, function (err, credentials) {\r\n\r\n        if (err) {\r\n            return callback(err, credentials || null, artifacts);\r\n        }\r\n\r\n        if (!credentials) {\r\n            return callback(Boom.unauthorized('Unknown credentials', 'Hawk'), null, artifacts);\r\n        }\r\n\r\n        if (!credentials.key ||\r\n            !credentials.algorithm) {\r\n\r\n            return callback(Boom.internal('Invalid credentials'), credentials, artifacts);\r\n        }\r\n\r\n        if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n            return callback(Boom.internal('Unknown algorithm'), credentials, artifacts);\r\n        }\r\n\r\n        // Calculate MAC\r\n\r\n        var mac = Crypto.calculateMac('header', credentials, artifacts);\r\n        if (!Cryptiles.fixedTimeComparison(mac, attributes.mac)) {\r\n            return callback(Boom.unauthorized('Bad mac', 'Hawk'), credentials, artifacts);\r\n        }\r\n\r\n        // Check payload hash\r\n\r\n        if (options.payload ||\r\n            options.payload === '') {\r\n\r\n            if (!attributes.hash) {\r\n                return callback(Boom.unauthorized('Missing required payload hash', 'Hawk'), credentials, artifacts);\r\n            }\r\n\r\n            var hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, request.contentType);\r\n            if (!Cryptiles.fixedTimeComparison(hash, attributes.hash)) {\r\n                return callback(Boom.unauthorized('Bad payload hash', 'Hawk'), credentials, artifacts);\r\n            }\r\n        }\r\n\r\n        // Check nonce\r\n\r\n        options.nonceFunc(credentials.key, attributes.nonce, attributes.ts, function (err) {\r\n\r\n            if (err) {\r\n                return callback(Boom.unauthorized('Invalid nonce', 'Hawk'), credentials, artifacts);\r\n            }\r\n\r\n            // Check timestamp staleness\r\n\r\n            if (Math.abs((attributes.ts * 1000) - now) > (options.timestampSkewSec * 1000)) {\r\n                var tsm = Crypto.timestampMessage(credentials, options.localtimeOffsetMsec);\r\n                return callback(Boom.unauthorized('Stale timestamp', 'Hawk', tsm), credentials, artifacts);\r\n            }\r\n\r\n            // Successful authentication\r\n\r\n            return callback(null, credentials, artifacts);\r\n        });\r\n    });\r\n};\r\n\r\n\r\n// Authenticate payload hash - used when payload cannot be provided during authenticate()\r\n\r\n/*\r\n    payload:        raw request payload\r\n    credentials:    from authenticate callback\r\n    artifacts:      from authenticate callback\r\n    contentType:    req.headers['content-type']\r\n*/\r\n\r\nexports.authenticatePayload = function (payload, credentials, artifacts, contentType) {\r\n\r\n    var calculatedHash = Crypto.calculatePayloadHash(payload, credentials.algorithm, contentType);\r\n    return Cryptiles.fixedTimeComparison(calculatedHash, artifacts.hash);\r\n};\r\n\r\n\r\n// Authenticate payload hash - used when payload cannot be provided during authenticate()\r\n\r\n/*\r\n    calculatedHash: the payload hash calculated using Crypto.calculatePayloadHash()\r\n    artifacts:      from authenticate callback\r\n*/\r\n\r\nexports.authenticatePayloadHash = function (calculatedHash, artifacts) {\r\n\r\n    return Cryptiles.fixedTimeComparison(calculatedHash, artifacts.hash);\r\n};\r\n\r\n\r\n// Generate a Server-Authorization header for a given response\r\n\r\n/*\r\n    credentials: {},                                        // Object received from authenticate()\r\n    artifacts: {}                                           // Object received from authenticate(); 'mac', 'hash', and 'ext' - ignored\r\n    options: {\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        payload: '{\"some\":\"payload\"}',                      // UTF-8 encoded string for body hash generation (ignored if hash provided)\r\n        contentType: 'application/json',                    // Payload content-type (ignored if hash provided)\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV='                     // Pre-calculated payload hash\r\n    }\r\n*/\r\n\r\nexports.header = function (credentials, artifacts, options) {\r\n\r\n    // Prepare inputs\r\n\r\n    options = options || {};\r\n\r\n    if (!artifacts ||\r\n        typeof artifacts !== 'object' ||\r\n        typeof options !== 'object') {\r\n\r\n        return '';\r\n    }\r\n\r\n    artifacts = Hoek.clone(artifacts);\r\n    delete artifacts.mac;\r\n    artifacts.hash = options.hash;\r\n    artifacts.ext = options.ext;\r\n\r\n    // Validate credentials\r\n\r\n    if (!credentials ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        // Invalid credential object\r\n        return '';\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return '';\r\n    }\r\n\r\n    // Calculate payload hash\r\n\r\n    if (!artifacts.hash &&\r\n        (options.payload || options.payload === '')) {\r\n\r\n        artifacts.hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, options.contentType);\r\n    }\r\n\r\n    var mac = Crypto.calculateMac('response', credentials, artifacts);\r\n\r\n    // Construct header\r\n\r\n    var header = 'Hawk mac=\"' + mac + '\"' +\r\n                 (artifacts.hash ? ', hash=\"' + artifacts.hash + '\"' : '');\r\n\r\n    if (artifacts.ext !== null &&\r\n        artifacts.ext !== undefined &&\r\n        artifacts.ext !== '') {                       // Other falsey values allowed\r\n\r\n        header += ', ext=\"' + Hoek.escapeHeaderAttribute(artifacts.ext) + '\"';\r\n    }\r\n\r\n    return header;\r\n};\r\n\r\n\r\n/*\r\n * Arguments and options are the same as authenticate() with the exception that the only supported options are:\r\n * 'hostHeaderName', 'localtimeOffsetMsec', 'host', 'port'\r\n */\r\n\r\n\r\n//                       1     2             3           4\r\ninternals.bewitRegex = /^(\\/.*)([\\?&])bewit\\=([^&$]*)(?:&(.+))?$/;\r\n\r\n\r\nexports.authenticateBewit = function (req, credentialsFunc, options, callback) {\r\n\r\n    callback = Hoek.nextTick(callback);\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now(options.localtimeOffsetMsec);\r\n\r\n    // Convert node Http request object to a request configuration object\r\n\r\n    var request = Utils.parseRequest(req, options);\r\n    if (request instanceof Error) {\r\n        return callback(Boom.badRequest(request.message));\r\n    }\r\n\r\n    // Extract bewit\r\n\r\n    if (request.url.length > Utils.limits.maxMatchLength) {\r\n        return callback(Boom.badRequest('Resource path exceeds max length'));\r\n    }\r\n\r\n    var resource = request.url.match(internals.bewitRegex);\r\n    if (!resource) {\r\n        return callback(Boom.unauthorized(null, 'Hawk'));\r\n    }\r\n\r\n    // Bewit not empty\r\n\r\n    if (!resource[3]) {\r\n        return callback(Boom.unauthorized('Empty bewit', 'Hawk'));\r\n    }\r\n\r\n    // Verify method is GET\r\n\r\n    if (request.method !== 'GET' &&\r\n        request.method !== 'HEAD') {\r\n\r\n        return callback(Boom.unauthorized('Invalid method', 'Hawk'));\r\n    }\r\n\r\n    // No other authentication\r\n\r\n    if (request.authorization) {\r\n        return callback(Boom.badRequest('Multiple authentications'));\r\n    }\r\n\r\n    // Parse bewit\r\n\r\n    var bewitString = Hoek.base64urlDecode(resource[3]);\r\n    if (bewitString instanceof Error) {\r\n        return callback(Boom.badRequest('Invalid bewit encoding'));\r\n    }\r\n\r\n    // Bewit format: id\\exp\\mac\\ext ('\\' is used because it is a reserved header attribute character)\r\n\r\n    var bewitParts = bewitString.split('\\\\');\r\n    if (bewitParts.length !== 4) {\r\n        return callback(Boom.badRequest('Invalid bewit structure'));\r\n    }\r\n\r\n    var bewit = {\r\n        id: bewitParts[0],\r\n        exp: parseInt(bewitParts[1], 10),\r\n        mac: bewitParts[2],\r\n        ext: bewitParts[3] || ''\r\n    };\r\n\r\n    if (!bewit.id ||\r\n        !bewit.exp ||\r\n        !bewit.mac) {\r\n\r\n        return callback(Boom.badRequest('Missing bewit attributes'));\r\n    }\r\n\r\n    // Construct URL without bewit\r\n\r\n    var url = resource[1];\r\n    if (resource[4]) {\r\n        url += resource[2] + resource[4];\r\n    }\r\n\r\n    // Check expiration\r\n\r\n    if (bewit.exp * 1000 <= now) {\r\n        return callback(Boom.unauthorized('Access expired', 'Hawk'), null, bewit);\r\n    }\r\n\r\n    // Fetch Hawk credentials\r\n\r\n    credentialsFunc(bewit.id, function (err, credentials) {\r\n\r\n        if (err) {\r\n            return callback(err, credentials || null, bewit.ext);\r\n        }\r\n\r\n        if (!credentials) {\r\n            return callback(Boom.unauthorized('Unknown credentials', 'Hawk'), null, bewit);\r\n        }\r\n\r\n        if (!credentials.key ||\r\n            !credentials.algorithm) {\r\n\r\n            return callback(Boom.internal('Invalid credentials'), credentials, bewit);\r\n        }\r\n\r\n        if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n            return callback(Boom.internal('Unknown algorithm'), credentials, bewit);\r\n        }\r\n\r\n        // Calculate MAC\r\n\r\n        var mac = Crypto.calculateMac('bewit', credentials, {\r\n            ts: bewit.exp,\r\n            nonce: '',\r\n            method: 'GET',\r\n            resource: url,\r\n            host: request.host,\r\n            port: request.port,\r\n            ext: bewit.ext\r\n        });\r\n\r\n        if (!Cryptiles.fixedTimeComparison(mac, bewit.mac)) {\r\n            return callback(Boom.unauthorized('Bad mac', 'Hawk'), credentials, bewit);\r\n        }\r\n\r\n        // Successful authentication\r\n\r\n        return callback(null, credentials, bewit);\r\n    });\r\n};\r\n\r\n\r\n/*\r\n *  options are the same as authenticate() with the exception that the only supported options are:\r\n * 'nonceFunc', 'timestampSkewSec', 'localtimeOffsetMsec'\r\n */\r\n\r\nexports.authenticateMessage = function (host, port, message, authorization, credentialsFunc, options, callback) {\r\n\r\n    callback = Hoek.nextTick(callback);\r\n\r\n    // Default options\r\n\r\n    options.nonceFunc = options.nonceFunc || internals.nonceFunc;\r\n    options.timestampSkewSec = options.timestampSkewSec || 60;                                                  // 60 seconds\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now(options.localtimeOffsetMsec);                       // Measure now before any other processing\r\n\r\n    // Validate authorization\r\n\r\n    if (!authorization.id ||\r\n        !authorization.ts ||\r\n        !authorization.nonce ||\r\n        !authorization.hash ||\r\n        !authorization.mac) {\r\n\r\n        return callback(Boom.badRequest('Invalid authorization'));\r\n    }\r\n\r\n    // Fetch Hawk credentials\r\n\r\n    credentialsFunc(authorization.id, function (err, credentials) {\r\n\r\n        if (err) {\r\n            return callback(err, credentials || null);\r\n        }\r\n\r\n        if (!credentials) {\r\n            return callback(Boom.unauthorized('Unknown credentials', 'Hawk'));\r\n        }\r\n\r\n        if (!credentials.key ||\r\n            !credentials.algorithm) {\r\n\r\n            return callback(Boom.internal('Invalid credentials'), credentials);\r\n        }\r\n\r\n        if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n            return callback(Boom.internal('Unknown algorithm'), credentials);\r\n        }\r\n\r\n        // Construct artifacts container\r\n\r\n        var artifacts = {\r\n            ts: authorization.ts,\r\n            nonce: authorization.nonce,\r\n            host: host,\r\n            port: port,\r\n            hash: authorization.hash\r\n        };\r\n\r\n        // Calculate MAC\r\n\r\n        var mac = Crypto.calculateMac('message', credentials, artifacts);\r\n        if (!Cryptiles.fixedTimeComparison(mac, authorization.mac)) {\r\n            return callback(Boom.unauthorized('Bad mac', 'Hawk'), credentials);\r\n        }\r\n\r\n        // Check payload hash\r\n\r\n        var hash = Crypto.calculatePayloadHash(message, credentials.algorithm);\r\n        if (!Cryptiles.fixedTimeComparison(hash, authorization.hash)) {\r\n            return callback(Boom.unauthorized('Bad message hash', 'Hawk'), credentials);\r\n        }\r\n\r\n        // Check nonce\r\n\r\n        options.nonceFunc(credentials.key, authorization.nonce, authorization.ts, function (err) {\r\n\r\n            if (err) {\r\n                return callback(Boom.unauthorized('Invalid nonce', 'Hawk'), credentials);\r\n            }\r\n\r\n            // Check timestamp staleness\r\n\r\n            if (Math.abs((authorization.ts * 1000) - now) > (options.timestampSkewSec * 1000)) {\r\n                return callback(Boom.unauthorized('Stale timestamp'), credentials);\r\n            }\r\n\r\n            // Successful authentication\r\n\r\n            return callback(null, credentials);\r\n        });\r\n    });\r\n};\r\n\r\n\r\ninternals.nonceFunc = function (key, nonce, ts, nonceCallback) {\r\n\r\n    return nonceCallback();         // No validation\r\n};\r\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/node_modules/cryptiles/lib/index.js":"// Load modules\n\nvar Crypto = require('crypto');\nvar Boom = require('boom');\n\n\n// Declare internals\n\nvar internals = {};\n\n\n// Generate a cryptographically strong pseudo-random data\n\nexports.randomString = function (size) {\n\n    var buffer = exports.randomBits((size + 1) * 6);\n    if (buffer instanceof Error) {\n        return buffer;\n    }\n\n    var string = buffer.toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\n    return string.slice(0, size);\n};\n\n\nexports.randomBits = function (bits) {\n\n    if (!bits ||\n        bits < 0) {\n\n        return Boom.internal('Invalid random bits count');\n    }\n\n    var bytes = Math.ceil(bits / 8);\n    try {\n        return Crypto.randomBytes(bytes);\n    }\n    catch (err) {\n        return Boom.internal('Failed generating random bits: ' + err.message);\n    }\n};\n\n\n// Compare two strings using fixed time algorithm (to prevent time-based analysis of MAC digest match)\n\nexports.fixedTimeComparison = function (a, b) {\n\n    if (typeof a !== 'string' ||\n        typeof b !== 'string') {\n\n        return false;\n    }\n\n    var mismatch = (a.length === b.length ? 0 : 1);\n    if (mismatch) {\n        b = a;\n    }\n\n    for (var i = 0, il = a.length; i < il; ++i) {\n        var ac = a.charCodeAt(i);\n        var bc = b.charCodeAt(i);\n        mismatch |= (ac ^ bc);\n    }\n\n    return (mismatch === 0);\n};\n\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/lib/crypto.js":"// Load modules\r\n\r\nvar Crypto = require('crypto');\r\nvar Url = require('url');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// MAC normalization format version\r\n\r\nexports.headerVersion = '1';                        // Prevent comparison of mac values generated with different normalized string formats\r\n\r\n\r\n// Supported HMAC algorithms\r\n\r\nexports.algorithms = ['sha1', 'sha256'];\r\n\r\n\r\n// Calculate the request MAC\r\n\r\n/*\r\n    type: 'header',                                 // 'header', 'bewit', 'response'\r\n    credentials: {\r\n        key: 'aoijedoaijsdlaksjdl',\r\n        algorithm: 'sha256'                         // 'sha1', 'sha256'\r\n    },\r\n    options: {\r\n        method: 'GET',\r\n        resource: '/resource?a=1&b=2',\r\n        host: 'example.com',\r\n        port: 8080,\r\n        ts: 1357718381034,\r\n        nonce: 'd3d345f',\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV/OhB3y+NdwoCr6RShbVkE=',\r\n        ext: 'app-specific-data',\r\n        app: 'hf48hd83qwkj',                        // Application id (Oz)\r\n        dlg: 'd8djwekds9cj'                         // Delegated by application id (Oz), requires options.app\r\n    }\r\n*/\r\n\r\nexports.calculateMac = function (type, credentials, options) {\r\n\r\n    var normalized = exports.generateNormalizedString(type, options);\r\n\r\n    var hmac = Crypto.createHmac(credentials.algorithm, credentials.key).update(normalized);\r\n    var digest = hmac.digest('base64');\r\n    return digest;\r\n};\r\n\r\n\r\nexports.generateNormalizedString = function (type, options) {\r\n\r\n    var resource = options.resource || '';\r\n    if (resource &&\r\n        resource[0] !== '/') {\r\n\r\n        var url = Url.parse(resource, false);\r\n        resource = url.path;                        // Includes query\r\n    }\r\n\r\n    var normalized = 'hawk.' + exports.headerVersion + '.' + type + '\\n' +\r\n                     options.ts + '\\n' +\r\n                     options.nonce + '\\n' +\r\n                     (options.method || '').toUpperCase() + '\\n' +\r\n                     resource + '\\n' +\r\n                     options.host.toLowerCase() + '\\n' +\r\n                     options.port + '\\n' +\r\n                     (options.hash || '') + '\\n';\r\n\r\n    if (options.ext) {\r\n        normalized += options.ext.replace('\\\\', '\\\\\\\\').replace('\\n', '\\\\n');\r\n    }\r\n\r\n    normalized += '\\n';\r\n\r\n    if (options.app) {\r\n        normalized += options.app + '\\n' +\r\n                      (options.dlg || '') + '\\n';\r\n    }\r\n\r\n    return normalized;\r\n};\r\n\r\n\r\nexports.calculatePayloadHash = function (payload, algorithm, contentType) {\r\n\r\n    var hash = exports.initializePayloadHash(algorithm, contentType);\r\n    hash.update(payload || '');\r\n    return exports.finalizePayloadHash(hash);\r\n};\r\n\r\n\r\nexports.initializePayloadHash = function (algorithm, contentType) {\r\n\r\n    var hash = Crypto.createHash(algorithm);\r\n    hash.update('hawk.' + exports.headerVersion + '.payload\\n');\r\n    hash.update(Utils.parseContentType(contentType) + '\\n');\r\n    return hash;\r\n};\r\n\r\n\r\nexports.finalizePayloadHash = function (hash) {\r\n\r\n    hash.update('\\n');\r\n    return hash.digest('base64');\r\n};\r\n\r\n\r\nexports.calculateTsMac = function (ts, credentials) {\r\n\r\n    var hmac = Crypto.createHmac(credentials.algorithm, credentials.key);\r\n    hmac.update('hawk.' + exports.headerVersion + '.ts\\n' + ts + '\\n');\r\n    return hmac.digest('base64');\r\n};\r\n\r\n\r\nexports.timestampMessage = function (credentials, localtimeOffsetMsec) {\r\n\r\n    var now = Utils.nowSecs(localtimeOffsetMsec);\r\n    var tsm = exports.calculateTsMac(now, credentials);\r\n    return { ts: now, tsm: tsm };\r\n};\r\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/lib/utils.js":"// Load modules\r\n\r\nvar Sntp = require('sntp');\r\nvar Boom = require('boom');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\nexports.version = function () {\r\n\r\n    return require('../package.json').version;\r\n};\r\n\r\n\r\nexports.limits = {\r\n    maxMatchLength: 4096            // Limit the length of uris and headers to avoid a DoS attack on string matching\r\n};\r\n\r\n\r\n// Extract host and port from request\r\n\r\n//                                            $1                            $2\r\ninternals.hostHeaderRegex = /^(?:(?:\\r\\n)?\\s)*((?:[^:]+)|(?:\\[[^\\]]+\\]))(?::(\\d+))?(?:(?:\\r\\n)?\\s)*$/;              // (IPv4, hostname)|(IPv6)\r\n\r\n\r\nexports.parseHost = function (req, hostHeaderName) {\r\n\r\n    hostHeaderName = (hostHeaderName ? hostHeaderName.toLowerCase() : 'host');\r\n    var hostHeader = req.headers[hostHeaderName];\r\n    if (!hostHeader) {\r\n        return null;\r\n    }\r\n\r\n    if (hostHeader.length > exports.limits.maxMatchLength) {\r\n        return null;\r\n    }\r\n\r\n    var hostParts = hostHeader.match(internals.hostHeaderRegex);\r\n    if (!hostParts) {\r\n        return null;\r\n    }\r\n\r\n    return {\r\n        name: hostParts[1],\r\n        port: (hostParts[2] ? hostParts[2] : (req.connection && req.connection.encrypted ? 443 : 80))\r\n    };\r\n};\r\n\r\n\r\n// Parse Content-Type header content\r\n\r\nexports.parseContentType = function (header) {\r\n\r\n    if (!header) {\r\n        return '';\r\n    }\r\n\r\n    return header.split(';')[0].trim().toLowerCase();\r\n};\r\n\r\n\r\n// Convert node's  to request configuration object\r\n\r\nexports.parseRequest = function (req, options) {\r\n\r\n    if (!req.headers) {\r\n        return req;\r\n    }\r\n\r\n    // Obtain host and port information\r\n\r\n    var host;\r\n    if (!options.host ||\r\n        !options.port) {\r\n\r\n        host = exports.parseHost(req, options.hostHeaderName);\r\n        if (!host) {\r\n            return new Error('Invalid Host header');\r\n        }\r\n    }\r\n\r\n    var request = {\r\n        method: req.method,\r\n        url: req.url,\r\n        host: options.host || host.name,\r\n        port: options.port || host.port,\r\n        authorization: req.headers.authorization,\r\n        contentType: req.headers['content-type'] || ''\r\n    };\r\n\r\n    return request;\r\n};\r\n\r\n\r\nexports.now = function (localtimeOffsetMsec) {\r\n\r\n    return Sntp.now() + (localtimeOffsetMsec || 0);\r\n};\r\n\r\n\r\nexports.nowSecs = function (localtimeOffsetMsec) {\r\n\r\n    return Math.floor(exports.now(localtimeOffsetMsec) / 1000);\r\n};\r\n\r\n\r\ninternals.authHeaderRegex = /^(\\w+)(?:\\s+(.*))?$/;                                      // Header: scheme[ something]\r\ninternals.attributeRegex = /^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~]+$/;   // !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9\r\n\r\n\r\n// Parse Hawk HTTP Authorization header\r\n\r\nexports.parseAuthorizationHeader = function (header, keys) {\r\n\r\n    keys = keys || ['id', 'ts', 'nonce', 'hash', 'ext', 'mac', 'app', 'dlg'];\r\n\r\n    if (!header) {\r\n        return Boom.unauthorized(null, 'Hawk');\r\n    }\r\n\r\n    if (header.length > exports.limits.maxMatchLength) {\r\n        return Boom.badRequest('Header length too long');\r\n    }\r\n\r\n    var headerParts = header.match(internals.authHeaderRegex);\r\n    if (!headerParts) {\r\n        return Boom.badRequest('Invalid header syntax');\r\n    }\r\n\r\n    var scheme = headerParts[1];\r\n    if (scheme.toLowerCase() !== 'hawk') {\r\n        return Boom.unauthorized(null, 'Hawk');\r\n    }\r\n\r\n    var attributesString = headerParts[2];\r\n    if (!attributesString) {\r\n        return Boom.badRequest('Invalid header syntax');\r\n    }\r\n\r\n    var attributes = {};\r\n    var errorMessage = '';\r\n    var verify = attributesString.replace(/(\\w+)=\"([^\"\\\\]*)\"\\s*(?:,\\s*|$)/g, function ($0, $1, $2) {\r\n\r\n        // Check valid attribute names\r\n\r\n        if (keys.indexOf($1) === -1) {\r\n            errorMessage = 'Unknown attribute: ' + $1;\r\n            return;\r\n        }\r\n\r\n        // Allowed attribute value characters\r\n\r\n        if ($2.match(internals.attributeRegex) === null) {\r\n            errorMessage = 'Bad attribute value: ' + $1;\r\n            return;\r\n        }\r\n\r\n        // Check for duplicates\r\n\r\n        if (attributes.hasOwnProperty($1)) {\r\n            errorMessage = 'Duplicate attribute: ' + $1;\r\n            return;\r\n        }\r\n\r\n        attributes[$1] = $2;\r\n        return '';\r\n    });\r\n\r\n    if (verify !== '') {\r\n        return Boom.badRequest(errorMessage || 'Bad header format');\r\n    }\r\n\r\n    return attributes;\r\n};\r\n\r\n\r\nexports.unauthorized = function (message, attributes) {\r\n\r\n    return Boom.unauthorized(message, 'Hawk', attributes);\r\n};\r\n\r\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/hawk/lib/client.js":"// Load modules\r\n\r\nvar Url = require('url');\r\nvar Hoek = require('hoek');\r\nvar Cryptiles = require('cryptiles');\r\nvar Crypto = require('./crypto');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Generate an Authorization header for a given request\r\n\r\n/*\r\n    uri: 'http://example.com/resource?a=b' or object from Url.parse()\r\n    method: HTTP verb (e.g. 'GET', 'POST')\r\n    options: {\r\n\r\n        // Required\r\n\r\n        credentials: {\r\n            id: 'dh37fgj492je',\r\n            key: 'aoijedoaijsdlaksjdl',\r\n            algorithm: 'sha256'                                 // 'sha1', 'sha256'\r\n        },\r\n\r\n        // Optional\r\n\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        timestamp: Date.now(),                              // A pre-calculated timestamp\r\n        nonce: '2334f34f',                                  // A pre-generated nonce\r\n        localtimeOffsetMsec: 400,                           // Time offset to sync with server time (ignored if timestamp provided)\r\n        payload: '{\"some\":\"payload\"}',                      // UTF-8 encoded string for body hash generation (ignored if hash provided)\r\n        contentType: 'application/json',                    // Payload content-type (ignored if hash provided)\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV=',                    // Pre-calculated payload hash\r\n        app: '24s23423f34dx',                               // Oz application id\r\n        dlg: '234sz34tww3sd'                                // Oz delegated-by application id\r\n    }\r\n*/\r\n\r\nexports.header = function (uri, method, options) {\r\n\r\n    var result = {\r\n        field: '',\r\n        artifacts: {}\r\n    };\r\n\r\n    // Validate inputs\r\n\r\n    if (!uri || (typeof uri !== 'string' && typeof uri !== 'object') ||\r\n        !method || typeof method !== 'string' ||\r\n        !options || typeof options !== 'object') {\r\n\r\n        result.err = 'Invalid argument type';\r\n        return result;\r\n    }\r\n\r\n    // Application time\r\n\r\n    var timestamp = options.timestamp || Utils.nowSecs(options.localtimeOffsetMsec);\r\n\r\n    // Validate credentials\r\n\r\n    var credentials = options.credentials;\r\n    if (!credentials ||\r\n        !credentials.id ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        result.err = 'Invalid credential object';\r\n        return result;\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        result.err = 'Unknown algorithm';\r\n        return result;\r\n    }\r\n\r\n    // Parse URI\r\n\r\n    if (typeof uri === 'string') {\r\n        uri = Url.parse(uri);\r\n    }\r\n\r\n    // Calculate signature\r\n\r\n    var artifacts = {\r\n        ts: timestamp,\r\n        nonce: options.nonce || Cryptiles.randomString(6),\r\n        method: method,\r\n        resource: uri.pathname + (uri.search || ''),                            // Maintain trailing '?'\r\n        host: uri.hostname,\r\n        port: uri.port || (uri.protocol === 'http:' ? 80 : 443),\r\n        hash: options.hash,\r\n        ext: options.ext,\r\n        app: options.app,\r\n        dlg: options.dlg\r\n    };\r\n\r\n    result.artifacts = artifacts;\r\n\r\n    // Calculate payload hash\r\n\r\n    if (!artifacts.hash &&\r\n        (options.payload || options.payload === '')) {\r\n\r\n        artifacts.hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, options.contentType);\r\n    }\r\n\r\n    var mac = Crypto.calculateMac('header', credentials, artifacts);\r\n\r\n    // Construct header\r\n\r\n    var hasExt = artifacts.ext !== null && artifacts.ext !== undefined && artifacts.ext !== '';       // Other falsey values allowed\r\n    var header = 'Hawk id=\"' + credentials.id +\r\n                 '\", ts=\"' + artifacts.ts +\r\n                 '\", nonce=\"' + artifacts.nonce +\r\n                 (artifacts.hash ? '\", hash=\"' + artifacts.hash : '') +\r\n                 (hasExt ? '\", ext=\"' + Hoek.escapeHeaderAttribute(artifacts.ext) : '') +\r\n                 '\", mac=\"' + mac + '\"';\r\n\r\n    if (artifacts.app) {\r\n        header += ', app=\"' + artifacts.app +\r\n                  (artifacts.dlg ? '\", dlg=\"' + artifacts.dlg : '') + '\"';\r\n    }\r\n\r\n    result.field = header;\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Validate server response\r\n\r\n/*\r\n    res:        node's response object\r\n    artifacts:  object received from header().artifacts\r\n    options: {\r\n        payload:    optional payload received\r\n        required:   specifies if a Server-Authorization header is required. Defaults to 'false'\r\n    }\r\n*/\r\n\r\nexports.authenticate = function (res, credentials, artifacts, options) {\r\n\r\n    artifacts = Hoek.clone(artifacts);\r\n    options = options || {};\r\n\r\n    if (res.headers['www-authenticate']) {\r\n\r\n        // Parse HTTP WWW-Authenticate header\r\n\r\n        var wwwAttributes = Utils.parseAuthorizationHeader(res.headers['www-authenticate'], ['ts', 'tsm', 'error']);\r\n        if (wwwAttributes instanceof Error) {\r\n            return false;\r\n        }\r\n\r\n        // Validate server timestamp (not used to update clock since it is done via the SNPT client)\r\n\r\n        if (wwwAttributes.ts) {\r\n            var tsm = Crypto.calculateTsMac(wwwAttributes.ts, credentials);\r\n            if (tsm !== wwwAttributes.tsm) {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n\r\n    // Parse HTTP Server-Authorization header\r\n\r\n    if (!res.headers['server-authorization'] &&\r\n        !options.required) {\r\n\r\n        return true;\r\n    }\r\n\r\n    var attributes = Utils.parseAuthorizationHeader(res.headers['server-authorization'], ['mac', 'ext', 'hash']);\r\n    if (attributes instanceof Error) {\r\n        return false;\r\n    }\r\n\r\n    artifacts.ext = attributes.ext;\r\n    artifacts.hash = attributes.hash;\r\n\r\n    var mac = Crypto.calculateMac('response', credentials, artifacts);\r\n    if (mac !== attributes.mac) {\r\n        return false;\r\n    }\r\n\r\n    if (!options.payload &&\r\n        options.payload !== '') {\r\n\r\n        return true;\r\n    }\r\n\r\n    if (!attributes.hash) {\r\n        return false;\r\n    }\r\n\r\n    var calculatedHash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, res.headers['content-type']);\r\n    return (calculatedHash === attributes.hash);\r\n};\r\n\r\n\r\n// Generate a bewit value for a given URI\r\n\r\n/*\r\n    uri: 'http://example.com/resource?a=b' or object from Url.parse()\r\n    options: {\r\n\r\n        // Required\r\n\r\n        credentials: {\r\n            id: 'dh37fgj492je',\r\n            key: 'aoijedoaijsdlaksjdl',\r\n            algorithm: 'sha256'                             // 'sha1', 'sha256'\r\n        },\r\n        ttlSec: 60 * 60,                                    // TTL in seconds\r\n\r\n        // Optional\r\n\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        localtimeOffsetMsec: 400                            // Time offset to sync with server time\r\n    };\r\n*/\r\n\r\nexports.getBewit = function (uri, options) {\r\n\r\n    // Validate inputs\r\n\r\n    if (!uri ||\r\n        (typeof uri !== 'string' && typeof uri !== 'object') ||\r\n        !options ||\r\n        typeof options !== 'object' ||\r\n        !options.ttlSec) {\r\n\r\n        return '';\r\n    }\r\n\r\n    options.ext = (options.ext === null || options.ext === undefined ? '' : options.ext);       // Zero is valid value\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now(options.localtimeOffsetMsec);\r\n\r\n    // Validate credentials\r\n\r\n    var credentials = options.credentials;\r\n    if (!credentials ||\r\n        !credentials.id ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        return '';\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return '';\r\n    }\r\n\r\n    // Parse URI\r\n\r\n    if (typeof uri === 'string') {\r\n        uri = Url.parse(uri);\r\n    }\r\n\r\n    // Calculate signature\r\n\r\n    var exp = Math.floor(now / 1000) + options.ttlSec;\r\n    var mac = Crypto.calculateMac('bewit', credentials, {\r\n        ts: exp,\r\n        nonce: '',\r\n        method: 'GET',\r\n        resource: uri.pathname + (uri.search || ''),                            // Maintain trailing '?'\r\n        host: uri.hostname,\r\n        port: uri.port || (uri.protocol === 'http:' ? 80 : 443),\r\n        ext: options.ext\r\n    });\r\n\r\n    // Construct bewit: id\\exp\\mac\\ext\r\n\r\n    var bewit = credentials.id + '\\\\' + exp + '\\\\' + mac + '\\\\' + options.ext;\r\n    return Hoek.base64urlEncode(bewit);\r\n};\r\n\r\n\r\n// Generate an authorization string for a message\r\n\r\n/*\r\n    host: 'example.com',\r\n    port: 8000,\r\n    message: '{\"some\":\"payload\"}',                          // UTF-8 encoded string for body hash generation\r\n    options: {\r\n\r\n        // Required\r\n\r\n        credentials: {\r\n            id: 'dh37fgj492je',\r\n            key: 'aoijedoaijsdlaksjdl',\r\n            algorithm: 'sha256'                             // 'sha1', 'sha256'\r\n        },\r\n\r\n        // Optional\r\n\r\n        timestamp: Date.now(),                              // A pre-calculated timestamp\r\n        nonce: '2334f34f',                                  // A pre-generated nonce\r\n        localtimeOffsetMsec: 400,                           // Time offset to sync with server time (ignored if timestamp provided)\r\n    }\r\n*/\r\n\r\nexports.message = function (host, port, message, options) {\r\n\r\n    // Validate inputs\r\n\r\n    if (!host || typeof host !== 'string' ||\r\n        !port || typeof port !== 'number' ||\r\n        message === null || message === undefined || typeof message !== 'string' ||\r\n        !options || typeof options !== 'object') {\r\n\r\n        return null;\r\n    }\r\n\r\n    // Application time\r\n\r\n    var timestamp = options.timestamp || Utils.nowSecs(options.localtimeOffsetMsec);\r\n\r\n    // Validate credentials\r\n\r\n    var credentials = options.credentials;\r\n    if (!credentials ||\r\n        !credentials.id ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        // Invalid credential object\r\n        return null;\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return null;\r\n    }\r\n\r\n    // Calculate signature\r\n\r\n    var artifacts = {\r\n        ts: timestamp,\r\n        nonce: options.nonce || Cryptiles.randomString(6),\r\n        host: host,\r\n        port: port,\r\n        hash: Crypto.calculatePayloadHash(message, credentials.algorithm)\r\n    };\r\n\r\n    // Construct authorization\r\n\r\n    var result = {\r\n        id: credentials.id,\r\n        ts: artifacts.ts,\r\n        nonce: artifacts.nonce,\r\n        hash: artifacts.hash,\r\n        mac: Crypto.calculateMac('message', credentials, artifacts)\r\n    };\r\n\r\n    return result;\r\n};\r\n\r\n\r\n\r\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/aws-sign2/index.js":"\n/*!\n *  Copyright 2010 LearnBoost <dev@learnboost.com>\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Module dependencies.\n */\n\nvar crypto = require('crypto')\n  , parse = require('url').parse\n  ;\n\n/**\n * Valid keys.\n */\n\nvar keys = \n  [ 'acl'\n  , 'location'\n  , 'logging'\n  , 'notification'\n  , 'partNumber'\n  , 'policy'\n  , 'requestPayment'\n  , 'torrent'\n  , 'uploadId'\n  , 'uploads'\n  , 'versionId'\n  , 'versioning'\n  , 'versions'\n  , 'website'\n  ]\n\n/**\n * Return an \"Authorization\" header value with the given `options`\n * in the form of \"AWS <key>:<signature>\"\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction authorization (options) {\n  return 'AWS ' + options.key + ':' + sign(options)\n}\n\nmodule.exports = authorization\nmodule.exports.authorization = authorization\n\n/**\n * Simple HMAC-SHA1 Wrapper\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */ \n\nfunction hmacSha1 (options) {\n  return crypto.createHmac('sha1', options.secret).update(options.message).digest('base64')\n}\n\nmodule.exports.hmacSha1 = hmacSha1\n\n/**\n * Create a base64 sha1 HMAC for `options`. \n * \n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction sign (options) {\n  options.message = stringToSign(options)\n  return hmacSha1(options)\n}\nmodule.exports.sign = sign\n\n/**\n * Create a base64 sha1 HMAC for `options`. \n *\n * Specifically to be used with S3 presigned URLs\n * \n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction signQuery (options) {\n  options.message = queryStringToSign(options)\n  return hmacSha1(options)\n}\nmodule.exports.signQuery= signQuery\n\n/**\n * Return a string for sign() with the given `options`.\n *\n * Spec:\n * \n *    <verb>\\n\n *    <md5>\\n\n *    <content-type>\\n\n *    <date>\\n\n *    [headers\\n]\n *    <resource>\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction stringToSign (options) {\n  var headers = options.amazonHeaders || ''\n  if (headers) headers += '\\n'\n  var r = \n    [ options.verb\n    , options.md5\n    , options.contentType\n    , options.date ? options.date.toUTCString() : ''\n    , headers + options.resource\n    ]\n  return r.join('\\n')\n}\nmodule.exports.queryStringToSign = stringToSign\n\n/**\n * Return a string for sign() with the given `options`, but is meant exclusively\n * for S3 presigned URLs\n *\n * Spec:\n * \n *    <date>\\n\n *    <resource>\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction queryStringToSign (options){\n  return 'GET\\n\\n\\n' + options.date + '\\n' + options.resource\n}\nmodule.exports.queryStringToSign = queryStringToSign\n\n/**\n * Perform the following:\n *\n *  - ignore non-amazon headers\n *  - lowercase fields\n *  - sort lexicographically\n *  - trim whitespace between \":\"\n *  - join with newline\n *\n * @param {Object} headers\n * @return {String}\n * @api private\n */\n\nfunction canonicalizeHeaders (headers) {\n  var buf = []\n    , fields = Object.keys(headers)\n    ;\n  for (var i = 0, len = fields.length; i < len; ++i) {\n    var field = fields[i]\n      , val = headers[field]\n      , field = field.toLowerCase()\n      ;\n    if (0 !== field.indexOf('x-amz')) continue\n    buf.push(field + ':' + val)\n  }\n  return buf.sort().join('\\n')\n}\nmodule.exports.canonicalizeHeaders = canonicalizeHeaders\n\n/**\n * Perform the following:\n *\n *  - ignore non sub-resources\n *  - sort lexicographically\n *\n * @param {String} resource\n * @return {String}\n * @api private\n */\n\nfunction canonicalizeResource (resource) {\n  var url = parse(resource, true)\n    , path = url.pathname\n    , buf = []\n    ;\n\n  Object.keys(url.query).forEach(function(key){\n    if (!~keys.indexOf(key)) return\n    var val = '' == url.query[key] ? '' : '=' + encodeURIComponent(url.query[key])\n    buf.push(key + val)\n  })\n\n  return path + (buf.length ? '?' + buf.sort().join('&') : '')\n}\nmodule.exports.canonicalizeResource = canonicalizeResource\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/aws4/aws4.js":"var aws4 = exports,\n    url = require('url'),\n    querystring = require('querystring'),\n    crypto = require('crypto'),\n    lru = require('./lru'),\n    credentialsCache = lru(1000)\n\n// http://docs.amazonwebservices.com/general/latest/gr/signature-version-4.html\n\nfunction hmac(key, string, encoding) {\n  return crypto.createHmac('sha256', key).update(string, 'utf8').digest(encoding)\n}\n\nfunction hash(string, encoding) {\n  return crypto.createHash('sha256').update(string, 'utf8').digest(encoding)\n}\n\n// This function assumes the string has already been percent encoded\nfunction encodeRfc3986(urlEncodedString) {\n  return urlEncodedString.replace(/[!'()*]/g, function(c) {\n    return '%' + c.charCodeAt(0).toString(16).toUpperCase()\n  })\n}\n\n// request: { path | body, [host], [method], [headers], [service], [region] }\n// credentials: { accessKeyId, secretAccessKey, [sessionToken] }\nfunction RequestSigner(request, credentials) {\n\n  if (typeof request === 'string') request = url.parse(request)\n\n  var headers = request.headers = (request.headers || {}),\n      hostParts = this.matchHost(request.hostname || request.host || headers.Host || headers.host)\n\n  this.request = request\n  this.credentials = credentials || this.defaultCredentials()\n\n  this.service = request.service || hostParts[0] || ''\n  this.region = request.region || hostParts[1] || 'us-east-1'\n\n  // SES uses a different domain from the service name\n  if (this.service === 'email') this.service = 'ses'\n\n  if (!request.method && request.body)\n    request.method = 'POST'\n\n  if (!headers.Host && !headers.host) {\n    headers.Host = request.hostname || request.host || this.createHost()\n\n    // If a port is specified explicitly, use it as is\n    if (request.port)\n      headers.Host += ':' + request.port\n  }\n  if (!request.hostname && !request.host)\n    request.hostname = headers.Host || headers.host\n\n  this.isCodeCommitGit = this.service === 'codecommit' && request.method === 'GIT'\n}\n\nRequestSigner.prototype.matchHost = function(host) {\n  var match = (host || '').match(/([^\\.]+)\\.(?:([^\\.]*)\\.)?amazonaws\\.com$/)\n  var hostParts = (match || []).slice(1, 3)\n\n  // ES's hostParts are sometimes the other way round, if the value that is expected\n  // to be region equals es switch them back\n  // e.g. search-cluster-name-aaaa00aaaa0aaa0aaaaaaa0aaa.us-east-1.es.amazonaws.com\n  if (hostParts[1] === 'es')\n    hostParts = hostParts.reverse()\n\n  return hostParts\n}\n\n// http://docs.aws.amazon.com/general/latest/gr/rande.html\nRequestSigner.prototype.isSingleRegion = function() {\n  // Special case for S3 and SimpleDB in us-east-1\n  if (['s3', 'sdb'].indexOf(this.service) >= 0 && this.region === 'us-east-1') return true\n\n  return ['cloudfront', 'ls', 'route53', 'iam', 'importexport', 'sts']\n    .indexOf(this.service) >= 0\n}\n\nRequestSigner.prototype.createHost = function() {\n  var region = this.isSingleRegion() ? '' :\n        (this.service === 's3' && this.region !== 'us-east-1' ? '-' : '.') + this.region,\n      service = this.service === 'ses' ? 'email' : this.service\n  return service + region + '.amazonaws.com'\n}\n\nRequestSigner.prototype.prepareRequest = function() {\n  this.parsePath()\n\n  var request = this.request, headers = request.headers, query\n\n  if (request.signQuery) {\n\n    this.parsedPath.query = query = this.parsedPath.query || {}\n\n    if (this.credentials.sessionToken)\n      query['X-Amz-Security-Token'] = this.credentials.sessionToken\n\n    if (this.service === 's3' && !query['X-Amz-Expires'])\n      query['X-Amz-Expires'] = 86400\n\n    if (query['X-Amz-Date'])\n      this.datetime = query['X-Amz-Date']\n    else\n      query['X-Amz-Date'] = this.getDateTime()\n\n    query['X-Amz-Algorithm'] = 'AWS4-HMAC-SHA256'\n    query['X-Amz-Credential'] = this.credentials.accessKeyId + '/' + this.credentialString()\n    query['X-Amz-SignedHeaders'] = this.signedHeaders()\n\n  } else {\n\n    if (!request.doNotModifyHeaders && !this.isCodeCommitGit) {\n      if (request.body && !headers['Content-Type'] && !headers['content-type'])\n        headers['Content-Type'] = 'application/x-www-form-urlencoded; charset=utf-8'\n\n      if (request.body && !headers['Content-Length'] && !headers['content-length'])\n        headers['Content-Length'] = Buffer.byteLength(request.body)\n\n      if (this.credentials.sessionToken && !headers['X-Amz-Security-Token'] && !headers['x-amz-security-token'])\n        headers['X-Amz-Security-Token'] = this.credentials.sessionToken\n\n      if (this.service === 's3' && !headers['X-Amz-Content-Sha256'] && !headers['x-amz-content-sha256'])\n        headers['X-Amz-Content-Sha256'] = hash(this.request.body || '', 'hex')\n\n      if (headers['X-Amz-Date'] || headers['x-amz-date'])\n        this.datetime = headers['X-Amz-Date'] || headers['x-amz-date']\n      else\n        headers['X-Amz-Date'] = this.getDateTime()\n    }\n\n    delete headers.Authorization\n    delete headers.authorization\n  }\n}\n\nRequestSigner.prototype.sign = function() {\n  if (!this.parsedPath) this.prepareRequest()\n\n  if (this.request.signQuery) {\n    this.parsedPath.query['X-Amz-Signature'] = this.signature()\n  } else {\n    this.request.headers.Authorization = this.authHeader()\n  }\n\n  this.request.path = this.formatPath()\n\n  return this.request\n}\n\nRequestSigner.prototype.getDateTime = function() {\n  if (!this.datetime) {\n    var headers = this.request.headers,\n      date = new Date(headers.Date || headers.date || new Date)\n\n    this.datetime = date.toISOString().replace(/[:\\-]|\\.\\d{3}/g, '')\n\n    // Remove the trailing 'Z' on the timestamp string for CodeCommit git access\n    if (this.isCodeCommitGit) this.datetime = this.datetime.slice(0, -1)\n  }\n  return this.datetime\n}\n\nRequestSigner.prototype.getDate = function() {\n  return this.getDateTime().substr(0, 8)\n}\n\nRequestSigner.prototype.authHeader = function() {\n  return [\n    'AWS4-HMAC-SHA256 Credential=' + this.credentials.accessKeyId + '/' + this.credentialString(),\n    'SignedHeaders=' + this.signedHeaders(),\n    'Signature=' + this.signature(),\n  ].join(', ')\n}\n\nRequestSigner.prototype.signature = function() {\n  var date = this.getDate(),\n      cacheKey = [this.credentials.secretAccessKey, date, this.region, this.service].join(),\n      kDate, kRegion, kService, kCredentials = credentialsCache.get(cacheKey)\n  if (!kCredentials) {\n    kDate = hmac('AWS4' + this.credentials.secretAccessKey, date)\n    kRegion = hmac(kDate, this.region)\n    kService = hmac(kRegion, this.service)\n    kCredentials = hmac(kService, 'aws4_request')\n    credentialsCache.set(cacheKey, kCredentials)\n  }\n  return hmac(kCredentials, this.stringToSign(), 'hex')\n}\n\nRequestSigner.prototype.stringToSign = function() {\n  return [\n    'AWS4-HMAC-SHA256',\n    this.getDateTime(),\n    this.credentialString(),\n    hash(this.canonicalString(), 'hex'),\n  ].join('\\n')\n}\n\nRequestSigner.prototype.canonicalString = function() {\n  if (!this.parsedPath) this.prepareRequest()\n\n  var pathStr = this.parsedPath.path,\n      query = this.parsedPath.query,\n      headers = this.request.headers,\n      queryStr = '',\n      normalizePath = this.service !== 's3',\n      decodePath = this.service === 's3' || this.request.doNotEncodePath,\n      decodeSlashesInPath = this.service === 's3',\n      firstValOnly = this.service === 's3',\n      bodyHash\n\n  if (this.service === 's3' && this.request.signQuery) {\n    bodyHash = 'UNSIGNED-PAYLOAD'\n  } else if (this.isCodeCommitGit) {\n    bodyHash = ''\n  } else {\n    bodyHash = headers['X-Amz-Content-Sha256'] || headers['x-amz-content-sha256'] ||\n      hash(this.request.body || '', 'hex')\n  }\n\n  if (query) {\n    queryStr = encodeRfc3986(querystring.stringify(Object.keys(query).sort().reduce(function(obj, key) {\n      if (!key) return obj\n      obj[key] = !Array.isArray(query[key]) ? query[key] :\n        (firstValOnly ? query[key][0] : query[key].slice().sort())\n      return obj\n    }, {})))\n  }\n  if (pathStr !== '/') {\n    if (normalizePath) pathStr = pathStr.replace(/\\/{2,}/g, '/')\n    pathStr = pathStr.split('/').reduce(function(path, piece) {\n      if (normalizePath && piece === '..') {\n        path.pop()\n      } else if (!normalizePath || piece !== '.') {\n        if (decodePath) piece = querystring.unescape(piece)\n        path.push(encodeRfc3986(querystring.escape(piece)))\n      }\n      return path\n    }, []).join('/')\n    if (pathStr[0] !== '/') pathStr = '/' + pathStr\n    if (decodeSlashesInPath) pathStr = pathStr.replace(/%2F/g, '/')\n  }\n\n  return [\n    this.request.method || 'GET',\n    pathStr,\n    queryStr,\n    this.canonicalHeaders() + '\\n',\n    this.signedHeaders(),\n    bodyHash,\n  ].join('\\n')\n}\n\nRequestSigner.prototype.canonicalHeaders = function() {\n  var headers = this.request.headers\n  function trimAll(header) {\n    return header.toString().trim().replace(/\\s+/g, ' ')\n  }\n  return Object.keys(headers)\n    .sort(function(a, b) { return a.toLowerCase() < b.toLowerCase() ? -1 : 1 })\n    .map(function(key) { return key.toLowerCase() + ':' + trimAll(headers[key]) })\n    .join('\\n')\n}\n\nRequestSigner.prototype.signedHeaders = function() {\n  return Object.keys(this.request.headers)\n    .map(function(key) { return key.toLowerCase() })\n    .sort()\n    .join(';')\n}\n\nRequestSigner.prototype.credentialString = function() {\n  return [\n    this.getDate(),\n    this.region,\n    this.service,\n    'aws4_request',\n  ].join('/')\n}\n\nRequestSigner.prototype.defaultCredentials = function() {\n  var env = process.env\n  return {\n    accessKeyId: env.AWS_ACCESS_KEY_ID || env.AWS_ACCESS_KEY,\n    secretAccessKey: env.AWS_SECRET_ACCESS_KEY || env.AWS_SECRET_KEY,\n    sessionToken: env.AWS_SESSION_TOKEN,\n  }\n}\n\nRequestSigner.prototype.parsePath = function() {\n  var path = this.request.path || '/',\n      queryIx = path.indexOf('?'),\n      query = null\n\n  if (queryIx >= 0) {\n    query = querystring.parse(path.slice(queryIx + 1))\n    path = path.slice(0, queryIx)\n  }\n\n  // S3 doesn't always encode characters > 127 correctly and\n  // all services don't encode characters > 255 correctly\n  // So if there are non-reserved chars (and it's not already all % encoded), just encode them all\n  if (/[^0-9A-Za-z!'()*\\-._~%/]/.test(path)) {\n    path = path.split('/').map(function(piece) {\n      return querystring.escape(querystring.unescape(piece))\n    }).join('/')\n  }\n\n  this.parsedPath = {\n    path: path,\n    query: query,\n  }\n}\n\nRequestSigner.prototype.formatPath = function() {\n  var path = this.parsedPath.path,\n      query = this.parsedPath.query\n\n  if (!query) return path\n\n  // Services don't support empty query string keys\n  if (query[''] != null) delete query['']\n\n  return path + '?' + encodeRfc3986(querystring.stringify(query))\n}\n\naws4.RequestSigner = RequestSigner\n\naws4.sign = function(request, credentials) {\n  return new RequestSigner(request, credentials).sign()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/aws4/lru.js":"module.exports = function(size) {\n  return new LruCache(size)\n}\n\nfunction LruCache(size) {\n  this.capacity = size | 0\n  this.map = Object.create(null)\n  this.list = new DoublyLinkedList()\n}\n\nLruCache.prototype.get = function(key) {\n  var node = this.map[key]\n  if (node == null) return undefined\n  this.used(node)\n  return node.val\n}\n\nLruCache.prototype.set = function(key, val) {\n  var node = this.map[key]\n  if (node != null) {\n    node.val = val\n  } else {\n    if (!this.capacity) this.prune()\n    if (!this.capacity) return false\n    node = new DoublyLinkedNode(key, val)\n    this.map[key] = node\n    this.capacity--\n  }\n  this.used(node)\n  return true\n}\n\nLruCache.prototype.used = function(node) {\n  this.list.moveToFront(node)\n}\n\nLruCache.prototype.prune = function() {\n  var node = this.list.pop()\n  if (node != null) {\n    delete this.map[node.key]\n    this.capacity++\n  }\n}\n\n\nfunction DoublyLinkedList() {\n  this.firstNode = null\n  this.lastNode = null\n}\n\nDoublyLinkedList.prototype.moveToFront = function(node) {\n  if (this.firstNode == node) return\n\n  this.remove(node)\n\n  if (this.firstNode == null) {\n    this.firstNode = node\n    this.lastNode = node\n    node.prev = null\n    node.next = null\n  } else {\n    node.prev = null\n    node.next = this.firstNode\n    node.next.prev = node\n    this.firstNode = node\n  }\n}\n\nDoublyLinkedList.prototype.pop = function() {\n  var lastNode = this.lastNode\n  if (lastNode != null) {\n    this.remove(lastNode)\n  }\n  return lastNode\n}\n\nDoublyLinkedList.prototype.remove = function(node) {\n  if (this.firstNode == node) {\n    this.firstNode = node.next\n  } else if (node.prev != null) {\n    node.prev.next = node.next\n  }\n  if (this.lastNode == node) {\n    this.lastNode = node.prev\n  } else if (node.next != null) {\n    node.next.prev = node.prev\n  }\n}\n\n\nfunction DoublyLinkedNode(key, val) {\n  this.key = key\n  this.val = val\n  this.prev = null\n  this.next = null\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/lib/index.js":"// Copyright 2015 Joyent, Inc.\n\nvar parser = require('./parser');\nvar signer = require('./signer');\nvar verify = require('./verify');\nvar utils = require('./utils');\n\n\n\n///--- API\n\nmodule.exports = {\n\n  parse: parser.parseRequest,\n  parseRequest: parser.parseRequest,\n\n  sign: signer.signRequest,\n  signRequest: signer.signRequest,\n  createSigner: signer.createSigner,\n  isSigner: signer.isSigner,\n\n  sshKeyToPEM: utils.sshKeyToPEM,\n  sshKeyFingerprint: utils.fingerprint,\n  pemToRsaSSHKey: utils.pemToRsaSSHKey,\n\n  verify: verify.verifySignature,\n  verifySignature: verify.verifySignature,\n  verifyHMAC: verify.verifyHMAC\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/lib/parser.js":"// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar util = require('util');\nvar utils = require('./utils');\n\n\n\n///--- Globals\n\nvar HASH_ALGOS = utils.HASH_ALGOS;\nvar PK_ALGOS = utils.PK_ALGOS;\nvar HttpSignatureError = utils.HttpSignatureError;\nvar InvalidAlgorithmError = utils.InvalidAlgorithmError;\nvar validateAlgorithm = utils.validateAlgorithm;\n\nvar State = {\n  New: 0,\n  Params: 1\n};\n\nvar ParamsState = {\n  Name: 0,\n  Quote: 1,\n  Value: 2,\n  Comma: 3\n};\n\n\n///--- Specific Errors\n\n\nfunction ExpiredRequestError(message) {\n  HttpSignatureError.call(this, message, ExpiredRequestError);\n}\nutil.inherits(ExpiredRequestError, HttpSignatureError);\n\n\nfunction InvalidHeaderError(message) {\n  HttpSignatureError.call(this, message, InvalidHeaderError);\n}\nutil.inherits(InvalidHeaderError, HttpSignatureError);\n\n\nfunction InvalidParamsError(message) {\n  HttpSignatureError.call(this, message, InvalidParamsError);\n}\nutil.inherits(InvalidParamsError, HttpSignatureError);\n\n\nfunction MissingHeaderError(message) {\n  HttpSignatureError.call(this, message, MissingHeaderError);\n}\nutil.inherits(MissingHeaderError, HttpSignatureError);\n\nfunction StrictParsingError(message) {\n  HttpSignatureError.call(this, message, StrictParsingError);\n}\nutil.inherits(StrictParsingError, HttpSignatureError);\n\n///--- Exported API\n\nmodule.exports = {\n\n  /**\n   * Parses the 'Authorization' header out of an http.ServerRequest object.\n   *\n   * Note that this API will fully validate the Authorization header, and throw\n   * on any error.  It will not however check the signature, or the keyId format\n   * as those are specific to your environment.  You can use the options object\n   * to pass in extra constraints.\n   *\n   * As a response object you can expect this:\n   *\n   *     {\n   *       \"scheme\": \"Signature\",\n   *       \"params\": {\n   *         \"keyId\": \"foo\",\n   *         \"algorithm\": \"rsa-sha256\",\n   *         \"headers\": [\n   *           \"date\" or \"x-date\",\n   *           \"digest\"\n   *         ],\n   *         \"signature\": \"base64\"\n   *       },\n   *       \"signingString\": \"ready to be passed to crypto.verify()\"\n   *     }\n   *\n   * @param {Object} request an http.ServerRequest.\n   * @param {Object} options an optional options object with:\n   *                   - clockSkew: allowed clock skew in seconds (default 300).\n   *                   - headers: required header names (def: date or x-date)\n   *                   - algorithms: algorithms to support (default: all).\n   *                   - strict: should enforce latest spec parsing\n   *                             (default: false).\n   * @return {Object} parsed out object (see above).\n   * @throws {TypeError} on invalid input.\n   * @throws {InvalidHeaderError} on an invalid Authorization header error.\n   * @throws {InvalidParamsError} if the params in the scheme are invalid.\n   * @throws {MissingHeaderError} if the params indicate a header not present,\n   *                              either in the request headers from the params,\n   *                              or not in the params from a required header\n   *                              in options.\n   * @throws {StrictParsingError} if old attributes are used in strict parsing\n   *                              mode.\n   * @throws {ExpiredRequestError} if the value of date or x-date exceeds skew.\n   */\n  parseRequest: function parseRequest(request, options) {\n    assert.object(request, 'request');\n    assert.object(request.headers, 'request.headers');\n    if (options === undefined) {\n      options = {};\n    }\n    if (options.headers === undefined) {\n      options.headers = [request.headers['x-date'] ? 'x-date' : 'date'];\n    }\n    assert.object(options, 'options');\n    assert.arrayOfString(options.headers, 'options.headers');\n    assert.optionalNumber(options.clockSkew, 'options.clockSkew');\n\n    if (!request.headers.authorization)\n      throw new MissingHeaderError('no authorization header present in ' +\n                                   'the request');\n\n    options.clockSkew = options.clockSkew || 300;\n\n\n    var i = 0;\n    var state = State.New;\n    var substate = ParamsState.Name;\n    var tmpName = '';\n    var tmpValue = '';\n\n    var parsed = {\n      scheme: '',\n      params: {},\n      signingString: '',\n\n      get algorithm() {\n        return this.params.algorithm.toUpperCase();\n      },\n\n      get keyId() {\n        return this.params.keyId;\n      }\n    };\n\n    var authz = request.headers.authorization;\n    for (i = 0; i < authz.length; i++) {\n      var c = authz.charAt(i);\n\n      switch (Number(state)) {\n\n      case State.New:\n        if (c !== ' ') parsed.scheme += c;\n        else state = State.Params;\n        break;\n\n      case State.Params:\n        switch (Number(substate)) {\n\n        case ParamsState.Name:\n          var code = c.charCodeAt(0);\n          // restricted name of A-Z / a-z\n          if ((code >= 0x41 && code <= 0x5a) || // A-Z\n              (code >= 0x61 && code <= 0x7a)) { // a-z\n            tmpName += c;\n          } else if (c === '=') {\n            if (tmpName.length === 0)\n              throw new InvalidHeaderError('bad param format');\n            substate = ParamsState.Quote;\n          } else {\n            throw new InvalidHeaderError('bad param format');\n          }\n          break;\n\n        case ParamsState.Quote:\n          if (c === '\"') {\n            tmpValue = '';\n            substate = ParamsState.Value;\n          } else {\n            throw new InvalidHeaderError('bad param format');\n          }\n          break;\n\n        case ParamsState.Value:\n          if (c === '\"') {\n            parsed.params[tmpName] = tmpValue;\n            substate = ParamsState.Comma;\n          } else {\n            tmpValue += c;\n          }\n          break;\n\n        case ParamsState.Comma:\n          if (c === ',') {\n            tmpName = '';\n            substate = ParamsState.Name;\n          } else {\n            throw new InvalidHeaderError('bad param format');\n          }\n          break;\n\n        default:\n          throw new Error('Invalid substate');\n        }\n        break;\n\n      default:\n        throw new Error('Invalid substate');\n      }\n\n    }\n\n    if (!parsed.params.headers || parsed.params.headers === '') {\n      if (request.headers['x-date']) {\n        parsed.params.headers = ['x-date'];\n      } else {\n        parsed.params.headers = ['date'];\n      }\n    } else {\n      parsed.params.headers = parsed.params.headers.split(' ');\n    }\n\n    // Minimally validate the parsed object\n    if (!parsed.scheme || parsed.scheme !== 'Signature')\n      throw new InvalidHeaderError('scheme was not \"Signature\"');\n\n    if (!parsed.params.keyId)\n      throw new InvalidHeaderError('keyId was not specified');\n\n    if (!parsed.params.algorithm)\n      throw new InvalidHeaderError('algorithm was not specified');\n\n    if (!parsed.params.signature)\n      throw new InvalidHeaderError('signature was not specified');\n\n    // Check the algorithm against the official list\n    parsed.params.algorithm = parsed.params.algorithm.toLowerCase();\n    try {\n      validateAlgorithm(parsed.params.algorithm);\n    } catch (e) {\n      if (e instanceof InvalidAlgorithmError)\n        throw (new InvalidParamsError(parsed.params.algorithm + ' is not ' +\n          'supported'));\n      else\n        throw (e);\n    }\n\n    // Build the signingString\n    for (i = 0; i < parsed.params.headers.length; i++) {\n      var h = parsed.params.headers[i].toLowerCase();\n      parsed.params.headers[i] = h;\n\n      if (h === 'request-line') {\n        if (!options.strict) {\n          /*\n           * We allow headers from the older spec drafts if strict parsing isn't\n           * specified in options.\n           */\n          parsed.signingString +=\n            request.method + ' ' + request.url + ' HTTP/' + request.httpVersion;\n        } else {\n          /* Strict parsing doesn't allow older draft headers. */\n          throw (new StrictParsingError('request-line is not a valid header ' +\n            'with strict parsing enabled.'));\n        }\n      } else if (h === '(request-target)') {\n        parsed.signingString +=\n          '(request-target): ' + request.method.toLowerCase() + ' ' +\n          request.url;\n      } else {\n        var value = request.headers[h];\n        if (value === undefined)\n          throw new MissingHeaderError(h + ' was not in the request');\n        parsed.signingString += h + ': ' + value;\n      }\n\n      if ((i + 1) < parsed.params.headers.length)\n        parsed.signingString += '\\n';\n    }\n\n    // Check against the constraints\n    var date;\n    if (request.headers.date || request.headers['x-date']) {\n        if (request.headers['x-date']) {\n          date = new Date(request.headers['x-date']);\n        } else {\n          date = new Date(request.headers.date);\n        }\n      var now = new Date();\n      var skew = Math.abs(now.getTime() - date.getTime());\n\n      if (skew > options.clockSkew * 1000) {\n        throw new ExpiredRequestError('clock skew of ' +\n                                      (skew / 1000) +\n                                      's was greater than ' +\n                                      options.clockSkew + 's');\n      }\n    }\n\n    options.headers.forEach(function (hdr) {\n      // Remember that we already checked any headers in the params\n      // were in the request, so if this passes we're good.\n      if (parsed.params.headers.indexOf(hdr) < 0)\n        throw new MissingHeaderError(hdr + ' was not a signed header');\n    });\n\n    if (options.algorithms) {\n      if (options.algorithms.indexOf(parsed.params.algorithm) === -1)\n        throw new InvalidParamsError(parsed.params.algorithm +\n                                     ' is not a supported algorithm');\n    }\n\n    return parsed;\n  }\n\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/assert-plus/assert.js":"// Copyright (c) 2012, Mark Cavage. All rights reserved.\n// Copyright 2015 Joyent, Inc.\n\nvar assert = require('assert');\nvar Stream = require('stream').Stream;\nvar util = require('util');\n\n\n///--- Globals\n\n/* JSSTYLED */\nvar UUID_REGEXP = /^[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}$/;\n\n\n///--- Internal\n\nfunction _capitalize(str) {\n    return (str.charAt(0).toUpperCase() + str.slice(1));\n}\n\nfunction _toss(name, expected, oper, arg, actual) {\n    throw new assert.AssertionError({\n        message: util.format('%s (%s) is required', name, expected),\n        actual: (actual === undefined) ? typeof (arg) : actual(arg),\n        expected: expected,\n        operator: oper || '===',\n        stackStartFunction: _toss.caller\n    });\n}\n\nfunction _getClass(arg) {\n    return (Object.prototype.toString.call(arg).slice(8, -1));\n}\n\nfunction noop() {\n    // Why even bother with asserts?\n}\n\n\n///--- Exports\n\nvar types = {\n    bool: {\n        check: function (arg) { return typeof (arg) === 'boolean'; }\n    },\n    func: {\n        check: function (arg) { return typeof (arg) === 'function'; }\n    },\n    string: {\n        check: function (arg) { return typeof (arg) === 'string'; }\n    },\n    object: {\n        check: function (arg) {\n            return typeof (arg) === 'object' && arg !== null;\n        }\n    },\n    number: {\n        check: function (arg) {\n            return typeof (arg) === 'number' && !isNaN(arg) && isFinite(arg);\n        }\n    },\n    buffer: {\n        check: function (arg) { return Buffer.isBuffer(arg); },\n        operator: 'Buffer.isBuffer'\n    },\n    array: {\n        check: function (arg) { return Array.isArray(arg); },\n        operator: 'Array.isArray'\n    },\n    stream: {\n        check: function (arg) { return arg instanceof Stream; },\n        operator: 'instanceof',\n        actual: _getClass\n    },\n    date: {\n        check: function (arg) { return arg instanceof Date; },\n        operator: 'instanceof',\n        actual: _getClass\n    },\n    regexp: {\n        check: function (arg) { return arg instanceof RegExp; },\n        operator: 'instanceof',\n        actual: _getClass\n    },\n    uuid: {\n        check: function (arg) {\n            return typeof (arg) === 'string' && UUID_REGEXP.test(arg);\n        },\n        operator: 'isUUID'\n    }\n};\n\nfunction _setExports(ndebug) {\n    var keys = Object.keys(types);\n    var out;\n\n    /* re-export standard assert */\n    if (process.env.NODE_NDEBUG) {\n        out = noop;\n    } else {\n        out = function (arg, msg) {\n            if (!arg) {\n                _toss(msg, 'true', arg);\n            }\n        };\n    }\n\n    /* standard checks */\n    keys.forEach(function (k) {\n        if (ndebug) {\n            out[k] = noop;\n            return;\n        }\n        var type = types[k];\n        out[k] = function (arg, msg) {\n            if (!type.check(arg)) {\n                _toss(msg, k, type.operator, arg, type.actual);\n            }\n        };\n    });\n\n    /* optional checks */\n    keys.forEach(function (k) {\n        var name = 'optional' + _capitalize(k);\n        if (ndebug) {\n            out[name] = noop;\n            return;\n        }\n        var type = types[k];\n        out[name] = function (arg, msg) {\n            if (arg === undefined || arg === null) {\n                return;\n            }\n            if (!type.check(arg)) {\n                _toss(msg, k, type.operator, arg, type.actual);\n            }\n        };\n    });\n\n    /* arrayOf checks */\n    keys.forEach(function (k) {\n        var name = 'arrayOf' + _capitalize(k);\n        if (ndebug) {\n            out[name] = noop;\n            return;\n        }\n        var type = types[k];\n        var expected = '[' + k + ']';\n        out[name] = function (arg, msg) {\n            if (!Array.isArray(arg)) {\n                _toss(msg, expected, type.operator, arg, type.actual);\n            }\n            var i;\n            for (i = 0; i < arg.length; i++) {\n                if (!type.check(arg[i])) {\n                    _toss(msg, expected, type.operator, arg, type.actual);\n                }\n            }\n        };\n    });\n\n    /* optionalArrayOf checks */\n    keys.forEach(function (k) {\n        var name = 'optionalArrayOf' + _capitalize(k);\n        if (ndebug) {\n            out[name] = noop;\n            return;\n        }\n        var type = types[k];\n        var expected = '[' + k + ']';\n        out[name] = function (arg, msg) {\n            if (arg === undefined || arg === null) {\n                return;\n            }\n            if (!Array.isArray(arg)) {\n                _toss(msg, expected, type.operator, arg, type.actual);\n            }\n            var i;\n            for (i = 0; i < arg.length; i++) {\n                if (!type.check(arg[i])) {\n                    _toss(msg, expected, type.operator, arg, type.actual);\n                }\n            }\n        };\n    });\n\n    /* re-export built-in assertions */\n    Object.keys(assert).forEach(function (k) {\n        if (k === 'AssertionError') {\n            out[k] = assert[k];\n            return;\n        }\n        if (ndebug) {\n            out[k] = noop;\n            return;\n        }\n        out[k] = assert[k];\n    });\n\n    /* export ourselves (for unit tests _only_) */\n    out._setExports = _setExports;\n\n    return out;\n}\n\nmodule.exports = _setExports(process.env.NODE_NDEBUG);\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/lib/utils.js":"// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar sshpk = require('sshpk');\nvar util = require('util');\n\nvar HASH_ALGOS = {\n  'sha1': true,\n  'sha256': true,\n  'sha512': true\n};\n\nvar PK_ALGOS = {\n  'rsa': true,\n  'dsa': true,\n  'ecdsa': true\n};\n\nfunction HttpSignatureError(message, caller) {\n  if (Error.captureStackTrace)\n    Error.captureStackTrace(this, caller || HttpSignatureError);\n\n  this.message = message;\n  this.name = caller.name;\n}\nutil.inherits(HttpSignatureError, Error);\n\nfunction InvalidAlgorithmError(message) {\n  HttpSignatureError.call(this, message, InvalidAlgorithmError);\n}\nutil.inherits(InvalidAlgorithmError, HttpSignatureError);\n\nfunction validateAlgorithm(algorithm) {\n  var alg = algorithm.toLowerCase().split('-');\n\n  if (alg.length !== 2) {\n    throw (new InvalidAlgorithmError(alg[0].toUpperCase() + ' is not a ' +\n      'valid algorithm'));\n  }\n\n  if (alg[0] !== 'hmac' && !PK_ALGOS[alg[0]]) {\n    throw (new InvalidAlgorithmError(alg[0].toUpperCase() + ' type keys ' +\n      'are not supported'));\n  }\n\n  if (!HASH_ALGOS[alg[1]]) {\n    throw (new InvalidAlgorithmError(alg[1].toUpperCase() + ' is not a ' +\n      'supported hash algorithm'));\n  }\n\n  return (alg);\n}\n\n///--- API\n\nmodule.exports = {\n\n  HASH_ALGOS: HASH_ALGOS,\n  PK_ALGOS: PK_ALGOS,\n\n  HttpSignatureError: HttpSignatureError,\n  InvalidAlgorithmError: InvalidAlgorithmError,\n\n  validateAlgorithm: validateAlgorithm,\n\n  /**\n   * Converts an OpenSSH public key (rsa only) to a PKCS#8 PEM file.\n   *\n   * The intent of this module is to interoperate with OpenSSL only,\n   * specifically the node crypto module's `verify` method.\n   *\n   * @param {String} key an OpenSSH public key.\n   * @return {String} PEM encoded form of the RSA public key.\n   * @throws {TypeError} on bad input.\n   * @throws {Error} on invalid ssh key formatted data.\n   */\n  sshKeyToPEM: function sshKeyToPEM(key) {\n    assert.string(key, 'ssh_key');\n\n    var k = sshpk.parseKey(key, 'ssh');\n    return (k.toString('pem'));\n  },\n\n\n  /**\n   * Generates an OpenSSH fingerprint from an ssh public key.\n   *\n   * @param {String} key an OpenSSH public key.\n   * @return {String} key fingerprint.\n   * @throws {TypeError} on bad input.\n   * @throws {Error} if what you passed doesn't look like an ssh public key.\n   */\n  fingerprint: function fingerprint(key) {\n    assert.string(key, 'ssh_key');\n\n    var k = sshpk.parseKey(key, 'ssh');\n    return (k.fingerprint('md5').toString('hex'));\n  },\n\n  /**\n   * Converts a PKGCS#8 PEM file to an OpenSSH public key (rsa)\n   *\n   * The reverse of the above function.\n   */\n  pemToRsaSSHKey: function pemToRsaSSHKey(pem, comment) {\n    assert.equal('string', typeof (pem), 'typeof pem');\n\n    var k = sshpk.parseKey(pem, 'pem');\n    k.comment = comment;\n    return (k.toString('ssh'));\n  }\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/index.js":"// Copyright 2015 Joyent, Inc.\n\nvar Key = require('./key');\nvar Fingerprint = require('./fingerprint');\nvar Signature = require('./signature');\nvar PrivateKey = require('./private-key');\nvar Certificate = require('./certificate');\nvar Identity = require('./identity');\nvar errs = require('./errors');\n\nmodule.exports = {\n\t/* top-level classes */\n\tKey: Key,\n\tparseKey: Key.parse,\n\tFingerprint: Fingerprint,\n\tparseFingerprint: Fingerprint.parse,\n\tSignature: Signature,\n\tparseSignature: Signature.parse,\n\tPrivateKey: PrivateKey,\n\tparsePrivateKey: PrivateKey.parse,\n\tCertificate: Certificate,\n\tparseCertificate: Certificate.parse,\n\tcreateSelfSignedCertificate: Certificate.createSelfSigned,\n\tcreateCertificate: Certificate.create,\n\tIdentity: Identity,\n\tidentityFromDN: Identity.parseDN,\n\tidentityForHost: Identity.forHost,\n\tidentityForUser: Identity.forUser,\n\tidentityForEmail: Identity.forEmail,\n\n\t/* errors */\n\tFingerprintFormatError: errs.FingerprintFormatError,\n\tInvalidAlgorithmError: errs.InvalidAlgorithmError,\n\tKeyParseError: errs.KeyParseError,\n\tSignatureParseError: errs.SignatureParseError,\n\tKeyEncryptedError: errs.KeyEncryptedError,\n\tCertificateParseError: errs.CertificateParseError\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/key.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = Key;\n\nvar assert = require('assert-plus');\nvar algs = require('./algs');\nvar crypto = require('crypto');\nvar Fingerprint = require('./fingerprint');\nvar Signature = require('./signature');\nvar DiffieHellman = require('./dhe');\nvar errs = require('./errors');\nvar utils = require('./utils');\nvar PrivateKey = require('./private-key');\nvar edCompat;\n\ntry {\n\tedCompat = require('./ed-compat');\n} catch (e) {\n\t/* Just continue through, and bail out if we try to use it. */\n}\n\nvar InvalidAlgorithmError = errs.InvalidAlgorithmError;\nvar KeyParseError = errs.KeyParseError;\n\nvar formats = {};\nformats['auto'] = require('./formats/auto');\nformats['pem'] = require('./formats/pem');\nformats['pkcs1'] = require('./formats/pkcs1');\nformats['pkcs8'] = require('./formats/pkcs8');\nformats['rfc4253'] = require('./formats/rfc4253');\nformats['ssh'] = require('./formats/ssh');\nformats['ssh-private'] = require('./formats/ssh-private');\nformats['openssh'] = formats['ssh-private'];\n\nfunction Key(opts) {\n\tassert.object(opts, 'options');\n\tassert.arrayOfObject(opts.parts, 'options.parts');\n\tassert.string(opts.type, 'options.type');\n\tassert.optionalString(opts.comment, 'options.comment');\n\n\tvar algInfo = algs.info[opts.type];\n\tif (typeof (algInfo) !== 'object')\n\t\tthrow (new InvalidAlgorithmError(opts.type));\n\n\tvar partLookup = {};\n\tfor (var i = 0; i < opts.parts.length; ++i) {\n\t\tvar part = opts.parts[i];\n\t\tpartLookup[part.name] = part;\n\t}\n\n\tthis.type = opts.type;\n\tthis.parts = opts.parts;\n\tthis.part = partLookup;\n\tthis.comment = undefined;\n\tthis.source = opts.source;\n\n\t/* for speeding up hashing/fingerprint operations */\n\tthis._rfc4253Cache = opts._rfc4253Cache;\n\tthis._hashCache = {};\n\n\tvar sz;\n\tthis.curve = undefined;\n\tif (this.type === 'ecdsa') {\n\t\tvar curve = this.part.curve.data.toString();\n\t\tthis.curve = curve;\n\t\tsz = algs.curves[curve].size;\n\t} else if (this.type === 'ed25519') {\n\t\tsz = 256;\n\t\tthis.curve = 'curve25519';\n\t} else {\n\t\tvar szPart = this.part[algInfo.sizePart];\n\t\tsz = szPart.data.length;\n\t\tsz = sz * 8 - utils.countZeros(szPart.data);\n\t}\n\tthis.size = sz;\n}\n\nKey.formats = formats;\n\nKey.prototype.toBuffer = function (format, options) {\n\tif (format === undefined)\n\t\tformat = 'ssh';\n\tassert.string(format, 'format');\n\tassert.object(formats[format], 'formats[format]');\n\tassert.optionalObject(options, 'options');\n\n\tif (format === 'rfc4253') {\n\t\tif (this._rfc4253Cache === undefined)\n\t\t\tthis._rfc4253Cache = formats['rfc4253'].write(this);\n\t\treturn (this._rfc4253Cache);\n\t}\n\n\treturn (formats[format].write(this, options));\n};\n\nKey.prototype.toString = function (format, options) {\n\treturn (this.toBuffer(format, options).toString());\n};\n\nKey.prototype.hash = function (algo) {\n\tassert.string(algo, 'algorithm');\n\talgo = algo.toLowerCase();\n\tif (algs.hashAlgs[algo] === undefined)\n\t\tthrow (new InvalidAlgorithmError(algo));\n\n\tif (this._hashCache[algo])\n\t\treturn (this._hashCache[algo]);\n\n\tvar hash = crypto.createHash(algo).\n\t    update(this.toBuffer('rfc4253')).digest();\n\tthis._hashCache[algo] = hash;\n\treturn (hash);\n};\n\nKey.prototype.fingerprint = function (algo) {\n\tif (algo === undefined)\n\t\talgo = 'sha256';\n\tassert.string(algo, 'algorithm');\n\tvar opts = {\n\t\ttype: 'key',\n\t\thash: this.hash(algo),\n\t\talgorithm: algo\n\t};\n\treturn (new Fingerprint(opts));\n};\n\nKey.prototype.defaultHashAlgorithm = function () {\n\tvar hashAlgo = 'sha1';\n\tif (this.type === 'rsa')\n\t\thashAlgo = 'sha256';\n\tif (this.type === 'dsa' && this.size > 1024)\n\t\thashAlgo = 'sha256';\n\tif (this.type === 'ed25519')\n\t\thashAlgo = 'sha512';\n\tif (this.type === 'ecdsa') {\n\t\tif (this.size <= 256)\n\t\t\thashAlgo = 'sha256';\n\t\telse if (this.size <= 384)\n\t\t\thashAlgo = 'sha384';\n\t\telse\n\t\t\thashAlgo = 'sha512';\n\t}\n\treturn (hashAlgo);\n};\n\nKey.prototype.createVerify = function (hashAlgo) {\n\tif (hashAlgo === undefined)\n\t\thashAlgo = this.defaultHashAlgorithm();\n\tassert.string(hashAlgo, 'hash algorithm');\n\n\t/* ED25519 is not supported by OpenSSL, use a javascript impl. */\n\tif (this.type === 'ed25519' && edCompat !== undefined)\n\t\treturn (new edCompat.Verifier(this, hashAlgo));\n\tif (this.type === 'curve25519')\n\t\tthrow (new Error('Curve25519 keys are not suitable for ' +\n\t\t    'signing or verification'));\n\n\tvar v, nm, err;\n\ttry {\n\t\tnm = hashAlgo.toUpperCase();\n\t\tv = crypto.createVerify(nm);\n\t} catch (e) {\n\t\terr = e;\n\t}\n\tif (v === undefined || (err instanceof Error &&\n\t    err.message.match(/Unknown message digest/))) {\n\t\tnm = 'RSA-';\n\t\tnm += hashAlgo.toUpperCase();\n\t\tv = crypto.createVerify(nm);\n\t}\n\tassert.ok(v, 'failed to create verifier');\n\tvar oldVerify = v.verify.bind(v);\n\tvar key = this.toBuffer('pkcs8');\n\tvar self = this;\n\tv.verify = function (signature, fmt) {\n\t\tif (Signature.isSignature(signature, [2, 0])) {\n\t\t\tif (signature.type !== self.type)\n\t\t\t\treturn (false);\n\t\t\tif (signature.hashAlgorithm &&\n\t\t\t    signature.hashAlgorithm !== hashAlgo)\n\t\t\t\treturn (false);\n\t\t\treturn (oldVerify(key, signature.toBuffer('asn1')));\n\n\t\t} else if (typeof (signature) === 'string' ||\n\t\t    Buffer.isBuffer(signature)) {\n\t\t\treturn (oldVerify(key, signature, fmt));\n\n\t\t/*\n\t\t * Avoid doing this on valid arguments, walking the prototype\n\t\t * chain can be quite slow.\n\t\t */\n\t\t} else if (Signature.isSignature(signature, [1, 0])) {\n\t\t\tthrow (new Error('signature was created by too old ' +\n\t\t\t    'a version of sshpk and cannot be verified'));\n\n\t\t} else {\n\t\t\tthrow (new TypeError('signature must be a string, ' +\n\t\t\t    'Buffer, or Signature object'));\n\t\t}\n\t};\n\treturn (v);\n};\n\nKey.prototype.createDiffieHellman = function () {\n\tif (this.type === 'rsa')\n\t\tthrow (new Error('RSA keys do not support Diffie-Hellman'));\n\n\treturn (new DiffieHellman(this));\n};\nKey.prototype.createDH = Key.prototype.createDiffieHellman;\n\nKey.parse = function (data, format, options) {\n\tif (typeof (data) !== 'string')\n\t\tassert.buffer(data, 'data');\n\tif (format === undefined)\n\t\tformat = 'auto';\n\tassert.string(format, 'format');\n\tif (typeof (options) === 'string')\n\t\toptions = { filename: options };\n\tassert.optionalObject(options, 'options');\n\tif (options === undefined)\n\t\toptions = {};\n\tassert.optionalString(options.filename, 'options.filename');\n\tif (options.filename === undefined)\n\t\toptions.filename = '(unnamed)';\n\n\tassert.object(formats[format], 'formats[format]');\n\n\ttry {\n\t\tvar k = formats[format].read(data, options);\n\t\tif (k instanceof PrivateKey)\n\t\t\tk = k.toPublic();\n\t\tif (!k.comment)\n\t\t\tk.comment = options.filename;\n\t\treturn (k);\n\t} catch (e) {\n\t\tif (e.name === 'KeyEncryptedError')\n\t\t\tthrow (e);\n\t\tthrow (new KeyParseError(options.filename, format, e));\n\t}\n};\n\nKey.isKey = function (obj, ver) {\n\treturn (utils.isCompatible(obj, Key, ver));\n};\n\n/*\n * API versions for Key:\n * [1,0] -- initial ver, may take Signature for createVerify or may not\n * [1,1] -- added pkcs1, pkcs8 formats\n * [1,2] -- added auto, ssh-private, openssh formats\n * [1,3] -- added defaultHashAlgorithm\n * [1,4] -- added ed support, createDH\n * [1,5] -- first explicitly tagged version\n */\nKey.prototype._sshpkApiVersion = [1, 5];\n\nKey._oldVersionDetect = function (obj) {\n\tassert.func(obj.toBuffer);\n\tassert.func(obj.fingerprint);\n\tif (obj.createDH)\n\t\treturn ([1, 4]);\n\tif (obj.defaultHashAlgorithm)\n\t\treturn ([1, 3]);\n\tif (obj.formats['auto'])\n\t\treturn ([1, 2]);\n\tif (obj.formats['pkcs1'])\n\t\treturn ([1, 1]);\n\treturn ([1, 0]);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/node_modules/assert-plus/assert.js":"// Copyright (c) 2012, Mark Cavage. All rights reserved.\n// Copyright 2015 Joyent, Inc.\n\nvar assert = require('assert');\nvar Stream = require('stream').Stream;\nvar util = require('util');\n\n\n///--- Globals\n\n/* JSSTYLED */\nvar UUID_REGEXP = /^[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}$/;\n\n\n///--- Internal\n\nfunction _capitalize(str) {\n    return (str.charAt(0).toUpperCase() + str.slice(1));\n}\n\nfunction _toss(name, expected, oper, arg, actual) {\n    throw new assert.AssertionError({\n        message: util.format('%s (%s) is required', name, expected),\n        actual: (actual === undefined) ? typeof (arg) : actual(arg),\n        expected: expected,\n        operator: oper || '===',\n        stackStartFunction: _toss.caller\n    });\n}\n\nfunction _getClass(arg) {\n    return (Object.prototype.toString.call(arg).slice(8, -1));\n}\n\nfunction noop() {\n    // Why even bother with asserts?\n}\n\n\n///--- Exports\n\nvar types = {\n    bool: {\n        check: function (arg) { return typeof (arg) === 'boolean'; }\n    },\n    func: {\n        check: function (arg) { return typeof (arg) === 'function'; }\n    },\n    string: {\n        check: function (arg) { return typeof (arg) === 'string'; }\n    },\n    object: {\n        check: function (arg) {\n            return typeof (arg) === 'object' && arg !== null;\n        }\n    },\n    number: {\n        check: function (arg) {\n            return typeof (arg) === 'number' && !isNaN(arg);\n        }\n    },\n    finite: {\n        check: function (arg) {\n            return typeof (arg) === 'number' && !isNaN(arg) && isFinite(arg);\n        }\n    },\n    buffer: {\n        check: function (arg) { return Buffer.isBuffer(arg); },\n        operator: 'Buffer.isBuffer'\n    },\n    array: {\n        check: function (arg) { return Array.isArray(arg); },\n        operator: 'Array.isArray'\n    },\n    stream: {\n        check: function (arg) { return arg instanceof Stream; },\n        operator: 'instanceof',\n        actual: _getClass\n    },\n    date: {\n        check: function (arg) { return arg instanceof Date; },\n        operator: 'instanceof',\n        actual: _getClass\n    },\n    regexp: {\n        check: function (arg) { return arg instanceof RegExp; },\n        operator: 'instanceof',\n        actual: _getClass\n    },\n    uuid: {\n        check: function (arg) {\n            return typeof (arg) === 'string' && UUID_REGEXP.test(arg);\n        },\n        operator: 'isUUID'\n    }\n};\n\nfunction _setExports(ndebug) {\n    var keys = Object.keys(types);\n    var out;\n\n    /* re-export standard assert */\n    if (process.env.NODE_NDEBUG) {\n        out = noop;\n    } else {\n        out = function (arg, msg) {\n            if (!arg) {\n                _toss(msg, 'true', arg);\n            }\n        };\n    }\n\n    /* standard checks */\n    keys.forEach(function (k) {\n        if (ndebug) {\n            out[k] = noop;\n            return;\n        }\n        var type = types[k];\n        out[k] = function (arg, msg) {\n            if (!type.check(arg)) {\n                _toss(msg, k, type.operator, arg, type.actual);\n            }\n        };\n    });\n\n    /* optional checks */\n    keys.forEach(function (k) {\n        var name = 'optional' + _capitalize(k);\n        if (ndebug) {\n            out[name] = noop;\n            return;\n        }\n        var type = types[k];\n        out[name] = function (arg, msg) {\n            if (arg === undefined || arg === null) {\n                return;\n            }\n            if (!type.check(arg)) {\n                _toss(msg, k, type.operator, arg, type.actual);\n            }\n        };\n    });\n\n    /* arrayOf checks */\n    keys.forEach(function (k) {\n        var name = 'arrayOf' + _capitalize(k);\n        if (ndebug) {\n            out[name] = noop;\n            return;\n        }\n        var type = types[k];\n        var expected = '[' + k + ']';\n        out[name] = function (arg, msg) {\n            if (!Array.isArray(arg)) {\n                _toss(msg, expected, type.operator, arg, type.actual);\n            }\n            var i;\n            for (i = 0; i < arg.length; i++) {\n                if (!type.check(arg[i])) {\n                    _toss(msg, expected, type.operator, arg, type.actual);\n                }\n            }\n        };\n    });\n\n    /* optionalArrayOf checks */\n    keys.forEach(function (k) {\n        var name = 'optionalArrayOf' + _capitalize(k);\n        if (ndebug) {\n            out[name] = noop;\n            return;\n        }\n        var type = types[k];\n        var expected = '[' + k + ']';\n        out[name] = function (arg, msg) {\n            if (arg === undefined || arg === null) {\n                return;\n            }\n            if (!Array.isArray(arg)) {\n                _toss(msg, expected, type.operator, arg, type.actual);\n            }\n            var i;\n            for (i = 0; i < arg.length; i++) {\n                if (!type.check(arg[i])) {\n                    _toss(msg, expected, type.operator, arg, type.actual);\n                }\n            }\n        };\n    });\n\n    /* re-export built-in assertions */\n    Object.keys(assert).forEach(function (k) {\n        if (k === 'AssertionError') {\n            out[k] = assert[k];\n            return;\n        }\n        if (ndebug) {\n            out[k] = noop;\n            return;\n        }\n        out[k] = assert[k];\n    });\n\n    /* export ourselves (for unit tests _only_) */\n    out._setExports = _setExports;\n\n    return out;\n}\n\nmodule.exports = _setExports(process.env.NODE_NDEBUG);\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/algs.js":"// Copyright 2015 Joyent, Inc.\n\nvar algInfo = {\n\t'dsa': {\n\t\tparts: ['p', 'q', 'g', 'y'],\n\t\tsizePart: 'p'\n\t},\n\t'rsa': {\n\t\tparts: ['e', 'n'],\n\t\tsizePart: 'n'\n\t},\n\t'ecdsa': {\n\t\tparts: ['curve', 'Q'],\n\t\tsizePart: 'Q'\n\t},\n\t'ed25519': {\n\t\tparts: ['R'],\n\t\tnormalize: false,\n\t\tsizePart: 'R'\n\t}\n};\nalgInfo['curve25519'] = algInfo['ed25519'];\n\nvar algPrivInfo = {\n\t'dsa': {\n\t\tparts: ['p', 'q', 'g', 'y', 'x']\n\t},\n\t'rsa': {\n\t\tparts: ['n', 'e', 'd', 'iqmp', 'p', 'q']\n\t},\n\t'ecdsa': {\n\t\tparts: ['curve', 'Q', 'd']\n\t},\n\t'ed25519': {\n\t\tparts: ['R', 'r'],\n\t\tnormalize: false\n\t}\n};\nalgPrivInfo['curve25519'] = algPrivInfo['ed25519'];\n\nvar hashAlgs = {\n\t'md5': true,\n\t'sha1': true,\n\t'sha256': true,\n\t'sha384': true,\n\t'sha512': true\n};\n\n/*\n * Taken from\n * http://csrc.nist.gov/groups/ST/toolkit/documents/dss/NISTReCur.pdf\n */\nvar curves = {\n\t'nistp256': {\n\t\tsize: 256,\n\t\tpkcs8oid: '1.2.840.10045.3.1.7',\n\t\tp: new Buffer(('00' +\n\t\t    'ffffffff 00000001 00000000 00000000' +\n\t\t    '00000000 ffffffff ffffffff ffffffff').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\ta: new Buffer(('00' +\n\t\t    'FFFFFFFF 00000001 00000000 00000000' +\n\t\t    '00000000 FFFFFFFF FFFFFFFF FFFFFFFC').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tb: new Buffer((\n\t\t    '5ac635d8 aa3a93e7 b3ebbd55 769886bc' +\n\t\t    '651d06b0 cc53b0f6 3bce3c3e 27d2604b').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\ts: new Buffer(('00' +\n\t\t    'c49d3608 86e70493 6a6678e1 139d26b7' +\n\t\t    '819f7e90').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tn: new Buffer(('00' +\n\t\t    'ffffffff 00000000 ffffffff ffffffff' +\n\t\t    'bce6faad a7179e84 f3b9cac2 fc632551').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tG: new Buffer(('04' +\n\t\t    '6b17d1f2 e12c4247 f8bce6e5 63a440f2' +\n\t\t    '77037d81 2deb33a0 f4a13945 d898c296' +\n\t\t    '4fe342e2 fe1a7f9b 8ee7eb4a 7c0f9e16' +\n\t\t    '2bce3357 6b315ece cbb64068 37bf51f5').\n\t\t    replace(/ /g, ''), 'hex')\n\t},\n\t'nistp384': {\n\t\tsize: 384,\n\t\tpkcs8oid: '1.3.132.0.34',\n\t\tp: new Buffer(('00' +\n\t\t    'ffffffff ffffffff ffffffff ffffffff' +\n\t\t    'ffffffff ffffffff ffffffff fffffffe' +\n\t\t    'ffffffff 00000000 00000000 ffffffff').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\ta: new Buffer(('00' +\n\t\t    'FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF' +\n\t\t    'FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFE' +\n\t\t    'FFFFFFFF 00000000 00000000 FFFFFFFC').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tb: new Buffer((\n\t\t    'b3312fa7 e23ee7e4 988e056b e3f82d19' +\n\t\t    '181d9c6e fe814112 0314088f 5013875a' +\n\t\t    'c656398d 8a2ed19d 2a85c8ed d3ec2aef').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\ts: new Buffer(('00' +\n\t\t    'a335926a a319a27a 1d00896a 6773a482' +\n\t\t    '7acdac73').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tn: new Buffer(('00' +\n\t\t    'ffffffff ffffffff ffffffff ffffffff' +\n\t\t    'ffffffff ffffffff c7634d81 f4372ddf' +\n\t\t    '581a0db2 48b0a77a ecec196a ccc52973').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tG: new Buffer(('04' +\n\t\t    'aa87ca22 be8b0537 8eb1c71e f320ad74' +\n\t\t    '6e1d3b62 8ba79b98 59f741e0 82542a38' +\n\t\t    '5502f25d bf55296c 3a545e38 72760ab7' +\n\t\t    '3617de4a 96262c6f 5d9e98bf 9292dc29' +\n\t\t    'f8f41dbd 289a147c e9da3113 b5f0b8c0' +\n\t\t    '0a60b1ce 1d7e819d 7a431d7c 90ea0e5f').\n\t\t    replace(/ /g, ''), 'hex')\n\t},\n\t'nistp521': {\n\t\tsize: 521,\n\t\tpkcs8oid: '1.3.132.0.35',\n\t\tp: new Buffer((\n\t\t    '01ffffff ffffffff ffffffff ffffffff' +\n\t\t    'ffffffff ffffffff ffffffff ffffffff' +\n\t\t    'ffffffff ffffffff ffffffff ffffffff' +\n\t\t    'ffffffff ffffffff ffffffff ffffffff' +\n\t\t    'ffff').replace(/ /g, ''), 'hex'),\n\t\ta: new Buffer(('01FF' +\n\t\t    'FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF' +\n\t\t    'FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF' +\n\t\t    'FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF' +\n\t\t    'FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFC').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tb: new Buffer(('51' +\n\t\t    '953eb961 8e1c9a1f 929a21a0 b68540ee' +\n\t\t    'a2da725b 99b315f3 b8b48991 8ef109e1' +\n\t\t    '56193951 ec7e937b 1652c0bd 3bb1bf07' +\n\t\t    '3573df88 3d2c34f1 ef451fd4 6b503f00').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\ts: new Buffer(('00' +\n\t\t    'd09e8800 291cb853 96cc6717 393284aa' +\n\t\t    'a0da64ba').replace(/ /g, ''), 'hex'),\n\t\tn: new Buffer(('01ff' +\n\t\t    'ffffffff ffffffff ffffffff ffffffff' +\n\t\t    'ffffffff ffffffff ffffffff fffffffa' +\n\t\t    '51868783 bf2f966b 7fcc0148 f709a5d0' +\n\t\t    '3bb5c9b8 899c47ae bb6fb71e 91386409').\n\t\t    replace(/ /g, ''), 'hex'),\n\t\tG: new Buffer(('04' +\n\t\t    '00c6 858e06b7 0404e9cd 9e3ecb66 2395b442' +\n\t\t         '9c648139 053fb521 f828af60 6b4d3dba' +\n\t\t         'a14b5e77 efe75928 fe1dc127 a2ffa8de' +\n\t\t         '3348b3c1 856a429b f97e7e31 c2e5bd66' +\n\t\t    '0118 39296a78 9a3bc004 5c8a5fb4 2c7d1bd9' +\n\t\t         '98f54449 579b4468 17afbd17 273e662c' +\n\t\t         '97ee7299 5ef42640 c550b901 3fad0761' +\n\t\t         '353c7086 a272c240 88be9476 9fd16650').\n\t\t    replace(/ /g, ''), 'hex')\n\t}\n};\n\nmodule.exports = {\n\tinfo: algInfo,\n\tprivInfo: algPrivInfo,\n\thashAlgs: hashAlgs,\n\tcurves: curves\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/fingerprint.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = Fingerprint;\n\nvar assert = require('assert-plus');\nvar algs = require('./algs');\nvar crypto = require('crypto');\nvar errs = require('./errors');\nvar Key = require('./key');\nvar Certificate = require('./certificate');\nvar utils = require('./utils');\n\nvar FingerprintFormatError = errs.FingerprintFormatError;\nvar InvalidAlgorithmError = errs.InvalidAlgorithmError;\n\nfunction Fingerprint(opts) {\n\tassert.object(opts, 'options');\n\tassert.string(opts.type, 'options.type');\n\tassert.buffer(opts.hash, 'options.hash');\n\tassert.string(opts.algorithm, 'options.algorithm');\n\n\tthis.algorithm = opts.algorithm.toLowerCase();\n\tif (algs.hashAlgs[this.algorithm] !== true)\n\t\tthrow (new InvalidAlgorithmError(this.algorithm));\n\n\tthis.hash = opts.hash;\n\tthis.type = opts.type;\n}\n\nFingerprint.prototype.toString = function (format) {\n\tif (format === undefined) {\n\t\tif (this.algorithm === 'md5')\n\t\t\tformat = 'hex';\n\t\telse\n\t\t\tformat = 'base64';\n\t}\n\tassert.string(format);\n\n\tswitch (format) {\n\tcase 'hex':\n\t\treturn (addColons(this.hash.toString('hex')));\n\tcase 'base64':\n\t\treturn (sshBase64Format(this.algorithm,\n\t\t    this.hash.toString('base64')));\n\tdefault:\n\t\tthrow (new FingerprintFormatError(undefined, format));\n\t}\n};\n\nFingerprint.prototype.matches = function (other) {\n\tassert.object(other, 'key or certificate');\n\tif (this.type === 'key') {\n\t\tutils.assertCompatible(other, Key, [1, 0], 'key');\n\t} else {\n\t\tutils.assertCompatible(other, Certificate, [1, 0],\n\t\t    'certificate');\n\t}\n\n\tvar theirHash = other.hash(this.algorithm);\n\tvar theirHash2 = crypto.createHash(this.algorithm).\n\t    update(theirHash).digest('base64');\n\n\tif (this.hash2 === undefined)\n\t\tthis.hash2 = crypto.createHash(this.algorithm).\n\t\t    update(this.hash).digest('base64');\n\n\treturn (this.hash2 === theirHash2);\n};\n\nFingerprint.parse = function (fp, options) {\n\tassert.string(fp, 'fingerprint');\n\n\tvar alg, hash, enAlgs;\n\tif (Array.isArray(options)) {\n\t\tenAlgs = options;\n\t\toptions = {};\n\t}\n\tassert.optionalObject(options, 'options');\n\tif (options === undefined)\n\t\toptions = {};\n\tif (options.enAlgs !== undefined)\n\t\tenAlgs = options.enAlgs;\n\tassert.optionalArrayOfString(enAlgs, 'algorithms');\n\n\tvar parts = fp.split(':');\n\tif (parts.length == 2) {\n\t\talg = parts[0].toLowerCase();\n\t\t/*JSSTYLED*/\n\t\tvar base64RE = /^[A-Za-z0-9+\\/=]+$/;\n\t\tif (!base64RE.test(parts[1]))\n\t\t\tthrow (new FingerprintFormatError(fp));\n\t\ttry {\n\t\t\thash = new Buffer(parts[1], 'base64');\n\t\t} catch (e) {\n\t\t\tthrow (new FingerprintFormatError(fp));\n\t\t}\n\t} else if (parts.length > 2) {\n\t\talg = 'md5';\n\t\tif (parts[0].toLowerCase() === 'md5')\n\t\t\tparts = parts.slice(1);\n\t\tparts = parts.join('');\n\t\t/*JSSTYLED*/\n\t\tvar md5RE = /^[a-fA-F0-9]+$/;\n\t\tif (!md5RE.test(parts))\n\t\t\tthrow (new FingerprintFormatError(fp));\n\t\ttry {\n\t\t\thash = new Buffer(parts, 'hex');\n\t\t} catch (e) {\n\t\t\tthrow (new FingerprintFormatError(fp));\n\t\t}\n\t}\n\n\tif (alg === undefined)\n\t\tthrow (new FingerprintFormatError(fp));\n\n\tif (algs.hashAlgs[alg] === undefined)\n\t\tthrow (new InvalidAlgorithmError(alg));\n\n\tif (enAlgs !== undefined) {\n\t\tenAlgs = enAlgs.map(function (a) { return a.toLowerCase(); });\n\t\tif (enAlgs.indexOf(alg) === -1)\n\t\t\tthrow (new InvalidAlgorithmError(alg));\n\t}\n\n\treturn (new Fingerprint({\n\t\talgorithm: alg,\n\t\thash: hash,\n\t\ttype: options.type || 'key'\n\t}));\n};\n\nfunction addColons(s) {\n\t/*JSSTYLED*/\n\treturn (s.replace(/(.{2})(?=.)/g, '$1:'));\n}\n\nfunction base64Strip(s) {\n\t/*JSSTYLED*/\n\treturn (s.replace(/=*$/, ''));\n}\n\nfunction sshBase64Format(alg, h) {\n\treturn (alg.toUpperCase() + ':' + base64Strip(h));\n}\n\nFingerprint.isFingerprint = function (obj, ver) {\n\treturn (utils.isCompatible(obj, Fingerprint, ver));\n};\n\n/*\n * API versions for Fingerprint:\n * [1,0] -- initial ver\n * [1,1] -- first tagged ver\n */\nFingerprint.prototype._sshpkApiVersion = [1, 1];\n\nFingerprint._oldVersionDetect = function (obj) {\n\tassert.func(obj.toString);\n\tassert.func(obj.matches);\n\treturn ([1, 0]);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/errors.js":"// Copyright 2015 Joyent, Inc.\n\nvar assert = require('assert-plus');\nvar util = require('util');\n\nfunction FingerprintFormatError(fp, format) {\n\tif (Error.captureStackTrace)\n\t\tError.captureStackTrace(this, FingerprintFormatError);\n\tthis.name = 'FingerprintFormatError';\n\tthis.fingerprint = fp;\n\tthis.format = format;\n\tthis.message = 'Fingerprint format is not supported, or is invalid: ';\n\tif (fp !== undefined)\n\t\tthis.message += ' fingerprint = ' + fp;\n\tif (format !== undefined)\n\t\tthis.message += ' format = ' + format;\n}\nutil.inherits(FingerprintFormatError, Error);\n\nfunction InvalidAlgorithmError(alg) {\n\tif (Error.captureStackTrace)\n\t\tError.captureStackTrace(this, InvalidAlgorithmError);\n\tthis.name = 'InvalidAlgorithmError';\n\tthis.algorithm = alg;\n\tthis.message = 'Algorithm \"' + alg + '\" is not supported';\n}\nutil.inherits(InvalidAlgorithmError, Error);\n\nfunction KeyParseError(name, format, innerErr) {\n\tif (Error.captureStackTrace)\n\t\tError.captureStackTrace(this, KeyParseError);\n\tthis.name = 'KeyParseError';\n\tthis.format = format;\n\tthis.keyName = name;\n\tthis.innerErr = innerErr;\n\tthis.message = 'Failed to parse ' + name + ' as a valid ' + format +\n\t    ' format key: ' + innerErr.message;\n}\nutil.inherits(KeyParseError, Error);\n\nfunction SignatureParseError(type, format, innerErr) {\n\tif (Error.captureStackTrace)\n\t\tError.captureStackTrace(this, SignatureParseError);\n\tthis.name = 'SignatureParseError';\n\tthis.type = type;\n\tthis.format = format;\n\tthis.innerErr = innerErr;\n\tthis.message = 'Failed to parse the given data as a ' + type +\n\t    ' signature in ' + format + ' format: ' + innerErr.message;\n}\nutil.inherits(SignatureParseError, Error);\n\nfunction CertificateParseError(name, format, innerErr) {\n\tif (Error.captureStackTrace)\n\t\tError.captureStackTrace(this, CertificateParseError);\n\tthis.name = 'CertificateParseError';\n\tthis.format = format;\n\tthis.certName = name;\n\tthis.innerErr = innerErr;\n\tthis.message = 'Failed to parse ' + name + ' as a valid ' + format +\n\t    ' format certificate: ' + innerErr.message;\n}\nutil.inherits(CertificateParseError, Error);\n\nfunction KeyEncryptedError(name, format) {\n\tif (Error.captureStackTrace)\n\t\tError.captureStackTrace(this, KeyEncryptedError);\n\tthis.name = 'KeyEncryptedError';\n\tthis.format = format;\n\tthis.keyName = name;\n\tthis.message = 'The ' + format + ' format key ' + name + ' is ' +\n\t    'encrypted (password-protected), and no passphrase was ' +\n\t    'provided in `options`';\n}\nutil.inherits(KeyEncryptedError, Error);\n\nmodule.exports = {\n\tFingerprintFormatError: FingerprintFormatError,\n\tInvalidAlgorithmError: InvalidAlgorithmError,\n\tKeyParseError: KeyParseError,\n\tSignatureParseError: SignatureParseError,\n\tKeyEncryptedError: KeyEncryptedError,\n\tCertificateParseError: CertificateParseError\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/certificate.js":"// Copyright 2016 Joyent, Inc.\n\nmodule.exports = Certificate;\n\nvar assert = require('assert-plus');\nvar algs = require('./algs');\nvar crypto = require('crypto');\nvar Fingerprint = require('./fingerprint');\nvar Signature = require('./signature');\nvar errs = require('./errors');\nvar util = require('util');\nvar utils = require('./utils');\nvar Key = require('./key');\nvar PrivateKey = require('./private-key');\nvar Identity = require('./identity');\n\nvar formats = {};\nformats['openssh'] = require('./formats/openssh-cert');\nformats['x509'] = require('./formats/x509');\nformats['pem'] = require('./formats/x509-pem');\n\nvar CertificateParseError = errs.CertificateParseError;\nvar InvalidAlgorithmError = errs.InvalidAlgorithmError;\n\nfunction Certificate(opts) {\n\tassert.object(opts, 'options');\n\tassert.arrayOfObject(opts.subjects, 'options.subjects');\n\tutils.assertCompatible(opts.subjects[0], Identity, [1, 0],\n\t    'options.subjects');\n\tutils.assertCompatible(opts.subjectKey, Key, [1, 0],\n\t    'options.subjectKey');\n\tutils.assertCompatible(opts.issuer, Identity, [1, 0], 'options.issuer');\n\tif (opts.issuerKey !== undefined) {\n\t\tutils.assertCompatible(opts.issuerKey, Key, [1, 0],\n\t\t    'options.issuerKey');\n\t}\n\tassert.object(opts.signatures, 'options.signatures');\n\tassert.buffer(opts.serial, 'options.serial');\n\tassert.date(opts.validFrom, 'options.validFrom');\n\tassert.date(opts.validUntil, 'optons.validUntil');\n\n\tassert.optionalArrayOfString(opts.purposes, 'options.purposes');\n\n\tthis._hashCache = {};\n\n\tthis.subjects = opts.subjects;\n\tthis.issuer = opts.issuer;\n\tthis.subjectKey = opts.subjectKey;\n\tthis.issuerKey = opts.issuerKey;\n\tthis.signatures = opts.signatures;\n\tthis.serial = opts.serial;\n\tthis.validFrom = opts.validFrom;\n\tthis.validUntil = opts.validUntil;\n\tthis.purposes = opts.purposes;\n}\n\nCertificate.formats = formats;\n\nCertificate.prototype.toBuffer = function (format, options) {\n\tif (format === undefined)\n\t\tformat = 'x509';\n\tassert.string(format, 'format');\n\tassert.object(formats[format], 'formats[format]');\n\tassert.optionalObject(options, 'options');\n\n\treturn (formats[format].write(this, options));\n};\n\nCertificate.prototype.toString = function (format, options) {\n\tif (format === undefined)\n\t\tformat = 'pem';\n\treturn (this.toBuffer(format, options).toString());\n};\n\nCertificate.prototype.fingerprint = function (algo) {\n\tif (algo === undefined)\n\t\talgo = 'sha256';\n\tassert.string(algo, 'algorithm');\n\tvar opts = {\n\t\ttype: 'certificate',\n\t\thash: this.hash(algo),\n\t\talgorithm: algo\n\t};\n\treturn (new Fingerprint(opts));\n};\n\nCertificate.prototype.hash = function (algo) {\n\tassert.string(algo, 'algorithm');\n\talgo = algo.toLowerCase();\n\tif (algs.hashAlgs[algo] === undefined)\n\t\tthrow (new InvalidAlgorithmError(algo));\n\n\tif (this._hashCache[algo])\n\t\treturn (this._hashCache[algo]);\n\n\tvar hash = crypto.createHash(algo).\n\t    update(this.toBuffer('x509')).digest();\n\tthis._hashCache[algo] = hash;\n\treturn (hash);\n};\n\nCertificate.prototype.isExpired = function (when) {\n\tif (when === undefined)\n\t\twhen = new Date();\n\treturn (!((when.getTime() >= this.validFrom.getTime()) &&\n\t\t(when.getTime() < this.validUntil.getTime())));\n};\n\nCertificate.prototype.isSignedBy = function (issuerCert) {\n\tutils.assertCompatible(issuerCert, Certificate, [1, 0], 'issuer');\n\n\tif (!this.issuer.equals(issuerCert.subjects[0]))\n\t\treturn (false);\n\tif (this.issuer.purposes && this.issuer.purposes.length > 0 &&\n\t    this.issuer.purposes.indexOf('ca') === -1) {\n\t\treturn (false);\n\t}\n\n\treturn (this.isSignedByKey(issuerCert.subjectKey));\n};\n\nCertificate.prototype.isSignedByKey = function (issuerKey) {\n\tutils.assertCompatible(issuerKey, Key, [1, 2], 'issuerKey');\n\n\tif (this.issuerKey !== undefined) {\n\t\treturn (this.issuerKey.\n\t\t    fingerprint('sha512').matches(issuerKey));\n\t}\n\n\tvar fmt = Object.keys(this.signatures)[0];\n\tvar valid = formats[fmt].verify(this, issuerKey);\n\tif (valid)\n\t\tthis.issuerKey = issuerKey;\n\treturn (valid);\n};\n\nCertificate.prototype.signWith = function (key) {\n\tutils.assertCompatible(key, PrivateKey, [1, 2], 'key');\n\tvar fmts = Object.keys(formats);\n\tvar didOne = false;\n\tfor (var i = 0; i < fmts.length; ++i) {\n\t\tif (fmts[i] !== 'pem') {\n\t\t\tvar ret = formats[fmts[i]].sign(this, key);\n\t\t\tif (ret === true)\n\t\t\t\tdidOne = true;\n\t\t}\n\t}\n\tif (!didOne) {\n\t\tthrow (new Error('Failed to sign the certificate for any ' +\n\t\t    'available certificate formats'));\n\t}\n};\n\nCertificate.createSelfSigned = function (subjectOrSubjects, key, options) {\n\tvar subjects;\n\tif (Array.isArray(subjectOrSubjects))\n\t\tsubjects = subjectOrSubjects;\n\telse\n\t\tsubjects = [subjectOrSubjects];\n\n\tassert.arrayOfObject(subjects);\n\tsubjects.forEach(function (subject) {\n\t\tutils.assertCompatible(subject, Identity, [1, 0], 'subject');\n\t});\n\n\tutils.assertCompatible(key, PrivateKey, [1, 2], 'private key');\n\n\tassert.optionalObject(options, 'options');\n\tif (options === undefined)\n\t\toptions = {};\n\tassert.optionalObject(options.validFrom, 'options.validFrom');\n\tassert.optionalObject(options.validUntil, 'options.validUntil');\n\tvar validFrom = options.validFrom;\n\tvar validUntil = options.validUntil;\n\tif (validFrom === undefined)\n\t\tvalidFrom = new Date();\n\tif (validUntil === undefined) {\n\t\tassert.optionalNumber(options.lifetime, 'options.lifetime');\n\t\tvar lifetime = options.lifetime;\n\t\tif (lifetime === undefined)\n\t\t\tlifetime = 10*365*24*3600;\n\t\tvalidUntil = new Date();\n\t\tvalidUntil.setTime(validUntil.getTime() + lifetime*1000);\n\t}\n\tassert.optionalBuffer(options.serial, 'options.serial');\n\tvar serial = options.serial;\n\tif (serial === undefined)\n\t\tserial = new Buffer('0000000000000001', 'hex');\n\n\tvar purposes = options.purposes;\n\tif (purposes === undefined)\n\t\tpurposes = [];\n\n\tif (purposes.indexOf('signature') === -1)\n\t\tpurposes.push('signature');\n\n\t/* Self-signed certs are always CAs. */\n\tif (purposes.indexOf('ca') === -1)\n\t\tpurposes.push('ca');\n\tif (purposes.indexOf('crl') === -1)\n\t\tpurposes.push('crl');\n\n\t/*\n\t * If we weren't explicitly given any other purposes, do the sensible\n\t * thing and add some basic ones depending on the subject type.\n\t */\n\tif (purposes.length <= 3) {\n\t\tvar hostSubjects = subjects.filter(function (subject) {\n\t\t\treturn (subject.type === 'host');\n\t\t});\n\t\tvar userSubjects = subjects.filter(function (subject) {\n\t\t\treturn (subject.type === 'user');\n\t\t});\n\t\tif (hostSubjects.length > 0) {\n\t\t\tif (purposes.indexOf('serverAuth') === -1)\n\t\t\t\tpurposes.push('serverAuth');\n\t\t}\n\t\tif (userSubjects.length > 0) {\n\t\t\tif (purposes.indexOf('clientAuth') === -1)\n\t\t\t\tpurposes.push('clientAuth');\n\t\t}\n\t\tif (userSubjects.length > 0 || hostSubjects.length > 0) {\n\t\t\tif (purposes.indexOf('keyAgreement') === -1)\n\t\t\t\tpurposes.push('keyAgreement');\n\t\t\tif (key.type === 'rsa' &&\n\t\t\t    purposes.indexOf('encryption') === -1)\n\t\t\t\tpurposes.push('encryption');\n\t\t}\n\t}\n\n\tvar cert = new Certificate({\n\t\tsubjects: subjects,\n\t\tissuer: subjects[0],\n\t\tsubjectKey: key.toPublic(),\n\t\tissuerKey: key.toPublic(),\n\t\tsignatures: {},\n\t\tserial: serial,\n\t\tvalidFrom: validFrom,\n\t\tvalidUntil: validUntil,\n\t\tpurposes: purposes\n\t});\n\tcert.signWith(key);\n\n\treturn (cert);\n};\n\nCertificate.create =\n    function (subjectOrSubjects, key, issuer, issuerKey, options) {\n\tvar subjects;\n\tif (Array.isArray(subjectOrSubjects))\n\t\tsubjects = subjectOrSubjects;\n\telse\n\t\tsubjects = [subjectOrSubjects];\n\n\tassert.arrayOfObject(subjects);\n\tsubjects.forEach(function (subject) {\n\t\tutils.assertCompatible(subject, Identity, [1, 0], 'subject');\n\t});\n\n\tutils.assertCompatible(key, Key, [1, 0], 'key');\n\tif (PrivateKey.isPrivateKey(key))\n\t\tkey = key.toPublic();\n\tutils.assertCompatible(issuer, Identity, [1, 0], 'issuer');\n\tutils.assertCompatible(issuerKey, PrivateKey, [1, 2], 'issuer key');\n\n\tassert.optionalObject(options, 'options');\n\tif (options === undefined)\n\t\toptions = {};\n\tassert.optionalObject(options.validFrom, 'options.validFrom');\n\tassert.optionalObject(options.validUntil, 'options.validUntil');\n\tvar validFrom = options.validFrom;\n\tvar validUntil = options.validUntil;\n\tif (validFrom === undefined)\n\t\tvalidFrom = new Date();\n\tif (validUntil === undefined) {\n\t\tassert.optionalNumber(options.lifetime, 'options.lifetime');\n\t\tvar lifetime = options.lifetime;\n\t\tif (lifetime === undefined)\n\t\t\tlifetime = 10*365*24*3600;\n\t\tvalidUntil = new Date();\n\t\tvalidUntil.setTime(validUntil.getTime() + lifetime*1000);\n\t}\n\tassert.optionalBuffer(options.serial, 'options.serial');\n\tvar serial = options.serial;\n\tif (serial === undefined)\n\t\tserial = new Buffer('0000000000000001', 'hex');\n\n\tvar purposes = options.purposes;\n\tif (purposes === undefined)\n\t\tpurposes = [];\n\n\tif (purposes.indexOf('signature') === -1)\n\t\tpurposes.push('signature');\n\n\tif (options.ca === true) {\n\t\tif (purposes.indexOf('ca') === -1)\n\t\t\tpurposes.push('ca');\n\t\tif (purposes.indexOf('crl') === -1)\n\t\t\tpurposes.push('crl');\n\t}\n\n\tvar hostSubjects = subjects.filter(function (subject) {\n\t\treturn (subject.type === 'host');\n\t});\n\tvar userSubjects = subjects.filter(function (subject) {\n\t\treturn (subject.type === 'user');\n\t});\n\tif (hostSubjects.length > 0) {\n\t\tif (purposes.indexOf('serverAuth') === -1)\n\t\t\tpurposes.push('serverAuth');\n\t}\n\tif (userSubjects.length > 0) {\n\t\tif (purposes.indexOf('clientAuth') === -1)\n\t\t\tpurposes.push('clientAuth');\n\t}\n\tif (userSubjects.length > 0 || hostSubjects.length > 0) {\n\t\tif (purposes.indexOf('keyAgreement') === -1)\n\t\t\tpurposes.push('keyAgreement');\n\t\tif (key.type === 'rsa' &&\n\t\t    purposes.indexOf('encryption') === -1)\n\t\t\tpurposes.push('encryption');\n\t}\n\n\tvar cert = new Certificate({\n\t\tsubjects: subjects,\n\t\tissuer: issuer,\n\t\tsubjectKey: key,\n\t\tissuerKey: issuerKey.toPublic(),\n\t\tsignatures: {},\n\t\tserial: serial,\n\t\tvalidFrom: validFrom,\n\t\tvalidUntil: validUntil,\n\t\tpurposes: purposes\n\t});\n\tcert.signWith(issuerKey);\n\n\treturn (cert);\n};\n\nCertificate.parse = function (data, format, options) {\n\tif (typeof (data) !== 'string')\n\t\tassert.buffer(data, 'data');\n\tif (format === undefined)\n\t\tformat = 'auto';\n\tassert.string(format, 'format');\n\tif (typeof (options) === 'string')\n\t\toptions = { filename: options };\n\tassert.optionalObject(options, 'options');\n\tif (options === undefined)\n\t\toptions = {};\n\tassert.optionalString(options.filename, 'options.filename');\n\tif (options.filename === undefined)\n\t\toptions.filename = '(unnamed)';\n\n\tassert.object(formats[format], 'formats[format]');\n\n\ttry {\n\t\tvar k = formats[format].read(data, options);\n\t\treturn (k);\n\t} catch (e) {\n\t\tthrow (new CertificateParseError(options.filename, format, e));\n\t}\n};\n\nCertificate.isCertificate = function (obj, ver) {\n\treturn (utils.isCompatible(obj, Certificate, ver));\n};\n\n/*\n * API versions for Certificate:\n * [1,0] -- initial ver\n */\nCertificate.prototype._sshpkApiVersion = [1, 0];\n\nCertificate._oldVersionDetect = function (obj) {\n\treturn ([1, 0]);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/signature.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = Signature;\n\nvar assert = require('assert-plus');\nvar algs = require('./algs');\nvar crypto = require('crypto');\nvar errs = require('./errors');\nvar utils = require('./utils');\nvar asn1 = require('asn1');\nvar SSHBuffer = require('./ssh-buffer');\n\nvar InvalidAlgorithmError = errs.InvalidAlgorithmError;\nvar SignatureParseError = errs.SignatureParseError;\n\nfunction Signature(opts) {\n\tassert.object(opts, 'options');\n\tassert.arrayOfObject(opts.parts, 'options.parts');\n\tassert.string(opts.type, 'options.type');\n\n\tvar partLookup = {};\n\tfor (var i = 0; i < opts.parts.length; ++i) {\n\t\tvar part = opts.parts[i];\n\t\tpartLookup[part.name] = part;\n\t}\n\n\tthis.type = opts.type;\n\tthis.hashAlgorithm = opts.hashAlgo;\n\tthis.parts = opts.parts;\n\tthis.part = partLookup;\n}\n\nSignature.prototype.toBuffer = function (format) {\n\tif (format === undefined)\n\t\tformat = 'asn1';\n\tassert.string(format, 'format');\n\n\tvar buf;\n\n\tswitch (this.type) {\n\tcase 'rsa':\n\tcase 'ed25519':\n\t\tif (format === 'ssh') {\n\t\t\tbuf = new SSHBuffer({});\n\t\t\tbuf.writeString('ssh-' + this.type);\n\t\t\tbuf.writePart(this.part.sig);\n\t\t\treturn (buf.toBuffer());\n\t\t} else {\n\t\t\treturn (this.part.sig.data);\n\t\t}\n\n\tcase 'dsa':\n\tcase 'ecdsa':\n\t\tvar r, s;\n\t\tif (format === 'asn1') {\n\t\t\tvar der = new asn1.BerWriter();\n\t\t\tder.startSequence();\n\t\t\tr = utils.mpNormalize(this.part.r.data);\n\t\t\ts = utils.mpNormalize(this.part.s.data);\n\t\t\tder.writeBuffer(r, asn1.Ber.Integer);\n\t\t\tder.writeBuffer(s, asn1.Ber.Integer);\n\t\t\tder.endSequence();\n\t\t\treturn (der.buffer);\n\t\t} else if (format === 'ssh' && this.type === 'dsa') {\n\t\t\tbuf = new SSHBuffer({});\n\t\t\tbuf.writeString('ssh-dss');\n\t\t\tr = this.part.r.data;\n\t\t\tif (r.length > 20 && r[0] === 0x00)\n\t\t\t\tr = r.slice(1);\n\t\t\ts = this.part.s.data;\n\t\t\tif (s.length > 20 && s[0] === 0x00)\n\t\t\t\ts = s.slice(1);\n\t\t\tif ((this.hashAlgorithm &&\n\t\t\t    this.hashAlgorithm !== 'sha1') ||\n\t\t\t    r.length + s.length !== 40) {\n\t\t\t\tthrow (new Error('OpenSSH only supports ' +\n\t\t\t\t    'DSA signatures with SHA1 hash'));\n\t\t\t}\n\t\t\tbuf.writeBuffer(Buffer.concat([r, s]));\n\t\t\treturn (buf.toBuffer());\n\t\t} else if (format === 'ssh' && this.type === 'ecdsa') {\n\t\t\tvar inner = new SSHBuffer({});\n\t\t\tr = this.part.r.data;\n\t\t\tinner.writeBuffer(r);\n\t\t\tinner.writePart(this.part.s);\n\n\t\t\tbuf = new SSHBuffer({});\n\t\t\t/* XXX: find a more proper way to do this? */\n\t\t\tvar curve;\n\t\t\tif (r[0] === 0x00)\n\t\t\t\tr = r.slice(1);\n\t\t\tvar sz = r.length * 8;\n\t\t\tif (sz === 256)\n\t\t\t\tcurve = 'nistp256';\n\t\t\telse if (sz === 384)\n\t\t\t\tcurve = 'nistp384';\n\t\t\telse if (sz === 528)\n\t\t\t\tcurve = 'nistp521';\n\t\t\tbuf.writeString('ecdsa-sha2-' + curve);\n\t\t\tbuf.writeBuffer(inner.toBuffer());\n\t\t\treturn (buf.toBuffer());\n\t\t}\n\t\tthrow (new Error('Invalid signature format'));\n\tdefault:\n\t\tthrow (new Error('Invalid signature data'));\n\t}\n};\n\nSignature.prototype.toString = function (format) {\n\tassert.optionalString(format, 'format');\n\treturn (this.toBuffer(format).toString('base64'));\n};\n\nSignature.parse = function (data, type, format) {\n\tif (typeof (data) === 'string')\n\t\tdata = new Buffer(data, 'base64');\n\tassert.buffer(data, 'data');\n\tassert.string(format, 'format');\n\tassert.string(type, 'type');\n\n\tvar opts = {};\n\topts.type = type.toLowerCase();\n\topts.parts = [];\n\n\ttry {\n\t\tassert.ok(data.length > 0, 'signature must not be empty');\n\t\tswitch (opts.type) {\n\t\tcase 'rsa':\n\t\t\treturn (parseOneNum(data, type, format, opts,\n\t\t\t    'ssh-rsa'));\n\t\tcase 'ed25519':\n\t\t\treturn (parseOneNum(data, type, format, opts,\n\t\t\t    'ssh-ed25519'));\n\n\t\tcase 'dsa':\n\t\tcase 'ecdsa':\n\t\t\tif (format === 'asn1')\n\t\t\t\treturn (parseDSAasn1(data, type, format, opts));\n\t\t\telse if (opts.type === 'dsa')\n\t\t\t\treturn (parseDSA(data, type, format, opts));\n\t\t\telse\n\t\t\t\treturn (parseECDSA(data, type, format, opts));\n\n\t\tdefault:\n\t\t\tthrow (new InvalidAlgorithmError(type));\n\t\t}\n\n\t} catch (e) {\n\t\tif (e instanceof InvalidAlgorithmError)\n\t\t\tthrow (e);\n\t\tthrow (new SignatureParseError(type, format, e));\n\t}\n};\n\nfunction parseOneNum(data, type, format, opts, headType) {\n\tif (format === 'ssh') {\n\t\ttry {\n\t\t\tvar buf = new SSHBuffer({buffer: data});\n\t\t\tvar head = buf.readString();\n\t\t} catch (e) {\n\t\t\t/* fall through */\n\t\t}\n\t\tif (head === headType) {\n\t\t\tvar sig = buf.readPart();\n\t\t\tassert.ok(buf.atEnd(), 'extra trailing bytes');\n\t\t\tsig.name = 'sig';\n\t\t\topts.parts.push(sig);\n\t\t\treturn (new Signature(opts));\n\t\t}\n\t}\n\topts.parts.push({name: 'sig', data: data});\n\treturn (new Signature(opts));\n}\n\nfunction parseDSAasn1(data, type, format, opts) {\n\tvar der = new asn1.BerReader(data);\n\tder.readSequence();\n\tvar r = der.readString(asn1.Ber.Integer, true);\n\tvar s = der.readString(asn1.Ber.Integer, true);\n\n\topts.parts.push({name: 'r', data: utils.mpNormalize(r)});\n\topts.parts.push({name: 's', data: utils.mpNormalize(s)});\n\n\treturn (new Signature(opts));\n}\n\nfunction parseDSA(data, type, format, opts) {\n\tif (data.length != 40) {\n\t\tvar buf = new SSHBuffer({buffer: data});\n\t\tvar d = buf.readBuffer();\n\t\tif (d.toString('ascii') === 'ssh-dss')\n\t\t\td = buf.readBuffer();\n\t\tassert.ok(buf.atEnd(), 'extra trailing bytes');\n\t\tassert.strictEqual(d.length, 40, 'invalid inner length');\n\t\tdata = d;\n\t}\n\topts.parts.push({name: 'r', data: data.slice(0, 20)});\n\topts.parts.push({name: 's', data: data.slice(20, 40)});\n\treturn (new Signature(opts));\n}\n\nfunction parseECDSA(data, type, format, opts) {\n\tvar buf = new SSHBuffer({buffer: data});\n\n\tvar r, s;\n\tvar inner = buf.readBuffer();\n\tif (inner.toString('ascii').match(/^ecdsa-/)) {\n\t\tinner = buf.readBuffer();\n\t\tassert.ok(buf.atEnd(), 'extra trailing bytes on outer');\n\t\tbuf = new SSHBuffer({buffer: inner});\n\t\tr = buf.readPart();\n\t} else {\n\t\tr = {data: inner};\n\t}\n\n\ts = buf.readPart();\n\tassert.ok(buf.atEnd(), 'extra trailing bytes');\n\n\tr.name = 'r';\n\ts.name = 's';\n\n\topts.parts.push(r);\n\topts.parts.push(s);\n\treturn (new Signature(opts));\n}\n\nSignature.isSignature = function (obj, ver) {\n\treturn (utils.isCompatible(obj, Signature, ver));\n};\n\n/*\n * API versions for Signature:\n * [1,0] -- initial ver\n * [2,0] -- support for rsa in full ssh format, compat with sshpk-agent\n *          hashAlgorithm property\n * [2,1] -- first tagged version\n */\nSignature.prototype._sshpkApiVersion = [2, 1];\n\nSignature._oldVersionDetect = function (obj) {\n\tassert.func(obj.toBuffer);\n\tif (obj.hasOwnProperty('hashAlgorithm'))\n\t\treturn ([2, 0]);\n\treturn ([1, 0]);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/utils.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tbufferSplit: bufferSplit,\n\taddRSAMissing: addRSAMissing,\n\tcalculateDSAPublic: calculateDSAPublic,\n\tmpNormalize: mpNormalize,\n\tecNormalize: ecNormalize,\n\tcountZeros: countZeros,\n\tassertCompatible: assertCompatible,\n\tisCompatible: isCompatible,\n\topensslKeyDeriv: opensslKeyDeriv,\n\topensshCipherInfo: opensshCipherInfo\n};\n\nvar assert = require('assert-plus');\nvar PrivateKey = require('./private-key');\nvar crypto = require('crypto');\n\nvar MAX_CLASS_DEPTH = 3;\n\nfunction isCompatible(obj, klass, needVer) {\n\tif (obj === null || typeof (obj) !== 'object')\n\t\treturn (false);\n\tif (needVer === undefined)\n\t\tneedVer = klass.prototype._sshpkApiVersion;\n\tif (obj instanceof klass &&\n\t    klass.prototype._sshpkApiVersion[0] == needVer[0])\n\t\treturn (true);\n\tvar proto = Object.getPrototypeOf(obj);\n\tvar depth = 0;\n\twhile (proto.constructor.name !== klass.name) {\n\t\tproto = Object.getPrototypeOf(proto);\n\t\tif (!proto || ++depth > MAX_CLASS_DEPTH)\n\t\t\treturn (false);\n\t}\n\tif (proto.constructor.name !== klass.name)\n\t\treturn (false);\n\tvar ver = proto._sshpkApiVersion;\n\tif (ver === undefined)\n\t\tver = klass._oldVersionDetect(obj);\n\tif (ver[0] != needVer[0] || ver[1] < needVer[1])\n\t\treturn (false);\n\treturn (true);\n}\n\nfunction assertCompatible(obj, klass, needVer, name) {\n\tif (name === undefined)\n\t\tname = 'object';\n\tassert.ok(obj, name + ' must not be null');\n\tassert.object(obj, name + ' must be an object');\n\tif (needVer === undefined)\n\t\tneedVer = klass.prototype._sshpkApiVersion;\n\tif (obj instanceof klass &&\n\t    klass.prototype._sshpkApiVersion[0] == needVer[0])\n\t\treturn;\n\tvar proto = Object.getPrototypeOf(obj);\n\tvar depth = 0;\n\twhile (proto.constructor.name !== klass.name) {\n\t\tproto = Object.getPrototypeOf(proto);\n\t\tassert.ok(proto && ++depth <= MAX_CLASS_DEPTH,\n\t\t    name + ' must be a ' + klass.name + ' instance');\n\t}\n\tassert.strictEqual(proto.constructor.name, klass.name,\n\t    name + ' must be a ' + klass.name + ' instance');\n\tvar ver = proto._sshpkApiVersion;\n\tif (ver === undefined)\n\t\tver = klass._oldVersionDetect(obj);\n\tassert.ok(ver[0] == needVer[0] && ver[1] >= needVer[1],\n\t    name + ' must be compatible with ' + klass.name + ' klass ' +\n\t    'version ' + needVer[0] + '.' + needVer[1]);\n}\n\nvar CIPHER_LEN = {\n\t'des-ede3-cbc': { key: 7, iv: 8 },\n\t'aes-128-cbc': { key: 16, iv: 16 }\n};\nvar PKCS5_SALT_LEN = 8;\n\nfunction opensslKeyDeriv(cipher, salt, passphrase, count) {\n\tassert.buffer(salt, 'salt');\n\tassert.buffer(passphrase, 'passphrase');\n\tassert.number(count, 'iteration count');\n\n\tvar clen = CIPHER_LEN[cipher];\n\tassert.object(clen, 'supported cipher');\n\n\tsalt = salt.slice(0, PKCS5_SALT_LEN);\n\n\tvar D, D_prev, bufs;\n\tvar material = new Buffer(0);\n\twhile (material.length < clen.key + clen.iv) {\n\t\tbufs = [];\n\t\tif (D_prev)\n\t\t\tbufs.push(D_prev);\n\t\tbufs.push(passphrase);\n\t\tbufs.push(salt);\n\t\tD = Buffer.concat(bufs);\n\t\tfor (var j = 0; j < count; ++j)\n\t\t\tD = crypto.createHash('md5').update(D).digest();\n\t\tmaterial = Buffer.concat([material, D]);\n\t\tD_prev = D;\n\t}\n\n\treturn ({\n\t    key: material.slice(0, clen.key),\n\t    iv: material.slice(clen.key, clen.key + clen.iv)\n\t});\n}\n\n/* Count leading zero bits on a buffer */\nfunction countZeros(buf) {\n\tvar o = 0, obit = 8;\n\twhile (o < buf.length) {\n\t\tvar mask = (1 << obit);\n\t\tif ((buf[o] & mask) === mask)\n\t\t\tbreak;\n\t\tobit--;\n\t\tif (obit < 0) {\n\t\t\to++;\n\t\t\tobit = 8;\n\t\t}\n\t}\n\treturn (o*8 + (8 - obit) - 1);\n}\n\nfunction bufferSplit(buf, chr) {\n\tassert.buffer(buf);\n\tassert.string(chr);\n\n\tvar parts = [];\n\tvar lastPart = 0;\n\tvar matches = 0;\n\tfor (var i = 0; i < buf.length; ++i) {\n\t\tif (buf[i] === chr.charCodeAt(matches))\n\t\t\t++matches;\n\t\telse if (buf[i] === chr.charCodeAt(0))\n\t\t\tmatches = 1;\n\t\telse\n\t\t\tmatches = 0;\n\n\t\tif (matches >= chr.length) {\n\t\t\tvar newPart = i + 1;\n\t\t\tparts.push(buf.slice(lastPart, newPart - matches));\n\t\t\tlastPart = newPart;\n\t\t\tmatches = 0;\n\t\t}\n\t}\n\tif (lastPart <= buf.length)\n\t\tparts.push(buf.slice(lastPart, buf.length));\n\n\treturn (parts);\n}\n\nfunction ecNormalize(buf, addZero) {\n\tassert.buffer(buf);\n\tif (buf[0] === 0x00 && buf[1] === 0x04) {\n\t\tif (addZero)\n\t\t\treturn (buf);\n\t\treturn (buf.slice(1));\n\t} else if (buf[0] === 0x04) {\n\t\tif (!addZero)\n\t\t\treturn (buf);\n\t} else {\n\t\twhile (buf[0] === 0x00)\n\t\t\tbuf = buf.slice(1);\n\t\tif (buf[0] === 0x02 || buf[0] === 0x03)\n\t\t\tthrow (new Error('Compressed elliptic curve points ' +\n\t\t\t    'are not supported'));\n\t\tif (buf[0] !== 0x04)\n\t\t\tthrow (new Error('Not a valid elliptic curve point'));\n\t\tif (!addZero)\n\t\t\treturn (buf);\n\t}\n\tvar b = new Buffer(buf.length + 1);\n\tb[0] = 0x0;\n\tbuf.copy(b, 1);\n\treturn (b);\n}\n\nfunction mpNormalize(buf) {\n\tassert.buffer(buf);\n\twhile (buf.length > 1 && buf[0] === 0x00 && (buf[1] & 0x80) === 0x00)\n\t\tbuf = buf.slice(1);\n\tif ((buf[0] & 0x80) === 0x80) {\n\t\tvar b = new Buffer(buf.length + 1);\n\t\tb[0] = 0x00;\n\t\tbuf.copy(b, 1);\n\t\tbuf = b;\n\t}\n\treturn (buf);\n}\n\nfunction bigintToMpBuf(bigint) {\n\tvar buf = new Buffer(bigint.toByteArray());\n\tbuf = mpNormalize(buf);\n\treturn (buf);\n}\n\nfunction calculateDSAPublic(g, p, x) {\n\tassert.buffer(g);\n\tassert.buffer(p);\n\tassert.buffer(x);\n\ttry {\n\t\tvar bigInt = require('jsbn').BigInteger;\n\t} catch (e) {\n\t\tthrow (new Error('To load a PKCS#8 format DSA private key, ' +\n\t\t    'the node jsbn library is required.'));\n\t}\n\tg = new bigInt(g);\n\tp = new bigInt(p);\n\tx = new bigInt(x);\n\tvar y = g.modPow(x, p);\n\tvar ybuf = bigintToMpBuf(y);\n\treturn (ybuf);\n}\n\nfunction addRSAMissing(key) {\n\tassert.object(key);\n\tassertCompatible(key, PrivateKey, [1, 1]);\n\ttry {\n\t\tvar bigInt = require('jsbn').BigInteger;\n\t} catch (e) {\n\t\tthrow (new Error('To write a PEM private key from ' +\n\t\t    'this source, the node jsbn lib is required.'));\n\t}\n\n\tvar d = new bigInt(key.part.d.data);\n\tvar buf;\n\n\tif (!key.part.dmodp) {\n\t\tvar p = new bigInt(key.part.p.data);\n\t\tvar dmodp = d.mod(p.subtract(1));\n\n\t\tbuf = bigintToMpBuf(dmodp);\n\t\tkey.part.dmodp = {name: 'dmodp', data: buf};\n\t\tkey.parts.push(key.part.dmodp);\n\t}\n\tif (!key.part.dmodq) {\n\t\tvar q = new bigInt(key.part.q.data);\n\t\tvar dmodq = d.mod(q.subtract(1));\n\n\t\tbuf = bigintToMpBuf(dmodq);\n\t\tkey.part.dmodq = {name: 'dmodq', data: buf};\n\t\tkey.parts.push(key.part.dmodq);\n\t}\n}\n\nfunction opensshCipherInfo(cipher) {\n\tvar inf = {};\n\tswitch (cipher) {\n\tcase '3des-cbc':\n\t\tinf.keySize = 24;\n\t\tinf.blockSize = 8;\n\t\tinf.opensslName = 'des-ede3-cbc';\n\t\tbreak;\n\tcase 'blowfish-cbc':\n\t\tinf.keySize = 16;\n\t\tinf.blockSize = 8;\n\t\tinf.opensslName = 'bf-cbc';\n\t\tbreak;\n\tcase 'aes128-cbc':\n\tcase 'aes128-ctr':\n\tcase 'aes128-gcm@openssh.com':\n\t\tinf.keySize = 16;\n\t\tinf.blockSize = 16;\n\t\tinf.opensslName = 'aes-128-' + cipher.slice(7, 10);\n\t\tbreak;\n\tcase 'aes192-cbc':\n\tcase 'aes192-ctr':\n\tcase 'aes192-gcm@openssh.com':\n\t\tinf.keySize = 24;\n\t\tinf.blockSize = 16;\n\t\tinf.opensslName = 'aes-192-' + cipher.slice(7, 10);\n\t\tbreak;\n\tcase 'aes256-cbc':\n\tcase 'aes256-ctr':\n\tcase 'aes256-gcm@openssh.com':\n\t\tinf.keySize = 32;\n\t\tinf.blockSize = 16;\n\t\tinf.opensslName = 'aes-256-' + cipher.slice(7, 10);\n\t\tbreak;\n\tdefault:\n\t\tthrow (new Error(\n\t\t    'Unsupported openssl cipher \"' + cipher + '\"'));\n\t}\n\treturn (inf);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/private-key.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = PrivateKey;\n\nvar assert = require('assert-plus');\nvar algs = require('./algs');\nvar crypto = require('crypto');\nvar Fingerprint = require('./fingerprint');\nvar Signature = require('./signature');\nvar errs = require('./errors');\nvar util = require('util');\nvar utils = require('./utils');\nvar edCompat;\nvar ed;\n\ntry {\n\tedCompat = require('./ed-compat');\n} catch (e) {\n\t/* Just continue through, and bail out if we try to use it. */\n}\n\nvar Key = require('./key');\n\nvar InvalidAlgorithmError = errs.InvalidAlgorithmError;\nvar KeyParseError = errs.KeyParseError;\nvar KeyEncryptedError = errs.KeyEncryptedError;\n\nvar formats = {};\nformats['auto'] = require('./formats/auto');\nformats['pem'] = require('./formats/pem');\nformats['pkcs1'] = require('./formats/pkcs1');\nformats['pkcs8'] = require('./formats/pkcs8');\nformats['rfc4253'] = require('./formats/rfc4253');\nformats['ssh-private'] = require('./formats/ssh-private');\nformats['openssh'] = formats['ssh-private'];\nformats['ssh'] = formats['ssh-private'];\n\nfunction PrivateKey(opts) {\n\tassert.object(opts, 'options');\n\tKey.call(this, opts);\n\n\tthis._pubCache = undefined;\n}\nutil.inherits(PrivateKey, Key);\n\nPrivateKey.formats = formats;\n\nPrivateKey.prototype.toBuffer = function (format, options) {\n\tif (format === undefined)\n\t\tformat = 'pkcs1';\n\tassert.string(format, 'format');\n\tassert.object(formats[format], 'formats[format]');\n\tassert.optionalObject(options, 'options');\n\n\treturn (formats[format].write(this, options));\n};\n\nPrivateKey.prototype.hash = function (algo) {\n\treturn (this.toPublic().hash(algo));\n};\n\nPrivateKey.prototype.toPublic = function () {\n\tif (this._pubCache)\n\t\treturn (this._pubCache);\n\n\tvar algInfo = algs.info[this.type];\n\tvar pubParts = [];\n\tfor (var i = 0; i < algInfo.parts.length; ++i) {\n\t\tvar p = algInfo.parts[i];\n\t\tpubParts.push(this.part[p]);\n\t}\n\n\tthis._pubCache = new Key({\n\t\ttype: this.type,\n\t\tsource: this,\n\t\tparts: pubParts\n\t});\n\tif (this.comment)\n\t\tthis._pubCache.comment = this.comment;\n\treturn (this._pubCache);\n};\n\nPrivateKey.prototype.derive = function (newType, newSize) {\n\tassert.string(newType, 'type');\n\tassert.optionalNumber(newSize, 'size');\n\tvar priv, pub;\n\n\tif (this.type === 'ed25519' && newType === 'curve25519') {\n\t\tif (ed === undefined)\n\t\t\ted = require('jodid25519');\n\n\t\tpriv = this.part.r.data;\n\t\tif (priv[0] === 0x00)\n\t\t\tpriv = priv.slice(1);\n\t\tpriv = priv.slice(0, 32);\n\n\t\tpub = ed.dh.publicKey(priv);\n\t\tpriv = utils.mpNormalize(Buffer.concat([priv, pub]));\n\n\t\treturn (new PrivateKey({\n\t\t\ttype: 'curve25519',\n\t\t\tparts: [\n\t\t\t\t{ name: 'R', data: utils.mpNormalize(pub) },\n\t\t\t\t{ name: 'r', data: priv }\n\t\t\t]\n\t\t}));\n\t} else if (this.type === 'curve25519' && newType === 'ed25519') {\n\t\tif (ed === undefined)\n\t\t\ted = require('jodid25519');\n\n\t\tpriv = this.part.r.data;\n\t\tif (priv[0] === 0x00)\n\t\t\tpriv = priv.slice(1);\n\t\tpriv = priv.slice(0, 32);\n\n\t\tpub = ed.eddsa.publicKey(priv.toString('binary'));\n\t\tpub = new Buffer(pub, 'binary');\n\n\t\tpriv = utils.mpNormalize(Buffer.concat([priv, pub]));\n\n\t\treturn (new PrivateKey({\n\t\t\ttype: 'ed25519',\n\t\t\tparts: [\n\t\t\t\t{ name: 'R', data: utils.mpNormalize(pub) },\n\t\t\t\t{ name: 'r', data: priv }\n\t\t\t]\n\t\t}));\n\t}\n\tthrow (new Error('Key derivation not supported from ' + this.type +\n\t    ' to ' + newType));\n};\n\nPrivateKey.prototype.createVerify = function (hashAlgo) {\n\treturn (this.toPublic().createVerify(hashAlgo));\n};\n\nPrivateKey.prototype.createSign = function (hashAlgo) {\n\tif (hashAlgo === undefined)\n\t\thashAlgo = this.defaultHashAlgorithm();\n\tassert.string(hashAlgo, 'hash algorithm');\n\n\t/* ED25519 is not supported by OpenSSL, use a javascript impl. */\n\tif (this.type === 'ed25519' && edCompat !== undefined)\n\t\treturn (new edCompat.Signer(this, hashAlgo));\n\tif (this.type === 'curve25519')\n\t\tthrow (new Error('Curve25519 keys are not suitable for ' +\n\t\t    'signing or verification'));\n\n\tvar v, nm, err;\n\ttry {\n\t\tnm = hashAlgo.toUpperCase();\n\t\tv = crypto.createSign(nm);\n\t} catch (e) {\n\t\terr = e;\n\t}\n\tif (v === undefined || (err instanceof Error &&\n\t    err.message.match(/Unknown message digest/))) {\n\t\tnm = 'RSA-';\n\t\tnm += hashAlgo.toUpperCase();\n\t\tv = crypto.createSign(nm);\n\t}\n\tassert.ok(v, 'failed to create verifier');\n\tvar oldSign = v.sign.bind(v);\n\tvar key = this.toBuffer('pkcs1');\n\tvar type = this.type;\n\tv.sign = function () {\n\t\tvar sig = oldSign(key);\n\t\tif (typeof (sig) === 'string')\n\t\t\tsig = new Buffer(sig, 'binary');\n\t\tsig = Signature.parse(sig, type, 'asn1');\n\t\tsig.hashAlgorithm = hashAlgo;\n\t\treturn (sig);\n\t};\n\treturn (v);\n};\n\nPrivateKey.parse = function (data, format, options) {\n\tif (typeof (data) !== 'string')\n\t\tassert.buffer(data, 'data');\n\tif (format === undefined)\n\t\tformat = 'auto';\n\tassert.string(format, 'format');\n\tif (typeof (options) === 'string')\n\t\toptions = { filename: options };\n\tassert.optionalObject(options, 'options');\n\tif (options === undefined)\n\t\toptions = {};\n\tassert.optionalString(options.filename, 'options.filename');\n\tif (options.filename === undefined)\n\t\toptions.filename = '(unnamed)';\n\n\tassert.object(formats[format], 'formats[format]');\n\n\ttry {\n\t\tvar k = formats[format].read(data, options);\n\t\tassert.ok(k instanceof PrivateKey, 'key is not a private key');\n\t\tif (!k.comment)\n\t\t\tk.comment = options.filename;\n\t\treturn (k);\n\t} catch (e) {\n\t\tif (e.name === 'KeyEncryptedError')\n\t\t\tthrow (e);\n\t\tthrow (new KeyParseError(options.filename, format, e));\n\t}\n};\n\nPrivateKey.isPrivateKey = function (obj, ver) {\n\treturn (utils.isCompatible(obj, PrivateKey, ver));\n};\n\n/*\n * API versions for PrivateKey:\n * [1,0] -- initial ver\n * [1,1] -- added auto, pkcs[18], openssh/ssh-private formats\n * [1,2] -- added defaultHashAlgorithm\n * [1,3] -- added derive, ed, createDH\n * [1,4] -- first tagged version\n */\nPrivateKey.prototype._sshpkApiVersion = [1, 4];\n\nPrivateKey._oldVersionDetect = function (obj) {\n\tassert.func(obj.toPublic);\n\tassert.func(obj.createSign);\n\tif (obj.derive)\n\t\treturn ([1, 3]);\n\tif (obj.defaultHashAlgorithm)\n\t\treturn ([1, 2]);\n\tif (obj.formats['auto'])\n\t\treturn ([1, 1]);\n\treturn ([1, 0]);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/ed-compat.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tVerifier: Verifier,\n\tSigner: Signer\n};\n\nvar nacl;\nvar stream = require('stream');\nvar util = require('util');\nvar assert = require('assert-plus');\nvar Signature = require('./signature');\n\nfunction Verifier(key, hashAlgo) {\n\tif (nacl === undefined)\n\t\tnacl = require('tweetnacl');\n\n\tif (hashAlgo.toLowerCase() !== 'sha512')\n\t\tthrow (new Error('ED25519 only supports the use of ' +\n\t\t    'SHA-512 hashes'));\n\n\tthis.key = key;\n\tthis.chunks = [];\n\n\tstream.Writable.call(this, {});\n}\nutil.inherits(Verifier, stream.Writable);\n\nVerifier.prototype._write = function (chunk, enc, cb) {\n\tthis.chunks.push(chunk);\n\tcb();\n};\n\nVerifier.prototype.update = function (chunk) {\n\tif (typeof (chunk) === 'string')\n\t\tchunk = new Buffer(chunk, 'binary');\n\tthis.chunks.push(chunk);\n};\n\nVerifier.prototype.verify = function (signature, fmt) {\n\tvar sig;\n\tif (Signature.isSignature(signature, [2, 0])) {\n\t\tif (signature.type !== 'ed25519')\n\t\t\treturn (false);\n\t\tsig = signature.toBuffer('raw');\n\n\t} else if (typeof (signature) === 'string') {\n\t\tsig = new Buffer(signature, 'base64');\n\n\t} else if (Signature.isSignature(signature, [1, 0])) {\n\t\tthrow (new Error('signature was created by too old ' +\n\t\t    'a version of sshpk and cannot be verified'));\n\t}\n\n\tassert.buffer(sig);\n\treturn (nacl.sign.detached.verify(\n\t    new Uint8Array(Buffer.concat(this.chunks)),\n\t    new Uint8Array(sig),\n\t    new Uint8Array(this.key.part.R.data)));\n};\n\nfunction Signer(key, hashAlgo) {\n\tif (nacl === undefined)\n\t\tnacl = require('tweetnacl');\n\n\tif (hashAlgo.toLowerCase() !== 'sha512')\n\t\tthrow (new Error('ED25519 only supports the use of ' +\n\t\t    'SHA-512 hashes'));\n\n\tthis.key = key;\n\tthis.chunks = [];\n\n\tstream.Writable.call(this, {});\n}\nutil.inherits(Signer, stream.Writable);\n\nSigner.prototype._write = function (chunk, enc, cb) {\n\tthis.chunks.push(chunk);\n\tcb();\n};\n\nSigner.prototype.update = function (chunk) {\n\tif (typeof (chunk) === 'string')\n\t\tchunk = new Buffer(chunk, 'binary');\n\tthis.chunks.push(chunk);\n};\n\nSigner.prototype.sign = function () {\n\tvar sig = nacl.sign.detached(\n\t    new Uint8Array(Buffer.concat(this.chunks)),\n\t    new Uint8Array(this.key.part.r.data));\n\tvar sigBuf = new Buffer(sig);\n\tvar sigObj = Signature.parse(sigBuf, 'ed25519', 'raw');\n\tsigObj.hashAlgorithm = 'sha512';\n\treturn (sigObj);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/auto.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\twrite: write\n};\n\nvar assert = require('assert-plus');\nvar utils = require('../utils');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\n\nvar pem = require('./pem');\nvar ssh = require('./ssh');\nvar rfc4253 = require('./rfc4253');\n\nfunction read(buf, options) {\n\tif (typeof (buf) === 'string') {\n\t\tif (buf.trim().match(/^[-]+[ ]*BEGIN/))\n\t\t\treturn (pem.read(buf, options));\n\t\tif (buf.match(/^\\s*ssh-[a-z]/))\n\t\t\treturn (ssh.read(buf, options));\n\t\tif (buf.match(/^\\s*ecdsa-/))\n\t\t\treturn (ssh.read(buf, options));\n\t\tbuf = new Buffer(buf, 'binary');\n\t} else {\n\t\tassert.buffer(buf);\n\t\tif (findPEMHeader(buf))\n\t\t\treturn (pem.read(buf, options));\n\t\tif (findSSHHeader(buf))\n\t\t\treturn (ssh.read(buf, options));\n\t}\n\tif (buf.readUInt32BE(0) < buf.length)\n\t\treturn (rfc4253.read(buf, options));\n\tthrow (new Error('Failed to auto-detect format of key'));\n}\n\nfunction findSSHHeader(buf) {\n\tvar offset = 0;\n\twhile (offset < buf.length &&\n\t    (buf[offset] === 32 || buf[offset] === 10 || buf[offset] === 9))\n\t\t++offset;\n\tif (offset + 4 <= buf.length &&\n\t    buf.slice(offset, offset + 4).toString('ascii') === 'ssh-')\n\t\treturn (true);\n\tif (offset + 6 <= buf.length &&\n\t    buf.slice(offset, offset + 6).toString('ascii') === 'ecdsa-')\n\t\treturn (true);\n\treturn (false);\n}\n\nfunction findPEMHeader(buf) {\n\tvar offset = 0;\n\twhile (offset < buf.length &&\n\t    (buf[offset] === 32 || buf[offset] === 10))\n\t\t++offset;\n\tif (buf[offset] !== 45)\n\t\treturn (false);\n\twhile (offset < buf.length &&\n\t    (buf[offset] === 45))\n\t\t++offset;\n\twhile (offset < buf.length &&\n\t    (buf[offset] === 32))\n\t\t++offset;\n\tif (offset + 5 > buf.length ||\n\t    buf.slice(offset, offset + 5).toString('ascii') !== 'BEGIN')\n\t\treturn (false);\n\treturn (true);\n}\n\nfunction write(key, options) {\n\tthrow (new Error('\"auto\" format cannot be used for writing'));\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/pem.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\twrite: write\n};\n\nvar assert = require('assert-plus');\nvar asn1 = require('asn1');\nvar crypto = require('crypto');\nvar algs = require('../algs');\nvar utils = require('../utils');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\n\nvar pkcs1 = require('./pkcs1');\nvar pkcs8 = require('./pkcs8');\nvar sshpriv = require('./ssh-private');\nvar rfc4253 = require('./rfc4253');\n\nvar errors = require('../errors');\n\n/*\n * For reading we support both PKCS#1 and PKCS#8. If we find a private key,\n * we just take the public component of it and use that.\n */\nfunction read(buf, options, forceType) {\n\tvar input = buf;\n\tif (typeof (buf) !== 'string') {\n\t\tassert.buffer(buf, 'buf');\n\t\tbuf = buf.toString('ascii');\n\t}\n\n\tvar lines = buf.trim().split('\\n');\n\n\tvar m = lines[0].match(/*JSSTYLED*/\n\t    /[-]+[ ]*BEGIN ([A-Z0-9]+ )?(PUBLIC|PRIVATE) KEY[ ]*[-]+/);\n\tassert.ok(m, 'invalid PEM header');\n\n\tvar m2 = lines[lines.length - 1].match(/*JSSTYLED*/\n\t    /[-]+[ ]*END ([A-Z0-9]+ )?(PUBLIC|PRIVATE) KEY[ ]*[-]+/);\n\tassert.ok(m2, 'invalid PEM footer');\n\n\t/* Begin and end banners must match key type */\n\tassert.equal(m[2], m2[2]);\n\tvar type = m[2].toLowerCase();\n\n\tvar alg;\n\tif (m[1]) {\n\t\t/* They also must match algorithms, if given */\n\t\tassert.equal(m[1], m2[1], 'PEM header and footer mismatch');\n\t\talg = m[1].trim();\n\t}\n\n\tvar headers = {};\n\twhile (true) {\n\t\tlines = lines.slice(1);\n\t\tm = lines[0].match(/*JSSTYLED*/\n\t\t    /^([A-Za-z0-9-]+): (.+)$/);\n\t\tif (!m)\n\t\t\tbreak;\n\t\theaders[m[1].toLowerCase()] = m[2];\n\t}\n\n\tvar cipher, key, iv;\n\tif (headers['proc-type']) {\n\t\tvar parts = headers['proc-type'].split(',');\n\t\tif (parts[0] === '4' && parts[1] === 'ENCRYPTED') {\n\t\t\tif (typeof (options.passphrase) === 'string') {\n\t\t\t\toptions.passphrase = new Buffer(\n\t\t\t\t    options.passphrase, 'utf-8');\n\t\t\t}\n\t\t\tif (!Buffer.isBuffer(options.passphrase)) {\n\t\t\t\tthrow (new errors.KeyEncryptedError(\n\t\t\t\t    options.filename, 'PEM'));\n\t\t\t} else {\n\t\t\t\tparts = headers['dek-info'].split(',');\n\t\t\t\tassert.ok(parts.length === 2);\n\t\t\t\tcipher = parts[0].toLowerCase();\n\t\t\t\tiv = new Buffer(parts[1], 'hex');\n\t\t\t\tkey = utils.opensslKeyDeriv(cipher, iv,\n\t\t\t\t    options.passphrase, 1).key;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Chop off the first and last lines */\n\tlines = lines.slice(0, -1).join('');\n\tbuf = new Buffer(lines, 'base64');\n\n\tif (cipher && key && iv) {\n\t\tvar cipherStream = crypto.createDecipheriv(cipher, key, iv);\n\t\tvar chunk, chunks = [];\n\t\tcipherStream.once('error', function (e) {\n\t\t\tif (e.toString().indexOf('bad decrypt') !== -1) {\n\t\t\t\tthrow (new Error('Incorrect passphrase ' +\n\t\t\t\t    'supplied, could not decrypt key'));\n\t\t\t}\n\t\t\tthrow (e);\n\t\t});\n\t\tcipherStream.write(buf);\n\t\tcipherStream.end();\n\t\twhile ((chunk = cipherStream.read()) !== null)\n\t\t\tchunks.push(chunk);\n\t\tbuf = Buffer.concat(chunks);\n\t}\n\n\t/* The new OpenSSH internal format abuses PEM headers */\n\tif (alg && alg.toLowerCase() === 'openssh')\n\t\treturn (sshpriv.readSSHPrivate(type, buf, options));\n\tif (alg && alg.toLowerCase() === 'ssh2')\n\t\treturn (rfc4253.readType(type, buf, options));\n\n\tvar der = new asn1.BerReader(buf);\n\tder.originalInput = input;\n\n\t/*\n\t * All of the PEM file types start with a sequence tag, so chop it\n\t * off here\n\t */\n\tder.readSequence();\n\n\t/* PKCS#1 type keys name an algorithm in the banner explicitly */\n\tif (alg) {\n\t\tif (forceType)\n\t\t\tassert.strictEqual(forceType, 'pkcs1');\n\t\treturn (pkcs1.readPkcs1(alg, type, der));\n\t} else {\n\t\tif (forceType)\n\t\t\tassert.strictEqual(forceType, 'pkcs8');\n\t\treturn (pkcs8.readPkcs8(alg, type, der));\n\t}\n}\n\nfunction write(key, options, type) {\n\tassert.object(key);\n\n\tvar alg = {'ecdsa': 'EC', 'rsa': 'RSA', 'dsa': 'DSA'}[key.type];\n\tvar header;\n\n\tvar der = new asn1.BerWriter();\n\n\tif (PrivateKey.isPrivateKey(key)) {\n\t\tif (type && type === 'pkcs8') {\n\t\t\theader = 'PRIVATE KEY';\n\t\t\tpkcs8.writePkcs8(der, key);\n\t\t} else {\n\t\t\tif (type)\n\t\t\t\tassert.strictEqual(type, 'pkcs1');\n\t\t\theader = alg + ' PRIVATE KEY';\n\t\t\tpkcs1.writePkcs1(der, key);\n\t\t}\n\n\t} else if (Key.isKey(key)) {\n\t\tif (type && type === 'pkcs1') {\n\t\t\theader = alg + ' PUBLIC KEY';\n\t\t\tpkcs1.writePkcs1(der, key);\n\t\t} else {\n\t\t\tif (type)\n\t\t\t\tassert.strictEqual(type, 'pkcs8');\n\t\t\theader = 'PUBLIC KEY';\n\t\t\tpkcs8.writePkcs8(der, key);\n\t\t}\n\n\t} else {\n\t\tthrow (new Error('key is not a Key or PrivateKey'));\n\t}\n\n\tvar tmp = der.buffer.toString('base64');\n\tvar len = tmp.length + (tmp.length / 64) +\n\t    18 + 16 + header.length*2 + 10;\n\tvar buf = new Buffer(len);\n\tvar o = 0;\n\to += buf.write('-----BEGIN ' + header + '-----\\n', o);\n\tfor (var i = 0; i < tmp.length; ) {\n\t\tvar limit = i + 64;\n\t\tif (limit > tmp.length)\n\t\t\tlimit = tmp.length;\n\t\to += buf.write(tmp.slice(i, limit), o);\n\t\tbuf[o++] = 10;\n\t\ti = limit;\n\t}\n\to += buf.write('-----END ' + header + '-----\\n', o);\n\n\treturn (buf.slice(0, o));\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/node_modules/asn1/lib/index.js":"// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n// If you have no idea what ASN.1 or BER is, see this:\n// ftp://ftp.rsa.com/pub/pkcs/ascii/layman.asc\n\nvar Ber = require('./ber/index');\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  Ber: Ber,\n\n  BerReader: Ber.Reader,\n\n  BerWriter: Ber.Writer\n\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/node_modules/asn1/lib/ber/index.js":"// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar errors = require('./errors');\nvar types = require('./types');\n\nvar Reader = require('./reader');\nvar Writer = require('./writer');\n\n\n///--- Exports\n\nmodule.exports = {\n\n  Reader: Reader,\n\n  Writer: Writer\n\n};\n\nfor (var t in types) {\n  if (types.hasOwnProperty(t))\n    module.exports[t] = types[t];\n}\nfor (var e in errors) {\n  if (errors.hasOwnProperty(e))\n    module.exports[e] = errors[e];\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/node_modules/asn1/lib/ber/errors.js":"// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n\n  newInvalidAsn1Error: function(msg) {\n    var e = new Error();\n    e.name = 'InvalidAsn1Error';\n    e.message = msg || '';\n    return e;\n  }\n\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/node_modules/asn1/lib/ber/types.js":"// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n  EOC: 0,\n  Boolean: 1,\n  Integer: 2,\n  BitString: 3,\n  OctetString: 4,\n  Null: 5,\n  OID: 6,\n  ObjectDescriptor: 7,\n  External: 8,\n  Real: 9, // float\n  Enumeration: 10,\n  PDV: 11,\n  Utf8String: 12,\n  RelativeOID: 13,\n  Sequence: 16,\n  Set: 17,\n  NumericString: 18,\n  PrintableString: 19,\n  T61String: 20,\n  VideotexString: 21,\n  IA5String: 22,\n  UTCTime: 23,\n  GeneralizedTime: 24,\n  GraphicString: 25,\n  VisibleString: 26,\n  GeneralString: 28,\n  UniversalString: 29,\n  CharacterString: 30,\n  BMPString: 31,\n  Constructor: 32,\n  Context: 128\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/node_modules/asn1/lib/ber/reader.js":"// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = require('assert');\n\nvar ASN1 = require('./types');\nvar errors = require('./errors');\n\n\n///--- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\n\n\n///--- API\n\nfunction Reader(data) {\n  if (!data || !Buffer.isBuffer(data))\n    throw new TypeError('data must be a node Buffer');\n\n  this._buf = data;\n  this._size = data.length;\n\n  // These hold the \"current\" state\n  this._len = 0;\n  this._offset = 0;\n}\n\nObject.defineProperty(Reader.prototype, 'length', {\n  enumerable: true,\n  get: function () { return (this._len); }\n});\n\nObject.defineProperty(Reader.prototype, 'offset', {\n  enumerable: true,\n  get: function () { return (this._offset); }\n});\n\nObject.defineProperty(Reader.prototype, 'remain', {\n  get: function () { return (this._size - this._offset); }\n});\n\nObject.defineProperty(Reader.prototype, 'buffer', {\n  get: function () { return (this._buf.slice(this._offset)); }\n});\n\n\n/**\n * Reads a single byte and advances offset; you can pass in `true` to make this\n * a \"peek\" operation (i.e., get the byte, but don't advance the offset).\n *\n * @param {Boolean} peek true means don't move offset.\n * @return {Number} the next byte, null if not enough data.\n */\nReader.prototype.readByte = function(peek) {\n  if (this._size - this._offset < 1)\n    return null;\n\n  var b = this._buf[this._offset] & 0xff;\n\n  if (!peek)\n    this._offset += 1;\n\n  return b;\n};\n\n\nReader.prototype.peek = function() {\n  return this.readByte(true);\n};\n\n\n/**\n * Reads a (potentially) variable length off the BER buffer.  This call is\n * not really meant to be called directly, as callers have to manipulate\n * the internal buffer afterwards.\n *\n * As a result of this call, you can call `Reader.length`, until the\n * next thing called that does a readLength.\n *\n * @return {Number} the amount of offset to advance the buffer.\n * @throws {InvalidAsn1Error} on bad ASN.1\n */\nReader.prototype.readLength = function(offset) {\n  if (offset === undefined)\n    offset = this._offset;\n\n  if (offset >= this._size)\n    return null;\n\n  var lenB = this._buf[offset++] & 0xff;\n  if (lenB === null)\n    return null;\n\n  if ((lenB & 0x80) == 0x80) {\n    lenB &= 0x7f;\n\n    if (lenB == 0)\n      throw newInvalidAsn1Error('Indefinite length not supported');\n\n    if (lenB > 4)\n      throw newInvalidAsn1Error('encoding too long');\n\n    if (this._size - offset < lenB)\n      return null;\n\n    this._len = 0;\n    for (var i = 0; i < lenB; i++)\n      this._len = (this._len << 8) + (this._buf[offset++] & 0xff);\n\n  } else {\n    // Wasn't a variable length\n    this._len = lenB;\n  }\n\n  return offset;\n};\n\n\n/**\n * Parses the next sequence in this BER buffer.\n *\n * To get the length of the sequence, call `Reader.length`.\n *\n * @return {Number} the sequence's tag.\n */\nReader.prototype.readSequence = function(tag) {\n  var seq = this.peek();\n  if (seq === null)\n    return null;\n  if (tag !== undefined && tag !== seq)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + seq.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  this._offset = o;\n  return seq;\n};\n\n\nReader.prototype.readInt = function() {\n  return this._readTag(ASN1.Integer);\n};\n\n\nReader.prototype.readBoolean = function() {\n  return (this._readTag(ASN1.Boolean) === 0 ? false : true);\n};\n\n\nReader.prototype.readEnumeration = function() {\n  return this._readTag(ASN1.Enumeration);\n};\n\n\nReader.prototype.readString = function(tag, retbuf) {\n  if (!tag)\n    tag = ASN1.OctetString;\n\n  var b = this.peek();\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n\n  if (o === null)\n    return null;\n\n  if (this.length > this._size - o)\n    return null;\n\n  this._offset = o;\n\n  if (this.length === 0)\n    return retbuf ? new Buffer(0) : '';\n\n  var str = this._buf.slice(this._offset, this._offset + this.length);\n  this._offset += this.length;\n\n  return retbuf ? str : str.toString('utf8');\n};\n\nReader.prototype.readOID = function(tag) {\n  if (!tag)\n    tag = ASN1.OID;\n\n  var b = this.readString(tag, true);\n  if (b === null)\n    return null;\n\n  var values = [];\n  var value = 0;\n\n  for (var i = 0; i < b.length; i++) {\n    var byte = b[i] & 0xff;\n\n    value <<= 7;\n    value += byte & 0x7f;\n    if ((byte & 0x80) == 0) {\n      values.push(value);\n      value = 0;\n    }\n  }\n\n  value = values.shift();\n  values.unshift(value % 40);\n  values.unshift((value / 40) >> 0);\n\n  return values.join('.');\n};\n\n\nReader.prototype._readTag = function(tag) {\n  assert.ok(tag !== undefined);\n\n  var b = this.peek();\n\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  if (this.length > 4)\n    throw newInvalidAsn1Error('Integer too long: ' + this.length);\n\n  if (this.length > this._size - o)\n    return null;\n  this._offset = o;\n\n  var fb = this._buf[this._offset];\n  var value = 0;\n\n  for (var i = 0; i < this.length; i++) {\n    value <<= 8;\n    value |= (this._buf[this._offset++] & 0xff);\n  }\n\n  if ((fb & 0x80) == 0x80 && i !== 4)\n    value -= (1 << (i * 8));\n\n  return value >> 0;\n};\n\n\n\n///--- Exported API\n\nmodule.exports = Reader;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/node_modules/asn1/lib/ber/writer.js":"// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = require('assert');\nvar ASN1 = require('./types');\nvar errors = require('./errors');\n\n\n///--- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\nvar DEFAULT_OPTS = {\n  size: 1024,\n  growthFactor: 8\n};\n\n\n///--- Helpers\n\nfunction merge(from, to) {\n  assert.ok(from);\n  assert.equal(typeof(from), 'object');\n  assert.ok(to);\n  assert.equal(typeof(to), 'object');\n\n  var keys = Object.getOwnPropertyNames(from);\n  keys.forEach(function(key) {\n    if (to[key])\n      return;\n\n    var value = Object.getOwnPropertyDescriptor(from, key);\n    Object.defineProperty(to, key, value);\n  });\n\n  return to;\n}\n\n\n\n///--- API\n\nfunction Writer(options) {\n  options = merge(DEFAULT_OPTS, options || {});\n\n  this._buf = new Buffer(options.size || 1024);\n  this._size = this._buf.length;\n  this._offset = 0;\n  this._options = options;\n\n  // A list of offsets in the buffer where we need to insert\n  // sequence tag/len pairs.\n  this._seq = [];\n}\n\nObject.defineProperty(Writer.prototype, 'buffer', {\n  get: function () {\n    if (this._seq.length)\n      throw new InvalidAsn1Error(this._seq.length + ' unended sequence(s)');\n\n    return (this._buf.slice(0, this._offset));\n  }\n});\n\nWriter.prototype.writeByte = function(b) {\n  if (typeof(b) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(1);\n  this._buf[this._offset++] = b;\n};\n\n\nWriter.prototype.writeInt = function(i, tag) {\n  if (typeof(i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Integer;\n\n  var sz = 4;\n\n  while ((((i & 0xff800000) === 0) || ((i & 0xff800000) === 0xff800000 >> 0)) &&\n         (sz > 1)) {\n    sz--;\n    i <<= 8;\n  }\n\n  if (sz > 4)\n    throw new InvalidAsn1Error('BER ints cannot be > 0xffffffff');\n\n  this._ensure(2 + sz);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = sz;\n\n  while (sz-- > 0) {\n    this._buf[this._offset++] = ((i & 0xff000000) >>> 24);\n    i <<= 8;\n  }\n\n};\n\n\nWriter.prototype.writeNull = function() {\n  this.writeByte(ASN1.Null);\n  this.writeByte(0x00);\n};\n\n\nWriter.prototype.writeEnumeration = function(i, tag) {\n  if (typeof(i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Enumeration;\n\n  return this.writeInt(i, tag);\n};\n\n\nWriter.prototype.writeBoolean = function(b, tag) {\n  if (typeof(b) !== 'boolean')\n    throw new TypeError('argument must be a Boolean');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Boolean;\n\n  this._ensure(3);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = 0x01;\n  this._buf[this._offset++] = b ? 0xff : 0x00;\n};\n\n\nWriter.prototype.writeString = function(s, tag) {\n  if (typeof(s) !== 'string')\n    throw new TypeError('argument must be a string (was: ' + typeof(s) + ')');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.OctetString;\n\n  var len = Buffer.byteLength(s);\n  this.writeByte(tag);\n  this.writeLength(len);\n  if (len) {\n    this._ensure(len);\n    this._buf.write(s, this._offset);\n    this._offset += len;\n  }\n};\n\n\nWriter.prototype.writeBuffer = function(buf, tag) {\n  if (typeof(tag) !== 'number')\n    throw new TypeError('tag must be a number');\n  if (!Buffer.isBuffer(buf))\n    throw new TypeError('argument must be a buffer');\n\n  this.writeByte(tag);\n  this.writeLength(buf.length);\n  this._ensure(buf.length);\n  buf.copy(this._buf, this._offset, 0, buf.length);\n  this._offset += buf.length;\n};\n\n\nWriter.prototype.writeStringArray = function(strings) {\n  if ((!strings instanceof Array))\n    throw new TypeError('argument must be an Array[String]');\n\n  var self = this;\n  strings.forEach(function(s) {\n    self.writeString(s);\n  });\n};\n\n// This is really to solve DER cases, but whatever for now\nWriter.prototype.writeOID = function(s, tag) {\n  if (typeof(s) !== 'string')\n    throw new TypeError('argument must be a string');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.OID;\n\n  if (!/^([0-9]+\\.){3,}[0-9]+$/.test(s))\n    throw new Error('argument is not a valid OID string');\n\n  function encodeOctet(bytes, octet) {\n    if (octet < 128) {\n        bytes.push(octet);\n    } else if (octet < 16384) {\n        bytes.push((octet >>> 7) | 0x80);\n        bytes.push(octet & 0x7F);\n    } else if (octet < 2097152) {\n      bytes.push((octet >>> 14) | 0x80);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else if (octet < 268435456) {\n      bytes.push((octet >>> 21) | 0x80);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else {\n      bytes.push(((octet >>> 28) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 21) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    }\n  }\n\n  var tmp = s.split('.');\n  var bytes = [];\n  bytes.push(parseInt(tmp[0], 10) * 40 + parseInt(tmp[1], 10));\n  tmp.slice(2).forEach(function(b) {\n    encodeOctet(bytes, parseInt(b, 10));\n  });\n\n  var self = this;\n  this._ensure(2 + bytes.length);\n  this.writeByte(tag);\n  this.writeLength(bytes.length);\n  bytes.forEach(function(b) {\n    self.writeByte(b);\n  });\n};\n\n\nWriter.prototype.writeLength = function(len) {\n  if (typeof(len) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(4);\n\n  if (len <= 0x7f) {\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xff) {\n    this._buf[this._offset++] = 0x81;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffff) {\n    this._buf[this._offset++] = 0x82;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffffff) {\n    this._buf[this._offset++] = 0x83;\n    this._buf[this._offset++] = len >> 16;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else {\n    throw new InvalidAsn1ERror('Length too long (> 4 bytes)');\n  }\n};\n\nWriter.prototype.startSequence = function(tag) {\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Sequence | ASN1.Constructor;\n\n  this.writeByte(tag);\n  this._seq.push(this._offset);\n  this._ensure(3);\n  this._offset += 3;\n};\n\n\nWriter.prototype.endSequence = function() {\n  var seq = this._seq.pop();\n  var start = seq + 3;\n  var len = this._offset - start;\n\n  if (len <= 0x7f) {\n    this._shift(start, len, -2);\n    this._buf[seq] = len;\n  } else if (len <= 0xff) {\n    this._shift(start, len, -1);\n    this._buf[seq] = 0x81;\n    this._buf[seq + 1] = len;\n  } else if (len <= 0xffff) {\n    this._buf[seq] = 0x82;\n    this._buf[seq + 1] = len >> 8;\n    this._buf[seq + 2] = len;\n  } else if (len <= 0xffffff) {\n    this._shift(start, len, 1);\n    this._buf[seq] = 0x83;\n    this._buf[seq + 1] = len >> 16;\n    this._buf[seq + 2] = len >> 8;\n    this._buf[seq + 3] = len;\n  } else {\n    throw new InvalidAsn1Error('Sequence too long');\n  }\n};\n\n\nWriter.prototype._shift = function(start, len, shift) {\n  assert.ok(start !== undefined);\n  assert.ok(len !== undefined);\n  assert.ok(shift);\n\n  this._buf.copy(this._buf, start + shift, start, start + len);\n  this._offset += shift;\n};\n\nWriter.prototype._ensure = function(len) {\n  assert.ok(len);\n\n  if (this._size - this._offset < len) {\n    var sz = this._size * this._options.growthFactor;\n    if (sz - this._offset < len)\n      sz += len;\n\n    var buf = new Buffer(sz);\n\n    this._buf.copy(buf, 0, 0, this._offset);\n    this._buf = buf;\n    this._size = sz;\n  }\n};\n\n\n\n///--- Exported API\n\nmodule.exports = Writer;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/pkcs1.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\treadPkcs1: readPkcs1,\n\twrite: write,\n\twritePkcs1: writePkcs1\n};\n\nvar assert = require('assert-plus');\nvar asn1 = require('asn1');\nvar algs = require('../algs');\nvar utils = require('../utils');\n\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\nvar pem = require('./pem');\n\nvar pkcs8 = require('./pkcs8');\nvar readECDSACurve = pkcs8.readECDSACurve;\n\nfunction read(buf, options) {\n\treturn (pem.read(buf, options, 'pkcs1'));\n}\n\nfunction write(key, options) {\n\treturn (pem.write(key, options, 'pkcs1'));\n}\n\n/* Helper to read in a single mpint */\nfunction readMPInt(der, nm) {\n\tassert.strictEqual(der.peek(), asn1.Ber.Integer,\n\t    nm + ' is not an Integer');\n\treturn (utils.mpNormalize(der.readString(asn1.Ber.Integer, true)));\n}\n\nfunction readPkcs1(alg, type, der) {\n\tswitch (alg) {\n\tcase 'RSA':\n\t\tif (type === 'public')\n\t\t\treturn (readPkcs1RSAPublic(der));\n\t\telse if (type === 'private')\n\t\t\treturn (readPkcs1RSAPrivate(der));\n\t\tthrow (new Error('Unknown key type: ' + type));\n\tcase 'DSA':\n\t\tif (type === 'public')\n\t\t\treturn (readPkcs1DSAPublic(der));\n\t\telse if (type === 'private')\n\t\t\treturn (readPkcs1DSAPrivate(der));\n\t\tthrow (new Error('Unknown key type: ' + type));\n\tcase 'EC':\n\tcase 'ECDSA':\n\t\tif (type === 'private')\n\t\t\treturn (readPkcs1ECDSAPrivate(der));\n\t\telse if (type === 'public')\n\t\t\treturn (readPkcs1ECDSAPublic(der));\n\t\tthrow (new Error('Unknown key type: ' + type));\n\tdefault:\n\t\tthrow (new Error('Unknown key algo: ' + alg));\n\t}\n}\n\nfunction readPkcs1RSAPublic(der) {\n\t// modulus and exponent\n\tvar n = readMPInt(der, 'modulus');\n\tvar e = readMPInt(der, 'exponent');\n\n\t// now, make the key\n\tvar key = {\n\t\ttype: 'rsa',\n\t\tparts: [\n\t\t\t{ name: 'e', data: e },\n\t\t\t{ name: 'n', data: n }\n\t\t]\n\t};\n\n\treturn (new Key(key));\n}\n\nfunction readPkcs1RSAPrivate(der) {\n\tvar version = readMPInt(der, 'version');\n\tassert.strictEqual(version[0], 0);\n\n\t// modulus then public exponent\n\tvar n = readMPInt(der, 'modulus');\n\tvar e = readMPInt(der, 'public exponent');\n\tvar d = readMPInt(der, 'private exponent');\n\tvar p = readMPInt(der, 'prime1');\n\tvar q = readMPInt(der, 'prime2');\n\tvar dmodp = readMPInt(der, 'exponent1');\n\tvar dmodq = readMPInt(der, 'exponent2');\n\tvar iqmp = readMPInt(der, 'iqmp');\n\n\t// now, make the key\n\tvar key = {\n\t\ttype: 'rsa',\n\t\tparts: [\n\t\t\t{ name: 'n', data: n },\n\t\t\t{ name: 'e', data: e },\n\t\t\t{ name: 'd', data: d },\n\t\t\t{ name: 'iqmp', data: iqmp },\n\t\t\t{ name: 'p', data: p },\n\t\t\t{ name: 'q', data: q },\n\t\t\t{ name: 'dmodp', data: dmodp },\n\t\t\t{ name: 'dmodq', data: dmodq }\n\t\t]\n\t};\n\n\treturn (new PrivateKey(key));\n}\n\nfunction readPkcs1DSAPrivate(der) {\n\tvar version = readMPInt(der, 'version');\n\tassert.strictEqual(version.readUInt8(0), 0);\n\n\tvar p = readMPInt(der, 'p');\n\tvar q = readMPInt(der, 'q');\n\tvar g = readMPInt(der, 'g');\n\tvar y = readMPInt(der, 'y');\n\tvar x = readMPInt(der, 'x');\n\n\t// now, make the key\n\tvar key = {\n\t\ttype: 'dsa',\n\t\tparts: [\n\t\t\t{ name: 'p', data: p },\n\t\t\t{ name: 'q', data: q },\n\t\t\t{ name: 'g', data: g },\n\t\t\t{ name: 'y', data: y },\n\t\t\t{ name: 'x', data: x }\n\t\t]\n\t};\n\n\treturn (new PrivateKey(key));\n}\n\nfunction readPkcs1DSAPublic(der) {\n\tvar y = readMPInt(der, 'y');\n\tvar p = readMPInt(der, 'p');\n\tvar q = readMPInt(der, 'q');\n\tvar g = readMPInt(der, 'g');\n\n\tvar key = {\n\t\ttype: 'dsa',\n\t\tparts: [\n\t\t\t{ name: 'y', data: y },\n\t\t\t{ name: 'p', data: p },\n\t\t\t{ name: 'q', data: q },\n\t\t\t{ name: 'g', data: g }\n\t\t]\n\t};\n\n\treturn (new Key(key));\n}\n\nfunction readPkcs1ECDSAPublic(der) {\n\tder.readSequence();\n\n\tvar oid = der.readOID();\n\tassert.strictEqual(oid, '1.2.840.10045.2.1', 'must be ecPublicKey');\n\n\tvar curveOid = der.readOID();\n\n\tvar curve;\n\tvar curves = Object.keys(algs.curves);\n\tfor (var j = 0; j < curves.length; ++j) {\n\t\tvar c = curves[j];\n\t\tvar cd = algs.curves[c];\n\t\tif (cd.pkcs8oid === curveOid) {\n\t\t\tcurve = c;\n\t\t\tbreak;\n\t\t}\n\t}\n\tassert.string(curve, 'a known ECDSA named curve');\n\n\tvar Q = der.readString(asn1.Ber.BitString, true);\n\tQ = utils.ecNormalize(Q);\n\n\tvar key = {\n\t\ttype: 'ecdsa',\n\t\tparts: [\n\t\t\t{ name: 'curve', data: new Buffer(curve) },\n\t\t\t{ name: 'Q', data: Q }\n\t\t]\n\t};\n\n\treturn (new Key(key));\n}\n\nfunction readPkcs1ECDSAPrivate(der) {\n\tvar version = readMPInt(der, 'version');\n\tassert.strictEqual(version.readUInt8(0), 1);\n\n\t// private key\n\tvar d = der.readString(asn1.Ber.OctetString, true);\n\n\tder.readSequence(0xa0);\n\tvar curve = readECDSACurve(der);\n\tassert.string(curve, 'a known elliptic curve');\n\n\tder.readSequence(0xa1);\n\tvar Q = der.readString(asn1.Ber.BitString, true);\n\tQ = utils.ecNormalize(Q);\n\n\tvar key = {\n\t\ttype: 'ecdsa',\n\t\tparts: [\n\t\t\t{ name: 'curve', data: new Buffer(curve) },\n\t\t\t{ name: 'Q', data: Q },\n\t\t\t{ name: 'd', data: d }\n\t\t]\n\t};\n\n\treturn (new PrivateKey(key));\n}\n\nfunction writePkcs1(der, key) {\n\tder.startSequence();\n\n\tswitch (key.type) {\n\tcase 'rsa':\n\t\tif (PrivateKey.isPrivateKey(key))\n\t\t\twritePkcs1RSAPrivate(der, key);\n\t\telse\n\t\t\twritePkcs1RSAPublic(der, key);\n\t\tbreak;\n\tcase 'dsa':\n\t\tif (PrivateKey.isPrivateKey(key))\n\t\t\twritePkcs1DSAPrivate(der, key);\n\t\telse\n\t\t\twritePkcs1DSAPublic(der, key);\n\t\tbreak;\n\tcase 'ecdsa':\n\t\tif (PrivateKey.isPrivateKey(key))\n\t\t\twritePkcs1ECDSAPrivate(der, key);\n\t\telse\n\t\t\twritePkcs1ECDSAPublic(der, key);\n\t\tbreak;\n\tdefault:\n\t\tthrow (new Error('Unknown key algo: ' + key.type));\n\t}\n\n\tder.endSequence();\n}\n\nfunction writePkcs1RSAPublic(der, key) {\n\tder.writeBuffer(key.part.n.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.e.data, asn1.Ber.Integer);\n}\n\nfunction writePkcs1RSAPrivate(der, key) {\n\tvar ver = new Buffer(1);\n\tver[0] = 0;\n\tder.writeBuffer(ver, asn1.Ber.Integer);\n\n\tder.writeBuffer(key.part.n.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.e.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.d.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.p.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.q.data, asn1.Ber.Integer);\n\tif (!key.part.dmodp || !key.part.dmodq)\n\t\tutils.addRSAMissing(key);\n\tder.writeBuffer(key.part.dmodp.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.dmodq.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.iqmp.data, asn1.Ber.Integer);\n}\n\nfunction writePkcs1DSAPrivate(der, key) {\n\tvar ver = new Buffer(1);\n\tver[0] = 0;\n\tder.writeBuffer(ver, asn1.Ber.Integer);\n\n\tder.writeBuffer(key.part.p.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.q.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.g.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.y.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.x.data, asn1.Ber.Integer);\n}\n\nfunction writePkcs1DSAPublic(der, key) {\n\tder.writeBuffer(key.part.y.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.p.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.q.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.g.data, asn1.Ber.Integer);\n}\n\nfunction writePkcs1ECDSAPublic(der, key) {\n\tder.startSequence();\n\n\tder.writeOID('1.2.840.10045.2.1'); /* ecPublicKey */\n\tvar curve = key.part.curve.data.toString();\n\tvar curveOid = algs.curves[curve].pkcs8oid;\n\tassert.string(curveOid, 'a known ECDSA named curve');\n\tder.writeOID(curveOid);\n\n\tder.endSequence();\n\n\tvar Q = utils.ecNormalize(key.part.Q.data, true);\n\tder.writeBuffer(Q, asn1.Ber.BitString);\n}\n\nfunction writePkcs1ECDSAPrivate(der, key) {\n\tvar ver = new Buffer(1);\n\tver[0] = 1;\n\tder.writeBuffer(ver, asn1.Ber.Integer);\n\n\tder.writeBuffer(key.part.d.data, asn1.Ber.OctetString);\n\n\tder.startSequence(0xa0);\n\tvar curve = key.part.curve.data.toString();\n\tvar curveOid = algs.curves[curve].pkcs8oid;\n\tassert.string(curveOid, 'a known ECDSA named curve');\n\tder.writeOID(curveOid);\n\tder.endSequence();\n\n\tder.startSequence(0xa1);\n\tvar Q = utils.ecNormalize(key.part.Q.data, true);\n\tder.writeBuffer(Q, asn1.Ber.BitString);\n\tder.endSequence();\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/pkcs8.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\treadPkcs8: readPkcs8,\n\twrite: write,\n\twritePkcs8: writePkcs8,\n\n\treadECDSACurve: readECDSACurve,\n\twriteECDSACurve: writeECDSACurve\n};\n\nvar assert = require('assert-plus');\nvar asn1 = require('asn1');\nvar algs = require('../algs');\nvar utils = require('../utils');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\nvar pem = require('./pem');\n\nfunction read(buf, options) {\n\treturn (pem.read(buf, options, 'pkcs8'));\n}\n\nfunction write(key, options) {\n\treturn (pem.write(key, options, 'pkcs8'));\n}\n\n/* Helper to read in a single mpint */\nfunction readMPInt(der, nm) {\n\tassert.strictEqual(der.peek(), asn1.Ber.Integer,\n\t    nm + ' is not an Integer');\n\treturn (utils.mpNormalize(der.readString(asn1.Ber.Integer, true)));\n}\n\nfunction readPkcs8(alg, type, der) {\n\t/* Private keys in pkcs#8 format have a weird extra int */\n\tif (der.peek() === asn1.Ber.Integer) {\n\t\tassert.strictEqual(type, 'private',\n\t\t    'unexpected Integer at start of public key');\n\t\tder.readString(asn1.Ber.Integer, true);\n\t}\n\n\tder.readSequence();\n\tvar next = der.offset + der.length;\n\n\tvar oid = der.readOID();\n\tswitch (oid) {\n\tcase '1.2.840.113549.1.1.1':\n\t\tder._offset = next;\n\t\tif (type === 'public')\n\t\t\treturn (readPkcs8RSAPublic(der));\n\t\telse\n\t\t\treturn (readPkcs8RSAPrivate(der));\n\tcase '1.2.840.10040.4.1':\n\t\tif (type === 'public')\n\t\t\treturn (readPkcs8DSAPublic(der));\n\t\telse\n\t\t\treturn (readPkcs8DSAPrivate(der));\n\tcase '1.2.840.10045.2.1':\n\t\tif (type === 'public')\n\t\t\treturn (readPkcs8ECDSAPublic(der));\n\t\telse\n\t\t\treturn (readPkcs8ECDSAPrivate(der));\n\tdefault:\n\t\tthrow (new Error('Unknown key type OID ' + oid));\n\t}\n}\n\nfunction readPkcs8RSAPublic(der) {\n\t// bit string sequence\n\tder.readSequence(asn1.Ber.BitString);\n\tder.readByte();\n\tder.readSequence();\n\n\t// modulus\n\tvar n = readMPInt(der, 'modulus');\n\tvar e = readMPInt(der, 'exponent');\n\n\t// now, make the key\n\tvar key = {\n\t\ttype: 'rsa',\n\t\tsource: der.originalInput,\n\t\tparts: [\n\t\t\t{ name: 'e', data: e },\n\t\t\t{ name: 'n', data: n }\n\t\t]\n\t};\n\n\treturn (new Key(key));\n}\n\nfunction readPkcs8RSAPrivate(der) {\n\tder.readSequence(asn1.Ber.OctetString);\n\tder.readSequence();\n\n\tvar ver = readMPInt(der, 'version');\n\tassert.equal(ver[0], 0x0, 'unknown RSA private key version');\n\n\t// modulus then public exponent\n\tvar n = readMPInt(der, 'modulus');\n\tvar e = readMPInt(der, 'public exponent');\n\tvar d = readMPInt(der, 'private exponent');\n\tvar p = readMPInt(der, 'prime1');\n\tvar q = readMPInt(der, 'prime2');\n\tvar dmodp = readMPInt(der, 'exponent1');\n\tvar dmodq = readMPInt(der, 'exponent2');\n\tvar iqmp = readMPInt(der, 'iqmp');\n\n\t// now, make the key\n\tvar key = {\n\t\ttype: 'rsa',\n\t\tparts: [\n\t\t\t{ name: 'n', data: n },\n\t\t\t{ name: 'e', data: e },\n\t\t\t{ name: 'd', data: d },\n\t\t\t{ name: 'iqmp', data: iqmp },\n\t\t\t{ name: 'p', data: p },\n\t\t\t{ name: 'q', data: q },\n\t\t\t{ name: 'dmodp', data: dmodp },\n\t\t\t{ name: 'dmodq', data: dmodq }\n\t\t]\n\t};\n\n\treturn (new PrivateKey(key));\n}\n\nfunction readPkcs8DSAPublic(der) {\n\tder.readSequence();\n\n\tvar p = readMPInt(der, 'p');\n\tvar q = readMPInt(der, 'q');\n\tvar g = readMPInt(der, 'g');\n\n\t// bit string sequence\n\tder.readSequence(asn1.Ber.BitString);\n\tder.readByte();\n\n\tvar y = readMPInt(der, 'y');\n\n\t// now, make the key\n\tvar key = {\n\t\ttype: 'dsa',\n\t\tparts: [\n\t\t\t{ name: 'p', data: p },\n\t\t\t{ name: 'q', data: q },\n\t\t\t{ name: 'g', data: g },\n\t\t\t{ name: 'y', data: y }\n\t\t]\n\t};\n\n\treturn (new Key(key));\n}\n\nfunction readPkcs8DSAPrivate(der) {\n\tder.readSequence();\n\n\tvar p = readMPInt(der, 'p');\n\tvar q = readMPInt(der, 'q');\n\tvar g = readMPInt(der, 'g');\n\n\tder.readSequence(asn1.Ber.OctetString);\n\tvar x = readMPInt(der, 'x');\n\n\t/* The pkcs#8 format does not include the public key */\n\tvar y = utils.calculateDSAPublic(g, p, x);\n\n\tvar key = {\n\t\ttype: 'dsa',\n\t\tparts: [\n\t\t\t{ name: 'p', data: p },\n\t\t\t{ name: 'q', data: q },\n\t\t\t{ name: 'g', data: g },\n\t\t\t{ name: 'y', data: y },\n\t\t\t{ name: 'x', data: x }\n\t\t]\n\t};\n\n\treturn (new PrivateKey(key));\n}\n\nfunction readECDSACurve(der) {\n\tvar curveName, curveNames;\n\tvar j, c, cd;\n\n\tif (der.peek() === asn1.Ber.OID) {\n\t\tvar oid = der.readOID();\n\n\t\tcurveNames = Object.keys(algs.curves);\n\t\tfor (j = 0; j < curveNames.length; ++j) {\n\t\t\tc = curveNames[j];\n\t\t\tcd = algs.curves[c];\n\t\t\tif (cd.pkcs8oid === oid) {\n\t\t\t\tcurveName = c;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t} else {\n\t\t// ECParameters sequence\n\t\tder.readSequence();\n\t\tvar version = der.readString(asn1.Ber.Integer, true);\n\t\tassert.strictEqual(version[0], 1, 'ECDSA key not version 1');\n\n\t\tvar curve = {};\n\n\t\t// FieldID sequence\n\t\tder.readSequence();\n\t\tvar fieldTypeOid = der.readOID();\n\t\tassert.strictEqual(fieldTypeOid, '1.2.840.10045.1.1',\n\t\t    'ECDSA key is not from a prime-field');\n\t\tvar p = curve.p = utils.mpNormalize(\n\t\t    der.readString(asn1.Ber.Integer, true));\n\t\t/*\n\t\t * p always starts with a 1 bit, so count the zeros to get its\n\t\t * real size.\n\t\t */\n\t\tcurve.size = p.length * 8 - utils.countZeros(p);\n\n\t\t// Curve sequence\n\t\tder.readSequence();\n\t\tcurve.a = utils.mpNormalize(\n\t\t    der.readString(asn1.Ber.OctetString, true));\n\t\tcurve.b = utils.mpNormalize(\n\t\t    der.readString(asn1.Ber.OctetString, true));\n\t\tif (der.peek() === asn1.Ber.BitString)\n\t\t\tcurve.s = der.readString(asn1.Ber.BitString, true);\n\n\t\t// Combined Gx and Gy\n\t\tcurve.G = der.readString(asn1.Ber.OctetString, true);\n\t\tassert.strictEqual(curve.G[0], 0x4,\n\t\t    'uncompressed G is required');\n\n\t\tcurve.n = utils.mpNormalize(\n\t\t    der.readString(asn1.Ber.Integer, true));\n\t\tcurve.h = utils.mpNormalize(\n\t\t    der.readString(asn1.Ber.Integer, true));\n\t\tassert.strictEqual(curve.h[0], 0x1, 'a cofactor=1 curve is ' +\n\t\t    'required');\n\n\t\tcurveNames = Object.keys(algs.curves);\n\t\tvar ks = Object.keys(curve);\n\t\tfor (j = 0; j < curveNames.length; ++j) {\n\t\t\tc = curveNames[j];\n\t\t\tcd = algs.curves[c];\n\t\t\tvar equal = true;\n\t\t\tfor (var i = 0; i < ks.length; ++i) {\n\t\t\t\tvar k = ks[i];\n\t\t\t\tif (cd[k] === undefined)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (typeof (cd[k]) === 'object' &&\n\t\t\t\t    cd[k].equals !== undefined) {\n\t\t\t\t\tif (!cd[k].equals(curve[k])) {\n\t\t\t\t\t\tequal = false;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else if (Buffer.isBuffer(cd[k])) {\n\t\t\t\t\tif (cd[k].toString('binary')\n\t\t\t\t\t    !== curve[k].toString('binary')) {\n\t\t\t\t\t\tequal = false;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (cd[k] !== curve[k]) {\n\t\t\t\t\t\tequal = false;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (equal) {\n\t\t\t\tcurveName = c;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn (curveName);\n}\n\nfunction readPkcs8ECDSAPrivate(der) {\n\tvar curveName = readECDSACurve(der);\n\tassert.string(curveName, 'a known elliptic curve');\n\n\tder.readSequence(asn1.Ber.OctetString);\n\tder.readSequence();\n\n\tvar version = readMPInt(der, 'version');\n\tassert.equal(version[0], 1, 'unknown version of ECDSA key');\n\n\tvar d = der.readString(asn1.Ber.OctetString, true);\n\tder.readSequence(0xa1);\n\n\tvar Q = der.readString(asn1.Ber.BitString, true);\n\tQ = utils.ecNormalize(Q);\n\n\tvar key = {\n\t\ttype: 'ecdsa',\n\t\tparts: [\n\t\t\t{ name: 'curve', data: new Buffer(curveName) },\n\t\t\t{ name: 'Q', data: Q },\n\t\t\t{ name: 'd', data: d }\n\t\t]\n\t};\n\n\treturn (new PrivateKey(key));\n}\n\nfunction readPkcs8ECDSAPublic(der) {\n\tvar curveName = readECDSACurve(der);\n\tassert.string(curveName, 'a known elliptic curve');\n\n\tvar Q = der.readString(asn1.Ber.BitString, true);\n\tQ = utils.ecNormalize(Q);\n\n\tvar key = {\n\t\ttype: 'ecdsa',\n\t\tparts: [\n\t\t\t{ name: 'curve', data: new Buffer(curveName) },\n\t\t\t{ name: 'Q', data: Q }\n\t\t]\n\t};\n\n\treturn (new Key(key));\n}\n\nfunction writePkcs8(der, key) {\n\tder.startSequence();\n\n\tif (PrivateKey.isPrivateKey(key)) {\n\t\tvar sillyInt = new Buffer(1);\n\t\tsillyInt[0] = 0x0;\n\t\tder.writeBuffer(sillyInt, asn1.Ber.Integer);\n\t}\n\n\tder.startSequence();\n\tswitch (key.type) {\n\tcase 'rsa':\n\t\tder.writeOID('1.2.840.113549.1.1.1');\n\t\tif (PrivateKey.isPrivateKey(key))\n\t\t\twritePkcs8RSAPrivate(key, der);\n\t\telse\n\t\t\twritePkcs8RSAPublic(key, der);\n\t\tbreak;\n\tcase 'dsa':\n\t\tder.writeOID('1.2.840.10040.4.1');\n\t\tif (PrivateKey.isPrivateKey(key))\n\t\t\twritePkcs8DSAPrivate(key, der);\n\t\telse\n\t\t\twritePkcs8DSAPublic(key, der);\n\t\tbreak;\n\tcase 'ecdsa':\n\t\tder.writeOID('1.2.840.10045.2.1');\n\t\tif (PrivateKey.isPrivateKey(key))\n\t\t\twritePkcs8ECDSAPrivate(key, der);\n\t\telse\n\t\t\twritePkcs8ECDSAPublic(key, der);\n\t\tbreak;\n\tdefault:\n\t\tthrow (new Error('Unsupported key type: ' + key.type));\n\t}\n\n\tder.endSequence();\n}\n\nfunction writePkcs8RSAPrivate(key, der) {\n\tder.writeNull();\n\tder.endSequence();\n\n\tder.startSequence(asn1.Ber.OctetString);\n\tder.startSequence();\n\n\tvar version = new Buffer(1);\n\tversion[0] = 0;\n\tder.writeBuffer(version, asn1.Ber.Integer);\n\n\tder.writeBuffer(key.part.n.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.e.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.d.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.p.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.q.data, asn1.Ber.Integer);\n\tif (!key.part.dmodp || !key.part.dmodq)\n\t\tutils.addRSAMissing(key);\n\tder.writeBuffer(key.part.dmodp.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.dmodq.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.iqmp.data, asn1.Ber.Integer);\n\n\tder.endSequence();\n\tder.endSequence();\n}\n\nfunction writePkcs8RSAPublic(key, der) {\n\tder.writeNull();\n\tder.endSequence();\n\n\tder.startSequence(asn1.Ber.BitString);\n\tder.writeByte(0x00);\n\n\tder.startSequence();\n\tder.writeBuffer(key.part.n.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.e.data, asn1.Ber.Integer);\n\tder.endSequence();\n\n\tder.endSequence();\n}\n\nfunction writePkcs8DSAPrivate(key, der) {\n\tder.startSequence();\n\tder.writeBuffer(key.part.p.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.q.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.g.data, asn1.Ber.Integer);\n\tder.endSequence();\n\n\tder.endSequence();\n\n\tder.startSequence(asn1.Ber.OctetString);\n\tder.writeBuffer(key.part.x.data, asn1.Ber.Integer);\n\tder.endSequence();\n}\n\nfunction writePkcs8DSAPublic(key, der) {\n\tder.startSequence();\n\tder.writeBuffer(key.part.p.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.q.data, asn1.Ber.Integer);\n\tder.writeBuffer(key.part.g.data, asn1.Ber.Integer);\n\tder.endSequence();\n\tder.endSequence();\n\n\tder.startSequence(asn1.Ber.BitString);\n\tder.writeByte(0x00);\n\tder.writeBuffer(key.part.y.data, asn1.Ber.Integer);\n\tder.endSequence();\n}\n\nfunction writeECDSACurve(key, der) {\n\tvar curve = algs.curves[key.curve];\n\tif (curve.pkcs8oid) {\n\t\t/* This one has a name in pkcs#8, so just write the oid */\n\t\tder.writeOID(curve.pkcs8oid);\n\n\t} else {\n\t\t// ECParameters sequence\n\t\tder.startSequence();\n\n\t\tvar version = new Buffer(1);\n\t\tversion.writeUInt8(1, 0);\n\t\tder.writeBuffer(version, asn1.Ber.Integer);\n\n\t\t// FieldID sequence\n\t\tder.startSequence();\n\t\tder.writeOID('1.2.840.10045.1.1'); // prime-field\n\t\tder.writeBuffer(curve.p, asn1.Ber.Integer);\n\t\tder.endSequence();\n\n\t\t// Curve sequence\n\t\tder.startSequence();\n\t\tvar a = curve.p;\n\t\tif (a[0] === 0x0)\n\t\t\ta = a.slice(1);\n\t\tder.writeBuffer(a, asn1.Ber.OctetString);\n\t\tder.writeBuffer(curve.b, asn1.Ber.OctetString);\n\t\tder.writeBuffer(curve.s, asn1.Ber.BitString);\n\t\tder.endSequence();\n\n\t\tder.writeBuffer(curve.G, asn1.Ber.OctetString);\n\t\tder.writeBuffer(curve.n, asn1.Ber.Integer);\n\t\tvar h = curve.h;\n\t\tif (!h) {\n\t\t\th = new Buffer(1);\n\t\t\th[0] = 1;\n\t\t}\n\t\tder.writeBuffer(h, asn1.Ber.Integer);\n\n\t\t// ECParameters\n\t\tder.endSequence();\n\t}\n}\n\nfunction writePkcs8ECDSAPublic(key, der) {\n\twriteECDSACurve(key, der);\n\tder.endSequence();\n\n\tvar Q = utils.ecNormalize(key.part.Q.data, true);\n\tder.writeBuffer(Q, asn1.Ber.BitString);\n}\n\nfunction writePkcs8ECDSAPrivate(key, der) {\n\twriteECDSACurve(key, der);\n\tder.endSequence();\n\n\tder.startSequence(asn1.Ber.OctetString);\n\tder.startSequence();\n\n\tvar version = new Buffer(1);\n\tversion[0] = 1;\n\tder.writeBuffer(version, asn1.Ber.Integer);\n\n\tder.writeBuffer(key.part.d.data, asn1.Ber.OctetString);\n\n\tder.startSequence(0xa1);\n\tvar Q = utils.ecNormalize(key.part.Q.data, true);\n\tder.writeBuffer(Q, asn1.Ber.BitString);\n\tder.endSequence();\n\n\tder.endSequence();\n\tder.endSequence();\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/ssh-private.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\treadSSHPrivate: readSSHPrivate,\n\twrite: write\n};\n\nvar assert = require('assert-plus');\nvar asn1 = require('asn1');\nvar algs = require('../algs');\nvar utils = require('../utils');\nvar crypto = require('crypto');\n\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\nvar pem = require('./pem');\nvar rfc4253 = require('./rfc4253');\nvar SSHBuffer = require('../ssh-buffer');\nvar errors = require('../errors');\n\nvar bcrypt;\n\nfunction read(buf, options) {\n\treturn (pem.read(buf, options));\n}\n\nvar MAGIC = 'openssh-key-v1';\n\nfunction readSSHPrivate(type, buf, options) {\n\tbuf = new SSHBuffer({buffer: buf});\n\n\tvar magic = buf.readCString();\n\tassert.strictEqual(magic, MAGIC, 'bad magic string');\n\n\tvar cipher = buf.readString();\n\tvar kdf = buf.readString();\n\tvar kdfOpts = buf.readBuffer();\n\n\tvar nkeys = buf.readInt();\n\tif (nkeys !== 1) {\n\t\tthrow (new Error('OpenSSH-format key file contains ' +\n\t\t    'multiple keys: this is unsupported.'));\n\t}\n\n\tvar pubKey = buf.readBuffer();\n\n\tif (type === 'public') {\n\t\tassert.ok(buf.atEnd(), 'excess bytes left after key');\n\t\treturn (rfc4253.read(pubKey));\n\t}\n\n\tvar privKeyBlob = buf.readBuffer();\n\tassert.ok(buf.atEnd(), 'excess bytes left after key');\n\n\tvar kdfOptsBuf = new SSHBuffer({ buffer: kdfOpts });\n\tswitch (kdf) {\n\tcase 'none':\n\t\tif (cipher !== 'none') {\n\t\t\tthrow (new Error('OpenSSH-format key uses KDF \"none\" ' +\n\t\t\t     'but specifies a cipher other than \"none\"'));\n\t\t}\n\t\tbreak;\n\tcase 'bcrypt':\n\t\tvar salt = kdfOptsBuf.readBuffer();\n\t\tvar rounds = kdfOptsBuf.readInt();\n\t\tvar cinf = utils.opensshCipherInfo(cipher);\n\t\tif (bcrypt === undefined) {\n\t\t\tbcrypt = require('bcrypt-pbkdf');\n\t\t}\n\n\t\tif (typeof (options.passphrase) === 'string') {\n\t\t\toptions.passphrase = new Buffer(options.passphrase,\n\t\t\t    'utf-8');\n\t\t}\n\t\tif (!Buffer.isBuffer(options.passphrase)) {\n\t\t\tthrow (new errors.KeyEncryptedError(\n\t\t\t    options.filename, 'OpenSSH'));\n\t\t}\n\n\t\tvar pass = new Uint8Array(options.passphrase);\n\t\tvar salti = new Uint8Array(salt);\n\t\t/* Use the pbkdf to derive both the key and the IV. */\n\t\tvar out = new Uint8Array(cinf.keySize + cinf.blockSize);\n\t\tvar res = bcrypt.pbkdf(pass, pass.length, salti, salti.length,\n\t\t    out, out.length, rounds);\n\t\tif (res !== 0) {\n\t\t\tthrow (new Error('bcrypt_pbkdf function returned ' +\n\t\t\t    'failure, parameters invalid'));\n\t\t}\n\t\tout = new Buffer(out);\n\t\tvar ckey = out.slice(0, cinf.keySize);\n\t\tvar iv = out.slice(cinf.keySize, cinf.keySize + cinf.blockSize);\n\t\tvar cipherStream = crypto.createDecipheriv(cinf.opensslName,\n\t\t    ckey, iv);\n\t\tcipherStream.setAutoPadding(false);\n\t\tvar chunk, chunks = [];\n\t\tcipherStream.once('error', function (e) {\n\t\t\tif (e.toString().indexOf('bad decrypt') !== -1) {\n\t\t\t\tthrow (new Error('Incorrect passphrase ' +\n\t\t\t\t    'supplied, could not decrypt key'));\n\t\t\t}\n\t\t\tthrow (e);\n\t\t});\n\t\tcipherStream.write(privKeyBlob);\n\t\tcipherStream.end();\n\t\twhile ((chunk = cipherStream.read()) !== null)\n\t\t\tchunks.push(chunk);\n\t\tprivKeyBlob = Buffer.concat(chunks);\n\t\tbreak;\n\tdefault:\n\t\tthrow (new Error(\n\t\t    'OpenSSH-format key uses unknown KDF \"' + kdf + '\"'));\n\t}\n\n\tbuf = new SSHBuffer({buffer: privKeyBlob});\n\n\tvar checkInt1 = buf.readInt();\n\tvar checkInt2 = buf.readInt();\n\tif (checkInt1 !== checkInt2) {\n\t\tthrow (new Error('Incorrect passphrase supplied, could not ' +\n\t\t    'decrypt key'));\n\t}\n\n\tvar ret = {};\n\tvar key = rfc4253.readInternal(ret, 'private', buf.remainder());\n\n\tbuf.skip(ret.consumed);\n\n\tvar comment = buf.readString();\n\tkey.comment = comment;\n\n\treturn (key);\n}\n\nfunction write(key, options) {\n\tvar pubKey;\n\tif (PrivateKey.isPrivateKey(key))\n\t\tpubKey = key.toPublic();\n\telse\n\t\tpubKey = key;\n\n\tvar cipher = 'none';\n\tvar kdf = 'none';\n\tvar kdfopts = new Buffer(0);\n\tvar cinf = { blockSize: 8 };\n\tvar passphrase;\n\tif (options !== undefined) {\n\t\tpassphrase = options.passphrase;\n\t\tif (typeof (passphrase) === 'string')\n\t\t\tpassphrase = new Buffer(passphrase, 'utf-8');\n\t\tif (passphrase !== undefined) {\n\t\t\tassert.buffer(passphrase, 'options.passphrase');\n\t\t\tassert.optionalString(options.cipher, 'options.cipher');\n\t\t\tcipher = options.cipher;\n\t\t\tif (cipher === undefined)\n\t\t\t\tcipher = 'aes128-ctr';\n\t\t\tcinf = utils.opensshCipherInfo(cipher);\n\t\t\tkdf = 'bcrypt';\n\t\t}\n\t}\n\n\tvar privBuf;\n\tif (PrivateKey.isPrivateKey(key)) {\n\t\tprivBuf = new SSHBuffer({});\n\t\tvar checkInt = crypto.randomBytes(4).readUInt32BE(0);\n\t\tprivBuf.writeInt(checkInt);\n\t\tprivBuf.writeInt(checkInt);\n\t\tprivBuf.write(key.toBuffer('rfc4253'));\n\t\tprivBuf.writeString(key.comment || '');\n\n\t\tvar n = 1;\n\t\twhile (privBuf._offset % cinf.blockSize !== 0)\n\t\t\tprivBuf.writeChar(n++);\n\t\tprivBuf = privBuf.toBuffer();\n\t}\n\n\tswitch (kdf) {\n\tcase 'none':\n\t\tbreak;\n\tcase 'bcrypt':\n\t\tvar salt = crypto.randomBytes(16);\n\t\tvar rounds = 16;\n\t\tvar kdfssh = new SSHBuffer({});\n\t\tkdfssh.writeBuffer(salt);\n\t\tkdfssh.writeInt(rounds);\n\t\tkdfopts = kdfssh.toBuffer();\n\n\t\tif (bcrypt === undefined) {\n\t\t\tbcrypt = require('bcrypt-pbkdf');\n\t\t}\n\t\tvar pass = new Uint8Array(passphrase);\n\t\tvar salti = new Uint8Array(salt);\n\t\t/* Use the pbkdf to derive both the key and the IV. */\n\t\tvar out = new Uint8Array(cinf.keySize + cinf.blockSize);\n\t\tvar res = bcrypt.pbkdf(pass, pass.length, salti, salti.length,\n\t\t    out, out.length, rounds);\n\t\tif (res !== 0) {\n\t\t\tthrow (new Error('bcrypt_pbkdf function returned ' +\n\t\t\t    'failure, parameters invalid'));\n\t\t}\n\t\tout = new Buffer(out);\n\t\tvar ckey = out.slice(0, cinf.keySize);\n\t\tvar iv = out.slice(cinf.keySize, cinf.keySize + cinf.blockSize);\n\n\t\tvar cipherStream = crypto.createCipheriv(cinf.opensslName,\n\t\t    ckey, iv);\n\t\tcipherStream.setAutoPadding(false);\n\t\tvar chunk, chunks = [];\n\t\tcipherStream.once('error', function (e) {\n\t\t\tthrow (e);\n\t\t});\n\t\tcipherStream.write(privBuf);\n\t\tcipherStream.end();\n\t\twhile ((chunk = cipherStream.read()) !== null)\n\t\t\tchunks.push(chunk);\n\t\tprivBuf = Buffer.concat(chunks);\n\t\tbreak;\n\tdefault:\n\t\tthrow (new Error('Unsupported kdf ' + kdf));\n\t}\n\n\tvar buf = new SSHBuffer({});\n\n\tbuf.writeCString(MAGIC);\n\tbuf.writeString(cipher);\t/* cipher */\n\tbuf.writeString(kdf);\t\t/* kdf */\n\tbuf.writeBuffer(kdfopts);\t/* kdfoptions */\n\n\tbuf.writeInt(1);\t\t/* nkeys */\n\tbuf.writeBuffer(pubKey.toBuffer('rfc4253'));\n\n\tif (privBuf)\n\t\tbuf.writeBuffer(privBuf);\n\n\tbuf = buf.toBuffer();\n\n\tvar header;\n\tif (PrivateKey.isPrivateKey(key))\n\t\theader = 'OPENSSH PRIVATE KEY';\n\telse\n\t\theader = 'OPENSSH PUBLIC KEY';\n\n\tvar tmp = buf.toString('base64');\n\tvar len = tmp.length + (tmp.length / 70) +\n\t    18 + 16 + header.length*2 + 10;\n\tbuf = new Buffer(len);\n\tvar o = 0;\n\to += buf.write('-----BEGIN ' + header + '-----\\n', o);\n\tfor (var i = 0; i < tmp.length; ) {\n\t\tvar limit = i + 70;\n\t\tif (limit > tmp.length)\n\t\t\tlimit = tmp.length;\n\t\to += buf.write(tmp.slice(i, limit), o);\n\t\tbuf[o++] = 10;\n\t\ti = limit;\n\t}\n\to += buf.write('-----END ' + header + '-----\\n', o);\n\n\treturn (buf.slice(0, o));\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/rfc4253.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tread: read.bind(undefined, false, undefined),\n\treadType: read.bind(undefined, false),\n\twrite: write,\n\t/* semi-private api, used by sshpk-agent */\n\treadPartial: read.bind(undefined, true),\n\n\t/* shared with ssh format */\n\treadInternal: read,\n\tkeyTypeToAlg: keyTypeToAlg,\n\talgToKeyType: algToKeyType\n};\n\nvar assert = require('assert-plus');\nvar algs = require('../algs');\nvar utils = require('../utils');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\nvar SSHBuffer = require('../ssh-buffer');\n\nfunction algToKeyType(alg) {\n\tassert.string(alg);\n\tif (alg === 'ssh-dss')\n\t\treturn ('dsa');\n\telse if (alg === 'ssh-rsa')\n\t\treturn ('rsa');\n\telse if (alg === 'ssh-ed25519')\n\t\treturn ('ed25519');\n\telse if (alg === 'ssh-curve25519')\n\t\treturn ('curve25519');\n\telse if (alg.match(/^ecdsa-sha2-/))\n\t\treturn ('ecdsa');\n\telse\n\t\tthrow (new Error('Unknown algorithm ' + alg));\n}\n\nfunction keyTypeToAlg(key) {\n\tassert.object(key);\n\tif (key.type === 'dsa')\n\t\treturn ('ssh-dss');\n\telse if (key.type === 'rsa')\n\t\treturn ('ssh-rsa');\n\telse if (key.type === 'ed25519')\n\t\treturn ('ssh-ed25519');\n\telse if (key.type === 'curve25519')\n\t\treturn ('ssh-curve25519');\n\telse if (key.type === 'ecdsa')\n\t\treturn ('ecdsa-sha2-' + key.part.curve.data.toString());\n\telse\n\t\tthrow (new Error('Unknown key type ' + key.type));\n}\n\nfunction read(partial, type, buf, options) {\n\tif (typeof (buf) === 'string')\n\t\tbuf = new Buffer(buf);\n\tassert.buffer(buf, 'buf');\n\n\tvar key = {};\n\n\tvar parts = key.parts = [];\n\tvar sshbuf = new SSHBuffer({buffer: buf});\n\n\tvar alg = sshbuf.readString();\n\tassert.ok(!sshbuf.atEnd(), 'key must have at least one part');\n\n\tkey.type = algToKeyType(alg);\n\n\tvar partCount = algs.info[key.type].parts.length;\n\tif (type && type === 'private')\n\t\tpartCount = algs.privInfo[key.type].parts.length;\n\n\twhile (!sshbuf.atEnd() && parts.length < partCount)\n\t\tparts.push(sshbuf.readPart());\n\twhile (!partial && !sshbuf.atEnd())\n\t\tparts.push(sshbuf.readPart());\n\n\tassert.ok(parts.length >= 1,\n\t    'key must have at least one part');\n\tassert.ok(partial || sshbuf.atEnd(),\n\t    'leftover bytes at end of key');\n\n\tvar Constructor = Key;\n\tvar algInfo = algs.info[key.type];\n\tif (type === 'private' || algInfo.parts.length !== parts.length) {\n\t\talgInfo = algs.privInfo[key.type];\n\t\tConstructor = PrivateKey;\n\t}\n\tassert.strictEqual(algInfo.parts.length, parts.length);\n\n\tif (key.type === 'ecdsa') {\n\t\tvar res = /^ecdsa-sha2-(.+)$/.exec(alg);\n\t\tassert.ok(res !== null);\n\t\tassert.strictEqual(res[1], parts[0].data.toString());\n\t}\n\n\tvar normalized = true;\n\tfor (var i = 0; i < algInfo.parts.length; ++i) {\n\t\tparts[i].name = algInfo.parts[i];\n\t\tif (parts[i].name !== 'curve' &&\n\t\t    algInfo.normalize !== false) {\n\t\t\tvar p = parts[i];\n\t\t\tvar nd = utils.mpNormalize(p.data);\n\t\t\tif (nd !== p.data) {\n\t\t\t\tp.data = nd;\n\t\t\t\tnormalized = false;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (normalized)\n\t\tkey._rfc4253Cache = sshbuf.toBuffer();\n\n\tif (partial && typeof (partial) === 'object') {\n\t\tpartial.remainder = sshbuf.remainder();\n\t\tpartial.consumed = sshbuf._offset;\n\t}\n\n\treturn (new Constructor(key));\n}\n\nfunction write(key, options) {\n\tassert.object(key);\n\n\tvar alg = keyTypeToAlg(key);\n\tvar i;\n\n\tvar algInfo = algs.info[key.type];\n\tif (PrivateKey.isPrivateKey(key))\n\t\talgInfo = algs.privInfo[key.type];\n\tvar parts = algInfo.parts;\n\n\tvar buf = new SSHBuffer({});\n\n\tbuf.writeString(alg);\n\n\tfor (i = 0; i < parts.length; ++i) {\n\t\tvar data = key.part[parts[i]].data;\n\t\tif (algInfo.normalize !== false)\n\t\t\tdata = utils.mpNormalize(data);\n\t\tbuf.writeBuffer(data);\n\t}\n\n\treturn (buf.toBuffer());\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/ssh-buffer.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = SSHBuffer;\n\nvar assert = require('assert-plus');\n\nfunction SSHBuffer(opts) {\n\tassert.object(opts, 'options');\n\tif (opts.buffer !== undefined)\n\t\tassert.buffer(opts.buffer, 'options.buffer');\n\n\tthis._size = opts.buffer ? opts.buffer.length : 1024;\n\tthis._buffer = opts.buffer || (new Buffer(this._size));\n\tthis._offset = 0;\n}\n\nSSHBuffer.prototype.toBuffer = function () {\n\treturn (this._buffer.slice(0, this._offset));\n};\n\nSSHBuffer.prototype.atEnd = function () {\n\treturn (this._offset >= this._buffer.length);\n};\n\nSSHBuffer.prototype.remainder = function () {\n\treturn (this._buffer.slice(this._offset));\n};\n\nSSHBuffer.prototype.skip = function (n) {\n\tthis._offset += n;\n};\n\nSSHBuffer.prototype.expand = function () {\n\tthis._size *= 2;\n\tvar buf = new Buffer(this._size);\n\tthis._buffer.copy(buf, 0);\n\tthis._buffer = buf;\n};\n\nSSHBuffer.prototype.readPart = function () {\n\treturn ({data: this.readBuffer()});\n};\n\nSSHBuffer.prototype.readBuffer = function () {\n\tvar len = this._buffer.readUInt32BE(this._offset);\n\tthis._offset += 4;\n\tassert.ok(this._offset + len <= this._buffer.length,\n\t    'length out of bounds at +0x' + this._offset.toString(16) +\n\t    ' (data truncated?)');\n\tvar buf = this._buffer.slice(this._offset, this._offset + len);\n\tthis._offset += len;\n\treturn (buf);\n};\n\nSSHBuffer.prototype.readString = function () {\n\treturn (this.readBuffer().toString());\n};\n\nSSHBuffer.prototype.readCString = function () {\n\tvar offset = this._offset;\n\twhile (offset < this._buffer.length &&\n\t    this._buffer[offset] !== 0x00)\n\t\toffset++;\n\tassert.ok(offset < this._buffer.length, 'c string does not terminate');\n\tvar str = this._buffer.slice(this._offset, offset).toString();\n\tthis._offset = offset + 1;\n\treturn (str);\n};\n\nSSHBuffer.prototype.readInt = function () {\n\tvar v = this._buffer.readUInt32BE(this._offset);\n\tthis._offset += 4;\n\treturn (v);\n};\n\nSSHBuffer.prototype.readInt64 = function () {\n\tassert.ok(this._offset + 8 < this._buffer.length,\n\t    'buffer not long enough to read Int64');\n\tvar v = this._buffer.slice(this._offset, this._offset + 8);\n\tthis._offset += 8;\n\treturn (v);\n};\n\nSSHBuffer.prototype.readChar = function () {\n\tvar v = this._buffer[this._offset++];\n\treturn (v);\n};\n\nSSHBuffer.prototype.writeBuffer = function (buf) {\n\twhile (this._offset + 4 + buf.length > this._size)\n\t\tthis.expand();\n\tthis._buffer.writeUInt32BE(buf.length, this._offset);\n\tthis._offset += 4;\n\tbuf.copy(this._buffer, this._offset);\n\tthis._offset += buf.length;\n};\n\nSSHBuffer.prototype.writeString = function (str) {\n\tthis.writeBuffer(new Buffer(str, 'utf8'));\n};\n\nSSHBuffer.prototype.writeCString = function (str) {\n\twhile (this._offset + 1 + str.length > this._size)\n\t\tthis.expand();\n\tthis._buffer.write(str, this._offset);\n\tthis._offset += str.length;\n\tthis._buffer[this._offset++] = 0;\n};\n\nSSHBuffer.prototype.writeInt = function (v) {\n\twhile (this._offset + 4 > this._size)\n\t\tthis.expand();\n\tthis._buffer.writeUInt32BE(v, this._offset);\n\tthis._offset += 4;\n};\n\nSSHBuffer.prototype.writeInt64 = function (v) {\n\tassert.buffer(v, 'value');\n\tif (v.length > 8) {\n\t\tvar lead = v.slice(0, v.length - 8);\n\t\tfor (var i = 0; i < lead.length; ++i) {\n\t\t\tassert.strictEqual(lead[i], 0,\n\t\t\t    'must fit in 64 bits of precision');\n\t\t}\n\t\tv = v.slice(v.length - 8, v.length);\n\t}\n\twhile (this._offset + 8 > this._size)\n\t\tthis.expand();\n\tv.copy(this._buffer, this._offset);\n\tthis._offset += 8;\n};\n\nSSHBuffer.prototype.writeChar = function (v) {\n\twhile (this._offset + 1 > this._size)\n\t\tthis.expand();\n\tthis._buffer[this._offset++] = v;\n};\n\nSSHBuffer.prototype.writePart = function (p) {\n\tthis.writeBuffer(p.data);\n};\n\nSSHBuffer.prototype.write = function (buf) {\n\twhile (this._offset + buf.length > this._size)\n\t\tthis.expand();\n\tbuf.copy(this._buffer, this._offset);\n\tthis._offset += buf.length;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/ssh.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\twrite: write\n};\n\nvar assert = require('assert-plus');\nvar rfc4253 = require('./rfc4253');\nvar utils = require('../utils');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\n\nvar sshpriv = require('./ssh-private');\n\n/*JSSTYLED*/\nvar SSHKEY_RE = /^([a-z0-9-]+)[ \\t]+([a-zA-Z0-9+\\/]+[=]*)([\\n \\t]+([^\\n]+))?$/;\n/*JSSTYLED*/\nvar SSHKEY_RE2 = /^([a-z0-9-]+)[ \\t]+([a-zA-Z0-9+\\/ \\t\\n]+[=]*)(.*)$/;\n\nfunction read(buf, options) {\n\tif (typeof (buf) !== 'string') {\n\t\tassert.buffer(buf, 'buf');\n\t\tbuf = buf.toString('ascii');\n\t}\n\n\tvar trimmed = buf.trim().replace(/[\\\\\\r]/g, '');\n\tvar m = trimmed.match(SSHKEY_RE);\n\tif (!m)\n\t\tm = trimmed.match(SSHKEY_RE2);\n\tassert.ok(m, 'key must match regex');\n\n\tvar type = rfc4253.algToKeyType(m[1]);\n\tvar kbuf = new Buffer(m[2], 'base64');\n\n\t/*\n\t * This is a bit tricky. If we managed to parse the key and locate the\n\t * key comment with the regex, then do a non-partial read and assert\n\t * that we have consumed all bytes. If we couldn't locate the key\n\t * comment, though, there may be whitespace shenanigans going on that\n\t * have conjoined the comment to the rest of the key. We do a partial\n\t * read in this case to try to make the best out of a sorry situation.\n\t */\n\tvar key;\n\tvar ret = {};\n\tif (m[4]) {\n\t\ttry {\n\t\t\tkey = rfc4253.read(kbuf);\n\n\t\t} catch (e) {\n\t\t\tm = trimmed.match(SSHKEY_RE2);\n\t\t\tassert.ok(m, 'key must match regex');\n\t\t\tkbuf = new Buffer(m[2], 'base64');\n\t\t\tkey = rfc4253.readInternal(ret, 'public', kbuf);\n\t\t}\n\t} else {\n\t\tkey = rfc4253.readInternal(ret, 'public', kbuf);\n\t}\n\n\tassert.strictEqual(type, key.type);\n\n\tif (m[4] && m[4].length > 0) {\n\t\tkey.comment = m[4];\n\n\t} else if (ret.consumed) {\n\t\t/*\n\t\t * Now the magic: trying to recover the key comment when it's\n\t\t * gotten conjoined to the key or otherwise shenanigan'd.\n\t\t *\n\t\t * Work out how much base64 we used, then drop all non-base64\n\t\t * chars from the beginning up to this point in the the string.\n\t\t * Then offset in this and try to make up for missing = chars.\n\t\t */\n\t\tvar data = m[2] + m[3];\n\t\tvar realOffset = Math.ceil(ret.consumed / 3) * 4;\n\t\tdata = data.slice(0, realOffset - 2). /*JSSTYLED*/\n\t\t    replace(/[^a-zA-Z0-9+\\/=]/g, '') +\n\t\t    data.slice(realOffset - 2);\n\n\t\tvar padding = ret.consumed % 3;\n\t\tif (padding > 0 &&\n\t\t    data.slice(realOffset - 1, realOffset) !== '=')\n\t\t\trealOffset--;\n\t\twhile (data.slice(realOffset, realOffset + 1) === '=')\n\t\t\trealOffset++;\n\n\t\t/* Finally, grab what we think is the comment & clean it up. */\n\t\tvar trailer = data.slice(realOffset);\n\t\ttrailer = trailer.replace(/[\\r\\n]/g, ' ').\n\t\t    replace(/^\\s+/, '');\n\t\tif (trailer.match(/^[a-zA-Z0-9]/))\n\t\t\tkey.comment = trailer;\n\t}\n\n\treturn (key);\n}\n\nfunction write(key, options) {\n\tassert.object(key);\n\tif (!Key.isKey(key))\n\t\tthrow (new Error('Must be a public key'));\n\n\tvar parts = [];\n\tvar alg = rfc4253.keyTypeToAlg(key);\n\tparts.push(alg);\n\n\tvar buf = rfc4253.write(key);\n\tparts.push(buf.toString('base64'));\n\n\tif (key.comment)\n\t\tparts.push(key.comment);\n\n\treturn (new Buffer(parts.join(' ')));\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/identity.js":"// Copyright 2016 Joyent, Inc.\n\nmodule.exports = Identity;\n\nvar assert = require('assert-plus');\nvar algs = require('./algs');\nvar crypto = require('crypto');\nvar Fingerprint = require('./fingerprint');\nvar Signature = require('./signature');\nvar errs = require('./errors');\nvar util = require('util');\nvar utils = require('./utils');\nvar asn1 = require('asn1');\n\n/*JSSTYLED*/\nvar DNS_NAME_RE = /^([*]|[a-z0-9][a-z0-9\\-]{0,62})(?:\\.([*]|[a-z0-9][a-z0-9\\-]{0,62}))*$/i;\n\nvar oids = {};\noids.cn = '2.5.4.3';\noids.o = '2.5.4.10';\noids.ou = '2.5.4.11';\noids.l = '2.5.4.7';\noids.s = '2.5.4.8';\noids.c = '2.5.4.6';\noids.sn = '2.5.4.4';\noids.dc = '0.9.2342.19200300.100.1.25';\noids.uid = '0.9.2342.19200300.100.1.1';\noids.mail = '0.9.2342.19200300.100.1.3';\n\nvar unoids = {};\nObject.keys(oids).forEach(function (k) {\n\tunoids[oids[k]] = k;\n});\n\nfunction Identity(opts) {\n\tvar self = this;\n\tassert.object(opts, 'options');\n\tassert.arrayOfObject(opts.components, 'options.components');\n\tthis.components = opts.components;\n\tthis.componentLookup = {};\n\tthis.components.forEach(function (c) {\n\t\tif (c.name && !c.oid)\n\t\t\tc.oid = oids[c.name];\n\t\tif (c.oid && !c.name)\n\t\t\tc.name = unoids[c.oid];\n\t\tif (self.componentLookup[c.name] === undefined)\n\t\t\tself.componentLookup[c.name] = [];\n\t\tself.componentLookup[c.name].push(c);\n\t});\n\tif (this.componentLookup.cn && this.componentLookup.cn.length > 0) {\n\t\tthis.cn = this.componentLookup.cn[0].value;\n\t}\n\tassert.optionalString(opts.type, 'options.type');\n\tif (opts.type === undefined) {\n\t\tif (this.components.length === 1 &&\n\t\t    this.componentLookup.cn &&\n\t\t    this.componentLookup.cn.length === 1 &&\n\t\t    this.componentLookup.cn[0].value.match(DNS_NAME_RE)) {\n\t\t\tthis.type = 'host';\n\t\t\tthis.hostname = this.componentLookup.cn[0].value;\n\n\t\t} else if (this.componentLookup.dc &&\n\t\t    this.components.length === this.componentLookup.dc.length) {\n\t\t\tthis.type = 'host';\n\t\t\tthis.hostname = this.componentLookup.dc.map(\n\t\t\t    function (c) {\n\t\t\t\treturn (c.value);\n\t\t\t}).join('.');\n\n\t\t} else if (this.componentLookup.uid &&\n\t\t    this.components.length ===\n\t\t    this.componentLookup.uid.length) {\n\t\t\tthis.type = 'user';\n\t\t\tthis.uid = this.componentLookup.uid[0].value;\n\n\t\t} else if (this.componentLookup.cn &&\n\t\t    this.componentLookup.cn.length === 1 &&\n\t\t    this.componentLookup.cn[0].value.match(DNS_NAME_RE)) {\n\t\t\tthis.type = 'host';\n\t\t\tthis.hostname = this.componentLookup.cn[0].value;\n\n\t\t} else if (this.componentLookup.uid &&\n\t\t    this.componentLookup.uid.length === 1) {\n\t\t\tthis.type = 'user';\n\t\t\tthis.uid = this.componentLookup.uid[0].value;\n\n\t\t} else if (this.componentLookup.mail &&\n\t\t    this.componentLookup.mail.length === 1) {\n\t\t\tthis.type = 'email';\n\t\t\tthis.email = this.componentLookup.mail[0].value;\n\n\t\t} else if (this.componentLookup.cn &&\n\t\t    this.componentLookup.cn.length === 1) {\n\t\t\tthis.type = 'user';\n\t\t\tthis.uid = this.componentLookup.cn[0].value;\n\n\t\t} else {\n\t\t\tthis.type = 'unknown';\n\t\t}\n\t} else {\n\t\tthis.type = opts.type;\n\t\tif (this.type === 'host')\n\t\t\tthis.hostname = opts.hostname;\n\t\telse if (this.type === 'user')\n\t\t\tthis.uid = opts.uid;\n\t\telse if (this.type === 'email')\n\t\t\tthis.email = opts.email;\n\t\telse\n\t\t\tthrow (new Error('Unknown type ' + this.type));\n\t}\n}\n\nIdentity.prototype.toString = function () {\n\treturn (this.components.map(function (c) {\n\t\treturn (c.name.toUpperCase() + '=' + c.value);\n\t}).join(', '));\n};\n\n/*\n * These are from X.680 -- PrintableString allowed chars are in section 37.4\n * table 8. Spec for IA5Strings is \"1,6 + SPACE + DEL\" where 1 refers to\n * ISO IR #001 (standard ASCII control characters) and 6 refers to ISO IR #006\n * (the basic ASCII character set).\n */\n/* JSSTYLED */\nvar NOT_PRINTABLE = /[^a-zA-Z0-9 '(),+.\\/:=?-]/;\n/* JSSTYLED */\nvar NOT_IA5 = /[^\\x00-\\x7f]/;\n\nIdentity.prototype.toAsn1 = function (der, tag) {\n\tder.startSequence(tag);\n\tthis.components.forEach(function (c) {\n\t\tder.startSequence(asn1.Ber.Constructor | asn1.Ber.Set);\n\t\tder.startSequence();\n\t\tder.writeOID(c.oid);\n\t\t/*\n\t\t * If we fit in a PrintableString, use that. Otherwise use an\n\t\t * IA5String or UTF8String.\n\t\t */\n\t\tif (c.value.match(NOT_IA5)) {\n\t\t\tvar v = new Buffer(c.value, 'utf8');\n\t\t\tder.writeBuffer(v, asn1.Ber.Utf8String);\n\t\t} else if (c.value.match(NOT_PRINTABLE)) {\n\t\t\tder.writeString(c.value, asn1.Ber.IA5String);\n\t\t} else {\n\t\t\tder.writeString(c.value, asn1.Ber.PrintableString);\n\t\t}\n\t\tder.endSequence();\n\t\tder.endSequence();\n\t});\n\tder.endSequence();\n};\n\nfunction globMatch(a, b) {\n\tif (a === '**' || b === '**')\n\t\treturn (true);\n\tvar aParts = a.split('.');\n\tvar bParts = b.split('.');\n\tif (aParts.length !== bParts.length)\n\t\treturn (false);\n\tfor (var i = 0; i < aParts.length; ++i) {\n\t\tif (aParts[i] === '*' || bParts[i] === '*')\n\t\t\tcontinue;\n\t\tif (aParts[i] !== bParts[i])\n\t\t\treturn (false);\n\t}\n\treturn (true);\n}\n\nIdentity.prototype.equals = function (other) {\n\tif (!Identity.isIdentity(other, [1, 0]))\n\t\treturn (false);\n\tif (other.components.length !== this.components.length)\n\t\treturn (false);\n\tfor (var i = 0; i < this.components.length; ++i) {\n\t\tif (this.components[i].oid !== other.components[i].oid)\n\t\t\treturn (false);\n\t\tif (!globMatch(this.components[i].value,\n\t\t    other.components[i].value)) {\n\t\t\treturn (false);\n\t\t}\n\t}\n\treturn (true);\n};\n\nIdentity.forHost = function (hostname) {\n\tassert.string(hostname, 'hostname');\n\treturn (new Identity({\n\t\ttype: 'host',\n\t\thostname: hostname,\n\t\tcomponents: [ { name: 'cn', value: hostname } ]\n\t}));\n};\n\nIdentity.forUser = function (uid) {\n\tassert.string(uid, 'uid');\n\treturn (new Identity({\n\t\ttype: 'user',\n\t\tuid: uid,\n\t\tcomponents: [ { name: 'uid', value: uid } ]\n\t}));\n};\n\nIdentity.forEmail = function (email) {\n\tassert.string(email, 'email');\n\treturn (new Identity({\n\t\ttype: 'email',\n\t\temail: email,\n\t\tcomponents: [ { name: 'mail', value: email } ]\n\t}));\n};\n\nIdentity.parseDN = function (dn) {\n\tassert.string(dn, 'dn');\n\tvar parts = dn.split(',');\n\tvar cmps = parts.map(function (c) {\n\t\tc = c.trim();\n\t\tvar eqPos = c.indexOf('=');\n\t\tvar name = c.slice(0, eqPos).toLowerCase();\n\t\tvar value = c.slice(eqPos + 1);\n\t\treturn ({ name: name, value: value });\n\t});\n\treturn (new Identity({ components: cmps }));\n};\n\nIdentity.parseAsn1 = function (der, top) {\n\tvar components = [];\n\tder.readSequence(top);\n\tvar end = der.offset + der.length;\n\twhile (der.offset < end) {\n\t\tder.readSequence(asn1.Ber.Constructor | asn1.Ber.Set);\n\t\tvar after = der.offset + der.length;\n\t\tder.readSequence();\n\t\tvar oid = der.readOID();\n\t\tvar type = der.peek();\n\t\tvar value;\n\t\tswitch (type) {\n\t\tcase asn1.Ber.PrintableString:\n\t\tcase asn1.Ber.IA5String:\n\t\tcase asn1.Ber.OctetString:\n\t\tcase asn1.Ber.T61String:\n\t\t\tvalue = der.readString(type);\n\t\t\tbreak;\n\t\tcase asn1.Ber.Utf8String:\n\t\t\tvalue = der.readString(type, true);\n\t\t\tvalue = value.toString('utf8');\n\t\t\tbreak;\n\t\tcase asn1.Ber.CharacterString:\n\t\tcase asn1.Ber.BMPString:\n\t\t\tvalue = der.readString(type, true);\n\t\t\tvalue = value.toString('utf16le');\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tthrow (new Error('Unknown asn1 type ' + type));\n\t\t}\n\t\tcomponents.push({ oid: oid, value: value });\n\t\tder._offset = after;\n\t}\n\tder._offset = end;\n\treturn (new Identity({\n\t\tcomponents: components\n\t}));\n};\n\nIdentity.isIdentity = function (obj, ver) {\n\treturn (utils.isCompatible(obj, Identity, ver));\n};\n\n/*\n * API versions for Identity:\n * [1,0] -- initial ver\n */\nIdentity.prototype._sshpkApiVersion = [1, 0];\n\nIdentity._oldVersionDetect = function (obj) {\n\treturn ([1, 0]);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/openssh-cert.js":"// Copyright 2016 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\tverify: verify,\n\tsign: sign,\n\twrite: write,\n\n\t/* Internal private API */\n\tfromBuffer: fromBuffer,\n\ttoBuffer: toBuffer\n};\n\nvar assert = require('assert-plus');\nvar SSHBuffer = require('../ssh-buffer');\nvar crypto = require('crypto');\nvar algs = require('../algs');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\nvar Identity = require('../identity');\nvar rfc4253 = require('./rfc4253');\nvar Signature = require('../signature');\nvar utils = require('../utils');\nvar Certificate = require('../certificate');\n\nfunction verify(cert, key) {\n\t/*\n\t * We always give an issuerKey, so if our verify() is being called then\n\t * there was no signature. Return false.\n\t */\n\treturn (false);\n}\n\nvar TYPES = {\n\t'user': 1,\n\t'host': 2\n};\nObject.keys(TYPES).forEach(function (k) { TYPES[TYPES[k]] = k; });\n\nvar ECDSA_ALGO = /^ecdsa-sha2-([^@-]+)-cert-v01@openssh.com$/;\n\nfunction read(buf, options) {\n\tif (Buffer.isBuffer(buf))\n\t\tbuf = buf.toString('ascii');\n\tvar parts = buf.trim().split(/[ \\t\\n]+/g);\n\tif (parts.length < 2 || parts.length > 3)\n\t\tthrow (new Error('Not a valid SSH certificate line'));\n\n\tvar algo = parts[0];\n\tvar data = parts[1];\n\n\tdata = new Buffer(data, 'base64');\n\treturn (fromBuffer(data, algo));\n}\n\nfunction fromBuffer(data, algo, partial) {\n\tvar sshbuf = new SSHBuffer({ buffer: data });\n\tvar innerAlgo = sshbuf.readString();\n\tif (algo !== undefined && innerAlgo !== algo)\n\t\tthrow (new Error('SSH certificate algorithm mismatch'));\n\tif (algo === undefined)\n\t\talgo = innerAlgo;\n\n\tvar cert = {};\n\tcert.signatures = {};\n\tcert.signatures.openssh = {};\n\n\tcert.signatures.openssh.nonce = sshbuf.readBuffer();\n\n\tvar key = {};\n\tvar parts = (key.parts = []);\n\tkey.type = getAlg(algo);\n\n\tvar partCount = algs.info[key.type].parts.length;\n\twhile (parts.length < partCount)\n\t\tparts.push(sshbuf.readPart());\n\tassert.ok(parts.length >= 1, 'key must have at least one part');\n\n\tvar algInfo = algs.info[key.type];\n\tif (key.type === 'ecdsa') {\n\t\tvar res = ECDSA_ALGO.exec(algo);\n\t\tassert.ok(res !== null);\n\t\tassert.strictEqual(res[1], parts[0].data.toString());\n\t}\n\n\tfor (var i = 0; i < algInfo.parts.length; ++i) {\n\t\tparts[i].name = algInfo.parts[i];\n\t\tif (parts[i].name !== 'curve' &&\n\t\t    algInfo.normalize !== false) {\n\t\t\tvar p = parts[i];\n\t\t\tp.data = utils.mpNormalize(p.data);\n\t\t}\n\t}\n\n\tcert.subjectKey = new Key(key);\n\n\tcert.serial = sshbuf.readInt64();\n\n\tvar type = TYPES[sshbuf.readInt()];\n\tassert.string(type, 'valid cert type');\n\n\tcert.signatures.openssh.keyId = sshbuf.readString();\n\n\tvar principals = [];\n\tvar pbuf = sshbuf.readBuffer();\n\tvar psshbuf = new SSHBuffer({ buffer: pbuf });\n\twhile (!psshbuf.atEnd())\n\t\tprincipals.push(psshbuf.readString());\n\tif (principals.length === 0)\n\t\tprincipals = ['*'];\n\n\tcert.subjects = principals.map(function (pr) {\n\t\tif (type === 'user')\n\t\t\treturn (Identity.forUser(pr));\n\t\telse if (type === 'host')\n\t\t\treturn (Identity.forHost(pr));\n\t\tthrow (new Error('Unknown identity type ' + type));\n\t});\n\n\tcert.validFrom = int64ToDate(sshbuf.readInt64());\n\tcert.validUntil = int64ToDate(sshbuf.readInt64());\n\n\tcert.signatures.openssh.critical = sshbuf.readBuffer();\n\tcert.signatures.openssh.exts = sshbuf.readBuffer();\n\n\t/* reserved */\n\tsshbuf.readBuffer();\n\n\tvar signingKeyBuf = sshbuf.readBuffer();\n\tcert.issuerKey = rfc4253.read(signingKeyBuf);\n\n\t/*\n\t * OpenSSH certs don't give the identity of the issuer, just their\n\t * public key. So, we use an Identity that matches anything. The\n\t * isSignedBy() function will later tell you if the key matches.\n\t */\n\tcert.issuer = Identity.forHost('**');\n\n\tvar sigBuf = sshbuf.readBuffer();\n\tcert.signatures.openssh.signature =\n\t    Signature.parse(sigBuf, cert.issuerKey.type, 'ssh');\n\n\tif (partial !== undefined) {\n\t\tpartial.remainder = sshbuf.remainder();\n\t\tpartial.consumed = sshbuf._offset;\n\t}\n\n\treturn (new Certificate(cert));\n}\n\nfunction int64ToDate(buf) {\n\tvar i = buf.readUInt32BE(0) * 4294967296;\n\ti += buf.readUInt32BE(4);\n\tvar d = new Date();\n\td.setTime(i * 1000);\n\td.sourceInt64 = buf;\n\treturn (d);\n}\n\nfunction dateToInt64(date) {\n\tif (date.sourceInt64 !== undefined)\n\t\treturn (date.sourceInt64);\n\tvar i = Math.round(date.getTime() / 1000);\n\tvar upper = Math.floor(i / 4294967296);\n\tvar lower = Math.floor(i % 4294967296);\n\tvar buf = new Buffer(8);\n\tbuf.writeUInt32BE(upper, 0);\n\tbuf.writeUInt32BE(lower, 4);\n\treturn (buf);\n}\n\nfunction sign(cert, key) {\n\tif (cert.signatures.openssh === undefined)\n\t\tcert.signatures.openssh = {};\n\ttry {\n\t\tvar blob = toBuffer(cert, true);\n\t} catch (e) {\n\t\tdelete (cert.signatures.openssh);\n\t\treturn (false);\n\t}\n\tvar sig = cert.signatures.openssh;\n\tvar hashAlgo = undefined;\n\tif (key.type === 'rsa' || key.type === 'dsa')\n\t\thashAlgo = 'sha1';\n\tvar signer = key.createSign(hashAlgo);\n\tsigner.write(blob);\n\tsig.signature = signer.sign();\n\treturn (true);\n}\n\nfunction write(cert, options) {\n\tif (options === undefined)\n\t\toptions = {};\n\n\tvar blob = toBuffer(cert);\n\tvar out = getCertType(cert.subjectKey) + ' ' + blob.toString('base64');\n\tif (options.comment)\n\t\tout = out + ' ' + options.comment;\n\treturn (out);\n}\n\n\nfunction toBuffer(cert, noSig) {\n\tassert.object(cert.signatures.openssh, 'signature for openssh format');\n\tvar sig = cert.signatures.openssh;\n\n\tif (sig.nonce === undefined)\n\t\tsig.nonce = crypto.randomBytes(16);\n\tvar buf = new SSHBuffer({});\n\tbuf.writeString(getCertType(cert.subjectKey));\n\tbuf.writeBuffer(sig.nonce);\n\n\tvar key = cert.subjectKey;\n\tvar algInfo = algs.info[key.type];\n\talgInfo.parts.forEach(function (part) {\n\t\tbuf.writePart(key.part[part]);\n\t});\n\n\tbuf.writeInt64(cert.serial);\n\n\tvar type = cert.subjects[0].type;\n\tassert.notStrictEqual(type, 'unknown');\n\tcert.subjects.forEach(function (id) {\n\t\tassert.strictEqual(id.type, type);\n\t});\n\ttype = TYPES[type];\n\tbuf.writeInt(type);\n\n\tif (sig.keyId === undefined) {\n\t\tsig.keyId = cert.subjects[0].type + '_' +\n\t\t    (cert.subjects[0].uid || cert.subjects[0].hostname);\n\t}\n\tbuf.writeString(sig.keyId);\n\n\tvar sub = new SSHBuffer({});\n\tcert.subjects.forEach(function (id) {\n\t\tif (type === TYPES.host)\n\t\t\tsub.writeString(id.hostname);\n\t\telse if (type === TYPES.user)\n\t\t\tsub.writeString(id.uid);\n\t});\n\tbuf.writeBuffer(sub.toBuffer());\n\n\tbuf.writeInt64(dateToInt64(cert.validFrom));\n\tbuf.writeInt64(dateToInt64(cert.validUntil));\n\n\tif (sig.critical === undefined)\n\t\tsig.critical = new Buffer(0);\n\tbuf.writeBuffer(sig.critical);\n\n\tif (sig.exts === undefined)\n\t\tsig.exts = new Buffer(0);\n\tbuf.writeBuffer(sig.exts);\n\n\t/* reserved */\n\tbuf.writeBuffer(new Buffer(0));\n\n\tsub = rfc4253.write(cert.issuerKey);\n\tbuf.writeBuffer(sub);\n\n\tif (!noSig)\n\t\tbuf.writeBuffer(sig.signature.toBuffer('ssh'));\n\n\treturn (buf.toBuffer());\n}\n\nfunction getAlg(certType) {\n\tif (certType === 'ssh-rsa-cert-v01@openssh.com')\n\t\treturn ('rsa');\n\tif (certType === 'ssh-dss-cert-v01@openssh.com')\n\t\treturn ('dsa');\n\tif (certType.match(ECDSA_ALGO))\n\t\treturn ('ecdsa');\n\tif (certType === 'ssh-ed25519-cert-v01@openssh.com')\n\t\treturn ('ed25519');\n\tthrow (new Error('Unsupported cert type ' + certType));\n}\n\nfunction getCertType(key) {\n\tif (key.type === 'rsa')\n\t\treturn ('ssh-rsa-cert-v01@openssh.com');\n\tif (key.type === 'dsa')\n\t\treturn ('ssh-dss-cert-v01@openssh.com');\n\tif (key.type === 'ecdsa')\n\t\treturn ('ecdsa-sha2-' + key.curve + '-cert-v01@openssh.com');\n\tif (key.type === 'ed25519')\n\t\treturn ('ssh-ed25519-cert-v01@openssh.com');\n\tthrow (new Error('Unsupported key type ' + key.type));\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/x509.js":"// Copyright 2016 Joyent, Inc.\n\nmodule.exports = {\n\tread: read,\n\tverify: verify,\n\tsign: sign,\n\twrite: write\n};\n\nvar assert = require('assert-plus');\nvar asn1 = require('asn1');\nvar algs = require('../algs');\nvar utils = require('../utils');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\nvar pem = require('./pem');\nvar Identity = require('../identity');\nvar Signature = require('../signature');\nvar Certificate = require('../certificate');\nvar pkcs8 = require('./pkcs8');\n\n/*\n * This file is based on RFC5280 (X.509).\n */\n\n/* Helper to read in a single mpint */\nfunction readMPInt(der, nm) {\n\tassert.strictEqual(der.peek(), asn1.Ber.Integer,\n\t    nm + ' is not an Integer');\n\treturn (utils.mpNormalize(der.readString(asn1.Ber.Integer, true)));\n}\n\nfunction verify(cert, key) {\n\tvar sig = cert.signatures.x509;\n\tassert.object(sig, 'x509 signature');\n\n\tvar algParts = sig.algo.split('-');\n\tif (algParts[0] !== key.type)\n\t\treturn (false);\n\n\tvar blob = sig.cache;\n\tif (blob === undefined) {\n\t\tvar der = new asn1.BerWriter();\n\t\twriteTBSCert(cert, der);\n\t\tblob = der.buffer;\n\t}\n\n\tvar verifier = key.createVerify(algParts[1]);\n\tverifier.write(blob);\n\treturn (verifier.verify(sig.signature));\n}\n\nfunction Local(i) {\n\treturn (asn1.Ber.Context | asn1.Ber.Constructor | i);\n}\n\nfunction Context(i) {\n\treturn (asn1.Ber.Context | i);\n}\n\nvar SIGN_ALGS = {\n\t'rsa-md5': '1.2.840.113549.1.1.4',\n\t'rsa-sha1': '1.2.840.113549.1.1.5',\n\t'rsa-sha256': '1.2.840.113549.1.1.11',\n\t'rsa-sha384': '1.2.840.113549.1.1.12',\n\t'rsa-sha512': '1.2.840.113549.1.1.13',\n\t'dsa-sha1': '1.2.840.10040.4.3',\n\t'dsa-sha256': '2.16.840.1.101.3.4.3.2',\n\t'ecdsa-sha1': '1.2.840.10045.4.1',\n\t'ecdsa-sha256': '1.2.840.10045.4.3.2',\n\t'ecdsa-sha384': '1.2.840.10045.4.3.3',\n\t'ecdsa-sha512': '1.2.840.10045.4.3.4'\n};\nObject.keys(SIGN_ALGS).forEach(function (k) {\n\tSIGN_ALGS[SIGN_ALGS[k]] = k;\n});\nSIGN_ALGS['1.3.14.3.2.3'] = 'rsa-md5';\nSIGN_ALGS['1.3.14.3.2.29'] = 'rsa-sha1';\n\nvar EXTS = {\n\t'issuerKeyId': '2.5.29.35',\n\t'altName': '2.5.29.17',\n\t'basicConstraints': '2.5.29.19',\n\t'keyUsage': '2.5.29.15',\n\t'extKeyUsage': '2.5.29.37'\n};\n\nfunction read(buf, options) {\n\tif (typeof (buf) === 'string') {\n\t\tbuf = new Buffer(buf, 'binary');\n\t}\n\tassert.buffer(buf, 'buf');\n\n\tvar der = new asn1.BerReader(buf);\n\n\tder.readSequence();\n\tif (Math.abs(der.length - der.remain) > 1) {\n\t\tthrow (new Error('DER sequence does not contain whole byte ' +\n\t\t    'stream'));\n\t}\n\n\tvar tbsStart = der.offset;\n\tder.readSequence();\n\tvar sigOffset = der.offset + der.length;\n\tvar tbsEnd = sigOffset;\n\n\tif (der.peek() === Local(0)) {\n\t\tder.readSequence(Local(0));\n\t\tvar version = der.readInt();\n\t\tassert.ok(version <= 3,\n\t\t    'only x.509 versions up to v3 supported');\n\t}\n\n\tvar cert = {};\n\tcert.signatures = {};\n\tvar sig = (cert.signatures.x509 = {});\n\tsig.extras = {};\n\n\tcert.serial = readMPInt(der, 'serial');\n\n\tder.readSequence();\n\tvar after = der.offset + der.length;\n\tvar certAlgOid = der.readOID();\n\tvar certAlg = SIGN_ALGS[certAlgOid];\n\tif (certAlg === undefined)\n\t\tthrow (new Error('unknown signature algorithm ' + certAlgOid));\n\n\tder._offset = after;\n\tcert.issuer = Identity.parseAsn1(der);\n\n\tder.readSequence();\n\tcert.validFrom = readDate(der);\n\tcert.validUntil = readDate(der);\n\n\tcert.subjects = [Identity.parseAsn1(der)];\n\n\tder.readSequence();\n\tafter = der.offset + der.length;\n\tcert.subjectKey = pkcs8.readPkcs8(undefined, 'public', der);\n\tder._offset = after;\n\n\t/* issuerUniqueID */\n\tif (der.peek() === Local(1)) {\n\t\tder.readSequence(Local(1));\n\t\tsig.extras.issuerUniqueID =\n\t\t    buf.slice(der.offset, der.offset + der.length);\n\t\tder._offset += der.length;\n\t}\n\n\t/* subjectUniqueID */\n\tif (der.peek() === Local(2)) {\n\t\tder.readSequence(Local(2));\n\t\tsig.extras.subjectUniqueID =\n\t\t    buf.slice(der.offset, der.offset + der.length);\n\t\tder._offset += der.length;\n\t}\n\n\t/* extensions */\n\tif (der.peek() === Local(3)) {\n\t\tder.readSequence(Local(3));\n\t\tvar extEnd = der.offset + der.length;\n\t\tder.readSequence();\n\n\t\twhile (der.offset < extEnd)\n\t\t\treadExtension(cert, buf, der);\n\n\t\tassert.strictEqual(der.offset, extEnd);\n\t}\n\n\tassert.strictEqual(der.offset, sigOffset);\n\n\tder.readSequence();\n\tafter = der.offset + der.length;\n\tvar sigAlgOid = der.readOID();\n\tvar sigAlg = SIGN_ALGS[sigAlgOid];\n\tif (sigAlg === undefined)\n\t\tthrow (new Error('unknown signature algorithm ' + sigAlgOid));\n\tder._offset = after;\n\n\tvar sigData = der.readString(asn1.Ber.BitString, true);\n\tif (sigData[0] === 0)\n\t\tsigData = sigData.slice(1);\n\tvar algParts = sigAlg.split('-');\n\n\tsig.signature = Signature.parse(sigData, algParts[0], 'asn1');\n\tsig.signature.hashAlgorithm = algParts[1];\n\tsig.algo = sigAlg;\n\tsig.cache = buf.slice(tbsStart, tbsEnd);\n\n\treturn (new Certificate(cert));\n}\n\nfunction readDate(der) {\n\tif (der.peek() === asn1.Ber.UTCTime) {\n\t\treturn (utcTimeToDate(der.readString(asn1.Ber.UTCTime)));\n\t} else if (der.peek() === asn1.Ber.GeneralizedTime) {\n\t\treturn (gTimeToDate(der.readString(asn1.Ber.GeneralizedTime)));\n\t} else {\n\t\tthrow (new Error('Unsupported date format'));\n\t}\n}\n\n/* RFC5280, section 4.2.1.6 (GeneralName type) */\nvar ALTNAME = {\n\tOtherName: Local(0),\n\tRFC822Name: Context(1),\n\tDNSName: Context(2),\n\tX400Address: Local(3),\n\tDirectoryName: Local(4),\n\tEDIPartyName: Local(5),\n\tURI: Context(6),\n\tIPAddress: Context(7),\n\tOID: Context(8)\n};\n\n/* RFC5280, section 4.2.1.12 (KeyPurposeId) */\nvar EXTPURPOSE = {\n\t'serverAuth': '1.3.6.1.5.5.7.3.1',\n\t'clientAuth': '1.3.6.1.5.5.7.3.2',\n\t'codeSigning': '1.3.6.1.5.5.7.3.3',\n\n\t/* See https://github.com/joyent/oid-docs/blob/master/root.md */\n\t'joyentDocker': '1.3.6.1.4.1.38678.1.4.1',\n\t'joyentCmon': '1.3.6.1.4.1.38678.1.4.2'\n};\nvar EXTPURPOSE_REV = {};\nObject.keys(EXTPURPOSE).forEach(function (k) {\n\tEXTPURPOSE_REV[EXTPURPOSE[k]] = k;\n});\n\nvar KEYUSEBITS = [\n\t'signature', 'identity', 'keyEncryption',\n\t'encryption', 'keyAgreement', 'ca', 'crl'\n];\n\nfunction readExtension(cert, buf, der) {\n\tder.readSequence();\n\tvar after = der.offset + der.length;\n\tvar extId = der.readOID();\n\tvar id;\n\tvar sig = cert.signatures.x509;\n\tsig.extras.exts = [];\n\n\tvar critical;\n\tif (der.peek() === asn1.Ber.Boolean)\n\t\tcritical = der.readBoolean();\n\n\tswitch (extId) {\n\tcase (EXTS.basicConstraints):\n\t\tder.readSequence(asn1.Ber.OctetString);\n\t\tder.readSequence();\n\t\tvar bcEnd = der.offset + der.length;\n\t\tvar ca = false;\n\t\tif (der.peek() === asn1.Ber.Boolean)\n\t\t\tca = der.readBoolean();\n\t\tif (cert.purposes === undefined)\n\t\t\tcert.purposes = [];\n\t\tif (ca === true)\n\t\t\tcert.purposes.push('ca');\n\t\tvar bc = { oid: extId, critical: critical };\n\t\tif (der.offset < bcEnd && der.peek() === asn1.Ber.Integer)\n\t\t\tbc.pathLen = der.readInt();\n\t\tsig.extras.exts.push(bc);\n\t\tbreak;\n\tcase (EXTS.extKeyUsage):\n\t\tder.readSequence(asn1.Ber.OctetString);\n\t\tder.readSequence();\n\t\tif (cert.purposes === undefined)\n\t\t\tcert.purposes = [];\n\t\tvar ekEnd = der.offset + der.length;\n\t\twhile (der.offset < ekEnd) {\n\t\t\tvar oid = der.readOID();\n\t\t\tcert.purposes.push(EXTPURPOSE_REV[oid] || oid);\n\t\t}\n\t\t/*\n\t\t * This is a bit of a hack: in the case where we have a cert\n\t\t * that's only allowed to do serverAuth or clientAuth (and not\n\t\t * the other), we want to make sure all our Subjects are of\n\t\t * the right type. But we already parsed our Subjects and\n\t\t * decided if they were hosts or users earlier (since it appears\n\t\t * first in the cert).\n\t\t *\n\t\t * So we go through and mutate them into the right kind here if\n\t\t * it doesn't match. This might not be hugely beneficial, as it\n\t\t * seems that single-purpose certs are not often seen in the\n\t\t * wild.\n\t\t */\n\t\tif (cert.purposes.indexOf('serverAuth') !== -1 &&\n\t\t    cert.purposes.indexOf('clientAuth') === -1) {\n\t\t\tcert.subjects.forEach(function (ide) {\n\t\t\t\tif (ide.type !== 'host') {\n\t\t\t\t\tide.type = 'host';\n\t\t\t\t\tide.hostname = ide.uid ||\n\t\t\t\t\t    ide.email ||\n\t\t\t\t\t    ide.components[0].value;\n\t\t\t\t}\n\t\t\t});\n\t\t} else if (cert.purposes.indexOf('clientAuth') !== -1 &&\n\t\t    cert.purposes.indexOf('serverAuth') === -1) {\n\t\t\tcert.subjects.forEach(function (ide) {\n\t\t\t\tif (ide.type !== 'user') {\n\t\t\t\t\tide.type = 'user';\n\t\t\t\t\tide.uid = ide.hostname ||\n\t\t\t\t\t    ide.email ||\n\t\t\t\t\t    ide.components[0].value;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\tsig.extras.exts.push({ oid: extId, critical: critical });\n\t\tbreak;\n\tcase (EXTS.keyUsage):\n\t\tder.readSequence(asn1.Ber.OctetString);\n\t\tvar bits = der.readString(asn1.Ber.BitString, true);\n\t\tvar setBits = readBitField(bits, KEYUSEBITS);\n\t\tsetBits.forEach(function (bit) {\n\t\t\tif (cert.purposes === undefined)\n\t\t\t\tcert.purposes = [];\n\t\t\tif (cert.purposes.indexOf(bit) === -1)\n\t\t\t\tcert.purposes.push(bit);\n\t\t});\n\t\tsig.extras.exts.push({ oid: extId, critical: critical,\n\t\t    bits: bits });\n\t\tbreak;\n\tcase (EXTS.altName):\n\t\tder.readSequence(asn1.Ber.OctetString);\n\t\tder.readSequence();\n\t\tvar aeEnd = der.offset + der.length;\n\t\twhile (der.offset < aeEnd) {\n\t\t\tswitch (der.peek()) {\n\t\t\tcase ALTNAME.OtherName:\n\t\t\tcase ALTNAME.EDIPartyName:\n\t\t\t\tder.readSequence();\n\t\t\t\tder._offset += der.length;\n\t\t\t\tbreak;\n\t\t\tcase ALTNAME.OID:\n\t\t\t\tder.readOID(ALTNAME.OID);\n\t\t\t\tbreak;\n\t\t\tcase ALTNAME.RFC822Name:\n\t\t\t\t/* RFC822 specifies email addresses */\n\t\t\t\tvar email = der.readString(ALTNAME.RFC822Name);\n\t\t\t\tid = Identity.forEmail(email);\n\t\t\t\tif (!cert.subjects[0].equals(id))\n\t\t\t\t\tcert.subjects.push(id);\n\t\t\t\tbreak;\n\t\t\tcase ALTNAME.DirectoryName:\n\t\t\t\tder.readSequence(ALTNAME.DirectoryName);\n\t\t\t\tid = Identity.parseAsn1(der);\n\t\t\t\tif (!cert.subjects[0].equals(id))\n\t\t\t\t\tcert.subjects.push(id);\n\t\t\t\tbreak;\n\t\t\tcase ALTNAME.DNSName:\n\t\t\t\tvar host = der.readString(\n\t\t\t\t    ALTNAME.DNSName);\n\t\t\t\tid = Identity.forHost(host);\n\t\t\t\tif (!cert.subjects[0].equals(id))\n\t\t\t\t\tcert.subjects.push(id);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tder.readString(der.peek());\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tsig.extras.exts.push({ oid: extId, critical: critical });\n\t\tbreak;\n\tdefault:\n\t\tsig.extras.exts.push({\n\t\t\toid: extId,\n\t\t\tcritical: critical,\n\t\t\tdata: der.readString(asn1.Ber.OctetString, true)\n\t\t});\n\t\tbreak;\n\t}\n\n\tder._offset = after;\n}\n\nvar UTCTIME_RE =\n    /^([0-9]{2})([0-9]{2})([0-9]{2})([0-9]{2})([0-9]{2})([0-9]{2})?Z$/;\nfunction utcTimeToDate(t) {\n\tvar m = t.match(UTCTIME_RE);\n\tassert.ok(m, 'timestamps must be in UTC');\n\tvar d = new Date();\n\n\tvar thisYear = d.getUTCFullYear();\n\tvar century = Math.floor(thisYear / 100) * 100;\n\n\tvar year = parseInt(m[1], 10);\n\tif (thisYear % 100 < 50 && year >= 60)\n\t\tyear += (century - 1);\n\telse\n\t\tyear += century;\n\td.setUTCFullYear(year, parseInt(m[2], 10) - 1, parseInt(m[3], 10));\n\td.setUTCHours(parseInt(m[4], 10), parseInt(m[5], 10));\n\tif (m[6] && m[6].length > 0)\n\t\td.setUTCSeconds(parseInt(m[6], 10));\n\treturn (d);\n}\n\nvar GTIME_RE =\n    /^([0-9]{4})([0-9]{2})([0-9]{2})([0-9]{2})([0-9]{2})([0-9]{2})?Z$/;\nfunction gTimeToDate(t) {\n\tvar m = t.match(GTIME_RE);\n\tassert.ok(m);\n\tvar d = new Date();\n\n\td.setUTCFullYear(parseInt(m[1], 10), parseInt(m[2], 10) - 1,\n\t    parseInt(m[3], 10));\n\td.setUTCHours(parseInt(m[4], 10), parseInt(m[5], 10));\n\tif (m[6] && m[6].length > 0)\n\t\td.setUTCSeconds(parseInt(m[6], 10));\n\treturn (d);\n}\n\nfunction zeroPad(n) {\n\tvar s = '' + n;\n\twhile (s.length < 2)\n\t\ts = '0' + s;\n\treturn (s);\n}\n\nfunction dateToUTCTime(d) {\n\tvar s = '';\n\ts += zeroPad(d.getUTCFullYear() % 100);\n\ts += zeroPad(d.getUTCMonth() + 1);\n\ts += zeroPad(d.getUTCDate());\n\ts += zeroPad(d.getUTCHours());\n\ts += zeroPad(d.getUTCMinutes());\n\ts += zeroPad(d.getUTCSeconds());\n\ts += 'Z';\n\treturn (s);\n}\n\nfunction sign(cert, key) {\n\tif (cert.signatures.x509 === undefined)\n\t\tcert.signatures.x509 = {};\n\tvar sig = cert.signatures.x509;\n\n\tsig.algo = key.type + '-' + key.defaultHashAlgorithm();\n\tif (SIGN_ALGS[sig.algo] === undefined)\n\t\treturn (false);\n\n\tvar der = new asn1.BerWriter();\n\twriteTBSCert(cert, der);\n\tvar blob = der.buffer;\n\tsig.cache = blob;\n\n\tvar signer = key.createSign();\n\tsigner.write(blob);\n\tcert.signatures.x509.signature = signer.sign();\n\n\treturn (true);\n}\n\nfunction write(cert, options) {\n\tvar sig = cert.signatures.x509;\n\tassert.object(sig, 'x509 signature');\n\n\tvar der = new asn1.BerWriter();\n\tder.startSequence();\n\tif (sig.cache) {\n\t\tder._ensure(sig.cache.length);\n\t\tsig.cache.copy(der._buf, der._offset);\n\t\tder._offset += sig.cache.length;\n\t} else {\n\t\twriteTBSCert(cert, der);\n\t}\n\n\tder.startSequence();\n\tder.writeOID(SIGN_ALGS[sig.algo]);\n\tif (sig.algo.match(/^rsa-/))\n\t\tder.writeNull();\n\tder.endSequence();\n\n\tvar sigData = sig.signature.toBuffer('asn1');\n\tvar data = new Buffer(sigData.length + 1);\n\tdata[0] = 0;\n\tsigData.copy(data, 1);\n\tder.writeBuffer(data, asn1.Ber.BitString);\n\tder.endSequence();\n\n\treturn (der.buffer);\n}\n\nfunction writeTBSCert(cert, der) {\n\tvar sig = cert.signatures.x509;\n\tassert.object(sig, 'x509 signature');\n\n\tder.startSequence();\n\n\tder.startSequence(Local(0));\n\tder.writeInt(2);\n\tder.endSequence();\n\n\tder.writeBuffer(utils.mpNormalize(cert.serial), asn1.Ber.Integer);\n\n\tder.startSequence();\n\tder.writeOID(SIGN_ALGS[sig.algo]);\n\tder.endSequence();\n\n\tcert.issuer.toAsn1(der);\n\n\tder.startSequence();\n\tder.writeString(dateToUTCTime(cert.validFrom), asn1.Ber.UTCTime);\n\tder.writeString(dateToUTCTime(cert.validUntil), asn1.Ber.UTCTime);\n\tder.endSequence();\n\n\tvar subject = cert.subjects[0];\n\tvar altNames = cert.subjects.slice(1);\n\tsubject.toAsn1(der);\n\n\tpkcs8.writePkcs8(der, cert.subjectKey);\n\n\tif (sig.extras && sig.extras.issuerUniqueID) {\n\t\tder.writeBuffer(sig.extras.issuerUniqueID, Local(1));\n\t}\n\n\tif (sig.extras && sig.extras.subjectUniqueID) {\n\t\tder.writeBuffer(sig.extras.subjectUniqueID, Local(2));\n\t}\n\n\tif (altNames.length > 0 || subject.type === 'host' ||\n\t    (cert.purposes !== undefined && cert.purposes.length > 0) ||\n\t    (sig.extras && sig.extras.exts)) {\n\t\tder.startSequence(Local(3));\n\t\tder.startSequence();\n\n\t\tvar exts = [];\n\t\tif (cert.purposes !== undefined && cert.purposes.length > 0) {\n\t\t\texts.push({\n\t\t\t\toid: EXTS.basicConstraints,\n\t\t\t\tcritical: true\n\t\t\t});\n\t\t\texts.push({\n\t\t\t\toid: EXTS.keyUsage,\n\t\t\t\tcritical: true\n\t\t\t});\n\t\t\texts.push({\n\t\t\t\toid: EXTS.extKeyUsage,\n\t\t\t\tcritical: true\n\t\t\t});\n\t\t}\n\t\texts.push({ oid: EXTS.altName });\n\t\tif (sig.extras && sig.extras.exts)\n\t\t\texts = sig.extras.exts;\n\n\t\tfor (var i = 0; i < exts.length; ++i) {\n\t\t\tder.startSequence();\n\t\t\tder.writeOID(exts[i].oid);\n\n\t\t\tif (exts[i].critical !== undefined)\n\t\t\t\tder.writeBoolean(exts[i].critical);\n\n\t\t\tif (exts[i].oid === EXTS.altName) {\n\t\t\t\tder.startSequence(asn1.Ber.OctetString);\n\t\t\t\tder.startSequence();\n\t\t\t\tif (subject.type === 'host') {\n\t\t\t\t\tder.writeString(subject.hostname,\n\t\t\t\t\t    Context(2));\n\t\t\t\t}\n\t\t\t\tfor (var j = 0; j < altNames.length; ++j) {\n\t\t\t\t\tif (altNames[j].type === 'host') {\n\t\t\t\t\t\tder.writeString(\n\t\t\t\t\t\t    altNames[j].hostname,\n\t\t\t\t\t\t    ALTNAME.DNSName);\n\t\t\t\t\t} else if (altNames[j].type ===\n\t\t\t\t\t    'email') {\n\t\t\t\t\t\tder.writeString(\n\t\t\t\t\t\t    altNames[j].email,\n\t\t\t\t\t\t    ALTNAME.RFC822Name);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Encode anything else as a\n\t\t\t\t\t\t * DN style name for now.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tder.startSequence(\n\t\t\t\t\t\t    ALTNAME.DirectoryName);\n\t\t\t\t\t\taltNames[j].toAsn1(der);\n\t\t\t\t\t\tder.endSequence();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tder.endSequence();\n\t\t\t\tder.endSequence();\n\t\t\t} else if (exts[i].oid === EXTS.basicConstraints) {\n\t\t\t\tder.startSequence(asn1.Ber.OctetString);\n\t\t\t\tder.startSequence();\n\t\t\t\tvar ca = (cert.purposes.indexOf('ca') !== -1);\n\t\t\t\tvar pathLen = exts[i].pathLen;\n\t\t\t\tder.writeBoolean(ca);\n\t\t\t\tif (pathLen !== undefined)\n\t\t\t\t\tder.writeInt(pathLen);\n\t\t\t\tder.endSequence();\n\t\t\t\tder.endSequence();\n\t\t\t} else if (exts[i].oid === EXTS.extKeyUsage) {\n\t\t\t\tder.startSequence(asn1.Ber.OctetString);\n\t\t\t\tder.startSequence();\n\t\t\t\tcert.purposes.forEach(function (purpose) {\n\t\t\t\t\tif (purpose === 'ca')\n\t\t\t\t\t\treturn;\n\t\t\t\t\tif (KEYUSEBITS.indexOf(purpose) !== -1)\n\t\t\t\t\t\treturn;\n\t\t\t\t\tvar oid = purpose;\n\t\t\t\t\tif (EXTPURPOSE[purpose] !== undefined)\n\t\t\t\t\t\toid = EXTPURPOSE[purpose];\n\t\t\t\t\tder.writeOID(oid);\n\t\t\t\t});\n\t\t\t\tder.endSequence();\n\t\t\t\tder.endSequence();\n\t\t\t} else if (exts[i].oid === EXTS.keyUsage) {\n\t\t\t\tder.startSequence(asn1.Ber.OctetString);\n\t\t\t\t/*\n\t\t\t\t * If we parsed this certificate from a byte\n\t\t\t\t * stream (i.e. we didn't generate it in sshpk)\n\t\t\t\t * then we'll have a \".bits\" property on the\n\t\t\t\t * ext with the original raw byte contents.\n\t\t\t\t *\n\t\t\t\t * If we have this, use it here instead of\n\t\t\t\t * regenerating it. This guarantees we output\n\t\t\t\t * the same data we parsed, so signatures still\n\t\t\t\t * validate.\n\t\t\t\t */\n\t\t\t\tif (exts[i].bits !== undefined) {\n\t\t\t\t\tder.writeBuffer(exts[i].bits,\n\t\t\t\t\t    asn1.Ber.BitString);\n\t\t\t\t} else {\n\t\t\t\t\tvar bits = writeBitField(cert.purposes,\n\t\t\t\t\t    KEYUSEBITS);\n\t\t\t\t\tder.writeBuffer(bits,\n\t\t\t\t\t    asn1.Ber.BitString);\n\t\t\t\t}\n\t\t\t\tder.endSequence();\n\t\t\t} else {\n\t\t\t\tder.writeBuffer(exts[i].data,\n\t\t\t\t    asn1.Ber.OctetString);\n\t\t\t}\n\n\t\t\tder.endSequence();\n\t\t}\n\n\t\tder.endSequence();\n\t\tder.endSequence();\n\t}\n\n\tder.endSequence();\n}\n\n/*\n * Reads an ASN.1 BER bitfield out of the Buffer produced by doing\n * `BerReader#readString(asn1.Ber.BitString)`. That function gives us the raw\n * contents of the BitString tag, which is a count of unused bits followed by\n * the bits as a right-padded byte string.\n *\n * `bits` is the Buffer, `bitIndex` should contain an array of string names\n * for the bits in the string, ordered starting with bit #0 in the ASN.1 spec.\n *\n * Returns an array of Strings, the names of the bits that were set to 1.\n */\nfunction readBitField(bits, bitIndex) {\n\tvar bitLen = 8 * (bits.length - 1) - bits[0];\n\tvar setBits = {};\n\tfor (var i = 0; i < bitLen; ++i) {\n\t\tvar byteN = 1 + Math.floor(i / 8);\n\t\tvar bit = 7 - (i % 8);\n\t\tvar mask = 1 << bit;\n\t\tvar bitVal = ((bits[byteN] & mask) !== 0);\n\t\tvar name = bitIndex[i];\n\t\tif (bitVal && typeof (name) === 'string') {\n\t\t\tsetBits[name] = true;\n\t\t}\n\t}\n\treturn (Object.keys(setBits));\n}\n\n/*\n * `setBits` is an array of strings, containing the names for each bit that\n * sould be set to 1. `bitIndex` is same as in `readBitField()`.\n *\n * Returns a Buffer, ready to be written out with `BerWriter#writeString()`.\n */\nfunction writeBitField(setBits, bitIndex) {\n\tvar bitLen = bitIndex.length;\n\tvar blen = Math.ceil(bitLen / 8);\n\tvar unused = blen * 8 - bitLen;\n\tvar bits = new Buffer(1 + blen);\n\tbits.fill(0);\n\tbits[0] = unused;\n\tfor (var i = 0; i < bitLen; ++i) {\n\t\tvar byteN = 1 + Math.floor(i / 8);\n\t\tvar bit = 7 - (i % 8);\n\t\tvar mask = 1 << bit;\n\t\tvar name = bitIndex[i];\n\t\tif (name === undefined)\n\t\t\tcontinue;\n\t\tvar bitVal = (setBits.indexOf(name) !== -1);\n\t\tif (bitVal) {\n\t\t\tbits[byteN] |= mask;\n\t\t}\n\t}\n\treturn (bits);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/x509-pem.js":"// Copyright 2016 Joyent, Inc.\n\nvar x509 = require('./x509');\n\nmodule.exports = {\n\tread: read,\n\tverify: x509.verify,\n\tsign: x509.sign,\n\twrite: write\n};\n\nvar assert = require('assert-plus');\nvar asn1 = require('asn1');\nvar algs = require('../algs');\nvar utils = require('../utils');\nvar Key = require('../key');\nvar PrivateKey = require('../private-key');\nvar pem = require('./pem');\nvar Identity = require('../identity');\nvar Signature = require('../signature');\nvar Certificate = require('../certificate');\n\nfunction read(buf, options) {\n\tif (typeof (buf) !== 'string') {\n\t\tassert.buffer(buf, 'buf');\n\t\tbuf = buf.toString('ascii');\n\t}\n\n\tvar lines = buf.trim().split(/[\\r\\n]+/g);\n\n\tvar m = lines[0].match(/*JSSTYLED*/\n\t    /[-]+[ ]*BEGIN CERTIFICATE[ ]*[-]+/);\n\tassert.ok(m, 'invalid PEM header');\n\n\tvar m2 = lines[lines.length - 1].match(/*JSSTYLED*/\n\t    /[-]+[ ]*END CERTIFICATE[ ]*[-]+/);\n\tassert.ok(m2, 'invalid PEM footer');\n\n\tvar headers = {};\n\twhile (true) {\n\t\tlines = lines.slice(1);\n\t\tm = lines[0].match(/*JSSTYLED*/\n\t\t    /^([A-Za-z0-9-]+): (.+)$/);\n\t\tif (!m)\n\t\t\tbreak;\n\t\theaders[m[1].toLowerCase()] = m[2];\n\t}\n\n\t/* Chop off the first and last lines */\n\tlines = lines.slice(0, -1).join('');\n\tbuf = new Buffer(lines, 'base64');\n\n\treturn (x509.read(buf, options));\n}\n\nfunction write(cert, options) {\n\tvar dbuf = x509.write(cert, options);\n\n\tvar header = 'CERTIFICATE';\n\tvar tmp = dbuf.toString('base64');\n\tvar len = tmp.length + (tmp.length / 64) +\n\t    18 + 16 + header.length*2 + 10;\n\tvar buf = new Buffer(len);\n\tvar o = 0;\n\to += buf.write('-----BEGIN ' + header + '-----\\n', o);\n\tfor (var i = 0; i < tmp.length; ) {\n\t\tvar limit = i + 64;\n\t\tif (limit > tmp.length)\n\t\t\tlimit = tmp.length;\n\t\to += buf.write(tmp.slice(i, limit), o);\n\t\tbuf[o++] = 10;\n\t\ti = limit;\n\t}\n\to += buf.write('-----END ' + header + '-----\\n', o);\n\n\treturn (buf.slice(0, o));\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/dhe.js":"// Copyright 2015 Joyent, Inc.\n\nmodule.exports = DiffieHellman;\n\nvar assert = require('assert-plus');\nvar crypto = require('crypto');\nvar algs = require('./algs');\nvar utils = require('./utils');\nvar ed;\n\nvar Key = require('./key');\nvar PrivateKey = require('./private-key');\n\nvar CRYPTO_HAVE_ECDH = (crypto.createECDH !== undefined);\n\nvar ecdh, ec, jsbn;\n\nfunction DiffieHellman(key) {\n\tutils.assertCompatible(key, Key, [1, 4], 'key');\n\tthis._isPriv = PrivateKey.isPrivateKey(key, [1, 3]);\n\tthis._algo = key.type;\n\tthis._curve = key.curve;\n\tthis._key = key;\n\tif (key.type === 'dsa') {\n\t\tif (!CRYPTO_HAVE_ECDH) {\n\t\t\tthrow (new Error('Due to bugs in the node 0.10 ' +\n\t\t\t    'crypto API, node 0.12.x or later is required ' +\n\t\t\t    'to use DH'));\n\t\t}\n\t\tthis._dh = crypto.createDiffieHellman(\n\t\t    key.part.p.data, undefined,\n\t\t    key.part.g.data, undefined);\n\t\tthis._p = key.part.p;\n\t\tthis._g = key.part.g;\n\t\tif (this._isPriv)\n\t\t\tthis._dh.setPrivateKey(key.part.x.data);\n\t\tthis._dh.setPublicKey(key.part.y.data);\n\n\t} else if (key.type === 'ecdsa') {\n\t\tif (!CRYPTO_HAVE_ECDH) {\n\t\t\tif (ecdh === undefined)\n\t\t\t\tecdh = require('ecc-jsbn');\n\t\t\tif (ec === undefined)\n\t\t\t\tec = require('ecc-jsbn/lib/ec');\n\t\t\tif (jsbn === undefined)\n\t\t\t\tjsbn = require('jsbn').BigInteger;\n\n\t\t\tthis._ecParams = new X9ECParameters(this._curve);\n\n\t\t\tif (this._isPriv) {\n\t\t\t\tthis._priv = new ECPrivate(\n\t\t\t\t    this._ecParams, key.part.d.data);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\tvar curve = {\n\t\t\t'nistp256': 'prime256v1',\n\t\t\t'nistp384': 'secp384r1',\n\t\t\t'nistp521': 'secp521r1'\n\t\t}[key.curve];\n\t\tthis._dh = crypto.createECDH(curve);\n\t\tif (typeof (this._dh) !== 'object' ||\n\t\t    typeof (this._dh.setPrivateKey) !== 'function') {\n\t\t\tCRYPTO_HAVE_ECDH = false;\n\t\t\tDiffieHellman.call(this, key);\n\t\t\treturn;\n\t\t}\n\t\tif (this._isPriv)\n\t\t\tthis._dh.setPrivateKey(key.part.d.data);\n\t\tthis._dh.setPublicKey(key.part.Q.data);\n\n\t} else if (key.type === 'curve25519') {\n\t\tif (ed === undefined)\n\t\t\ted = require('jodid25519');\n\n\t\tif (this._isPriv) {\n\t\t\tthis._priv = key.part.r.data;\n\t\t\tif (this._priv[0] === 0x00)\n\t\t\t\tthis._priv = this._priv.slice(1);\n\t\t\tthis._priv = this._priv.slice(0, 32);\n\t\t}\n\n\t} else {\n\t\tthrow (new Error('DH not supported for ' + key.type + ' keys'));\n\t}\n}\n\nDiffieHellman.prototype.getPublicKey = function () {\n\tif (this._isPriv)\n\t\treturn (this._key.toPublic());\n\treturn (this._key);\n};\n\nDiffieHellman.prototype.getPrivateKey = function () {\n\tif (this._isPriv)\n\t\treturn (this._key);\n\telse\n\t\treturn (undefined);\n};\nDiffieHellman.prototype.getKey = DiffieHellman.prototype.getPrivateKey;\n\nDiffieHellman.prototype._keyCheck = function (pk, isPub) {\n\tassert.object(pk, 'key');\n\tif (!isPub)\n\t\tutils.assertCompatible(pk, PrivateKey, [1, 3], 'key');\n\tutils.assertCompatible(pk, Key, [1, 4], 'key');\n\n\tif (pk.type !== this._algo) {\n\t\tthrow (new Error('A ' + pk.type + ' key cannot be used in ' +\n\t\t    this._algo + ' Diffie-Hellman'));\n\t}\n\n\tif (pk.curve !== this._curve) {\n\t\tthrow (new Error('A key from the ' + pk.curve + ' curve ' +\n\t\t    'cannot be used with a ' + this._curve +\n\t\t    ' Diffie-Hellman'));\n\t}\n\n\tif (pk.type === 'dsa') {\n\t\tassert.deepEqual(pk.part.p, this._p,\n\t\t    'DSA key prime does not match');\n\t\tassert.deepEqual(pk.part.g, this._g,\n\t\t    'DSA key generator does not match');\n\t}\n};\n\nDiffieHellman.prototype.setKey = function (pk) {\n\tthis._keyCheck(pk);\n\n\tif (pk.type === 'dsa') {\n\t\tthis._dh.setPrivateKey(pk.part.x.data);\n\t\tthis._dh.setPublicKey(pk.part.y.data);\n\n\t} else if (pk.type === 'ecdsa') {\n\t\tif (CRYPTO_HAVE_ECDH) {\n\t\t\tthis._dh.setPrivateKey(pk.part.d.data);\n\t\t\tthis._dh.setPublicKey(pk.part.Q.data);\n\t\t} else {\n\t\t\tthis._priv = new ECPrivate(\n\t\t\t    this._ecParams, pk.part.d.data);\n\t\t}\n\n\t} else if (pk.type === 'curve25519') {\n\t\tthis._priv = pk.part.r.data;\n\t\tif (this._priv[0] === 0x00)\n\t\t\tthis._priv = this._priv.slice(1);\n\t\tthis._priv = this._priv.slice(0, 32);\n\t}\n\tthis._key = pk;\n\tthis._isPriv = true;\n};\nDiffieHellman.prototype.setPrivateKey = DiffieHellman.prototype.setKey;\n\nDiffieHellman.prototype.computeSecret = function (otherpk) {\n\tthis._keyCheck(otherpk, true);\n\tif (!this._isPriv)\n\t\tthrow (new Error('DH exchange has not been initialized with ' +\n\t\t    'a private key yet'));\n\n\tvar pub;\n\tif (this._algo === 'dsa') {\n\t\treturn (this._dh.computeSecret(\n\t\t    otherpk.part.y.data));\n\n\t} else if (this._algo === 'ecdsa') {\n\t\tif (CRYPTO_HAVE_ECDH) {\n\t\t\treturn (this._dh.computeSecret(\n\t\t\t    otherpk.part.Q.data));\n\t\t} else {\n\t\t\tpub = new ECPublic(\n\t\t\t    this._ecParams, otherpk.part.Q.data);\n\t\t\treturn (this._priv.deriveSharedSecret(pub));\n\t\t}\n\n\t} else if (this._algo === 'curve25519') {\n\t\tpub = otherpk.part.R.data;\n\t\tif (pub[0] === 0x00)\n\t\t\tpub = pub.slice(1);\n\n\t\tvar secret = ed.dh.computeKey(\n\t\t    this._priv.toString('binary'),\n\t\t    pub.toString('binary'));\n\n\t\treturn (new Buffer(secret, 'binary'));\n\t}\n\n\tthrow (new Error('Invalid algorithm: ' + this._algo));\n};\n\nDiffieHellman.prototype.generateKey = function () {\n\tvar parts = [];\n\tvar priv, pub;\n\tif (this._algo === 'dsa') {\n\t\tthis._dh.generateKeys();\n\n\t\tparts.push({name: 'p', data: this._p.data});\n\t\tparts.push({name: 'q', data: this._key.part.q.data});\n\t\tparts.push({name: 'g', data: this._g.data});\n\t\tparts.push({name: 'y', data: this._dh.getPublicKey()});\n\t\tparts.push({name: 'x', data: this._dh.getPrivateKey()});\n\t\tthis._key = new PrivateKey({\n\t\t\ttype: 'dsa',\n\t\t\tparts: parts\n\t\t});\n\t\tthis._isPriv = true;\n\t\treturn (this._key);\n\n\t} else if (this._algo === 'ecdsa') {\n\t\tif (CRYPTO_HAVE_ECDH) {\n\t\t\tthis._dh.generateKeys();\n\n\t\t\tparts.push({name: 'curve',\n\t\t\t    data: new Buffer(this._curve)});\n\t\t\tparts.push({name: 'Q', data: this._dh.getPublicKey()});\n\t\t\tparts.push({name: 'd', data: this._dh.getPrivateKey()});\n\t\t\tthis._key = new PrivateKey({\n\t\t\t\ttype: 'ecdsa',\n\t\t\t\tcurve: this._curve,\n\t\t\t\tparts: parts\n\t\t\t});\n\t\t\tthis._isPriv = true;\n\t\t\treturn (this._key);\n\n\t\t} else {\n\t\t\tvar n = this._ecParams.getN();\n\t\t\tvar r = new jsbn(crypto.randomBytes(n.bitLength()));\n\t\t\tvar n1 = n.subtract(jsbn.ONE);\n\t\t\tpriv = r.mod(n1).add(jsbn.ONE);\n\t\t\tpub = this._ecParams.getG().multiply(priv);\n\n\t\t\tpriv = new Buffer(priv.toByteArray());\n\t\t\tpub = new Buffer(this._ecParams.getCurve().\n\t\t\t    encodePointHex(pub), 'hex');\n\n\t\t\tthis._priv = new ECPrivate(this._ecParams, priv);\n\n\t\t\tparts.push({name: 'curve',\n\t\t\t    data: new Buffer(this._curve)});\n\t\t\tparts.push({name: 'Q', data: pub});\n\t\t\tparts.push({name: 'd', data: priv});\n\n\t\t\tthis._key = new PrivateKey({\n\t\t\t\ttype: 'ecdsa',\n\t\t\t\tcurve: this._curve,\n\t\t\t\tparts: parts\n\t\t\t});\n\t\t\tthis._isPriv = true;\n\t\t\treturn (this._key);\n\t\t}\n\n\t} else if (this._algo === 'curve25519') {\n\t\tpriv = ed.dh.generateKey();\n\t\tpub = ed.dh.publicKey(priv);\n\t\tthis._priv = priv = new Buffer(priv, 'binary');\n\t\tpub = new Buffer(pub, 'binary');\n\n\t\tparts.push({name: 'R', data: pub});\n\t\tparts.push({name: 'r', data: Buffer.concat([priv, pub])});\n\t\tthis._key = new PrivateKey({\n\t\t\ttype: 'curve25519',\n\t\t\tparts: parts\n\t\t});\n\t\tthis._isPriv = true;\n\t\treturn (this._key);\n\t}\n\n\tthrow (new Error('Invalid algorithm: ' + this._algo));\n};\nDiffieHellman.prototype.generateKeys = DiffieHellman.prototype.generateKey;\n\n/* These are helpers for using ecc-jsbn (for node 0.10 compatibility). */\n\nfunction X9ECParameters(name) {\n\tvar params = algs.curves[name];\n\tassert.object(params);\n\n\tvar p = new jsbn(params.p);\n\tvar a = new jsbn(params.a);\n\tvar b = new jsbn(params.b);\n\tvar n = new jsbn(params.n);\n\tvar h = jsbn.ONE;\n\tvar curve = new ec.ECCurveFp(p, a, b);\n\tvar G = curve.decodePointHex(params.G.toString('hex'));\n\n\tthis.curve = curve;\n\tthis.g = G;\n\tthis.n = n;\n\tthis.h = h;\n}\nX9ECParameters.prototype.getCurve = function () { return (this.curve); };\nX9ECParameters.prototype.getG = function () { return (this.g); };\nX9ECParameters.prototype.getN = function () { return (this.n); };\nX9ECParameters.prototype.getH = function () { return (this.h); };\n\nfunction ECPublic(params, buffer) {\n\tthis._params = params;\n\tif (buffer[0] === 0x00)\n\t\tbuffer = buffer.slice(1);\n\tthis._pub = params.getCurve().decodePointHex(buffer.toString('hex'));\n}\n\nfunction ECPrivate(params, buffer) {\n\tthis._params = params;\n\tthis._priv = new jsbn(utils.mpNormalize(buffer));\n}\nECPrivate.prototype.deriveSharedSecret = function (pubKey) {\n\tassert.ok(pubKey instanceof ECPublic);\n\tvar S = pubKey._pub.multiply(this._priv);\n\treturn (new Buffer(S.getX().toBigInteger().toByteArray()));\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/lib/signer.js":"// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar crypto = require('crypto');\nvar http = require('http');\nvar util = require('util');\nvar sshpk = require('sshpk');\nvar jsprim = require('jsprim');\nvar utils = require('./utils');\n\nvar sprintf = require('util').format;\n\nvar HASH_ALGOS = utils.HASH_ALGOS;\nvar PK_ALGOS = utils.PK_ALGOS;\nvar InvalidAlgorithmError = utils.InvalidAlgorithmError;\nvar HttpSignatureError = utils.HttpSignatureError;\nvar validateAlgorithm = utils.validateAlgorithm;\n\n///--- Globals\n\nvar AUTHZ_FMT =\n  'Signature keyId=\"%s\",algorithm=\"%s\",headers=\"%s\",signature=\"%s\"';\n\n///--- Specific Errors\n\nfunction MissingHeaderError(message) {\n  HttpSignatureError.call(this, message, MissingHeaderError);\n}\nutil.inherits(MissingHeaderError, HttpSignatureError);\n\nfunction StrictParsingError(message) {\n  HttpSignatureError.call(this, message, StrictParsingError);\n}\nutil.inherits(StrictParsingError, HttpSignatureError);\n\n/* See createSigner() */\nfunction RequestSigner(options) {\n  assert.object(options, 'options');\n\n  var alg = [];\n  if (options.algorithm !== undefined) {\n    assert.string(options.algorithm, 'options.algorithm');\n    alg = validateAlgorithm(options.algorithm);\n  }\n  this.rs_alg = alg;\n\n  /*\n   * RequestSigners come in two varieties: ones with an rs_signFunc, and ones\n   * with an rs_signer.\n   *\n   * rs_signFunc-based RequestSigners have to build up their entire signing\n   * string within the rs_lines array and give it to rs_signFunc as a single\n   * concat'd blob. rs_signer-based RequestSigners can add a line at a time to\n   * their signing state by using rs_signer.update(), thus only needing to\n   * buffer the hash function state and one line at a time.\n   */\n  if (options.sign !== undefined) {\n    assert.func(options.sign, 'options.sign');\n    this.rs_signFunc = options.sign;\n\n  } else if (alg[0] === 'hmac' && options.key !== undefined) {\n    assert.string(options.keyId, 'options.keyId');\n    this.rs_keyId = options.keyId;\n\n    if (typeof (options.key) !== 'string' && !Buffer.isBuffer(options.key))\n      throw (new TypeError('options.key for HMAC must be a string or Buffer'));\n\n    /*\n     * Make an rs_signer for HMACs, not a rs_signFunc -- HMACs digest their\n     * data in chunks rather than requiring it all to be given in one go\n     * at the end, so they are more similar to signers than signFuncs.\n     */\n    this.rs_signer = crypto.createHmac(alg[1].toUpperCase(), options.key);\n    this.rs_signer.sign = function () {\n      var digest = this.digest('base64');\n      return ({\n        hashAlgorithm: alg[1],\n        toString: function () { return (digest); }\n      });\n    };\n\n  } else if (options.key !== undefined) {\n    var key = options.key;\n    if (typeof (key) === 'string' || Buffer.isBuffer(key))\n      key = sshpk.parsePrivateKey(key);\n\n    assert.ok(sshpk.PrivateKey.isPrivateKey(key, [1, 2]),\n      'options.key must be a sshpk.PrivateKey');\n    this.rs_key = key;\n\n    assert.string(options.keyId, 'options.keyId');\n    this.rs_keyId = options.keyId;\n\n    if (!PK_ALGOS[key.type]) {\n      throw (new InvalidAlgorithmError(key.type.toUpperCase() + ' type ' +\n        'keys are not supported'));\n    }\n\n    if (alg[0] !== undefined && key.type !== alg[0]) {\n      throw (new InvalidAlgorithmError('options.key must be a ' +\n        alg[0].toUpperCase() + ' key, was given a ' +\n        key.type.toUpperCase() + ' key instead'));\n    }\n\n    this.rs_signer = key.createSign(alg[1]);\n\n  } else {\n    throw (new TypeError('options.sign (func) or options.key is required'));\n  }\n\n  this.rs_headers = [];\n  this.rs_lines = [];\n}\n\n/**\n * Adds a header to be signed, with its value, into this signer.\n *\n * @param {String} header\n * @param {String} value\n * @return {String} value written\n */\nRequestSigner.prototype.writeHeader = function (header, value) {\n  assert.string(header, 'header');\n  header = header.toLowerCase();\n  assert.string(value, 'value');\n\n  this.rs_headers.push(header);\n\n  if (this.rs_signFunc) {\n    this.rs_lines.push(header + ': ' + value);\n\n  } else {\n    var line = header + ': ' + value;\n    if (this.rs_headers.length > 0)\n      line = '\\n' + line;\n    this.rs_signer.update(line);\n  }\n\n  return (value);\n};\n\n/**\n * Adds a default Date header, returning its value.\n *\n * @return {String}\n */\nRequestSigner.prototype.writeDateHeader = function () {\n  return (this.writeHeader('date', jsprim.rfc1123(new Date())));\n};\n\n/**\n * Adds the request target line to be signed.\n *\n * @param {String} method, HTTP method (e.g. 'get', 'post', 'put')\n * @param {String} path\n */\nRequestSigner.prototype.writeTarget = function (method, path) {\n  assert.string(method, 'method');\n  assert.string(path, 'path');\n  method = method.toLowerCase();\n  this.writeHeader('(request-target)', method + ' ' + path);\n};\n\n/**\n * Calculate the value for the Authorization header on this request\n * asynchronously.\n *\n * @param {Func} callback (err, authz)\n */\nRequestSigner.prototype.sign = function (cb) {\n  assert.func(cb, 'callback');\n\n  if (this.rs_headers.length < 1)\n    throw (new Error('At least one header must be signed'));\n\n  var alg, authz;\n  if (this.rs_signFunc) {\n    var data = this.rs_lines.join('\\n');\n    var self = this;\n    this.rs_signFunc(data, function (err, sig) {\n      if (err) {\n        cb(err);\n        return;\n      }\n      try {\n        assert.object(sig, 'signature');\n        assert.string(sig.keyId, 'signature.keyId');\n        assert.string(sig.algorithm, 'signature.algorithm');\n        assert.string(sig.signature, 'signature.signature');\n        alg = validateAlgorithm(sig.algorithm);\n\n        authz = sprintf(AUTHZ_FMT,\n          sig.keyId,\n          sig.algorithm,\n          self.rs_headers.join(' '),\n          sig.signature);\n      } catch (e) {\n        cb(e);\n        return;\n      }\n      cb(null, authz);\n    });\n\n  } else {\n    try {\n      var sigObj = this.rs_signer.sign();\n    } catch (e) {\n      cb(e);\n      return;\n    }\n    alg = (this.rs_alg[0] || this.rs_key.type) + '-' + sigObj.hashAlgorithm;\n    var signature = sigObj.toString();\n    authz = sprintf(AUTHZ_FMT,\n      this.rs_keyId,\n      alg,\n      this.rs_headers.join(' '),\n      signature);\n    cb(null, authz);\n  }\n};\n\n///--- Exported API\n\nmodule.exports = {\n  /**\n   * Identifies whether a given object is a request signer or not.\n   *\n   * @param {Object} object, the object to identify\n   * @returns {Boolean}\n   */\n  isSigner: function (obj) {\n    if (typeof (obj) === 'object' && obj instanceof RequestSigner)\n      return (true);\n    return (false);\n  },\n\n  /**\n   * Creates a request signer, used to asynchronously build a signature\n   * for a request (does not have to be an http.ClientRequest).\n   *\n   * @param {Object} options, either:\n   *                   - {String} keyId\n   *                   - {String|Buffer} key\n   *                   - {String} algorithm (optional, required for HMAC)\n   *                 or:\n   *                   - {Func} sign (data, cb)\n   * @return {RequestSigner}\n   */\n  createSigner: function createSigner(options) {\n    return (new RequestSigner(options));\n  },\n\n  /**\n   * Adds an 'Authorization' header to an http.ClientRequest object.\n   *\n   * Note that this API will add a Date header if it's not already set. Any\n   * other headers in the options.headers array MUST be present, or this\n   * will throw.\n   *\n   * You shouldn't need to check the return type; it's just there if you want\n   * to be pedantic.\n   *\n   * The optional flag indicates whether parsing should use strict enforcement\n   * of the version draft-cavage-http-signatures-04 of the spec or beyond.\n   * The default is to be loose and support\n   * older versions for compatibility.\n   *\n   * @param {Object} request an instance of http.ClientRequest.\n   * @param {Object} options signing parameters object:\n   *                   - {String} keyId required.\n   *                   - {String} key required (either a PEM or HMAC key).\n   *                   - {Array} headers optional; defaults to ['date'].\n   *                   - {String} algorithm optional (unless key is HMAC);\n   *                              default is the same as the sshpk default\n   *                              signing algorithm for the type of key given\n   *                   - {String} httpVersion optional; defaults to '1.1'.\n   *                   - {Boolean} strict optional; defaults to 'false'.\n   * @return {Boolean} true if Authorization (and optionally Date) were added.\n   * @throws {TypeError} on bad parameter types (input).\n   * @throws {InvalidAlgorithmError} if algorithm was bad or incompatible with\n   *                                 the given key.\n   * @throws {sshpk.KeyParseError} if key was bad.\n   * @throws {MissingHeaderError} if a header to be signed was specified but\n   *                              was not present.\n   */\n  signRequest: function signRequest(request, options) {\n    assert.object(request, 'request');\n    assert.object(options, 'options');\n    assert.optionalString(options.algorithm, 'options.algorithm');\n    assert.string(options.keyId, 'options.keyId');\n    assert.optionalArrayOfString(options.headers, 'options.headers');\n    assert.optionalString(options.httpVersion, 'options.httpVersion');\n\n    if (!request.getHeader('Date'))\n      request.setHeader('Date', jsprim.rfc1123(new Date()));\n    if (!options.headers)\n      options.headers = ['date'];\n    if (!options.httpVersion)\n      options.httpVersion = '1.1';\n\n    var alg = [];\n    if (options.algorithm) {\n      options.algorithm = options.algorithm.toLowerCase();\n      alg = validateAlgorithm(options.algorithm);\n    }\n\n    var i;\n    var stringToSign = '';\n    for (i = 0; i < options.headers.length; i++) {\n      if (typeof (options.headers[i]) !== 'string')\n        throw new TypeError('options.headers must be an array of Strings');\n\n      var h = options.headers[i].toLowerCase();\n\n      if (h === 'request-line') {\n        if (!options.strict) {\n          /**\n           * We allow headers from the older spec drafts if strict parsing isn't\n           * specified in options.\n           */\n          stringToSign +=\n            request.method + ' ' + request.path + ' HTTP/' +\n            options.httpVersion;\n        } else {\n          /* Strict parsing doesn't allow older draft headers. */\n          throw (new StrictParsingError('request-line is not a valid header ' +\n            'with strict parsing enabled.'));\n        }\n      } else if (h === '(request-target)') {\n        stringToSign +=\n          '(request-target): ' + request.method.toLowerCase() + ' ' +\n          request.path;\n      } else {\n        var value = request.getHeader(h);\n        if (value === undefined || value === '') {\n          throw new MissingHeaderError(h + ' was not in the request');\n        }\n        stringToSign += h + ': ' + value;\n      }\n\n      if ((i + 1) < options.headers.length)\n        stringToSign += '\\n';\n    }\n\n    /* This is just for unit tests. */\n    if (request.hasOwnProperty('_stringToSign')) {\n      request._stringToSign = stringToSign;\n    }\n\n    var signature;\n    if (alg[0] === 'hmac') {\n      if (typeof (options.key) !== 'string' && !Buffer.isBuffer(options.key))\n        throw (new TypeError('options.key must be a string or Buffer'));\n\n      var hmac = crypto.createHmac(alg[1].toUpperCase(), options.key);\n      hmac.update(stringToSign);\n      signature = hmac.digest('base64');\n\n    } else {\n      var key = options.key;\n      if (typeof (key) === 'string' || Buffer.isBuffer(key))\n        key = sshpk.parsePrivateKey(options.key);\n\n      assert.ok(sshpk.PrivateKey.isPrivateKey(key, [1, 2]),\n        'options.key must be a sshpk.PrivateKey');\n\n      if (!PK_ALGOS[key.type]) {\n        throw (new InvalidAlgorithmError(key.type.toUpperCase() + ' type ' +\n          'keys are not supported'));\n      }\n\n      if (alg[0] !== undefined && key.type !== alg[0]) {\n        throw (new InvalidAlgorithmError('options.key must be a ' +\n          alg[0].toUpperCase() + ' key, was given a ' +\n          key.type.toUpperCase() + ' key instead'));\n      }\n\n      var signer = key.createSign(alg[1]);\n      signer.update(stringToSign);\n      var sigObj = signer.sign();\n      if (!HASH_ALGOS[sigObj.hashAlgorithm]) {\n        throw (new InvalidAlgorithmError(sigObj.hashAlgorithm.toUpperCase() +\n          ' is not a supported hash algorithm'));\n      }\n      options.algorithm = key.type + '-' + sigObj.hashAlgorithm;\n      signature = sigObj.toString();\n      assert.notStrictEqual(signature, '', 'empty signature produced');\n    }\n\n    request.setHeader('Authorization', sprintf(AUTHZ_FMT,\n                                               options.keyId,\n                                               options.algorithm,\n                                               options.headers.join(' '),\n                                               signature));\n\n    return true;\n  }\n\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/jsprim/lib/jsprim.js":"/*\n * lib/jsprim.js: utilities for primitive JavaScript types\n */\n\nvar mod_assert = require('assert');\nvar mod_util = require('util');\n\nvar mod_extsprintf = require('extsprintf');\nvar mod_verror = require('verror');\nvar mod_jsonschema = require('json-schema');\n\n/*\n * Public interface\n */\nexports.deepCopy = deepCopy;\nexports.deepEqual = deepEqual;\nexports.isEmpty = isEmpty;\nexports.hasKey = hasKey;\nexports.forEachKey = forEachKey;\nexports.pluck = pluck;\nexports.flattenObject = flattenObject;\nexports.flattenIter = flattenIter;\nexports.validateJsonObject = validateJsonObjectJS;\nexports.validateJsonObjectJS = validateJsonObjectJS;\nexports.randElt = randElt;\nexports.extraProperties = extraProperties;\nexports.mergeObjects = mergeObjects;\n\nexports.startsWith = startsWith;\nexports.endsWith = endsWith;\n\nexports.iso8601 = iso8601;\nexports.rfc1123 = rfc1123;\nexports.parseDateTime = parseDateTime;\n\nexports.hrtimediff = hrtimeDiff;\nexports.hrtimeDiff = hrtimeDiff;\nexports.hrtimeAccum = hrtimeAccum;\nexports.hrtimeAdd = hrtimeAdd;\nexports.hrtimeNanosec = hrtimeNanosec;\nexports.hrtimeMicrosec = hrtimeMicrosec;\nexports.hrtimeMillisec = hrtimeMillisec;\n\n\n/*\n * Deep copy an acyclic *basic* Javascript object.  This only handles basic\n * scalars (strings, numbers, booleans) and arbitrarily deep arrays and objects\n * containing these.  This does *not* handle instances of other classes.\n */\nfunction deepCopy(obj)\n{\n\tvar ret, key;\n\tvar marker = '__deepCopy';\n\n\tif (obj && obj[marker])\n\t\tthrow (new Error('attempted deep copy of cyclic object'));\n\n\tif (obj && obj.constructor == Object) {\n\t\tret = {};\n\t\tobj[marker] = true;\n\n\t\tfor (key in obj) {\n\t\t\tif (key == marker)\n\t\t\t\tcontinue;\n\n\t\t\tret[key] = deepCopy(obj[key]);\n\t\t}\n\n\t\tdelete (obj[marker]);\n\t\treturn (ret);\n\t}\n\n\tif (obj && obj.constructor == Array) {\n\t\tret = [];\n\t\tobj[marker] = true;\n\n\t\tfor (key = 0; key < obj.length; key++)\n\t\t\tret.push(deepCopy(obj[key]));\n\n\t\tdelete (obj[marker]);\n\t\treturn (ret);\n\t}\n\n\t/*\n\t * It must be a primitive type -- just return it.\n\t */\n\treturn (obj);\n}\n\nfunction deepEqual(obj1, obj2)\n{\n\tif (typeof (obj1) != typeof (obj2))\n\t\treturn (false);\n\n\tif (obj1 === null || obj2 === null || typeof (obj1) != 'object')\n\t\treturn (obj1 === obj2);\n\n\tif (obj1.constructor != obj2.constructor)\n\t\treturn (false);\n\n\tvar k;\n\tfor (k in obj1) {\n\t\tif (!obj2.hasOwnProperty(k))\n\t\t\treturn (false);\n\n\t\tif (!deepEqual(obj1[k], obj2[k]))\n\t\t\treturn (false);\n\t}\n\n\tfor (k in obj2) {\n\t\tif (!obj1.hasOwnProperty(k))\n\t\t\treturn (false);\n\t}\n\n\treturn (true);\n}\n\nfunction isEmpty(obj)\n{\n\tvar key;\n\tfor (key in obj)\n\t\treturn (false);\n\treturn (true);\n}\n\nfunction hasKey(obj, key)\n{\n\tmod_assert.equal(typeof (key), 'string');\n\treturn (Object.prototype.hasOwnProperty.call(obj, key));\n}\n\nfunction forEachKey(obj, callback)\n{\n\tfor (var key in obj) {\n\t\tif (hasKey(obj, key)) {\n\t\t\tcallback(key, obj[key]);\n\t\t}\n\t}\n}\n\nfunction pluck(obj, key)\n{\n\tmod_assert.equal(typeof (key), 'string');\n\treturn (pluckv(obj, key));\n}\n\nfunction pluckv(obj, key)\n{\n\tif (obj === null || typeof (obj) !== 'object')\n\t\treturn (undefined);\n\n\tif (obj.hasOwnProperty(key))\n\t\treturn (obj[key]);\n\n\tvar i = key.indexOf('.');\n\tif (i == -1)\n\t\treturn (undefined);\n\n\tvar key1 = key.substr(0, i);\n\tif (!obj.hasOwnProperty(key1))\n\t\treturn (undefined);\n\n\treturn (pluckv(obj[key1], key.substr(i + 1)));\n}\n\n/*\n * Invoke callback(row) for each entry in the array that would be returned by\n * flattenObject(data, depth).  This is just like flattenObject(data,\n * depth).forEach(callback), except that the intermediate array is never\n * created.\n */\nfunction flattenIter(data, depth, callback)\n{\n\tdoFlattenIter(data, depth, [], callback);\n}\n\nfunction doFlattenIter(data, depth, accum, callback)\n{\n\tvar each;\n\tvar key;\n\n\tif (depth === 0) {\n\t\teach = accum.slice(0);\n\t\teach.push(data);\n\t\tcallback(each);\n\t\treturn;\n\t}\n\n\tmod_assert.ok(data !== null);\n\tmod_assert.equal(typeof (data), 'object');\n\tmod_assert.equal(typeof (depth), 'number');\n\tmod_assert.ok(depth >= 0);\n\n\tfor (key in data) {\n\t\teach = accum.slice(0);\n\t\teach.push(key);\n\t\tdoFlattenIter(data[key], depth - 1, each, callback);\n\t}\n}\n\nfunction flattenObject(data, depth)\n{\n\tif (depth === 0)\n\t\treturn ([ data ]);\n\n\tmod_assert.ok(data !== null);\n\tmod_assert.equal(typeof (data), 'object');\n\tmod_assert.equal(typeof (depth), 'number');\n\tmod_assert.ok(depth >= 0);\n\n\tvar rv = [];\n\tvar key;\n\n\tfor (key in data) {\n\t\tflattenObject(data[key], depth - 1).forEach(function (p) {\n\t\t\trv.push([ key ].concat(p));\n\t\t});\n\t}\n\n\treturn (rv);\n}\n\nfunction startsWith(str, prefix)\n{\n\treturn (str.substr(0, prefix.length) == prefix);\n}\n\nfunction endsWith(str, suffix)\n{\n\treturn (str.substr(\n\t    str.length - suffix.length, suffix.length) == suffix);\n}\n\nfunction iso8601(d)\n{\n\tif (typeof (d) == 'number')\n\t\td = new Date(d);\n\tmod_assert.ok(d.constructor === Date);\n\treturn (mod_extsprintf.sprintf('%4d-%02d-%02dT%02d:%02d:%02d.%03dZ',\n\t    d.getUTCFullYear(), d.getUTCMonth() + 1, d.getUTCDate(),\n\t    d.getUTCHours(), d.getUTCMinutes(), d.getUTCSeconds(),\n\t    d.getUTCMilliseconds()));\n}\n\nvar RFC1123_MONTHS = [\n    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'];\nvar RFC1123_DAYS = [\n    'Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'];\n\nfunction rfc1123(date) {\n\treturn (mod_extsprintf.sprintf('%s, %02d %s %04d %02d:%02d:%02d GMT',\n\t    RFC1123_DAYS[date.getUTCDay()], date.getUTCDate(),\n\t    RFC1123_MONTHS[date.getUTCMonth()], date.getUTCFullYear(),\n\t    date.getUTCHours(), date.getUTCMinutes(),\n\t    date.getUTCSeconds()));\n}\n\n/*\n * Parses a date expressed as a string, as either a number of milliseconds since\n * the epoch or any string format that Date accepts, giving preference to the\n * former where these two sets overlap (e.g., small numbers).\n */\nfunction parseDateTime(str)\n{\n\t/*\n\t * This is irritatingly implicit, but significantly more concise than\n\t * alternatives.  The \"+str\" will convert a string containing only a\n\t * number directly to a Number, or NaN for other strings.  Thus, if the\n\t * conversion succeeds, we use it (this is the milliseconds-since-epoch\n\t * case).  Otherwise, we pass the string directly to the Date\n\t * constructor to parse.\n\t */\n\tvar numeric = +str;\n\tif (!isNaN(numeric)) {\n\t\treturn (new Date(numeric));\n\t} else {\n\t\treturn (new Date(str));\n\t}\n}\n\nfunction validateJsonObjectJS(schema, input)\n{\n\tvar report = mod_jsonschema.validate(input, schema);\n\n\tif (report.errors.length === 0)\n\t\treturn (null);\n\n\t/* Currently, we only do anything useful with the first error. */\n\tvar error = report.errors[0];\n\n\t/* The failed property is given by a URI with an irrelevant prefix. */\n\tvar propname = error['property'];\n\tvar reason = error['message'].toLowerCase();\n\tvar i, j;\n\n\t/*\n\t * There's at least one case where the property error message is\n\t * confusing at best.  We work around this here.\n\t */\n\tif ((i = reason.indexOf('the property ')) != -1 &&\n\t    (j = reason.indexOf(' is not defined in the schema and the ' +\n\t    'schema does not allow additional properties')) != -1) {\n\t\ti += 'the property '.length;\n\t\tif (propname === '')\n\t\t\tpropname = reason.substr(i, j - i);\n\t\telse\n\t\t\tpropname = propname + '.' + reason.substr(i, j - i);\n\n\t\treason = 'unsupported property';\n\t}\n\n\tvar rv = new mod_verror.VError('property \"%s\": %s', propname, reason);\n\trv.jsv_details = error;\n\treturn (rv);\n}\n\nfunction randElt(arr)\n{\n\tmod_assert.ok(Array.isArray(arr) && arr.length > 0,\n\t    'randElt argument must be a non-empty array');\n\n\treturn (arr[Math.floor(Math.random() * arr.length)]);\n}\n\nfunction assertHrtime(a)\n{\n\tmod_assert.ok(a[0] >= 0 && a[1] >= 0,\n\t    'negative numbers not allowed in hrtimes');\n\tmod_assert.ok(a[1] < 1e9, 'nanoseconds column overflow');\n}\n\n/*\n * Compute the time elapsed between hrtime readings A and B, where A is later\n * than B.  hrtime readings come from Node's process.hrtime().  There is no\n * defined way to represent negative deltas, so it's illegal to diff B from A\n * where the time denoted by B is later than the time denoted by A.  If this\n * becomes valuable, we can define a representation and extend the\n * implementation to support it.\n */\nfunction hrtimeDiff(a, b)\n{\n\tassertHrtime(a);\n\tassertHrtime(b);\n\tmod_assert.ok(a[0] > b[0] || (a[0] == b[0] && a[1] >= b[1]),\n\t    'negative differences not allowed');\n\n\tvar rv = [ a[0] - b[0], 0 ];\n\n\tif (a[1] >= b[1]) {\n\t\trv[1] = a[1] - b[1];\n\t} else {\n\t\trv[0]--;\n\t\trv[1] = 1e9 - (b[1] - a[1]);\n\t}\n\n\treturn (rv);\n}\n\n/*\n * Convert a hrtime reading from the array format returned by Node's\n * process.hrtime() into a scalar number of nanoseconds.\n */\nfunction hrtimeNanosec(a)\n{\n\tassertHrtime(a);\n\n\treturn (Math.floor(a[0] * 1e9 + a[1]));\n}\n\n/*\n * Convert a hrtime reading from the array format returned by Node's\n * process.hrtime() into a scalar number of microseconds.\n */\nfunction hrtimeMicrosec(a)\n{\n\tassertHrtime(a);\n\n\treturn (Math.floor(a[0] * 1e6 + a[1] / 1e3));\n}\n\n/*\n * Convert a hrtime reading from the array format returned by Node's\n * process.hrtime() into a scalar number of milliseconds.\n */\nfunction hrtimeMillisec(a)\n{\n\tassertHrtime(a);\n\n\treturn (Math.floor(a[0] * 1e3 + a[1] / 1e6));\n}\n\n/*\n * Add two hrtime readings A and B, overwriting A with the result of the\n * addition.  This function is useful for accumulating several hrtime intervals\n * into a counter.  Returns A.\n */\nfunction hrtimeAccum(a, b)\n{\n\tassertHrtime(a);\n\tassertHrtime(b);\n\n\t/*\n\t * Accumulate the nanosecond component.\n\t */\n\ta[1] += b[1];\n\tif (a[1] >= 1e9) {\n\t\t/*\n\t\t * The nanosecond component overflowed, so carry to the seconds\n\t\t * field.\n\t\t */\n\t\ta[0]++;\n\t\ta[1] -= 1e9;\n\t}\n\n\t/*\n\t * Accumulate the seconds component.\n\t */\n\ta[0] += b[0];\n\n\treturn (a);\n}\n\n/*\n * Add two hrtime readings A and B, returning the result as a new hrtime array.\n * Does not modify either input argument.\n */\nfunction hrtimeAdd(a, b)\n{\n\tassertHrtime(a);\n\n\tvar rv = [ a[0], a[1] ];\n\n\treturn (hrtimeAccum(rv, b));\n}\n\n\n/*\n * Check an object for unexpected properties.  Accepts the object to check, and\n * an array of allowed property names (strings).  Returns an array of key names\n * that were found on the object, but did not appear in the list of allowed\n * properties.  If no properties were found, the returned array will be of\n * zero length.\n */\nfunction extraProperties(obj, allowed)\n{\n\tmod_assert.ok(typeof (obj) === 'object' && obj !== null,\n\t    'obj argument must be a non-null object');\n\tmod_assert.ok(Array.isArray(allowed),\n\t    'allowed argument must be an array of strings');\n\tfor (var i = 0; i < allowed.length; i++) {\n\t\tmod_assert.ok(typeof (allowed[i]) === 'string',\n\t\t    'allowed argument must be an array of strings');\n\t}\n\n\treturn (Object.keys(obj).filter(function (key) {\n\t\treturn (allowed.indexOf(key) === -1);\n\t}));\n}\n\n/*\n * Given three sets of properties \"provided\" (may be undefined), \"overrides\"\n * (required), and \"defaults\" (may be undefined), construct an object containing\n * the union of these sets with \"overrides\" overriding \"provided\", and\n * \"provided\" overriding \"defaults\".  None of the input objects are modified.\n */\nfunction mergeObjects(provided, overrides, defaults)\n{\n\tvar rv, k;\n\n\trv = {};\n\tif (defaults) {\n\t\tfor (k in defaults)\n\t\t\trv[k] = defaults[k];\n\t}\n\n\tif (provided) {\n\t\tfor (k in provided)\n\t\t\trv[k] = provided[k];\n\t}\n\n\tif (overrides) {\n\t\tfor (k in overrides)\n\t\t\trv[k] = overrides[k];\n\t}\n\n\treturn (rv);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/jsprim/node_modules/extsprintf/lib/extsprintf.js":"/*\n * extsprintf.js: extended POSIX-style sprintf\n */\n\nvar mod_assert = require('assert');\nvar mod_util = require('util');\n\n/*\n * Public interface\n */\nexports.sprintf = jsSprintf;\n\n/*\n * Stripped down version of s[n]printf(3c).  We make a best effort to throw an\n * exception when given a format string we don't understand, rather than\n * ignoring it, so that we won't break existing programs if/when we go implement\n * the rest of this.\n *\n * This implementation currently supports specifying\n *\t- field alignment ('-' flag),\n * \t- zero-pad ('0' flag)\n *\t- always show numeric sign ('+' flag),\n *\t- field width\n *\t- conversions for strings, decimal integers, and floats (numbers).\n *\t- argument size specifiers.  These are all accepted but ignored, since\n *\t  Javascript has no notion of the physical size of an argument.\n *\n * Everything else is currently unsupported, most notably precision, unsigned\n * numbers, non-decimal numbers, and characters.\n */\nfunction jsSprintf(fmt)\n{\n\tvar regex = [\n\t    '([^%]*)',\t\t\t\t/* normal text */\n\t    '%',\t\t\t\t/* start of format */\n\t    '([\\'\\\\-+ #0]*?)',\t\t\t/* flags (optional) */\n\t    '([1-9]\\\\d*)?',\t\t\t/* width (optional) */\n\t    '(\\\\.([1-9]\\\\d*))?',\t\t/* precision (optional) */\n\t    '[lhjztL]*?',\t\t\t/* length mods (ignored) */\n\t    '([diouxXfFeEgGaAcCsSp%jr])'\t/* conversion */\n\t].join('');\n\n\tvar re = new RegExp(regex);\n\tvar args = Array.prototype.slice.call(arguments, 1);\n\tvar flags, width, precision, conversion;\n\tvar left, pad, sign, arg, match;\n\tvar ret = '';\n\tvar argn = 1;\n\n\tmod_assert.equal('string', typeof (fmt));\n\n\twhile ((match = re.exec(fmt)) !== null) {\n\t\tret += match[1];\n\t\tfmt = fmt.substring(match[0].length);\n\n\t\tflags = match[2] || '';\n\t\twidth = match[3] || 0;\n\t\tprecision = match[4] || '';\n\t\tconversion = match[6];\n\t\tleft = false;\n\t\tsign = false;\n\t\tpad = ' ';\n\n\t\tif (conversion == '%') {\n\t\t\tret += '%';\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (args.length === 0)\n\t\t\tthrow (new Error('too few args to sprintf'));\n\n\t\targ = args.shift();\n\t\targn++;\n\n\t\tif (flags.match(/[\\' #]/))\n\t\t\tthrow (new Error(\n\t\t\t    'unsupported flags: ' + flags));\n\n\t\tif (precision.length > 0)\n\t\t\tthrow (new Error(\n\t\t\t    'non-zero precision not supported'));\n\n\t\tif (flags.match(/-/))\n\t\t\tleft = true;\n\n\t\tif (flags.match(/0/))\n\t\t\tpad = '0';\n\n\t\tif (flags.match(/\\+/))\n\t\t\tsign = true;\n\n\t\tswitch (conversion) {\n\t\tcase 's':\n\t\t\tif (arg === undefined || arg === null)\n\t\t\t\tthrow (new Error('argument ' + argn +\n\t\t\t\t    ': attempted to print undefined or null ' +\n\t\t\t\t    'as a string'));\n\t\t\tret += doPad(pad, width, left, arg.toString());\n\t\t\tbreak;\n\n\t\tcase 'd':\n\t\t\targ = Math.floor(arg);\n\t\t\t/*jsl:fallthru*/\n\t\tcase 'f':\n\t\t\tsign = sign && arg > 0 ? '+' : '';\n\t\t\tret += sign + doPad(pad, width, left,\n\t\t\t    arg.toString());\n\t\t\tbreak;\n\n\t\tcase 'j': /* non-standard */\n\t\t\tif (width === 0)\n\t\t\t\twidth = 10;\n\t\t\tret += mod_util.inspect(arg, false, width);\n\t\t\tbreak;\n\n\t\tcase 'r': /* non-standard */\n\t\t\tret += dumpException(arg);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tthrow (new Error('unsupported conversion: ' +\n\t\t\t    conversion));\n\t\t}\n\t}\n\n\tret += fmt;\n\treturn (ret);\n}\n\nfunction doPad(chr, width, left, str)\n{\n\tvar ret = str;\n\n\twhile (ret.length < width) {\n\t\tif (left)\n\t\t\tret += chr;\n\t\telse\n\t\t\tret = chr + ret;\n\t}\n\n\treturn (ret);\n}\n\n/*\n * This function dumps long stack traces for exceptions having a cause() method.\n * See node-verror for an example.\n */\nfunction dumpException(ex)\n{\n\tvar ret;\n\n\tif (!(ex instanceof Error))\n\t\tthrow (new Error(jsSprintf('invalid type for %%r: %j', ex)));\n\n\t/* Note that V8 prepends \"ex.stack\" with ex.toString(). */\n\tret = 'EXCEPTION: ' + ex.constructor.name + ': ' + ex.stack;\n\n\tif (ex.cause && typeof (ex.cause) === 'function') {\n\t\tvar cex = ex.cause();\n\t\tif (cex) {\n\t\t\tret += '\\nCaused by: ' + dumpException(cex);\n\t\t}\n\t}\n\n\treturn (ret);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/jsprim/node_modules/verror/lib/verror.js":"/*\n * verror.js: richer JavaScript errors\n */\n\nvar mod_assert = require('assert');\nvar mod_util = require('util');\n\nvar mod_extsprintf = require('extsprintf');\n\n/*\n * Public interface\n */\nexports.VError = VError;\nexports.WError = WError;\nexports.MultiError = MultiError;\n\n/*\n * Like JavaScript's built-in Error class, but supports a \"cause\" argument and a\n * printf-style message.  The cause argument can be null.\n */\nfunction VError(options)\n{\n\tvar args, causedBy, ctor, tailmsg;\n\n\tif (options instanceof Error || typeof (options) === 'object') {\n\t\targs = Array.prototype.slice.call(arguments, 1);\n\t} else {\n\t\targs = Array.prototype.slice.call(arguments, 0);\n\t\toptions = undefined;\n\t}\n\n\ttailmsg = args.length > 0 ?\n\t    mod_extsprintf.sprintf.apply(null, args) : '';\n\tthis.jse_shortmsg = tailmsg;\n\tthis.jse_summary = tailmsg;\n\n\tif (options) {\n\t\tcausedBy = options.cause;\n\n\t\tif (!causedBy || !(options.cause instanceof Error))\n\t\t\tcausedBy = options;\n\n\t\tif (causedBy && (causedBy instanceof Error)) {\n\t\t\tthis.jse_cause = causedBy;\n\t\t\tthis.jse_summary += ': ' + causedBy.message;\n\t\t}\n\t}\n\n\tthis.message = this.jse_summary;\n\tError.call(this, this.jse_summary);\n\n\tif (Error.captureStackTrace) {\n\t\tctor = options ? options.constructorOpt : undefined;\n\t\tctor = ctor || arguments.callee;\n\t\tError.captureStackTrace(this, ctor);\n\t}\n}\n\nmod_util.inherits(VError, Error);\nVError.prototype.name = 'VError';\n\nVError.prototype.toString = function ve_toString()\n{\n\tvar str = (this.hasOwnProperty('name') && this.name ||\n\t\tthis.constructor.name || this.constructor.prototype.name);\n\tif (this.message)\n\t\tstr += ': ' + this.message;\n\n\treturn (str);\n};\n\nVError.prototype.cause = function ve_cause()\n{\n\treturn (this.jse_cause);\n};\n\n\n/*\n * Represents a collection of errors for the purpose of consumers that generally\n * only deal with one error.  Callers can extract the individual errors\n * contained in this object, but may also just treat it as a normal single\n * error, in which case a summary message will be printed.\n */\nfunction MultiError(errors)\n{\n\tmod_assert.ok(errors.length > 0);\n\tthis.ase_errors = errors;\n\n\tVError.call(this, errors[0], 'first of %d error%s',\n\t    errors.length, errors.length == 1 ? '' : 's');\n}\n\nmod_util.inherits(MultiError, VError);\n\n\n\n/*\n * Like JavaScript's built-in Error class, but supports a \"cause\" argument which\n * is wrapped, not \"folded in\" as with VError.\tAccepts a printf-style message.\n * The cause argument can be null.\n */\nfunction WError(options)\n{\n\tError.call(this);\n\n\tvar args, cause, ctor;\n\tif (typeof (options) === 'object') {\n\t\targs = Array.prototype.slice.call(arguments, 1);\n\t} else {\n\t\targs = Array.prototype.slice.call(arguments, 0);\n\t\toptions = undefined;\n\t}\n\n\tif (args.length > 0) {\n\t\tthis.message = mod_extsprintf.sprintf.apply(null, args);\n\t} else {\n\t\tthis.message = '';\n\t}\n\n\tif (options) {\n\t\tif (options instanceof Error) {\n\t\t\tcause = options;\n\t\t} else {\n\t\t\tcause = options.cause;\n\t\t\tctor = options.constructorOpt;\n\t\t}\n\t}\n\n\tError.captureStackTrace(this, ctor || this.constructor);\n\tif (cause)\n\t\tthis.cause(cause);\n\n}\n\nmod_util.inherits(WError, Error);\nWError.prototype.name = 'WError';\n\n\nWError.prototype.toString = function we_toString()\n{\n\tvar str = (this.hasOwnProperty('name') && this.name ||\n\t\tthis.constructor.name || this.constructor.prototype.name);\n\tif (this.message)\n\t\tstr += ': ' + this.message;\n\tif (this.we_cause && this.we_cause.message)\n\t\tstr += '; caused by ' + this.we_cause.toString();\n\n\treturn (str);\n};\n\nWError.prototype.cause = function we_cause(c)\n{\n\tif (c instanceof Error)\n\t\tthis.we_cause = c;\n\n\treturn (this.we_cause);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/jsprim/node_modules/json-schema/lib/validate.js":"/**\r\n * JSONSchema Validator - Validates JavaScript objects using JSON Schemas\r\n *\t(http://www.json.com/json-schema-proposal/)\r\n *\r\n * Copyright (c) 2007 Kris Zyp SitePen (www.sitepen.com)\r\n * Licensed under the MIT (MIT-LICENSE.txt) license.\r\nTo use the validator call the validate function with an instance object and an optional schema object.\r\nIf a schema is provided, it will be used to validate. If the instance object refers to a schema (self-validating),\r\nthat schema will be used to validate and the schema parameter is not necessary (if both exist,\r\nboth validations will occur).\r\nThe validate method will return an array of validation errors. If there are no errors, then an\r\nempty list will be returned. A validation error will have two properties:\r\n\"property\" which indicates which property had the error\r\n\"message\" which indicates what the error was\r\n */\r\n(function (root, factory) {\r\n    if (typeof define === 'function' && define.amd) {\r\n        // AMD. Register as an anonymous module.\r\n        define([], function () {\r\n            return factory();\r\n        });\r\n    } else if (typeof module === 'object' && module.exports) {\r\n        // Node. Does not work with strict CommonJS, but\r\n        // only CommonJS-like environments that support module.exports,\r\n        // like Node.\r\n        module.exports = factory();\r\n    } else {\r\n        // Browser globals\r\n        root.jsonSchema = factory();\r\n    }\r\n}(this, function () {// setup primitive classes to be JSON Schema types\r\nvar exports = validate\r\nexports.Integer = {type:\"integer\"};\r\nvar primitiveConstructors = {\r\n\tString: String,\r\n\tBoolean: Boolean,\r\n\tNumber: Number,\r\n\tObject: Object,\r\n\tArray: Array,\r\n\tDate: Date\r\n}\r\nexports.validate = validate;\r\nfunction validate(/*Any*/instance,/*Object*/schema) {\r\n\t\t// Summary:\r\n\t\t//  \tTo use the validator call JSONSchema.validate with an instance object and an optional schema object.\r\n\t\t// \t\tIf a schema is provided, it will be used to validate. If the instance object refers to a schema (self-validating),\r\n\t\t// \t\tthat schema will be used to validate and the schema parameter is not necessary (if both exist,\r\n\t\t// \t\tboth validations will occur).\r\n\t\t// \t\tThe validate method will return an object with two properties:\r\n\t\t// \t\t\tvalid: A boolean indicating if the instance is valid by the schema\r\n\t\t// \t\t\terrors: An array of validation errors. If there are no errors, then an\r\n\t\t// \t\t\t\t\tempty list will be returned. A validation error will have two properties:\r\n\t\t// \t\t\t\t\t\tproperty: which indicates which property had the error\r\n\t\t// \t\t\t\t\t\tmessage: which indicates what the error was\r\n\t\t//\r\n\t\treturn validate(instance, schema, {changing: false});//, coerce: false, existingOnly: false});\r\n\t};\r\nexports.checkPropertyChange = function(/*Any*/value,/*Object*/schema, /*String*/property) {\r\n\t\t// Summary:\r\n\t\t// \t\tThe checkPropertyChange method will check to see if an value can legally be in property with the given schema\r\n\t\t// \t\tThis is slightly different than the validate method in that it will fail if the schema is readonly and it will\r\n\t\t// \t\tnot check for self-validation, it is assumed that the passed in value is already internally valid.\r\n\t\t// \t\tThe checkPropertyChange method will return the same object type as validate, see JSONSchema.validate for\r\n\t\t// \t\tinformation.\r\n\t\t//\r\n\t\treturn validate(value, schema, {changing: property || \"property\"});\r\n\t};\r\nvar validate = exports._validate = function(/*Any*/instance,/*Object*/schema,/*Object*/options) {\r\n\r\n\tif (!options) options = {};\r\n\tvar _changing = options.changing;\r\n\r\n\tfunction getType(schema){\r\n\t\treturn schema.type || (primitiveConstructors[schema.name] == schema && schema.name.toLowerCase());\r\n\t}\r\n\tvar errors = [];\r\n\t// validate a value against a property definition\r\n\tfunction checkProp(value, schema, path,i){\r\n\r\n\t\tvar l;\r\n\t\tpath += path ? typeof i == 'number' ? '[' + i + ']' : typeof i == 'undefined' ? '' : '.' + i : i;\r\n\t\tfunction addError(message){\r\n\t\t\terrors.push({property:path,message:message});\r\n\t\t}\r\n\r\n\t\tif((typeof schema != 'object' || schema instanceof Array) && (path || typeof schema != 'function') && !(schema && getType(schema))){\r\n\t\t\tif(typeof schema == 'function'){\r\n\t\t\t\tif(!(value instanceof schema)){\r\n\t\t\t\t\taddError(\"is not an instance of the class/constructor \" + schema.name);\r\n\t\t\t\t}\r\n\t\t\t}else if(schema){\r\n\t\t\t\taddError(\"Invalid schema/property definition \" + schema);\r\n\t\t\t}\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\tif(_changing && schema.readonly){\r\n\t\t\taddError(\"is a readonly field, it can not be changed\");\r\n\t\t}\r\n\t\tif(schema['extends']){ // if it extends another schema, it must pass that schema as well\r\n\t\t\tcheckProp(value,schema['extends'],path,i);\r\n\t\t}\r\n\t\t// validate a value against a type definition\r\n\t\tfunction checkType(type,value){\r\n\t\t\tif(type){\r\n\t\t\t\tif(typeof type == 'string' && type != 'any' &&\r\n\t\t\t\t\t\t(type == 'null' ? value !== null : typeof value != type) &&\r\n\t\t\t\t\t\t!(value instanceof Array && type == 'array') &&\r\n\t\t\t\t\t\t!(value instanceof Date && type == 'date') &&\r\n\t\t\t\t\t\t!(type == 'integer' && value%1===0)){\r\n\t\t\t\t\treturn [{property:path,message:(typeof value) + \" value found, but a \" + type + \" is required\"}];\r\n\t\t\t\t}\r\n\t\t\t\tif(type instanceof Array){\r\n\t\t\t\t\tvar unionErrors=[];\r\n\t\t\t\t\tfor(var j = 0; j < type.length; j++){ // a union type\r\n\t\t\t\t\t\tif(!(unionErrors=checkType(type[j],value)).length){\r\n\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif(unionErrors.length){\r\n\t\t\t\t\t\treturn unionErrors;\r\n\t\t\t\t\t}\r\n\t\t\t\t}else if(typeof type == 'object'){\r\n\t\t\t\t\tvar priorErrors = errors;\r\n\t\t\t\t\terrors = [];\r\n\t\t\t\t\tcheckProp(value,type,path);\r\n\t\t\t\t\tvar theseErrors = errors;\r\n\t\t\t\t\terrors = priorErrors;\r\n\t\t\t\t\treturn theseErrors;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn [];\r\n\t\t}\r\n\t\tif(value === undefined){\r\n\t\t\tif(schema.required){\r\n\t\t\t\taddError(\"is missing and it is required\");\r\n\t\t\t}\r\n\t\t}else{\r\n\t\t\terrors = errors.concat(checkType(getType(schema),value));\r\n\t\t\tif(schema.disallow && !checkType(schema.disallow,value).length){\r\n\t\t\t\taddError(\" disallowed value was matched\");\r\n\t\t\t}\r\n\t\t\tif(value !== null){\r\n\t\t\t\tif(value instanceof Array){\r\n\t\t\t\t\tif(schema.items){\r\n\t\t\t\t\t\tvar itemsIsArray = schema.items instanceof Array;\r\n\t\t\t\t\t\tvar propDef = schema.items;\r\n\t\t\t\t\t\tfor (i = 0, l = value.length; i < l; i += 1) {\r\n\t\t\t\t\t\t\tif (itemsIsArray)\r\n\t\t\t\t\t\t\t\tpropDef = schema.items[i];\r\n\t\t\t\t\t\t\tif (options.coerce)\r\n\t\t\t\t\t\t\t\tvalue[i] = options.coerce(value[i], propDef);\r\n\t\t\t\t\t\t\terrors.concat(checkProp(value[i],propDef,path,i));\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif(schema.minItems && value.length < schema.minItems){\r\n\t\t\t\t\t\taddError(\"There must be a minimum of \" + schema.minItems + \" in the array\");\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif(schema.maxItems && value.length > schema.maxItems){\r\n\t\t\t\t\t\taddError(\"There must be a maximum of \" + schema.maxItems + \" in the array\");\r\n\t\t\t\t\t}\r\n\t\t\t\t}else if(schema.properties || schema.additionalProperties){\r\n\t\t\t\t\terrors.concat(checkObj(value, schema.properties, path, schema.additionalProperties));\r\n\t\t\t\t}\r\n\t\t\t\tif(schema.pattern && typeof value == 'string' && !value.match(schema.pattern)){\r\n\t\t\t\t\taddError(\"does not match the regex pattern \" + schema.pattern);\r\n\t\t\t\t}\r\n\t\t\t\tif(schema.maxLength && typeof value == 'string' && value.length > schema.maxLength){\r\n\t\t\t\t\taddError(\"may only be \" + schema.maxLength + \" characters long\");\r\n\t\t\t\t}\r\n\t\t\t\tif(schema.minLength && typeof value == 'string' && value.length < schema.minLength){\r\n\t\t\t\t\taddError(\"must be at least \" + schema.minLength + \" characters long\");\r\n\t\t\t\t}\r\n\t\t\t\tif(typeof schema.minimum !== undefined && typeof value == typeof schema.minimum &&\r\n\t\t\t\t\t\tschema.minimum > value){\r\n\t\t\t\t\taddError(\"must have a minimum value of \" + schema.minimum);\r\n\t\t\t\t}\r\n\t\t\t\tif(typeof schema.maximum !== undefined && typeof value == typeof schema.maximum &&\r\n\t\t\t\t\t\tschema.maximum < value){\r\n\t\t\t\t\taddError(\"must have a maximum value of \" + schema.maximum);\r\n\t\t\t\t}\r\n\t\t\t\tif(schema['enum']){\r\n\t\t\t\t\tvar enumer = schema['enum'];\r\n\t\t\t\t\tl = enumer.length;\r\n\t\t\t\t\tvar found;\r\n\t\t\t\t\tfor(var j = 0; j < l; j++){\r\n\t\t\t\t\t\tif(enumer[j]===value){\r\n\t\t\t\t\t\t\tfound=1;\r\n\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif(!found){\r\n\t\t\t\t\t\taddError(\"does not have a value in the enumeration \" + enumer.join(\", \"));\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tif(typeof schema.maxDecimal == 'number' &&\r\n\t\t\t\t\t(value.toString().match(new RegExp(\"\\\\.[0-9]{\" + (schema.maxDecimal + 1) + \",}\")))){\r\n\t\t\t\t\taddError(\"may only have \" + schema.maxDecimal + \" digits of decimal places\");\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn null;\r\n\t}\r\n\t// validate an object against a schema\r\n\tfunction checkObj(instance,objTypeDef,path,additionalProp){\r\n\r\n\t\tif(typeof objTypeDef =='object'){\r\n\t\t\tif(typeof instance != 'object' || instance instanceof Array){\r\n\t\t\t\terrors.push({property:path,message:\"an object is required\"});\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tfor(var i in objTypeDef){ \r\n\t\t\t\tif(objTypeDef.hasOwnProperty(i)){\r\n\t\t\t\t\tvar value = instance[i];\r\n\t\t\t\t\t// skip _not_ specified properties\r\n\t\t\t\t\tif (value === undefined && options.existingOnly) continue;\r\n\t\t\t\t\tvar propDef = objTypeDef[i];\r\n\t\t\t\t\t// set default\r\n\t\t\t\t\tif(value === undefined && propDef[\"default\"]){\r\n\t\t\t\t\t\tvalue = instance[i] = propDef[\"default\"];\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif(options.coerce && i in instance){\r\n\t\t\t\t\t\tvalue = instance[i] = options.coerce(value, propDef);\r\n\t\t\t\t\t}\r\n\t\t\t\t\tcheckProp(value,propDef,path,i);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor(i in instance){\r\n\t\t\tif(instance.hasOwnProperty(i) && !(i.charAt(0) == '_' && i.charAt(1) == '_') && objTypeDef && !objTypeDef[i] && additionalProp===false){\r\n\t\t\t\tif (options.filter) {\r\n\t\t\t\t\tdelete instance[i];\r\n\t\t\t\t\tcontinue;\r\n\t\t\t\t} else {\r\n\t\t\t\t\terrors.push({property:path,message:(typeof value) + \"The property \" + i +\r\n\t\t\t\t\t\t\" is not defined in the schema and the schema does not allow additional properties\"});\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tvar requires = objTypeDef && objTypeDef[i] && objTypeDef[i].requires;\r\n\t\t\tif(requires && !(requires in instance)){\r\n\t\t\t\terrors.push({property:path,message:\"the presence of the property \" + i + \" requires that \" + requires + \" also be present\"});\r\n\t\t\t}\r\n\t\t\tvalue = instance[i];\r\n\t\t\tif(additionalProp && (!(objTypeDef && typeof objTypeDef == 'object') || !(i in objTypeDef))){\r\n\t\t\t\tif(options.coerce){\r\n\t\t\t\t\tvalue = instance[i] = options.coerce(value, additionalProp);\r\n\t\t\t\t}\r\n\t\t\t\tcheckProp(value,additionalProp,path,i);\r\n\t\t\t}\r\n\t\t\tif(!_changing && value && value.$schema){\r\n\t\t\t\terrors = errors.concat(checkProp(value,value.$schema,path,i));\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn errors;\r\n\t}\r\n\tif(schema){\r\n\t\tcheckProp(instance,schema,'',_changing || '');\r\n\t}\r\n\tif(!_changing && instance && instance.$schema){\r\n\t\tcheckProp(instance,instance.$schema,'','');\r\n\t}\r\n\treturn {valid:!errors.length,errors:errors};\r\n};\r\nexports.mustBeValid = function(result){\r\n\t//\tsummary:\r\n\t//\t\tThis checks to ensure that the result is valid and will throw an appropriate error message if it is not\r\n\t// result: the result returned from checkPropertyChange or validate\r\n\tif(!result.valid){\r\n\t\tthrow new TypeError(result.errors.map(function(error){return \"for property \" + error.property + ': ' + error.message;}).join(\", \\n\"));\r\n\t}\r\n}\r\n\r\nreturn exports;\r\n}));\r\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/http-signature/lib/verify.js":"// Copyright 2015 Joyent, Inc.\n\nvar assert = require('assert-plus');\nvar crypto = require('crypto');\nvar sshpk = require('sshpk');\nvar utils = require('./utils');\n\nvar HASH_ALGOS = utils.HASH_ALGOS;\nvar PK_ALGOS = utils.PK_ALGOS;\nvar InvalidAlgorithmError = utils.InvalidAlgorithmError;\nvar HttpSignatureError = utils.HttpSignatureError;\nvar validateAlgorithm = utils.validateAlgorithm;\n\n///--- Exported API\n\nmodule.exports = {\n  /**\n   * Verify RSA/DSA signature against public key.  You are expected to pass in\n   * an object that was returned from `parse()`.\n   *\n   * @param {Object} parsedSignature the object you got from `parse`.\n   * @param {String} pubkey RSA/DSA private key PEM.\n   * @return {Boolean} true if valid, false otherwise.\n   * @throws {TypeError} if you pass in bad arguments.\n   * @throws {InvalidAlgorithmError}\n   */\n  verifySignature: function verifySignature(parsedSignature, pubkey) {\n    assert.object(parsedSignature, 'parsedSignature');\n    if (typeof (pubkey) === 'string' || Buffer.isBuffer(pubkey))\n      pubkey = sshpk.parseKey(pubkey);\n    assert.ok(sshpk.Key.isKey(pubkey, [1, 1]), 'pubkey must be a sshpk.Key');\n\n    var alg = validateAlgorithm(parsedSignature.algorithm);\n    if (alg[0] === 'hmac' || alg[0] !== pubkey.type)\n      return (false);\n\n    var v = pubkey.createVerify(alg[1]);\n    v.update(parsedSignature.signingString);\n    return (v.verify(parsedSignature.params.signature, 'base64'));\n  },\n\n  /**\n   * Verify HMAC against shared secret.  You are expected to pass in an object\n   * that was returned from `parse()`.\n   *\n   * @param {Object} parsedSignature the object you got from `parse`.\n   * @param {String} secret HMAC shared secret.\n   * @return {Boolean} true if valid, false otherwise.\n   * @throws {TypeError} if you pass in bad arguments.\n   * @throws {InvalidAlgorithmError}\n   */\n  verifyHMAC: function verifyHMAC(parsedSignature, secret) {\n    assert.object(parsedSignature, 'parsedHMAC');\n    assert.string(secret, 'secret');\n\n    var alg = validateAlgorithm(parsedSignature.algorithm);\n    if (alg[0] !== 'hmac')\n      return (false);\n\n    var hashAlg = alg[1].toUpperCase();\n\n    var hmac = crypto.createHmac(hashAlg, secret);\n    hmac.update(parsedSignature.signingString);\n\n    /*\n     * Now double-hash to avoid leaking timing information - there's\n     * no easy constant-time compare in JS, so we use this approach\n     * instead. See for more info:\n     * https://www.isecpartners.com/blog/2011/february/double-hmac-\n     * verification.aspx\n     */\n    var h1 = crypto.createHmac(hashAlg, secret);\n    h1.update(hmac.digest());\n    h1 = h1.digest();\n    var h2 = crypto.createHmac(hashAlg, secret);\n    h2.update(new Buffer(parsedSignature.params.signature, 'base64'));\n    h2 = h2.digest();\n\n    /* Node 0.8 returns strings from .digest(). */\n    if (typeof (h1) === 'string')\n      return (h1 === h2);\n    /* And node 0.10 lacks the .equals() method on Buffers. */\n    if (Buffer.isBuffer(h1) && !h1.equals)\n      return (h1.toString('binary') === h2.toString('binary'));\n\n    return (h1.equals(h2));\n  }\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/mime-types/index.js":"/*!\n * mime-types\n * Copyright(c) 2014 Jonathan Ong\n * Copyright(c) 2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n'use strict'\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar db = require('mime-db')\nvar extname = require('path').extname\n\n/**\n * Module variables.\n * @private\n */\n\nvar extractTypeRegExp = /^\\s*([^;\\s]*)(?:;|\\s|$)/\nvar textTypeRegExp = /^text\\//i\n\n/**\n * Module exports.\n * @public\n */\n\nexports.charset = charset\nexports.charsets = { lookup: charset }\nexports.contentType = contentType\nexports.extension = extension\nexports.extensions = Object.create(null)\nexports.lookup = lookup\nexports.types = Object.create(null)\n\n// Populate the extensions/types maps\npopulateMaps(exports.extensions, exports.types)\n\n/**\n * Get the default charset for a MIME type.\n *\n * @param {string} type\n * @return {boolean|string}\n */\n\nfunction charset (type) {\n  if (!type || typeof type !== 'string') {\n    return false\n  }\n\n  // TODO: use media-typer\n  var match = extractTypeRegExp.exec(type)\n  var mime = match && db[match[1].toLowerCase()]\n\n  if (mime && mime.charset) {\n    return mime.charset\n  }\n\n  // default text/* to utf-8\n  if (match && textTypeRegExp.test(match[1])) {\n    return 'UTF-8'\n  }\n\n  return false\n}\n\n/**\n * Create a full Content-Type header given a MIME type or extension.\n *\n * @param {string} str\n * @return {boolean|string}\n */\n\nfunction contentType (str) {\n  // TODO: should this even be in this module?\n  if (!str || typeof str !== 'string') {\n    return false\n  }\n\n  var mime = str.indexOf('/') === -1\n    ? exports.lookup(str)\n    : str\n\n  if (!mime) {\n    return false\n  }\n\n  // TODO: use content-type or other module\n  if (mime.indexOf('charset') === -1) {\n    var charset = exports.charset(mime)\n    if (charset) mime += '; charset=' + charset.toLowerCase()\n  }\n\n  return mime\n}\n\n/**\n * Get the default extension for a MIME type.\n *\n * @param {string} type\n * @return {boolean|string}\n */\n\nfunction extension (type) {\n  if (!type || typeof type !== 'string') {\n    return false\n  }\n\n  // TODO: use media-typer\n  var match = extractTypeRegExp.exec(type)\n\n  // get extensions\n  var exts = match && exports.extensions[match[1].toLowerCase()]\n\n  if (!exts || !exts.length) {\n    return false\n  }\n\n  return exts[0]\n}\n\n/**\n * Lookup the MIME type for a file path/extension.\n *\n * @param {string} path\n * @return {boolean|string}\n */\n\nfunction lookup (path) {\n  if (!path || typeof path !== 'string') {\n    return false\n  }\n\n  // get the extension (\"ext\" or \".ext\" or full path)\n  var extension = extname('x.' + path)\n    .toLowerCase()\n    .substr(1)\n\n  if (!extension) {\n    return false\n  }\n\n  return exports.types[extension] || false\n}\n\n/**\n * Populate the extensions and types maps.\n * @private\n */\n\nfunction populateMaps (extensions, types) {\n  // source preference (least -> most)\n  var preference = ['nginx', 'apache', undefined, 'iana']\n\n  Object.keys(db).forEach(function forEachMimeType (type) {\n    var mime = db[type]\n    var exts = mime.extensions\n\n    if (!exts || !exts.length) {\n      return\n    }\n\n    // mime -> extensions\n    extensions[type] = exts\n\n    // extension -> mime\n    for (var i = 0; i < exts.length; i++) {\n      var extension = exts[i]\n\n      if (types[extension]) {\n        var from = preference.indexOf(db[types[extension]].source)\n        var to = preference.indexOf(mime.source)\n\n        if (types[extension] !== 'application/octet-stream' &&\n          from > to || (from === to && types[extension].substr(0, 12) === 'application/')) {\n          // skip the remapping\n          continue\n        }\n      }\n\n      // set the extension -> mime\n      types[extension] = type\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/mime-types/node_modules/mime-db/index.js":"/*!\n * mime-db\n * Copyright(c) 2014 Jonathan Ong\n * MIT Licensed\n */\n\n/**\n * Module exports.\n */\n\nmodule.exports = require('./db.json')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/stringstream/stringstream.js":"var util = require('util')\nvar Stream = require('stream')\nvar StringDecoder = require('string_decoder').StringDecoder\n\nmodule.exports = StringStream\nmodule.exports.AlignedStringDecoder = AlignedStringDecoder\n\nfunction StringStream(from, to) {\n  if (!(this instanceof StringStream)) return new StringStream(from, to)\n\n  Stream.call(this)\n\n  if (from == null) from = 'utf8'\n\n  this.readable = this.writable = true\n  this.paused = false\n  this.toEncoding = (to == null ? from : to)\n  this.fromEncoding = (to == null ? '' : from)\n  this.decoder = new AlignedStringDecoder(this.toEncoding)\n}\nutil.inherits(StringStream, Stream)\n\nStringStream.prototype.write = function(data) {\n  if (!this.writable) {\n    var err = new Error('stream not writable')\n    err.code = 'EPIPE'\n    this.emit('error', err)\n    return false\n  }\n  if (this.fromEncoding) {\n    if (Buffer.isBuffer(data)) data = data.toString()\n    data = new Buffer(data, this.fromEncoding)\n  }\n  var string = this.decoder.write(data)\n  if (string.length) this.emit('data', string)\n  return !this.paused\n}\n\nStringStream.prototype.flush = function() {\n  if (this.decoder.flush) {\n    var string = this.decoder.flush()\n    if (string.length) this.emit('data', string)\n  }\n}\n\nStringStream.prototype.end = function() {\n  if (!this.writable && !this.readable) return\n  this.flush()\n  this.emit('end')\n  this.writable = this.readable = false\n  this.destroy()\n}\n\nStringStream.prototype.destroy = function() {\n  this.decoder = null\n  this.writable = this.readable = false\n  this.emit('close')\n}\n\nStringStream.prototype.pause = function() {\n  this.paused = true\n}\n\nStringStream.prototype.resume = function () {\n  if (this.paused) this.emit('drain')\n  this.paused = false\n}\n\nfunction AlignedStringDecoder(encoding) {\n  StringDecoder.call(this, encoding)\n\n  switch (this.encoding) {\n    case 'base64':\n      this.write = alignedWrite\n      this.alignedBuffer = new Buffer(3)\n      this.alignedBytes = 0\n      break\n  }\n}\nutil.inherits(AlignedStringDecoder, StringDecoder)\n\nAlignedStringDecoder.prototype.flush = function() {\n  if (!this.alignedBuffer || !this.alignedBytes) return ''\n  var leftover = this.alignedBuffer.toString(this.encoding, 0, this.alignedBytes)\n  this.alignedBytes = 0\n  return leftover\n}\n\nfunction alignedWrite(buffer) {\n  var rem = (this.alignedBytes + buffer.length) % this.alignedBuffer.length\n  if (!rem && !this.alignedBytes) return buffer.toString(this.encoding)\n\n  var returnBuffer = new Buffer(this.alignedBytes + buffer.length - rem)\n\n  this.alignedBuffer.copy(returnBuffer, 0, 0, this.alignedBytes)\n  buffer.copy(returnBuffer, this.alignedBytes, 0, buffer.length - rem)\n\n  buffer.copy(this.alignedBuffer, 0, buffer.length - rem, buffer.length)\n  this.alignedBytes = rem\n\n  return returnBuffer.toString(this.encoding)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/caseless/index.js":"function Caseless (dict) {\n  this.dict = dict || {}\n}\nCaseless.prototype.set = function (name, value, clobber) {\n  if (typeof name === 'object') {\n    for (var i in name) {\n      this.set(i, name[i], value)\n    }\n  } else {\n    if (typeof clobber === 'undefined') clobber = true\n    var has = this.has(name)\n\n    if (!clobber && has) this.dict[has] = this.dict[has] + ',' + value\n    else this.dict[has || name] = value\n    return has\n  }\n}\nCaseless.prototype.has = function (name) {\n  var keys = Object.keys(this.dict)\n    , name = name.toLowerCase()\n    ;\n  for (var i=0;i<keys.length;i++) {\n    if (keys[i].toLowerCase() === name) return keys[i]\n  }\n  return false\n}\nCaseless.prototype.get = function (name) {\n  name = name.toLowerCase()\n  var result, _key\n  var headers = this.dict\n  Object.keys(headers).forEach(function (key) {\n    _key = key.toLowerCase()\n    if (name === _key) result = headers[key]\n  })\n  return result\n}\nCaseless.prototype.swap = function (name) {\n  var has = this.has(name)\n  if (has === name) return\n  if (!has) throw new Error('There is no header than matches \"'+name+'\"')\n  this.dict[name] = this.dict[has]\n  delete this.dict[has]\n}\nCaseless.prototype.del = function (name) {\n  var has = this.has(name)\n  return delete this.dict[has || name]\n}\n\nmodule.exports = function (dict) {return new Caseless(dict)}\nmodule.exports.httpify = function (resp, headers) {\n  var c = new Caseless(headers)\n  resp.setHeader = function (key, value, clobber) {\n    if (typeof value === 'undefined') return\n    return c.set(key, value, clobber)\n  }\n  resp.hasHeader = function (key) {\n    return c.has(key)\n  }\n  resp.getHeader = function (key) {\n    return c.get(key)\n  }\n  resp.removeHeader = function (key) {\n    return c.del(key)\n  }\n  resp.headers = c.dict\n  return c\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/forever-agent/index.js":"module.exports = ForeverAgent\nForeverAgent.SSL = ForeverAgentSSL\n\nvar util = require('util')\n  , Agent = require('http').Agent\n  , net = require('net')\n  , tls = require('tls')\n  , AgentSSL = require('https').Agent\n  \nfunction getConnectionName(host, port) {  \n  var name = ''\n  if (typeof host === 'string') {\n    name = host + ':' + port\n  } else {\n    // For node.js v012.0 and iojs-v1.5.1, host is an object. And any existing localAddress is part of the connection name.\n    name = host.host + ':' + host.port + ':' + (host.localAddress ? (host.localAddress + ':') : ':')\n  }\n  return name\n}    \n\nfunction ForeverAgent(options) {\n  var self = this\n  self.options = options || {}\n  self.requests = {}\n  self.sockets = {}\n  self.freeSockets = {}\n  self.maxSockets = self.options.maxSockets || Agent.defaultMaxSockets\n  self.minSockets = self.options.minSockets || ForeverAgent.defaultMinSockets\n  self.on('free', function(socket, host, port) {\n    var name = getConnectionName(host, port)\n\n    if (self.requests[name] && self.requests[name].length) {\n      self.requests[name].shift().onSocket(socket)\n    } else if (self.sockets[name].length < self.minSockets) {\n      if (!self.freeSockets[name]) self.freeSockets[name] = []\n      self.freeSockets[name].push(socket)\n      \n      // if an error happens while we don't use the socket anyway, meh, throw the socket away\n      var onIdleError = function() {\n        socket.destroy()\n      }\n      socket._onIdleError = onIdleError\n      socket.on('error', onIdleError)\n    } else {\n      // If there are no pending requests just destroy the\n      // socket and it will get removed from the pool. This\n      // gets us out of timeout issues and allows us to\n      // default to Connection:keep-alive.\n      socket.destroy()\n    }\n  })\n\n}\nutil.inherits(ForeverAgent, Agent)\n\nForeverAgent.defaultMinSockets = 5\n\n\nForeverAgent.prototype.createConnection = net.createConnection\nForeverAgent.prototype.addRequestNoreuse = Agent.prototype.addRequest\nForeverAgent.prototype.addRequest = function(req, host, port) {\n  var name = getConnectionName(host, port)\n  \n  if (typeof host !== 'string') {\n    var options = host\n    port = options.port\n    host = options.host\n  }\n\n  if (this.freeSockets[name] && this.freeSockets[name].length > 0 && !req.useChunkedEncodingByDefault) {\n    var idleSocket = this.freeSockets[name].pop()\n    idleSocket.removeListener('error', idleSocket._onIdleError)\n    delete idleSocket._onIdleError\n    req._reusedSocket = true\n    req.onSocket(idleSocket)\n  } else {\n    this.addRequestNoreuse(req, host, port)\n  }\n}\n\nForeverAgent.prototype.removeSocket = function(s, name, host, port) {\n  if (this.sockets[name]) {\n    var index = this.sockets[name].indexOf(s)\n    if (index !== -1) {\n      this.sockets[name].splice(index, 1)\n    }\n  } else if (this.sockets[name] && this.sockets[name].length === 0) {\n    // don't leak\n    delete this.sockets[name]\n    delete this.requests[name]\n  }\n  \n  if (this.freeSockets[name]) {\n    var index = this.freeSockets[name].indexOf(s)\n    if (index !== -1) {\n      this.freeSockets[name].splice(index, 1)\n      if (this.freeSockets[name].length === 0) {\n        delete this.freeSockets[name]\n      }\n    }\n  }\n\n  if (this.requests[name] && this.requests[name].length) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(name, host, port).emit('free')\n  }\n}\n\nfunction ForeverAgentSSL (options) {\n  ForeverAgent.call(this, options)\n}\nutil.inherits(ForeverAgentSSL, ForeverAgent)\n\nForeverAgentSSL.prototype.createConnection = createConnectionSSL\nForeverAgentSSL.prototype.addRequestNoreuse = AgentSSL.prototype.addRequest\n\nfunction createConnectionSSL (port, host, options) {\n  if (typeof port === 'object') {\n    options = port;\n  } else if (typeof host === 'object') {\n    options = host;\n  } else if (typeof options === 'object') {\n    options = options;\n  } else {\n    options = {};\n  }\n\n  if (typeof port === 'number') {\n    options.port = port;\n  }\n\n  if (typeof host === 'string') {\n    options.host = host;\n  }\n\n  return tls.connect(options);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/lib/form_data.js":"var CombinedStream = require('combined-stream');\nvar util = require('util');\nvar path = require('path');\nvar http = require('http');\nvar https = require('https');\nvar parseUrl = require('url').parse;\nvar fs = require('fs');\nvar mime = require('mime-types');\nvar asynckit = require('asynckit');\nvar populate = require('./populate.js');\n\n// Public API\nmodule.exports = FormData;\n\n// make it a Stream\nutil.inherits(FormData, CombinedStream);\n\n/**\n * Create readable \"multipart/form-data\" streams.\n * Can be used to submit forms\n * and file uploads to other web applications.\n *\n * @constructor\n */\nfunction FormData() {\n  if (!(this instanceof FormData)) {\n    return new FormData();\n  }\n\n  this._overheadLength = 0;\n  this._valueLength = 0;\n  this._valuesToMeasure = [];\n\n  CombinedStream.call(this);\n}\n\nFormData.LINE_BREAK = '\\r\\n';\nFormData.DEFAULT_CONTENT_TYPE = 'application/octet-stream';\n\nFormData.prototype.append = function(field, value, options) {\n\n  options = options || {};\n\n  // allow filename as single option\n  if (typeof options == 'string') {\n    options = {filename: options};\n  }\n\n  var append = CombinedStream.prototype.append.bind(this);\n\n  // all that streamy business can't handle numbers\n  if (typeof value == 'number') {\n    value = '' + value;\n  }\n\n  // https://github.com/felixge/node-form-data/issues/38\n  if (util.isArray(value)) {\n    // Please convert your array into string\n    // the way web server expects it\n    this._error(new Error('Arrays are not supported.'));\n    return;\n  }\n\n  var header = this._multiPartHeader(field, value, options);\n  var footer = this._multiPartFooter();\n\n  append(header);\n  append(value);\n  append(footer);\n\n  // pass along options.knownLength\n  this._trackLength(header, value, options);\n};\n\nFormData.prototype._trackLength = function(header, value, options) {\n  var valueLength = 0;\n\n  // used w/ getLengthSync(), when length is known.\n  // e.g. for streaming directly from a remote server,\n  // w/ a known file a size, and not wanting to wait for\n  // incoming file to finish to get its size.\n  if (options.knownLength != null) {\n    valueLength += +options.knownLength;\n  } else if (Buffer.isBuffer(value)) {\n    valueLength = value.length;\n  } else if (typeof value === 'string') {\n    valueLength = Buffer.byteLength(value);\n  }\n\n  this._valueLength += valueLength;\n\n  // @check why add CRLF? does this account for custom/multiple CRLFs?\n  this._overheadLength +=\n    Buffer.byteLength(header) +\n    FormData.LINE_BREAK.length;\n\n  // empty or either doesn't have path or not an http response\n  if (!value || ( !value.path && !(value.readable && value.hasOwnProperty('httpVersion')) )) {\n    return;\n  }\n\n  // no need to bother with the length\n  if (!options.knownLength) {\n    this._valuesToMeasure.push(value);\n  }\n};\n\nFormData.prototype._lengthRetriever = function(value, callback) {\n\n  if (value.hasOwnProperty('fd')) {\n\n    // take read range into a account\n    // `end` = Infinity > read file till the end\n    //\n    // TODO: Looks like there is bug in Node fs.createReadStream\n    // it doesn't respect `end` options without `start` options\n    // Fix it when node fixes it.\n    // https://github.com/joyent/node/issues/7819\n    if (value.end != undefined && value.end != Infinity && value.start != undefined) {\n\n      // when end specified\n      // no need to calculate range\n      // inclusive, starts with 0\n      callback(null, value.end + 1 - (value.start ? value.start : 0));\n\n    // not that fast snoopy\n    } else {\n      // still need to fetch file size from fs\n      fs.stat(value.path, function(err, stat) {\n\n        var fileSize;\n\n        if (err) {\n          callback(err);\n          return;\n        }\n\n        // update final size based on the range options\n        fileSize = stat.size - (value.start ? value.start : 0);\n        callback(null, fileSize);\n      });\n    }\n\n  // or http response\n  } else if (value.hasOwnProperty('httpVersion')) {\n    callback(null, +value.headers['content-length']);\n\n  // or request stream http://github.com/mikeal/request\n  } else if (value.hasOwnProperty('httpModule')) {\n    // wait till response come back\n    value.on('response', function(response) {\n      value.pause();\n      callback(null, +response.headers['content-length']);\n    });\n    value.resume();\n\n  // something else\n  } else {\n    callback('Unknown stream');\n  }\n};\n\nFormData.prototype._multiPartHeader = function(field, value, options) {\n  // custom header specified (as string)?\n  // it becomes responsible for boundary\n  // (e.g. to handle extra CRLFs on .NET servers)\n  if (typeof options.header == 'string') {\n    return options.header;\n  }\n\n  var contentDisposition = this._getContentDisposition(value, options);\n  var contentType = this._getContentType(value, options);\n\n  var contents = '';\n  var headers  = {\n    // add custom disposition as third element or keep it two elements if not\n    'Content-Disposition': ['form-data', 'name=\"' + field + '\"'].concat(contentDisposition || []),\n    // if no content type. allow it to be empty array\n    'Content-Type': [].concat(contentType || [])\n  };\n\n  // allow custom headers.\n  if (typeof options.header == 'object') {\n    populate(headers, options.header);\n  }\n\n  var header;\n  for (var prop in headers) {\n    header = headers[prop];\n\n    // skip nullish headers.\n    if (header == null) {\n      continue;\n    }\n\n    // convert all headers to arrays.\n    if (!Array.isArray(header)) {\n      header = [header];\n    }\n\n    // add non-empty headers.\n    if (header.length) {\n      contents += prop + ': ' + header.join('; ') + FormData.LINE_BREAK;\n    }\n  }\n\n  return '--' + this.getBoundary() + FormData.LINE_BREAK + contents + FormData.LINE_BREAK;\n};\n\nFormData.prototype._getContentDisposition = function(value, options) {\n\n  var contentDisposition;\n\n  // custom filename takes precedence\n  // fs- and request- streams have path property\n  // formidable and the browser add a name property.\n  var filename = options.filename || value.name || value.path;\n\n  // or try http response\n  if (!filename && value.readable && value.hasOwnProperty('httpVersion')) {\n    filename = value.client._httpMessage.path;\n  }\n\n  if (filename) {\n    contentDisposition = 'filename=\"' + path.basename(filename) + '\"';\n  }\n\n  return contentDisposition;\n};\n\nFormData.prototype._getContentType = function(value, options) {\n\n  // use custom content-type above all\n  var contentType = options.contentType;\n\n  // or try `name` from formidable, browser\n  if (!contentType && value.name) {\n    contentType = mime.lookup(value.name);\n  }\n\n  // or try `path` from fs-, request- streams\n  if (!contentType && value.path) {\n    contentType = mime.lookup(value.path);\n  }\n\n  // or if it's http-reponse\n  if (!contentType && value.readable && value.hasOwnProperty('httpVersion')) {\n    contentType = value.headers['content-type'];\n  }\n\n  // or guess it from the filename\n  if (!contentType && options.filename) {\n    contentType = mime.lookup(options.filename);\n  }\n\n  // fallback to the default content type if `value` is not simple value\n  if (!contentType && typeof value == 'object') {\n    contentType = FormData.DEFAULT_CONTENT_TYPE;\n  }\n\n  return contentType;\n};\n\nFormData.prototype._multiPartFooter = function() {\n  return function(next) {\n    var footer = FormData.LINE_BREAK;\n\n    var lastPart = (this._streams.length === 0);\n    if (lastPart) {\n      footer += this._lastBoundary();\n    }\n\n    next(footer);\n  }.bind(this);\n};\n\nFormData.prototype._lastBoundary = function() {\n  return '--' + this.getBoundary() + '--' + FormData.LINE_BREAK;\n};\n\nFormData.prototype.getHeaders = function(userHeaders) {\n  var header;\n  var formHeaders = {\n    'content-type': 'multipart/form-data; boundary=' + this.getBoundary()\n  };\n\n  for (header in userHeaders) {\n    if (userHeaders.hasOwnProperty(header)) {\n      formHeaders[header.toLowerCase()] = userHeaders[header];\n    }\n  }\n\n  return formHeaders;\n};\n\nFormData.prototype.getBoundary = function() {\n  if (!this._boundary) {\n    this._generateBoundary();\n  }\n\n  return this._boundary;\n};\n\nFormData.prototype._generateBoundary = function() {\n  // This generates a 50 character boundary similar to those used by Firefox.\n  // They are optimized for boyer-moore parsing.\n  var boundary = '--------------------------';\n  for (var i = 0; i < 24; i++) {\n    boundary += Math.floor(Math.random() * 10).toString(16);\n  }\n\n  this._boundary = boundary;\n};\n\n// Note: getLengthSync DOESN'T calculate streams length\n// As workaround one can calculate file size manually\n// and add it as knownLength option\nFormData.prototype.getLengthSync = function() {\n  var knownLength = this._overheadLength + this._valueLength;\n\n  // Don't get confused, there are 3 \"internal\" streams for each keyval pair\n  // so it basically checks if there is any value added to the form\n  if (this._streams.length) {\n    knownLength += this._lastBoundary().length;\n  }\n\n  // https://github.com/form-data/form-data/issues/40\n  if (!this.hasKnownLength()) {\n    // Some async length retrievers are present\n    // therefore synchronous length calculation is false.\n    // Please use getLength(callback) to get proper length\n    this._error(new Error('Cannot calculate proper length in synchronous way.'));\n  }\n\n  return knownLength;\n};\n\n// Public API to check if length of added values is known\n// https://github.com/form-data/form-data/issues/196\n// https://github.com/form-data/form-data/issues/262\nFormData.prototype.hasKnownLength = function() {\n  var hasKnownLength = true;\n\n  if (this._valuesToMeasure.length) {\n    hasKnownLength = false;\n  }\n\n  return hasKnownLength;\n};\n\nFormData.prototype.getLength = function(cb) {\n  var knownLength = this._overheadLength + this._valueLength;\n\n  if (this._streams.length) {\n    knownLength += this._lastBoundary().length;\n  }\n\n  if (!this._valuesToMeasure.length) {\n    process.nextTick(cb.bind(this, null, knownLength));\n    return;\n  }\n\n  asynckit.parallel(this._valuesToMeasure, this._lengthRetriever, function(err, values) {\n    if (err) {\n      cb(err);\n      return;\n    }\n\n    values.forEach(function(length) {\n      knownLength += length;\n    });\n\n    cb(null, knownLength);\n  });\n};\n\nFormData.prototype.submit = function(params, cb) {\n  var request\n    , options\n    , defaults = {method: 'post'}\n    ;\n\n  // parse provided url if it's string\n  // or treat it as options object\n  if (typeof params == 'string') {\n\n    params = parseUrl(params);\n    options = populate({\n      port: params.port,\n      path: params.pathname,\n      host: params.hostname\n    }, defaults);\n\n  // use custom params\n  } else {\n\n    options = populate(params, defaults);\n    // if no port provided use default one\n    if (!options.port) {\n      options.port = options.protocol == 'https:' ? 443 : 80;\n    }\n  }\n\n  // put that good code in getHeaders to some use\n  options.headers = this.getHeaders(params.headers);\n\n  // https if specified, fallback to http in any other case\n  if (options.protocol == 'https:') {\n    request = https.request(options);\n  } else {\n    request = http.request(options);\n  }\n\n  // get content length and fire away\n  this.getLength(function(err, length) {\n    if (err) {\n      this._error(err);\n      return;\n    }\n\n    // add content length\n    request.setHeader('Content-Length', length);\n\n    this.pipe(request);\n    if (cb) {\n      request.on('error', cb);\n      request.on('response', cb.bind(this, null));\n    }\n  }.bind(this));\n\n  return request;\n};\n\nFormData.prototype._error = function(err) {\n  if (!this.error) {\n    this.error = err;\n    this.pause();\n    this.emit('error', err);\n  }\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/combined-stream/lib/combined_stream.js":"var util = require('util');\nvar Stream = require('stream').Stream;\nvar DelayedStream = require('delayed-stream');\n\nmodule.exports = CombinedStream;\nfunction CombinedStream() {\n  this.writable = false;\n  this.readable = true;\n  this.dataSize = 0;\n  this.maxDataSize = 2 * 1024 * 1024;\n  this.pauseStreams = true;\n\n  this._released = false;\n  this._streams = [];\n  this._currentStream = null;\n}\nutil.inherits(CombinedStream, Stream);\n\nCombinedStream.create = function(options) {\n  var combinedStream = new this();\n\n  options = options || {};\n  for (var option in options) {\n    combinedStream[option] = options[option];\n  }\n\n  return combinedStream;\n};\n\nCombinedStream.isStreamLike = function(stream) {\n  return (typeof stream !== 'function')\n    && (typeof stream !== 'string')\n    && (typeof stream !== 'boolean')\n    && (typeof stream !== 'number')\n    && (!Buffer.isBuffer(stream));\n};\n\nCombinedStream.prototype.append = function(stream) {\n  var isStreamLike = CombinedStream.isStreamLike(stream);\n\n  if (isStreamLike) {\n    if (!(stream instanceof DelayedStream)) {\n      var newStream = DelayedStream.create(stream, {\n        maxDataSize: Infinity,\n        pauseStream: this.pauseStreams,\n      });\n      stream.on('data', this._checkDataSize.bind(this));\n      stream = newStream;\n    }\n\n    this._handleErrors(stream);\n\n    if (this.pauseStreams) {\n      stream.pause();\n    }\n  }\n\n  this._streams.push(stream);\n  return this;\n};\n\nCombinedStream.prototype.pipe = function(dest, options) {\n  Stream.prototype.pipe.call(this, dest, options);\n  this.resume();\n  return dest;\n};\n\nCombinedStream.prototype._getNext = function() {\n  this._currentStream = null;\n  var stream = this._streams.shift();\n\n\n  if (typeof stream == 'undefined') {\n    this.end();\n    return;\n  }\n\n  if (typeof stream !== 'function') {\n    this._pipeNext(stream);\n    return;\n  }\n\n  var getStream = stream;\n  getStream(function(stream) {\n    var isStreamLike = CombinedStream.isStreamLike(stream);\n    if (isStreamLike) {\n      stream.on('data', this._checkDataSize.bind(this));\n      this._handleErrors(stream);\n    }\n\n    this._pipeNext(stream);\n  }.bind(this));\n};\n\nCombinedStream.prototype._pipeNext = function(stream) {\n  this._currentStream = stream;\n\n  var isStreamLike = CombinedStream.isStreamLike(stream);\n  if (isStreamLike) {\n    stream.on('end', this._getNext.bind(this));\n    stream.pipe(this, {end: false});\n    return;\n  }\n\n  var value = stream;\n  this.write(value);\n  this._getNext();\n};\n\nCombinedStream.prototype._handleErrors = function(stream) {\n  var self = this;\n  stream.on('error', function(err) {\n    self._emitError(err);\n  });\n};\n\nCombinedStream.prototype.write = function(data) {\n  this.emit('data', data);\n};\n\nCombinedStream.prototype.pause = function() {\n  if (!this.pauseStreams) {\n    return;\n  }\n\n  if(this.pauseStreams && this._currentStream && typeof(this._currentStream.pause) == 'function') this._currentStream.pause();\n  this.emit('pause');\n};\n\nCombinedStream.prototype.resume = function() {\n  if (!this._released) {\n    this._released = true;\n    this.writable = true;\n    this._getNext();\n  }\n\n  if(this.pauseStreams && this._currentStream && typeof(this._currentStream.resume) == 'function') this._currentStream.resume();\n  this.emit('resume');\n};\n\nCombinedStream.prototype.end = function() {\n  this._reset();\n  this.emit('end');\n};\n\nCombinedStream.prototype.destroy = function() {\n  this._reset();\n  this.emit('close');\n};\n\nCombinedStream.prototype._reset = function() {\n  this.writable = false;\n  this._streams = [];\n  this._currentStream = null;\n};\n\nCombinedStream.prototype._checkDataSize = function() {\n  this._updateDataSize();\n  if (this.dataSize <= this.maxDataSize) {\n    return;\n  }\n\n  var message =\n    'DelayedStream#maxDataSize of ' + this.maxDataSize + ' bytes exceeded.';\n  this._emitError(new Error(message));\n};\n\nCombinedStream.prototype._updateDataSize = function() {\n  this.dataSize = 0;\n\n  var self = this;\n  this._streams.forEach(function(stream) {\n    if (!stream.dataSize) {\n      return;\n    }\n\n    self.dataSize += stream.dataSize;\n  });\n\n  if (this._currentStream && this._currentStream.dataSize) {\n    this.dataSize += this._currentStream.dataSize;\n  }\n};\n\nCombinedStream.prototype._emitError = function(err) {\n  this._reset();\n  this.emit('error', err);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/combined-stream/node_modules/delayed-stream/lib/delayed_stream.js":"var Stream = require('stream').Stream;\nvar util = require('util');\n\nmodule.exports = DelayedStream;\nfunction DelayedStream() {\n  this.source = null;\n  this.dataSize = 0;\n  this.maxDataSize = 1024 * 1024;\n  this.pauseStream = true;\n\n  this._maxDataSizeExceeded = false;\n  this._released = false;\n  this._bufferedEvents = [];\n}\nutil.inherits(DelayedStream, Stream);\n\nDelayedStream.create = function(source, options) {\n  var delayedStream = new this();\n\n  options = options || {};\n  for (var option in options) {\n    delayedStream[option] = options[option];\n  }\n\n  delayedStream.source = source;\n\n  var realEmit = source.emit;\n  source.emit = function() {\n    delayedStream._handleEmit(arguments);\n    return realEmit.apply(source, arguments);\n  };\n\n  source.on('error', function() {});\n  if (delayedStream.pauseStream) {\n    source.pause();\n  }\n\n  return delayedStream;\n};\n\nObject.defineProperty(DelayedStream.prototype, 'readable', {\n  configurable: true,\n  enumerable: true,\n  get: function() {\n    return this.source.readable;\n  }\n});\n\nDelayedStream.prototype.setEncoding = function() {\n  return this.source.setEncoding.apply(this.source, arguments);\n};\n\nDelayedStream.prototype.resume = function() {\n  if (!this._released) {\n    this.release();\n  }\n\n  this.source.resume();\n};\n\nDelayedStream.prototype.pause = function() {\n  this.source.pause();\n};\n\nDelayedStream.prototype.release = function() {\n  this._released = true;\n\n  this._bufferedEvents.forEach(function(args) {\n    this.emit.apply(this, args);\n  }.bind(this));\n  this._bufferedEvents = [];\n};\n\nDelayedStream.prototype.pipe = function() {\n  var r = Stream.prototype.pipe.apply(this, arguments);\n  this.resume();\n  return r;\n};\n\nDelayedStream.prototype._handleEmit = function(args) {\n  if (this._released) {\n    this.emit.apply(this, args);\n    return;\n  }\n\n  if (args[0] === 'data') {\n    this.dataSize += args[1].length;\n    this._checkIfMaxDataSizeExceeded();\n  }\n\n  this._bufferedEvents.push(args);\n};\n\nDelayedStream.prototype._checkIfMaxDataSizeExceeded = function() {\n  if (this._maxDataSizeExceeded) {\n    return;\n  }\n\n  if (this.dataSize <= this.maxDataSize) {\n    return;\n  }\n\n  this._maxDataSizeExceeded = true;\n  var message =\n    'DelayedStream#maxDataSize of ' + this.maxDataSize + ' bytes exceeded.'\n  this.emit('error', new Error(message));\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/index.js":"module.exports =\n{\n  parallel      : require('./parallel.js'),\n  serial        : require('./serial.js'),\n  serialOrdered : require('./serialOrdered.js')\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/parallel.js":"var iterate    = require('./lib/iterate.js')\n  , initState  = require('./lib/state.js')\n  , terminator = require('./lib/terminator.js')\n  ;\n\n// Public API\nmodule.exports = parallel;\n\n/**\n * Runs iterator over provided array elements in parallel\n *\n * @param   {array|object} list - array or object (named list) to iterate over\n * @param   {function} iterator - iterator to run\n * @param   {function} callback - invoked when all elements processed\n * @returns {function} - jobs terminator\n */\nfunction parallel(list, iterator, callback)\n{\n  var state = initState(list);\n\n  while (state.index < (state['keyedList'] || list).length)\n  {\n    iterate(list, iterator, state, function(error, result)\n    {\n      if (error)\n      {\n        callback(error, result);\n        return;\n      }\n\n      // looks like it's the last one\n      if (Object.keys(state.jobs).length === 0)\n      {\n        callback(null, state.results);\n        return;\n      }\n    });\n\n    state.index++;\n  }\n\n  return terminator.bind(state, callback);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/lib/iterate.js":"var async = require('./async.js')\n  , abort = require('./abort.js')\n  ;\n\n// API\nmodule.exports = iterate;\n\n/**\n * Iterates over each job object\n *\n * @param {array|object} list - array or object (named list) to iterate over\n * @param {function} iterator - iterator to run\n * @param {object} state - current job status\n * @param {function} callback - invoked when all elements processed\n */\nfunction iterate(list, iterator, state, callback)\n{\n  // store current index\n  var key = state['keyedList'] ? state['keyedList'][state.index] : state.index;\n\n  state.jobs[key] = runJob(iterator, key, list[key], function(error, output)\n  {\n    // don't repeat yourself\n    // skip secondary callbacks\n    if (!(key in state.jobs))\n    {\n      return;\n    }\n\n    // clean up jobs\n    delete state.jobs[key];\n\n    if (error)\n    {\n      // don't process rest of the results\n      // stop still active jobs\n      // and reset the list\n      abort(state);\n    }\n    else\n    {\n      state.results[key] = output;\n    }\n\n    // return salvaged results\n    callback(error, state.results);\n  });\n}\n\n/**\n * Runs iterator over provided job element\n *\n * @param   {function} iterator - iterator to invoke\n * @param   {string|number} key - key/index of the element in the list of jobs\n * @param   {mixed} item - job description\n * @param   {function} callback - invoked after iterator is done with the job\n * @returns {function|mixed} - job abort function or something else\n */\nfunction runJob(iterator, key, item, callback)\n{\n  var aborter;\n\n  // allow shortcut if iterator expects only two arguments\n  if (iterator.length == 2)\n  {\n    aborter = iterator(item, async(callback));\n  }\n  // otherwise go with full three arguments\n  else\n  {\n    aborter = iterator(item, key, async(callback));\n  }\n\n  return aborter;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/lib/async.js":"var defer = require('./defer.js');\n\n// API\nmodule.exports = async;\n\n/**\n * Runs provided callback asynchronously\n * even if callback itself is not\n *\n * @param   {function} callback - callback to invoke\n * @returns {function} - augmented callback\n */\nfunction async(callback)\n{\n  var isAsync = false;\n\n  // check if async happened\n  defer(function() { isAsync = true; });\n\n  return function async_callback(err, result)\n  {\n    if (isAsync)\n    {\n      callback(err, result);\n    }\n    else\n    {\n      defer(function nextTick_callback()\n      {\n        callback(err, result);\n      });\n    }\n  };\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/lib/defer.js":"module.exports = defer;\n\n/**\n * Runs provided function on next iteration of the event loop\n *\n * @param {function} fn - function to run\n */\nfunction defer(fn)\n{\n  var nextTick = typeof setImmediate == 'function'\n    ? setImmediate\n    : (\n      typeof process == 'object' && typeof process.nextTick == 'function'\n      ? process.nextTick\n      : null\n    );\n\n  if (nextTick)\n  {\n    nextTick(fn);\n  }\n  else\n  {\n    setTimeout(fn, 0);\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/lib/abort.js":"// API\nmodule.exports = abort;\n\n/**\n * Aborts leftover active jobs\n *\n * @param {object} state - current state object\n */\nfunction abort(state)\n{\n  Object.keys(state.jobs).forEach(clean.bind(state));\n\n  // reset leftover jobs\n  state.jobs = {};\n}\n\n/**\n * Cleans up leftover job by invoking abort function for the provided job id\n *\n * @this  state\n * @param {string|number} key - job id to abort\n */\nfunction clean(key)\n{\n  if (typeof this.jobs[key] == 'function')\n  {\n    this.jobs[key]();\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/lib/state.js":"// API\nmodule.exports = state;\n\n/**\n * Creates initial state object\n * for iteration over list\n *\n * @param   {array|object} list - list to iterate over\n * @param   {function|null} sortMethod - function to use for keys sort,\n *                                     or `null` to keep them as is\n * @returns {object} - initial state object\n */\nfunction state(list, sortMethod)\n{\n  var isNamedList = !Array.isArray(list)\n    , initState =\n    {\n      index    : 0,\n      keyedList: isNamedList || sortMethod ? Object.keys(list) : null,\n      jobs     : {},\n      results  : isNamedList ? {} : [],\n      size     : isNamedList ? Object.keys(list).length : list.length\n    }\n    ;\n\n  if (sortMethod)\n  {\n    // sort array keys based on it's values\n    // sort object's keys just on own merit\n    initState.keyedList.sort(isNamedList ? sortMethod : function(a, b)\n    {\n      return sortMethod(list[a], list[b]);\n    });\n  }\n\n  return initState;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/lib/terminator.js":"var abort = require('./abort.js')\n  , async = require('./async.js')\n  ;\n\n// API\nmodule.exports = terminator;\n\n/**\n * Terminates jobs in the attached state context\n *\n * @this  AsyncKitState#\n * @param {function} callback - final callback to invoke after termination\n */\nfunction terminator(callback)\n{\n  if (!Object.keys(this.jobs).length)\n  {\n    return;\n  }\n\n  // fast forward iteration index\n  this.index = this.size;\n\n  // abort jobs\n  abort(this);\n\n  // send back results we have so far\n  async(callback)(null, this.results);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/serial.js":"var serialOrdered = require('./serialOrdered.js');\n\n// Public API\nmodule.exports = serial;\n\n/**\n * Runs iterator over provided array elements in series\n *\n * @param   {array|object} list - array or object (named list) to iterate over\n * @param   {function} iterator - iterator to run\n * @param   {function} callback - invoked when all elements processed\n * @returns {function} - jobs terminator\n */\nfunction serial(list, iterator, callback)\n{\n  return serialOrdered(list, iterator, null, callback);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/node_modules/asynckit/serialOrdered.js":"var iterate    = require('./lib/iterate.js')\n  , initState  = require('./lib/state.js')\n  , terminator = require('./lib/terminator.js')\n  ;\n\n// Public API\nmodule.exports = serialOrdered;\n// sorting helpers\nmodule.exports.ascending  = ascending;\nmodule.exports.descending = descending;\n\n/**\n * Runs iterator over provided sorted array elements in series\n *\n * @param   {array|object} list - array or object (named list) to iterate over\n * @param   {function} iterator - iterator to run\n * @param   {function} sortMethod - custom sort function\n * @param   {function} callback - invoked when all elements processed\n * @returns {function} - jobs terminator\n */\nfunction serialOrdered(list, iterator, sortMethod, callback)\n{\n  var state = initState(list, sortMethod);\n\n  iterate(list, iterator, state, function iteratorHandler(error, result)\n  {\n    if (error)\n    {\n      callback(error, result);\n      return;\n    }\n\n    state.index++;\n\n    // are we there yet?\n    if (state.index < (state['keyedList'] || list).length)\n    {\n      iterate(list, iterator, state, iteratorHandler);\n      return;\n    }\n\n    // done here\n    callback(null, state.results);\n  });\n\n  return terminator.bind(state, callback);\n}\n\n/*\n * -- Sort methods\n */\n\n/**\n * sort helper to sort array elements in ascending order\n *\n * @param   {mixed} a - an item to compare\n * @param   {mixed} b - an item to compare\n * @returns {number} - comparison result\n */\nfunction ascending(a, b)\n{\n  return a < b ? -1 : a > b ? 1 : 0;\n}\n\n/**\n * sort helper to sort array elements in descending order\n *\n * @param   {mixed} a - an item to compare\n * @param   {mixed} b - an item to compare\n * @returns {number} - comparison result\n */\nfunction descending(a, b)\n{\n  return -1 * ascending(a, b);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/form-data/lib/populate.js":"// populates missing values\nmodule.exports = function(dst, src) {\n\n  Object.keys(src).forEach(function(prop)\n  {\n    dst[prop] = dst[prop] || src[prop];\n  });\n\n  return dst;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/isstream/isstream.js":"var stream = require('stream')\n\n\nfunction isStream (obj) {\n  return obj instanceof stream.Stream\n}\n\n\nfunction isReadable (obj) {\n  return isStream(obj) && typeof obj._read == 'function' && typeof obj._readableState == 'object'\n}\n\n\nfunction isWritable (obj) {\n  return isStream(obj) && typeof obj._write == 'function' && typeof obj._writableState == 'object'\n}\n\n\nfunction isDuplex (obj) {\n  return isReadable(obj) && isWritable(obj)\n}\n\n\nmodule.exports            = isStream\nmodule.exports.isReadable = isReadable\nmodule.exports.isWritable = isWritable\nmodule.exports.isDuplex   = isDuplex\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/is-typedarray/index.js":"module.exports      = isTypedArray\nisTypedArray.strict = isStrictTypedArray\nisTypedArray.loose  = isLooseTypedArray\n\nvar toString = Object.prototype.toString\nvar names = {\n    '[object Int8Array]': true\n  , '[object Int16Array]': true\n  , '[object Int32Array]': true\n  , '[object Uint8Array]': true\n  , '[object Uint8ClampedArray]': true\n  , '[object Uint16Array]': true\n  , '[object Uint32Array]': true\n  , '[object Float32Array]': true\n  , '[object Float64Array]': true\n}\n\nfunction isTypedArray(arr) {\n  return (\n       isStrictTypedArray(arr)\n    || isLooseTypedArray(arr)\n  )\n}\n\nfunction isStrictTypedArray(arr) {\n  return (\n       arr instanceof Int8Array\n    || arr instanceof Int16Array\n    || arr instanceof Int32Array\n    || arr instanceof Uint8Array\n    || arr instanceof Uint8ClampedArray\n    || arr instanceof Uint16Array\n    || arr instanceof Uint32Array\n    || arr instanceof Float32Array\n    || arr instanceof Float64Array\n  )\n}\n\nfunction isLooseTypedArray(arr) {\n  return names[toString.call(arr)]\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/getProxyFromURI.js":"'use strict'\n\nfunction formatHostname(hostname) {\n  // canonicalize the hostname, so that 'oogle.com' won't match 'google.com'\n  return hostname.replace(/^\\.*/, '.').toLowerCase()\n}\n\nfunction parseNoProxyZone(zone) {\n  zone = zone.trim().toLowerCase()\n\n  var zoneParts = zone.split(':', 2)\n    , zoneHost = formatHostname(zoneParts[0])\n    , zonePort = zoneParts[1]\n    , hasPort = zone.indexOf(':') > -1\n\n  return {hostname: zoneHost, port: zonePort, hasPort: hasPort}\n}\n\nfunction uriInNoProxy(uri, noProxy) {\n  var port = uri.port || (uri.protocol === 'https:' ? '443' : '80')\n    , hostname = formatHostname(uri.hostname)\n    , noProxyList = noProxy.split(',')\n\n  // iterate through the noProxyList until it finds a match.\n  return noProxyList.map(parseNoProxyZone).some(function(noProxyZone) {\n    var isMatchedAt = hostname.indexOf(noProxyZone.hostname)\n      , hostnameMatched = (\n          isMatchedAt > -1 &&\n          (isMatchedAt === hostname.length - noProxyZone.hostname.length)\n        )\n\n    if (noProxyZone.hasPort) {\n      return (port === noProxyZone.port) && hostnameMatched\n    }\n\n    return hostnameMatched\n  })\n}\n\nfunction getProxyFromURI(uri) {\n  // Decide the proper request proxy to use based on the request URI object and the\n  // environmental variables (NO_PROXY, HTTP_PROXY, etc.)\n  // respect NO_PROXY environment variables (see: http://lynx.isc.org/current/breakout/lynx_help/keystrokes/environments.html)\n\n  var noProxy = process.env.NO_PROXY || process.env.no_proxy || ''\n\n  // if the noProxy is a wildcard then return null\n\n  if (noProxy === '*') {\n    return null\n  }\n\n  // if the noProxy is not empty and the uri is found return null\n\n  if (noProxy !== '' && uriInNoProxy(uri, noProxy)) {\n    return null\n  }\n\n  // Check for HTTP or HTTPS Proxy in environment Else default to null\n\n  if (uri.protocol === 'http:') {\n    return process.env.HTTP_PROXY ||\n           process.env.http_proxy || null\n  }\n\n  if (uri.protocol === 'https:') {\n    return process.env.HTTPS_PROXY ||\n           process.env.https_proxy ||\n           process.env.HTTP_PROXY  ||\n           process.env.http_proxy  || null\n  }\n\n  // if none of that works, return null\n  // (What uri protocol are you using then?)\n\n  return null\n}\n\nmodule.exports = getProxyFromURI\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/querystring.js":"'use strict'\n\nvar qs = require('qs')\n  , querystring = require('querystring')\n\n\nfunction Querystring (request) {\n  this.request = request\n  this.lib = null\n  this.useQuerystring = null\n  this.parseOptions = null\n  this.stringifyOptions = null\n}\n\nQuerystring.prototype.init = function (options) {\n  if (this.lib) {return}\n\n  this.useQuerystring = options.useQuerystring\n  this.lib = (this.useQuerystring ? querystring : qs)\n\n  this.parseOptions = options.qsParseOptions || {}\n  this.stringifyOptions = options.qsStringifyOptions || {}\n}\n\nQuerystring.prototype.stringify = function (obj) {\n  return (this.useQuerystring)\n    ? this.rfc3986(this.lib.stringify(obj,\n      this.stringifyOptions.sep || null,\n      this.stringifyOptions.eq || null,\n      this.stringifyOptions))\n    : this.lib.stringify(obj, this.stringifyOptions)\n}\n\nQuerystring.prototype.parse = function (str) {\n  return (this.useQuerystring)\n    ? this.lib.parse(str,\n      this.parseOptions.sep || null,\n      this.parseOptions.eq || null,\n      this.parseOptions)\n    : this.lib.parse(str, this.parseOptions)\n}\n\nQuerystring.prototype.rfc3986 = function (str) {\n  return str.replace(/[!'()*]/g, function (c) {\n    return '%' + c.charCodeAt(0).toString(16).toUpperCase()\n  })\n}\n\nQuerystring.prototype.unescape = querystring.unescape\n\nexports.Querystring = Querystring\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/qs/lib/index.js":"'use strict';\n\nvar stringify = require('./stringify');\nvar parse = require('./parse');\nvar formats = require('./formats');\n\nmodule.exports = {\n    formats: formats,\n    parse: parse,\n    stringify: stringify\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/qs/lib/stringify.js":"'use strict';\n\nvar utils = require('./utils');\nvar formats = require('./formats');\n\nvar arrayPrefixGenerators = {\n    brackets: function brackets(prefix) { // eslint-disable-line func-name-matching\n        return prefix + '[]';\n    },\n    indices: function indices(prefix, key) { // eslint-disable-line func-name-matching\n        return prefix + '[' + key + ']';\n    },\n    repeat: function repeat(prefix) { // eslint-disable-line func-name-matching\n        return prefix;\n    }\n};\n\nvar toISO = Date.prototype.toISOString;\n\nvar defaults = {\n    delimiter: '&',\n    encode: true,\n    encoder: utils.encode,\n    encodeValuesOnly: false,\n    serializeDate: function serializeDate(date) { // eslint-disable-line func-name-matching\n        return toISO.call(date);\n    },\n    skipNulls: false,\n    strictNullHandling: false\n};\n\nvar stringify = function stringify( // eslint-disable-line func-name-matching\n    object,\n    prefix,\n    generateArrayPrefix,\n    strictNullHandling,\n    skipNulls,\n    encoder,\n    filter,\n    sort,\n    allowDots,\n    serializeDate,\n    formatter,\n    encodeValuesOnly\n) {\n    var obj = object;\n    if (typeof filter === 'function') {\n        obj = filter(prefix, obj);\n    } else if (obj instanceof Date) {\n        obj = serializeDate(obj);\n    } else if (obj === null) {\n        if (strictNullHandling) {\n            return encoder && !encodeValuesOnly ? encoder(prefix) : prefix;\n        }\n\n        obj = '';\n    }\n\n    if (typeof obj === 'string' || typeof obj === 'number' || typeof obj === 'boolean' || utils.isBuffer(obj)) {\n        if (encoder) {\n            var keyValue = encodeValuesOnly ? prefix : encoder(prefix);\n            return [formatter(keyValue) + '=' + formatter(encoder(obj))];\n        }\n        return [formatter(prefix) + '=' + formatter(String(obj))];\n    }\n\n    var values = [];\n\n    if (typeof obj === 'undefined') {\n        return values;\n    }\n\n    var objKeys;\n    if (Array.isArray(filter)) {\n        objKeys = filter;\n    } else {\n        var keys = Object.keys(obj);\n        objKeys = sort ? keys.sort(sort) : keys;\n    }\n\n    for (var i = 0; i < objKeys.length; ++i) {\n        var key = objKeys[i];\n\n        if (skipNulls && obj[key] === null) {\n            continue;\n        }\n\n        if (Array.isArray(obj)) {\n            values = values.concat(stringify(\n                obj[key],\n                generateArrayPrefix(prefix, key),\n                generateArrayPrefix,\n                strictNullHandling,\n                skipNulls,\n                encoder,\n                filter,\n                sort,\n                allowDots,\n                serializeDate,\n                formatter,\n                encodeValuesOnly\n            ));\n        } else {\n            values = values.concat(stringify(\n                obj[key],\n                prefix + (allowDots ? '.' + key : '[' + key + ']'),\n                generateArrayPrefix,\n                strictNullHandling,\n                skipNulls,\n                encoder,\n                filter,\n                sort,\n                allowDots,\n                serializeDate,\n                formatter,\n                encodeValuesOnly\n            ));\n        }\n    }\n\n    return values;\n};\n\nmodule.exports = function (object, opts) {\n    var obj = object;\n    var options = opts || {};\n\n    if (options.encoder !== null && options.encoder !== undefined && typeof options.encoder !== 'function') {\n        throw new TypeError('Encoder has to be a function.');\n    }\n\n    var delimiter = typeof options.delimiter === 'undefined' ? defaults.delimiter : options.delimiter;\n    var strictNullHandling = typeof options.strictNullHandling === 'boolean' ? options.strictNullHandling : defaults.strictNullHandling;\n    var skipNulls = typeof options.skipNulls === 'boolean' ? options.skipNulls : defaults.skipNulls;\n    var encode = typeof options.encode === 'boolean' ? options.encode : defaults.encode;\n    var encoder = typeof options.encoder === 'function' ? options.encoder : defaults.encoder;\n    var sort = typeof options.sort === 'function' ? options.sort : null;\n    var allowDots = typeof options.allowDots === 'undefined' ? false : options.allowDots;\n    var serializeDate = typeof options.serializeDate === 'function' ? options.serializeDate : defaults.serializeDate;\n    var encodeValuesOnly = typeof options.encodeValuesOnly === 'boolean' ? options.encodeValuesOnly : defaults.encodeValuesOnly;\n    if (typeof options.format === 'undefined') {\n        options.format = formats.default;\n    } else if (!Object.prototype.hasOwnProperty.call(formats.formatters, options.format)) {\n        throw new TypeError('Unknown format option provided.');\n    }\n    var formatter = formats.formatters[options.format];\n    var objKeys;\n    var filter;\n\n    if (typeof options.filter === 'function') {\n        filter = options.filter;\n        obj = filter('', obj);\n    } else if (Array.isArray(options.filter)) {\n        filter = options.filter;\n        objKeys = filter;\n    }\n\n    var keys = [];\n\n    if (typeof obj !== 'object' || obj === null) {\n        return '';\n    }\n\n    var arrayFormat;\n    if (options.arrayFormat in arrayPrefixGenerators) {\n        arrayFormat = options.arrayFormat;\n    } else if ('indices' in options) {\n        arrayFormat = options.indices ? 'indices' : 'repeat';\n    } else {\n        arrayFormat = 'indices';\n    }\n\n    var generateArrayPrefix = arrayPrefixGenerators[arrayFormat];\n\n    if (!objKeys) {\n        objKeys = Object.keys(obj);\n    }\n\n    if (sort) {\n        objKeys.sort(sort);\n    }\n\n    for (var i = 0; i < objKeys.length; ++i) {\n        var key = objKeys[i];\n\n        if (skipNulls && obj[key] === null) {\n            continue;\n        }\n\n        keys = keys.concat(stringify(\n            obj[key],\n            key,\n            generateArrayPrefix,\n            strictNullHandling,\n            skipNulls,\n            encode ? encoder : null,\n            filter,\n            sort,\n            allowDots,\n            serializeDate,\n            formatter,\n            encodeValuesOnly\n        ));\n    }\n\n    return keys.join(delimiter);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/qs/lib/utils.js":"'use strict';\n\nvar has = Object.prototype.hasOwnProperty;\n\nvar hexTable = (function () {\n    var array = [];\n    for (var i = 0; i < 256; ++i) {\n        array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n    }\n\n    return array;\n}());\n\nexports.arrayToObject = function (source, options) {\n    var obj = options && options.plainObjects ? Object.create(null) : {};\n    for (var i = 0; i < source.length; ++i) {\n        if (typeof source[i] !== 'undefined') {\n            obj[i] = source[i];\n        }\n    }\n\n    return obj;\n};\n\nexports.merge = function (target, source, options) {\n    if (!source) {\n        return target;\n    }\n\n    if (typeof source !== 'object') {\n        if (Array.isArray(target)) {\n            target.push(source);\n        } else if (typeof target === 'object') {\n            if (options.plainObjects || options.allowPrototypes || !has.call(Object.prototype, source)) {\n                target[source] = true;\n            }\n        } else {\n            return [target, source];\n        }\n\n        return target;\n    }\n\n    if (typeof target !== 'object') {\n        return [target].concat(source);\n    }\n\n    var mergeTarget = target;\n    if (Array.isArray(target) && !Array.isArray(source)) {\n        mergeTarget = exports.arrayToObject(target, options);\n    }\n\n    if (Array.isArray(target) && Array.isArray(source)) {\n        source.forEach(function (item, i) {\n            if (has.call(target, i)) {\n                if (target[i] && typeof target[i] === 'object') {\n                    target[i] = exports.merge(target[i], item, options);\n                } else {\n                    target.push(item);\n                }\n            } else {\n                target[i] = item;\n            }\n        });\n        return target;\n    }\n\n    return Object.keys(source).reduce(function (acc, key) {\n        var value = source[key];\n\n        if (Object.prototype.hasOwnProperty.call(acc, key)) {\n            acc[key] = exports.merge(acc[key], value, options);\n        } else {\n            acc[key] = value;\n        }\n        return acc;\n    }, mergeTarget);\n};\n\nexports.decode = function (str) {\n    try {\n        return decodeURIComponent(str.replace(/\\+/g, ' '));\n    } catch (e) {\n        return str;\n    }\n};\n\nexports.encode = function (str) {\n    // This code was originally written by Brian White (mscdex) for the io.js core querystring library.\n    // It has been adapted here for stricter adherence to RFC 3986\n    if (str.length === 0) {\n        return str;\n    }\n\n    var string = typeof str === 'string' ? str : String(str);\n\n    var out = '';\n    for (var i = 0; i < string.length; ++i) {\n        var c = string.charCodeAt(i);\n\n        if (\n            c === 0x2D || // -\n            c === 0x2E || // .\n            c === 0x5F || // _\n            c === 0x7E || // ~\n            (c >= 0x30 && c <= 0x39) || // 0-9\n            (c >= 0x41 && c <= 0x5A) || // a-z\n            (c >= 0x61 && c <= 0x7A) // A-Z\n        ) {\n            out += string.charAt(i);\n            continue;\n        }\n\n        if (c < 0x80) {\n            out = out + hexTable[c];\n            continue;\n        }\n\n        if (c < 0x800) {\n            out = out + (hexTable[0xC0 | (c >> 6)] + hexTable[0x80 | (c & 0x3F)]);\n            continue;\n        }\n\n        if (c < 0xD800 || c >= 0xE000) {\n            out = out + (hexTable[0xE0 | (c >> 12)] + hexTable[0x80 | ((c >> 6) & 0x3F)] + hexTable[0x80 | (c & 0x3F)]);\n            continue;\n        }\n\n        i += 1;\n        c = 0x10000 + (((c & 0x3FF) << 10) | (string.charCodeAt(i) & 0x3FF));\n        out += hexTable[0xF0 | (c >> 18)] + hexTable[0x80 | ((c >> 12) & 0x3F)] + hexTable[0x80 | ((c >> 6) & 0x3F)] + hexTable[0x80 | (c & 0x3F)]; // eslint-disable-line max-len\n    }\n\n    return out;\n};\n\nexports.compact = function (obj, references) {\n    if (typeof obj !== 'object' || obj === null) {\n        return obj;\n    }\n\n    var refs = references || [];\n    var lookup = refs.indexOf(obj);\n    if (lookup !== -1) {\n        return refs[lookup];\n    }\n\n    refs.push(obj);\n\n    if (Array.isArray(obj)) {\n        var compacted = [];\n\n        for (var i = 0; i < obj.length; ++i) {\n            if (obj[i] && typeof obj[i] === 'object') {\n                compacted.push(exports.compact(obj[i], refs));\n            } else if (typeof obj[i] !== 'undefined') {\n                compacted.push(obj[i]);\n            }\n        }\n\n        return compacted;\n    }\n\n    var keys = Object.keys(obj);\n    keys.forEach(function (key) {\n        obj[key] = exports.compact(obj[key], refs);\n    });\n\n    return obj;\n};\n\nexports.isRegExp = function (obj) {\n    return Object.prototype.toString.call(obj) === '[object RegExp]';\n};\n\nexports.isBuffer = function (obj) {\n    if (obj === null || typeof obj === 'undefined') {\n        return false;\n    }\n\n    return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/qs/lib/formats.js":"'use strict';\n\nvar replace = String.prototype.replace;\nvar percentTwenties = /%20/g;\n\nmodule.exports = {\n    'default': 'RFC3986',\n    formatters: {\n        RFC1738: function (value) {\n            return replace.call(value, percentTwenties, '+');\n        },\n        RFC3986: function (value) {\n            return value;\n        }\n    },\n    RFC1738: 'RFC1738',\n    RFC3986: 'RFC3986'\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/qs/lib/parse.js":"'use strict';\n\nvar utils = require('./utils');\n\nvar has = Object.prototype.hasOwnProperty;\n\nvar defaults = {\n    allowDots: false,\n    allowPrototypes: false,\n    arrayLimit: 20,\n    decoder: utils.decode,\n    delimiter: '&',\n    depth: 5,\n    parameterLimit: 1000,\n    plainObjects: false,\n    strictNullHandling: false\n};\n\nvar parseValues = function parseQueryStringValues(str, options) {\n    var obj = {};\n    var parts = str.split(options.delimiter, options.parameterLimit === Infinity ? undefined : options.parameterLimit);\n\n    for (var i = 0; i < parts.length; ++i) {\n        var part = parts[i];\n        var pos = part.indexOf(']=') === -1 ? part.indexOf('=') : part.indexOf(']=') + 1;\n\n        var key, val;\n        if (pos === -1) {\n            key = options.decoder(part);\n            val = options.strictNullHandling ? null : '';\n        } else {\n            key = options.decoder(part.slice(0, pos));\n            val = options.decoder(part.slice(pos + 1));\n        }\n        if (has.call(obj, key)) {\n            obj[key] = [].concat(obj[key]).concat(val);\n        } else {\n            obj[key] = val;\n        }\n    }\n\n    return obj;\n};\n\nvar parseObject = function parseObjectRecursive(chain, val, options) {\n    if (!chain.length) {\n        return val;\n    }\n\n    var root = chain.shift();\n\n    var obj;\n    if (root === '[]') {\n        obj = [];\n        obj = obj.concat(parseObject(chain, val, options));\n    } else {\n        obj = options.plainObjects ? Object.create(null) : {};\n        var cleanRoot = root.charAt(0) === '[' && root.charAt(root.length - 1) === ']' ? root.slice(1, -1) : root;\n        var index = parseInt(cleanRoot, 10);\n        if (\n            !isNaN(index) &&\n            root !== cleanRoot &&\n            String(index) === cleanRoot &&\n            index >= 0 &&\n            (options.parseArrays && index <= options.arrayLimit)\n        ) {\n            obj = [];\n            obj[index] = parseObject(chain, val, options);\n        } else {\n            obj[cleanRoot] = parseObject(chain, val, options);\n        }\n    }\n\n    return obj;\n};\n\nvar parseKeys = function parseQueryStringKeys(givenKey, val, options) {\n    if (!givenKey) {\n        return;\n    }\n\n    // Transform dot notation to bracket notation\n    var key = options.allowDots ? givenKey.replace(/\\.([^.[]+)/g, '[$1]') : givenKey;\n\n    // The regex chunks\n\n    var brackets = /(\\[[^[\\]]*])/;\n    var child = /(\\[[^[\\]]*])/g;\n\n    // Get the parent\n\n    var segment = brackets.exec(key);\n    var parent = segment ? key.slice(0, segment.index) : key;\n\n    // Stash the parent if it exists\n\n    var keys = [];\n    if (parent) {\n        // If we aren't using plain objects, optionally prefix keys\n        // that would overwrite object prototype properties\n        if (!options.plainObjects && has.call(Object.prototype, parent)) {\n            if (!options.allowPrototypes) {\n                return;\n            }\n        }\n\n        keys.push(parent);\n    }\n\n    // Loop through children appending to the array until we hit depth\n\n    var i = 0;\n    while ((segment = child.exec(key)) !== null && i < options.depth) {\n        i += 1;\n        if (!options.plainObjects && has.call(Object.prototype, segment[1].slice(1, -1))) {\n            if (!options.allowPrototypes) {\n                return;\n            }\n        }\n        keys.push(segment[1]);\n    }\n\n    // If there's a remainder, just add whatever is left\n\n    if (segment) {\n        keys.push('[' + key.slice(segment.index) + ']');\n    }\n\n    return parseObject(keys, val, options);\n};\n\nmodule.exports = function (str, opts) {\n    var options = opts || {};\n\n    if (options.decoder !== null && options.decoder !== undefined && typeof options.decoder !== 'function') {\n        throw new TypeError('Decoder has to be a function.');\n    }\n\n    options.delimiter = typeof options.delimiter === 'string' || utils.isRegExp(options.delimiter) ? options.delimiter : defaults.delimiter;\n    options.depth = typeof options.depth === 'number' ? options.depth : defaults.depth;\n    options.arrayLimit = typeof options.arrayLimit === 'number' ? options.arrayLimit : defaults.arrayLimit;\n    options.parseArrays = options.parseArrays !== false;\n    options.decoder = typeof options.decoder === 'function' ? options.decoder : defaults.decoder;\n    options.allowDots = typeof options.allowDots === 'boolean' ? options.allowDots : defaults.allowDots;\n    options.plainObjects = typeof options.plainObjects === 'boolean' ? options.plainObjects : defaults.plainObjects;\n    options.allowPrototypes = typeof options.allowPrototypes === 'boolean' ? options.allowPrototypes : defaults.allowPrototypes;\n    options.parameterLimit = typeof options.parameterLimit === 'number' ? options.parameterLimit : defaults.parameterLimit;\n    options.strictNullHandling = typeof options.strictNullHandling === 'boolean' ? options.strictNullHandling : defaults.strictNullHandling;\n\n    if (str === '' || str === null || typeof str === 'undefined') {\n        return options.plainObjects ? Object.create(null) : {};\n    }\n\n    var tempObj = typeof str === 'string' ? parseValues(str, options) : str;\n    var obj = options.plainObjects ? Object.create(null) : {};\n\n    // Iterate over the keys and setup the new object\n\n    var keys = Object.keys(tempObj);\n    for (var i = 0; i < keys.length; ++i) {\n        var key = keys[i];\n        var newObj = parseKeys(key, tempObj[key], options);\n        obj = utils.merge(obj, newObj, options);\n    }\n\n    return utils.compact(obj);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/har.js":"'use strict'\n\nvar fs = require('fs')\nvar qs = require('querystring')\nvar validate = require('har-validator')\nvar extend = require('extend')\n\nfunction Har (request) {\n  this.request = request\n}\n\nHar.prototype.reducer = function (obj, pair) {\n  // new property ?\n  if (obj[pair.name] === undefined) {\n    obj[pair.name] = pair.value\n    return obj\n  }\n\n  // existing? convert to array\n  var arr = [\n    obj[pair.name],\n    pair.value\n  ]\n\n  obj[pair.name] = arr\n\n  return obj\n}\n\nHar.prototype.prep = function (data) {\n  // construct utility properties\n  data.queryObj = {}\n  data.headersObj = {}\n  data.postData.jsonObj = false\n  data.postData.paramsObj = false\n\n  // construct query objects\n  if (data.queryString && data.queryString.length) {\n    data.queryObj = data.queryString.reduce(this.reducer, {})\n  }\n\n  // construct headers objects\n  if (data.headers && data.headers.length) {\n    // loweCase header keys\n    data.headersObj = data.headers.reduceRight(function (headers, header) {\n      headers[header.name] = header.value\n      return headers\n    }, {})\n  }\n\n  // construct Cookie header\n  if (data.cookies && data.cookies.length) {\n    var cookies = data.cookies.map(function (cookie) {\n      return cookie.name + '=' + cookie.value\n    })\n\n    if (cookies.length) {\n      data.headersObj.cookie = cookies.join('; ')\n    }\n  }\n\n  // prep body\n  function some (arr) {\n    return arr.some(function (type) {\n      return data.postData.mimeType.indexOf(type) === 0\n    })\n  }\n\n  if (some([\n    'multipart/mixed',\n    'multipart/related',\n    'multipart/form-data',\n    'multipart/alternative'])) {\n\n    // reset values\n    data.postData.mimeType = 'multipart/form-data'\n  }\n\n  else if (some([\n    'application/x-www-form-urlencoded'])) {\n\n    if (!data.postData.params) {\n      data.postData.text = ''\n    } else {\n      data.postData.paramsObj = data.postData.params.reduce(this.reducer, {})\n\n      // always overwrite\n      data.postData.text = qs.stringify(data.postData.paramsObj)\n    }\n  }\n\n  else if (some([\n    'text/json',\n    'text/x-json',\n    'application/json',\n    'application/x-json'])) {\n\n    data.postData.mimeType = 'application/json'\n\n    if (data.postData.text) {\n      try {\n        data.postData.jsonObj = JSON.parse(data.postData.text)\n      } catch (e) {\n        this.request.debug(e)\n\n        // force back to text/plain\n        data.postData.mimeType = 'text/plain'\n      }\n    }\n  }\n\n  return data\n}\n\nHar.prototype.options = function (options) {\n  // skip if no har property defined\n  if (!options.har) {\n    return options\n  }\n\n  var har = {}\n  extend(har, options.har)\n\n  // only process the first entry\n  if (har.log && har.log.entries) {\n    har = har.log.entries[0]\n  }\n\n  // add optional properties to make validation successful\n  har.url = har.url || options.url || options.uri || options.baseUrl || '/'\n  har.httpVersion = har.httpVersion || 'HTTP/1.1'\n  har.queryString = har.queryString || []\n  har.headers = har.headers || []\n  har.cookies = har.cookies || []\n  har.postData = har.postData || {}\n  har.postData.mimeType = har.postData.mimeType || 'application/octet-stream'\n\n  har.bodySize = 0\n  har.headersSize = 0\n  har.postData.size = 0\n\n  if (!validate.request(har)) {\n    return options\n  }\n\n  // clean up and get some utility properties\n  var req = this.prep(har)\n\n  // construct new options\n  if (req.url) {\n    options.url = req.url\n  }\n\n  if (req.method) {\n    options.method = req.method\n  }\n\n  if (Object.keys(req.queryObj).length) {\n    options.qs = req.queryObj\n  }\n\n  if (Object.keys(req.headersObj).length) {\n    options.headers = req.headersObj\n  }\n\n  function test (type) {\n    return req.postData.mimeType.indexOf(type) === 0\n  }\n  if (test('application/x-www-form-urlencoded')) {\n    options.form = req.postData.paramsObj\n  }\n  else if (test('application/json')) {\n    if (req.postData.jsonObj) {\n      options.body = req.postData.jsonObj\n      options.json = true\n    }\n  }\n  else if (test('multipart/form-data')) {\n    options.formData = {}\n\n    req.postData.params.forEach(function (param) {\n      var attachment = {}\n\n      if (!param.fileName && !param.fileName && !param.contentType) {\n        options.formData[param.name] = param.value\n        return\n      }\n\n      // attempt to read from disk!\n      if (param.fileName && !param.value) {\n        attachment.value = fs.createReadStream(param.fileName)\n      } else if (param.value) {\n        attachment.value = param.value\n      }\n\n      if (param.fileName) {\n        attachment.options = {\n          filename: param.fileName,\n          contentType: param.contentType ? param.contentType : null\n        }\n      }\n\n      options.formData[param.name] = attachment\n    })\n  }\n  else {\n    if (req.postData.text) {\n      options.body = req.postData.text\n    }\n  }\n\n  return options\n}\n\nexports.Har = Har\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/lib/node4/promise.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.validate = validate;\nexports.afterRequest = afterRequest;\nexports.beforeRequest = beforeRequest;\nexports.browser = browser;\nexports.cache = cache;\nexports.content = content;\nexports.cookie = cookie;\nexports.creator = creator;\nexports.entry = entry;\nexports.har = har;\nexports.header = header;\nexports.log = log;\nexports.page = page;\nexports.pageTimings = pageTimings;\nexports.postData = postData;\nexports.query = query;\nexports.request = request;\nexports.response = response;\nexports.timings = timings;\n\nvar _harSchema = require('har-schema');\n\nvar schemas = _interopRequireWildcard(_harSchema);\n\nvar _ajv = require('ajv');\n\nvar _ajv2 = _interopRequireDefault(_ajv);\n\nvar _error = require('./error');\n\nvar _error2 = _interopRequireDefault(_error);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nvar ajv = void 0;\n\nfunction validate(name) {\n  var data = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n  // validator config\n  ajv = ajv || new _ajv2.default({\n    allErrors: true,\n    schemas: schemas\n  });\n\n  var validate = ajv.getSchema(name + '.json');\n\n  return new Promise(function (resolve, reject) {\n    var valid = validate(data);\n\n    !valid ? reject(new _error2.default(validate.errors)) : resolve(data);\n  });\n}\n\nfunction afterRequest(data) {\n  return validate('afterRequest', data);\n}\n\nfunction beforeRequest(data) {\n  return validate('beforeRequest', data);\n}\n\nfunction browser(data) {\n  return validate('browser', data);\n}\n\nfunction cache(data) {\n  return validate('cache', data);\n}\n\nfunction content(data) {\n  return validate('content', data);\n}\n\nfunction cookie(data) {\n  return validate('cookie', data);\n}\n\nfunction creator(data) {\n  return validate('creator', data);\n}\n\nfunction entry(data) {\n  return validate('entry', data);\n}\n\nfunction har(data) {\n  return validate('har', data);\n}\n\nfunction header(data) {\n  return validate('header', data);\n}\n\nfunction log(data) {\n  return validate('log', data);\n}\n\nfunction page(data) {\n  return validate('page', data);\n}\n\nfunction pageTimings(data) {\n  return validate('pageTimings', data);\n}\n\nfunction postData(data) {\n  return validate('postData', data);\n}\n\nfunction query(data) {\n  return validate('query', data);\n}\n\nfunction request(data) {\n  return validate('request', data);\n}\n\nfunction response(data) {\n  return validate('response', data);\n}\n\nfunction timings(data) {\n  return validate('timings', data);\n}","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/har-schema/lib/index.js":"'use strict'\n\nmodule.exports = {\n  afterRequest: require('./afterRequest.json'),\n  beforeRequest: require('./beforeRequest.json'),\n  browser: require('./browser.json'),\n  cache: require('./cache.json'),\n  content: require('./content.json'),\n  cookie: require('./cookie.json'),\n  creator: require('./creator.json'),\n  entry: require('./entry.json'),\n  har: require('./har.json'),\n  header: require('./header.json'),\n  log: require('./log.json'),\n  page: require('./page.json'),\n  pageTimings: require('./pageTimings.json'),\n  postData: require('./postData.json'),\n  query: require('./query.json'),\n  request: require('./request.json'),\n  response: require('./response.json'),\n  timings: require('./timings.json')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/ajv.js":"'use strict';\n\nvar compileSchema = require('./compile')\n  , resolve = require('./compile/resolve')\n  , Cache = require('./cache')\n  , SchemaObject = require('./compile/schema_obj')\n  , stableStringify = require('json-stable-stringify')\n  , formats = require('./compile/formats')\n  , rules = require('./compile/rules')\n  , v5 = require('./v5')\n  , util = require('./compile/util')\n  , async = require('./async')\n  , co = require('co');\n\nmodule.exports = Ajv;\n\nAjv.prototype.compileAsync = async.compile;\n\nvar customKeyword = require('./keyword');\nAjv.prototype.addKeyword = customKeyword.add;\nAjv.prototype.getKeyword = customKeyword.get;\nAjv.prototype.removeKeyword = customKeyword.remove;\nAjv.ValidationError = require('./compile/validation_error');\n\nvar META_SCHEMA_ID = 'http://json-schema.org/draft-04/schema';\nvar SCHEMA_URI_FORMAT = /^(?:(?:[a-z][a-z0-9+-.]*:)?\\/\\/)?[^\\s]*$/i;\nfunction SCHEMA_URI_FORMAT_FUNC(str) {\n  return SCHEMA_URI_FORMAT.test(str);\n}\n\nvar META_IGNORE_OPTIONS = [ 'removeAdditional', 'useDefaults', 'coerceTypes' ];\n\n/**\n * Creates validator instance.\n * Usage: `Ajv(opts)`\n * @param {Object} opts optional options\n * @return {Object} ajv instance\n */\nfunction Ajv(opts) {\n  if (!(this instanceof Ajv)) return new Ajv(opts);\n  var self = this;\n\n  opts = this._opts = util.copy(opts) || {};\n  this._schemas = {};\n  this._refs = {};\n  this._fragments = {};\n  this._formats = formats(opts.format);\n  this._cache = opts.cache || new Cache;\n  this._loadingSchemas = {};\n  this._compilations = [];\n  this.RULES = rules();\n\n  // this is done on purpose, so that methods are bound to the instance\n  // (without using bind) so that they can be used without the instance\n  this.validate = validate;\n  this.compile = compile;\n  this.addSchema = addSchema;\n  this.addMetaSchema = addMetaSchema;\n  this.validateSchema = validateSchema;\n  this.getSchema = getSchema;\n  this.removeSchema = removeSchema;\n  this.addFormat = addFormat;\n  this.errorsText = errorsText;\n\n  this._addSchema = _addSchema;\n  this._compile = _compile;\n\n  opts.loopRequired = opts.loopRequired || Infinity;\n  if (opts.async || opts.transpile) async.setup(opts);\n  if (opts.beautify === true) opts.beautify = { indent_size: 2 };\n  if (opts.errorDataPath == 'property') opts._errorDataPathProperty = true;\n  this._metaOpts = getMetaSchemaOptions();\n\n  if (opts.formats) addInitialFormats();\n  addDraft4MetaSchema();\n  if (opts.v5) v5.enable(this);\n  if (typeof opts.meta == 'object') addMetaSchema(opts.meta);\n  addInitialSchemas();\n\n\n  /**\n   * Validate data using schema\n   * Schema will be compiled and cached (using serialized JSON as key. [json-stable-stringify](https://github.com/substack/json-stable-stringify) is used to serialize.\n   * @param  {String|Object} schemaKeyRef key, ref or schema object\n   * @param  {Any} data to be validated\n   * @return {Boolean} validation result. Errors from the last validation will be available in `ajv.errors` (and also in compiled schema: `schema.errors`).\n   */\n  function validate(schemaKeyRef, data) {\n    var v;\n    if (typeof schemaKeyRef == 'string') {\n      v = getSchema(schemaKeyRef);\n      if (!v) throw new Error('no schema with key or ref \"' + schemaKeyRef + '\"');\n    } else {\n      var schemaObj = _addSchema(schemaKeyRef);\n      v = schemaObj.validate || _compile(schemaObj);\n    }\n\n    var valid = v(data);\n    if (v.$async === true)\n      return self._opts.async == '*' ? co(valid) : valid;\n    self.errors = v.errors;\n    return valid;\n  }\n\n\n  /**\n   * Create validating function for passed schema.\n   * @param  {Object} schema schema object\n   * @param  {Boolean} _meta true if schema is a meta-schema. Used internally to compile meta schemas of custom keywords.\n   * @return {Function} validating function\n   */\n  function compile(schema, _meta) {\n    var schemaObj = _addSchema(schema, undefined, _meta);\n    return schemaObj.validate || _compile(schemaObj);\n  }\n\n\n  /**\n   * Adds schema to the instance.\n   * @param {Object|Array} schema schema or array of schemas. If array is passed, `key` and other parameters will be ignored.\n   * @param {String} key Optional schema key. Can be passed to `validate` method instead of schema object or id/ref. One schema per instance can have empty `id` and `key`.\n   * @param {Boolean} _skipValidation true to skip schema validation. Used internally, option validateSchema should be used instead.\n   * @param {Boolean} _meta true if schema is a meta-schema. Used internally, addMetaSchema should be used instead.\n   */\n  function addSchema(schema, key, _skipValidation, _meta) {\n    if (Array.isArray(schema)){\n      for (var i=0; i<schema.length; i++) addSchema(schema[i], undefined, _skipValidation, _meta);\n      return;\n    }\n    // can key/id have # inside?\n    key = resolve.normalizeId(key || schema.id);\n    checkUnique(key);\n    self._schemas[key] = _addSchema(schema, _skipValidation, _meta, true);\n  }\n\n\n  /**\n   * Add schema that will be used to validate other schemas\n   * options in META_IGNORE_OPTIONS are alway set to false\n   * @param {Object} schema schema object\n   * @param {String} key optional schema key\n   * @param {Boolean} skipValidation true to skip schema validation, can be used to override validateSchema option for meta-schema\n   */\n  function addMetaSchema(schema, key, skipValidation) {\n    addSchema(schema, key, skipValidation, true);\n  }\n\n\n  /**\n   * Validate schema\n   * @param {Object} schema schema to validate\n   * @param {Boolean} throwOrLogError pass true to throw (or log) an error if invalid\n   * @return {Boolean} true if schema is valid\n   */\n  function validateSchema(schema, throwOrLogError) {\n    var $schema = schema.$schema || self._opts.defaultMeta || defaultMeta();\n    var currentUriFormat = self._formats.uri;\n    self._formats.uri = typeof currentUriFormat == 'function'\n                        ? SCHEMA_URI_FORMAT_FUNC\n                        : SCHEMA_URI_FORMAT;\n    var valid;\n    try { valid = validate($schema, schema); }\n    finally { self._formats.uri = currentUriFormat; }\n    if (!valid && throwOrLogError) {\n      var message = 'schema is invalid: ' + errorsText();\n      if (self._opts.validateSchema == 'log') console.error(message);\n      else throw new Error(message);\n    }\n    return valid;\n  }\n\n\n  function defaultMeta() {\n    var meta = self._opts.meta;\n    self._opts.defaultMeta = typeof meta == 'object'\n                              ? meta.id || meta\n                              : self._opts.v5\n                                ? v5.META_SCHEMA_ID\n                                : META_SCHEMA_ID;\n    return self._opts.defaultMeta;\n  }\n\n\n  /**\n   * Get compiled schema from the instance by `key` or `ref`.\n   * @param  {String} keyRef `key` that was passed to `addSchema` or full schema reference (`schema.id` or resolved id).\n   * @return {Function} schema validating function (with property `schema`).\n   */\n  function getSchema(keyRef) {\n    var schemaObj = _getSchemaObj(keyRef);\n    switch (typeof schemaObj) {\n      case 'object': return schemaObj.validate || _compile(schemaObj);\n      case 'string': return getSchema(schemaObj);\n      case 'undefined': return _getSchemaFragment(keyRef);\n    }\n  }\n\n\n  function _getSchemaFragment(ref) {\n    var res = resolve.schema.call(self, { schema: {} }, ref);\n    if (res) {\n      var schema = res.schema\n        , root = res.root\n        , baseId = res.baseId;\n      var v = compileSchema.call(self, schema, root, undefined, baseId);\n      self._fragments[ref] = new SchemaObject({\n        ref: ref,\n        fragment: true,\n        schema: schema,\n        root: root,\n        baseId: baseId,\n        validate: v\n      });\n      return v;\n    }\n  }\n\n\n  function _getSchemaObj(keyRef) {\n    keyRef = resolve.normalizeId(keyRef);\n    return self._schemas[keyRef] || self._refs[keyRef] || self._fragments[keyRef];\n  }\n\n\n  /**\n   * Remove cached schema(s).\n   * If no parameter is passed all schemas but meta-schemas are removed.\n   * If RegExp is passed all schemas with key/id matching pattern but meta-schemas are removed.\n   * Even if schema is referenced by other schemas it still can be removed as other schemas have local references.\n   * @param  {String|Object|RegExp} schemaKeyRef key, ref, pattern to match key/ref or schema object\n   */\n  function removeSchema(schemaKeyRef) {\n    if (schemaKeyRef instanceof RegExp) {\n      _removeAllSchemas(self._schemas, schemaKeyRef);\n      _removeAllSchemas(self._refs, schemaKeyRef);\n      return;\n    }\n    switch (typeof schemaKeyRef) {\n      case 'undefined':\n        _removeAllSchemas(self._schemas);\n        _removeAllSchemas(self._refs);\n        self._cache.clear();\n        return;\n      case 'string':\n        var schemaObj = _getSchemaObj(schemaKeyRef);\n        if (schemaObj) self._cache.del(schemaObj.jsonStr);\n        delete self._schemas[schemaKeyRef];\n        delete self._refs[schemaKeyRef];\n        return;\n      case 'object':\n        var jsonStr = stableStringify(schemaKeyRef);\n        self._cache.del(jsonStr);\n        var id = schemaKeyRef.id;\n        if (id) {\n          id = resolve.normalizeId(id);\n          delete self._schemas[id];\n          delete self._refs[id];\n        }\n    }\n  }\n\n\n  function _removeAllSchemas(schemas, regex) {\n    for (var keyRef in schemas) {\n      var schemaObj = schemas[keyRef];\n      if (!schemaObj.meta && (!regex || regex.test(keyRef))) {\n        self._cache.del(schemaObj.jsonStr);\n        delete schemas[keyRef];\n      }\n    }\n  }\n\n\n  function _addSchema(schema, skipValidation, meta, shouldAddSchema) {\n    if (typeof schema != 'object') throw new Error('schema should be object');\n    var jsonStr = stableStringify(schema);\n    var cached = self._cache.get(jsonStr);\n    if (cached) return cached;\n\n    shouldAddSchema = shouldAddSchema || self._opts.addUsedSchema !== false;\n\n    var id = resolve.normalizeId(schema.id);\n    if (id && shouldAddSchema) checkUnique(id);\n\n    var willValidate = self._opts.validateSchema !== false && !skipValidation;\n    var recursiveMeta;\n    if (willValidate && !(recursiveMeta = schema.id && schema.id == schema.$schema))\n      validateSchema(schema, true);\n\n    var localRefs = resolve.ids.call(self, schema);\n\n    var schemaObj = new SchemaObject({\n      id: id,\n      schema: schema,\n      localRefs: localRefs,\n      jsonStr: jsonStr,\n      meta: meta\n    });\n\n    if (id[0] != '#' && shouldAddSchema) self._refs[id] = schemaObj;\n    self._cache.put(jsonStr, schemaObj);\n\n    if (willValidate && recursiveMeta) validateSchema(schema, true);\n\n    return schemaObj;\n  }\n\n\n  function _compile(schemaObj, root) {\n    if (schemaObj.compiling) {\n      schemaObj.validate = callValidate;\n      callValidate.schema = schemaObj.schema;\n      callValidate.errors = null;\n      callValidate.root = root ? root : callValidate;\n      if (schemaObj.schema.$async === true)\n        callValidate.$async = true;\n      return callValidate;\n    }\n    schemaObj.compiling = true;\n\n    var currentOpts;\n    if (schemaObj.meta) {\n      currentOpts = self._opts;\n      self._opts = self._metaOpts;\n    }\n\n    var v;\n    try { v = compileSchema.call(self, schemaObj.schema, root, schemaObj.localRefs); }\n    finally {\n      schemaObj.compiling = false;\n      if (schemaObj.meta) self._opts = currentOpts;\n    }\n\n    schemaObj.validate = v;\n    schemaObj.refs = v.refs;\n    schemaObj.refVal = v.refVal;\n    schemaObj.root = v.root;\n    return v;\n\n\n    function callValidate() {\n      var _validate = schemaObj.validate;\n      var result = _validate.apply(null, arguments);\n      callValidate.errors = _validate.errors;\n      return result;\n    }\n  }\n\n\n  /**\n   * Convert array of error message objects to string\n   * @param  {Array<Object>} errors optional array of validation errors, if not passed errors from the instance are used.\n   * @param  {Object} options optional options with properties `separator` and `dataVar`.\n   * @return {String} human readable string with all errors descriptions\n   */\n  function errorsText(errors, options) {\n    errors = errors || self.errors;\n    if (!errors) return 'No errors';\n    options = options || {};\n    var separator = options.separator === undefined ? ', ' : options.separator;\n    var dataVar = options.dataVar === undefined ? 'data' : options.dataVar;\n\n    var text = '';\n    for (var i=0; i<errors.length; i++) {\n      var e = errors[i];\n      if (e) text += dataVar + e.dataPath + ' ' + e.message + separator;\n    }\n    return text.slice(0, -separator.length);\n  }\n\n\n  /**\n   * Add custom format\n   * @param {String} name format name\n   * @param {String|RegExp|Function} format string is converted to RegExp; function should return boolean (true when valid)\n   */\n  function addFormat(name, format) {\n    if (typeof format == 'string') format = new RegExp(format);\n    self._formats[name] = format;\n  }\n\n\n  function addDraft4MetaSchema() {\n    if (self._opts.meta !== false) {\n      var metaSchema = require('./refs/json-schema-draft-04.json');\n      addMetaSchema(metaSchema, META_SCHEMA_ID, true);\n      self._refs['http://json-schema.org/schema'] = META_SCHEMA_ID;\n    }\n  }\n\n\n  function addInitialSchemas() {\n    var optsSchemas = self._opts.schemas;\n    if (!optsSchemas) return;\n    if (Array.isArray(optsSchemas)) addSchema(optsSchemas);\n    else for (var key in optsSchemas) addSchema(optsSchemas[key], key);\n  }\n\n\n  function addInitialFormats() {\n    for (var name in self._opts.formats) {\n      var format = self._opts.formats[name];\n      addFormat(name, format);\n    }\n  }\n\n\n  function checkUnique(id) {\n    if (self._schemas[id] || self._refs[id])\n      throw new Error('schema with key or id \"' + id + '\" already exists');\n  }\n\n\n  function getMetaSchemaOptions() {\n    var metaOpts = util.copy(self._opts);\n    for (var i=0; i<META_IGNORE_OPTIONS.length; i++)\n      delete metaOpts[META_IGNORE_OPTIONS[i]];\n    return metaOpts;\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/index.js":"'use strict';\n\nvar resolve = require('./resolve')\n  , util = require('./util')\n  , stableStringify = require('json-stable-stringify')\n  , async = require('../async');\n\nvar beautify;\n\nfunction loadBeautify(){\n  if (beautify === undefined) {\n    var name = 'js-beautify';\n    try { beautify = require(name).js_beautify; }\n    catch(e) { beautify = false; }\n  }\n}\n\nvar validateGenerator = require('../dotjs/validate');\n\n/**\n * Functions below are used inside compiled validations function\n */\n\nvar co = require('co');\nvar ucs2length = util.ucs2length;\nvar equal = require('./equal');\n\n// this error is thrown by async schemas to return validation errors via exception\nvar ValidationError = require('./validation_error');\n\nmodule.exports = compile;\n\n\n/**\n * Compiles schema to validation function\n * @this   Ajv\n * @param  {Object} schema schema object\n * @param  {Object} root object with information about the root schema for this schema\n * @param  {Object} localRefs the hash of local references inside the schema (created by resolve.id), used for inline resolution\n * @param  {String} baseId base ID for IDs in the schema\n * @return {Function} validation function\n */\nfunction compile(schema, root, localRefs, baseId) {\n  /* jshint validthis: true, evil: true */\n  /* eslint no-shadow: 0 */\n  var self = this\n    , opts = this._opts\n    , refVal = [ undefined ]\n    , refs = {}\n    , patterns = []\n    , patternsHash = {}\n    , defaults = []\n    , defaultsHash = {}\n    , customRules = []\n    , keepSourceCode = opts.sourceCode !== false;\n\n  root = root || { schema: schema, refVal: refVal, refs: refs };\n\n  var c = checkCompiling.call(this, schema, root, baseId);\n  var compilation = this._compilations[c.index];\n  if (c.compiling) return (compilation.callValidate = callValidate);\n\n  var formats = this._formats;\n  var RULES = this.RULES;\n\n  try {\n    var v = localCompile(schema, root, localRefs, baseId);\n    compilation.validate = v;\n    var cv = compilation.callValidate;\n    if (cv) {\n      cv.schema = v.schema;\n      cv.errors = null;\n      cv.refs = v.refs;\n      cv.refVal = v.refVal;\n      cv.root = v.root;\n      cv.$async = v.$async;\n      if (keepSourceCode) cv.sourceCode = v.sourceCode;\n    }\n    return v;\n  } finally {\n    endCompiling.call(this, schema, root, baseId);\n  }\n\n  function callValidate() {\n    var validate = compilation.validate;\n    var result = validate.apply(null, arguments);\n    callValidate.errors = validate.errors;\n    return result;\n  }\n\n  function localCompile(_schema, _root, localRefs, baseId) {\n    var isRoot = !_root || (_root && _root.schema == _schema);\n    if (_root.schema != root.schema)\n      return compile.call(self, _schema, _root, localRefs, baseId);\n\n    var $async = _schema.$async === true;\n    if ($async && !opts.transpile) async.setup(opts);\n\n    var sourceCode = validateGenerator({\n      isTop: true,\n      schema: _schema,\n      isRoot: isRoot,\n      baseId: baseId,\n      root: _root,\n      schemaPath: '',\n      errSchemaPath: '#',\n      errorPath: '\"\"',\n      RULES: RULES,\n      validate: validateGenerator,\n      util: util,\n      resolve: resolve,\n      resolveRef: resolveRef,\n      usePattern: usePattern,\n      useDefault: useDefault,\n      useCustomRule: useCustomRule,\n      opts: opts,\n      formats: formats,\n      self: self\n    });\n\n    sourceCode = vars(refVal, refValCode) + vars(patterns, patternCode)\n                   + vars(defaults, defaultCode) + vars(customRules, customRuleCode)\n                   + sourceCode;\n\n    if (opts.beautify) {\n      loadBeautify();\n      /* istanbul ignore else */\n      if (beautify) sourceCode = beautify(sourceCode, opts.beautify);\n      else console.error('\"npm install js-beautify\" to use beautify option');\n    }\n    // console.log('\\n\\n\\n *** \\n', sourceCode);\n    var validate, validateCode\n      , transpile = opts._transpileFunc;\n    try {\n      validateCode = $async && transpile\n                      ? transpile(sourceCode)\n                      : sourceCode;\n\n      var makeValidate = new Function(\n        'self',\n        'RULES',\n        'formats',\n        'root',\n        'refVal',\n        'defaults',\n        'customRules',\n        'co',\n        'equal',\n        'ucs2length',\n        'ValidationError',\n        validateCode\n      );\n\n      validate = makeValidate(\n        self,\n        RULES,\n        formats,\n        root,\n        refVal,\n        defaults,\n        customRules,\n        co,\n        equal,\n        ucs2length,\n        ValidationError\n      );\n\n      refVal[0] = validate;\n    } catch(e) {\n      console.error('Error compiling schema, function code:', validateCode);\n      throw e;\n    }\n\n    validate.schema = _schema;\n    validate.errors = null;\n    validate.refs = refs;\n    validate.refVal = refVal;\n    validate.root = isRoot ? validate : _root;\n    if ($async) validate.$async = true;\n    if (keepSourceCode) validate.sourceCode = sourceCode;\n    if (opts.sourceCode === true) {\n      validate.source = {\n        patterns: patterns,\n        defaults: defaults\n      };\n    }\n\n    return validate;\n  }\n\n  function resolveRef(baseId, ref, isRoot) {\n    ref = resolve.url(baseId, ref);\n    var refIndex = refs[ref];\n    var _refVal, refCode;\n    if (refIndex !== undefined) {\n      _refVal = refVal[refIndex];\n      refCode = 'refVal[' + refIndex + ']';\n      return resolvedRef(_refVal, refCode);\n    }\n    if (!isRoot && root.refs) {\n      var rootRefId = root.refs[ref];\n      if (rootRefId !== undefined) {\n        _refVal = root.refVal[rootRefId];\n        refCode = addLocalRef(ref, _refVal);\n        return resolvedRef(_refVal, refCode);\n      }\n    }\n\n    refCode = addLocalRef(ref);\n    var v = resolve.call(self, localCompile, root, ref);\n    if (!v) {\n      var localSchema = localRefs && localRefs[ref];\n      if (localSchema) {\n        v = resolve.inlineRef(localSchema, opts.inlineRefs)\n            ? localSchema\n            : compile.call(self, localSchema, root, localRefs, baseId);\n      }\n    }\n\n    if (v) {\n      replaceLocalRef(ref, v);\n      return resolvedRef(v, refCode);\n    }\n  }\n\n  function addLocalRef(ref, v) {\n    var refId = refVal.length;\n    refVal[refId] = v;\n    refs[ref] = refId;\n    return 'refVal' + refId;\n  }\n\n  function replaceLocalRef(ref, v) {\n    var refId = refs[ref];\n    refVal[refId] = v;\n  }\n\n  function resolvedRef(refVal, code) {\n    return typeof refVal == 'object'\n            ? { code: code, schema: refVal, inline: true }\n            : { code: code, $async: refVal && refVal.$async };\n  }\n\n  function usePattern(regexStr) {\n    var index = patternsHash[regexStr];\n    if (index === undefined) {\n      index = patternsHash[regexStr] = patterns.length;\n      patterns[index] = regexStr;\n    }\n    return 'pattern' + index;\n  }\n\n  function useDefault(value) {\n    switch (typeof value) {\n      case 'boolean':\n      case 'number':\n        return '' + value;\n      case 'string':\n        return util.toQuotedString(value);\n      case 'object':\n        if (value === null) return 'null';\n        var valueStr = stableStringify(value);\n        var index = defaultsHash[valueStr];\n        if (index === undefined) {\n          index = defaultsHash[valueStr] = defaults.length;\n          defaults[index] = value;\n        }\n        return 'default' + index;\n    }\n  }\n\n  function useCustomRule(rule, schema, parentSchema, it) {\n    var validateSchema = rule.definition.validateSchema;\n    if (validateSchema && self._opts.validateSchema !== false) {\n      var valid = validateSchema(schema);\n      if (!valid) {\n        var message = 'keyword schema is invalid: ' + self.errorsText(validateSchema.errors);\n        if (self._opts.validateSchema == 'log') console.error(message);\n        else throw new Error(message);\n      }\n    }\n\n    var compile = rule.definition.compile\n      , inline = rule.definition.inline\n      , macro = rule.definition.macro;\n\n    var validate;\n    if (compile) {\n      validate = compile.call(self, schema, parentSchema, it);\n    } else if (macro) {\n      validate = macro.call(self, schema, parentSchema, it);\n      if (opts.validateSchema !== false) self.validateSchema(validate, true);\n    } else if (inline) {\n      validate = inline.call(self, it, rule.keyword, schema, parentSchema);\n    } else {\n      validate = rule.definition.validate;\n    }\n\n    var index = customRules.length;\n    customRules[index] = validate;\n\n    return {\n      code: 'customRule' + index,\n      validate: validate\n    };\n  }\n}\n\n\n/**\n * Checks if the schema is currently compiled\n * @this   Ajv\n * @param  {Object} schema schema to compile\n * @param  {Object} root root object\n * @param  {String} baseId base schema ID\n * @return {Object} object with properties \"index\" (compilation index) and \"compiling\" (boolean)\n */\nfunction checkCompiling(schema, root, baseId) {\n  /* jshint validthis: true */\n  var index = compIndex.call(this, schema, root, baseId);\n  if (index >= 0) return { index: index, compiling: true };\n  index = this._compilations.length;\n  this._compilations[index] = {\n    schema: schema,\n    root: root,\n    baseId: baseId\n  };\n  return { index: index, compiling: false };\n}\n\n\n/**\n * Removes the schema from the currently compiled list\n * @this   Ajv\n * @param  {Object} schema schema to compile\n * @param  {Object} root root object\n * @param  {String} baseId base schema ID\n */\nfunction endCompiling(schema, root, baseId) {\n  /* jshint validthis: true */\n  var i = compIndex.call(this, schema, root, baseId);\n  if (i >= 0) this._compilations.splice(i, 1);\n}\n\n\n/**\n * Index of schema compilation in the currently compiled list\n * @this   Ajv\n * @param  {Object} schema schema to compile\n * @param  {Object} root root object\n * @param  {String} baseId base schema ID\n * @return {Integer} compilation index\n */\nfunction compIndex(schema, root, baseId) {\n  /* jshint validthis: true */\n  for (var i=0; i<this._compilations.length; i++) {\n    var c = this._compilations[i];\n    if (c.schema == schema && c.root == root && c.baseId == baseId) return i;\n  }\n  return -1;\n}\n\n\nfunction patternCode(i, patterns) {\n  return 'var pattern' + i + ' = new RegExp(' + util.toQuotedString(patterns[i]) + ');';\n}\n\n\nfunction defaultCode(i) {\n  return 'var default' + i + ' = defaults[' + i + '];';\n}\n\n\nfunction refValCode(i, refVal) {\n  return refVal[i] ? 'var refVal' + i + ' = refVal[' + i + '];' : '';\n}\n\n\nfunction customRuleCode(i) {\n  return 'var customRule' + i + ' = customRules[' + i + '];';\n}\n\n\nfunction vars(arr, statement) {\n  if (!arr.length) return '';\n  var code = '';\n  for (var i=0; i<arr.length; i++)\n    code += statement(i, arr);\n  return code;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/resolve.js":"'use strict';\n\nvar url = require('url')\n  , equal = require('./equal')\n  , util = require('./util')\n  , SchemaObject = require('./schema_obj');\n\nmodule.exports = resolve;\n\nresolve.normalizeId = normalizeId;\nresolve.fullPath = getFullPath;\nresolve.url = resolveUrl;\nresolve.ids = resolveIds;\nresolve.inlineRef = inlineRef;\nresolve.schema = resolveSchema;\n\n/**\n * [resolve and compile the references ($ref)]\n * @this   Ajv\n * @param  {Function} compile reference to schema compilation funciton (localCompile)\n * @param  {Object} root object with information about the root schema for the current schema\n * @param  {String} ref reference to resolve\n * @return {Object|Function} schema object (if the schema can be inlined) or validation function\n */\nfunction resolve(compile, root, ref) {\n  /* jshint validthis: true */\n  var refVal = this._refs[ref];\n  if (typeof refVal == 'string') {\n    if (this._refs[refVal]) refVal = this._refs[refVal];\n    else return resolve.call(this, compile, root, refVal);\n  }\n\n  refVal = refVal || this._schemas[ref];\n  if (refVal instanceof SchemaObject) {\n    return inlineRef(refVal.schema, this._opts.inlineRefs)\n            ? refVal.schema\n            : refVal.validate || this._compile(refVal);\n  }\n\n  var res = resolveSchema.call(this, root, ref);\n  var schema, v, baseId;\n  if (res) {\n    schema = res.schema;\n    root = res.root;\n    baseId = res.baseId;\n  }\n\n  if (schema instanceof SchemaObject) {\n    v = schema.validate || compile.call(this, schema.schema, root, undefined, baseId);\n  } else if (schema) {\n    v = inlineRef(schema, this._opts.inlineRefs)\n        ? schema\n        : compile.call(this, schema, root, undefined, baseId);\n  }\n\n  return v;\n}\n\n\n/**\n * Resolve schema, its root and baseId\n * @this Ajv\n * @param  {Object} root root object with properties schema, refVal, refs\n * @param  {String} ref  reference to resolve\n * @return {Object} object with properties schema, root, baseId\n */\nfunction resolveSchema(root, ref) {\n  /* jshint validthis: true */\n  var p = url.parse(ref, false, true)\n    , refPath = _getFullPath(p)\n    , baseId = getFullPath(root.schema.id);\n  if (refPath !== baseId) {\n    var id = normalizeId(refPath);\n    var refVal = this._refs[id];\n    if (typeof refVal == 'string') {\n      return resolveRecursive.call(this, root, refVal, p);\n    } else if (refVal instanceof SchemaObject) {\n      if (!refVal.validate) this._compile(refVal);\n      root = refVal;\n    } else {\n      refVal = this._schemas[id];\n      if (refVal instanceof SchemaObject) {\n        if (!refVal.validate) this._compile(refVal);\n        if (id == normalizeId(ref))\n          return { schema: refVal, root: root, baseId: baseId };\n        root = refVal;\n      } else {\n        return;\n      }\n    }\n    if (!root.schema) return;\n    baseId = getFullPath(root.schema.id);\n  }\n  return getJsonPointer.call(this, p, baseId, root.schema, root);\n}\n\n\n/* @this Ajv */\nfunction resolveRecursive(root, ref, parsedRef) {\n  /* jshint validthis: true */\n  var res = resolveSchema.call(this, root, ref);\n  if (res) {\n    var schema = res.schema;\n    var baseId = res.baseId;\n    root = res.root;\n    if (schema.id) baseId = resolveUrl(baseId, schema.id);\n    return getJsonPointer.call(this, parsedRef, baseId, schema, root);\n  }\n}\n\n\nvar PREVENT_SCOPE_CHANGE = util.toHash(['properties', 'patternProperties', 'enum', 'dependencies', 'definitions']);\n/* @this Ajv */\nfunction getJsonPointer(parsedRef, baseId, schema, root) {\n  /* jshint validthis: true */\n  parsedRef.hash = parsedRef.hash || '';\n  if (parsedRef.hash.slice(0,2) != '#/') return;\n  var parts = parsedRef.hash.split('/');\n\n  for (var i = 1; i < parts.length; i++) {\n    var part = parts[i];\n    if (part) {\n      part = util.unescapeFragment(part);\n      schema = schema[part];\n      if (!schema) break;\n      if (schema.id && !PREVENT_SCOPE_CHANGE[part]) baseId = resolveUrl(baseId, schema.id);\n      if (schema.$ref) {\n        var $ref = resolveUrl(baseId, schema.$ref);\n        var res = resolveSchema.call(this, root, $ref);\n        if (res) {\n          schema = res.schema;\n          root = res.root;\n          baseId = res.baseId;\n        }\n      }\n    }\n  }\n  if (schema && schema != root.schema)\n    return { schema: schema, root: root, baseId: baseId };\n}\n\n\nvar SIMPLE_INLINED = util.toHash([\n  'type', 'format', 'pattern',\n  'maxLength', 'minLength',\n  'maxProperties', 'minProperties',\n  'maxItems', 'minItems',\n  'maximum', 'minimum',\n  'uniqueItems', 'multipleOf',\n  'required', 'enum'\n]);\nfunction inlineRef(schema, limit) {\n  if (limit === false) return false;\n  if (limit === undefined || limit === true) return checkNoRef(schema);\n  else if (limit) return countKeys(schema) <= limit;\n}\n\n\nfunction checkNoRef(schema) {\n  var item;\n  if (Array.isArray(schema)) {\n    for (var i=0; i<schema.length; i++) {\n      item = schema[i];\n      if (typeof item == 'object' && !checkNoRef(item)) return false;\n    }\n  } else {\n    for (var key in schema) {\n      if (key == '$ref') return false;\n      item = schema[key];\n      if (typeof item == 'object' && !checkNoRef(item)) return false;\n    }\n  }\n  return true;\n}\n\n\nfunction countKeys(schema) {\n  var count = 0, item;\n  if (Array.isArray(schema)) {\n    for (var i=0; i<schema.length; i++) {\n      item = schema[i];\n      if (typeof item == 'object') count += countKeys(item);\n      if (count == Infinity) return Infinity;\n    }\n  } else {\n    for (var key in schema) {\n      if (key == '$ref') return Infinity;\n      if (SIMPLE_INLINED[key]) {\n        count++;\n      } else {\n        item = schema[key];\n        if (typeof item == 'object') count += countKeys(item) + 1;\n        if (count == Infinity) return Infinity;\n      }\n    }\n  }\n  return count;\n}\n\n\nfunction getFullPath(id, normalize) {\n  if (normalize !== false) id = normalizeId(id);\n  var p = url.parse(id, false, true);\n  return _getFullPath(p);\n}\n\n\nfunction _getFullPath(p) {\n  var protocolSeparator = p.protocol || p.href.slice(0,2) == '//' ? '//' : '';\n  return (p.protocol||'') + protocolSeparator + (p.host||'') + (p.path||'')  + '#';\n}\n\n\nvar TRAILING_SLASH_HASH = /#\\/?$/;\nfunction normalizeId(id) {\n  return id ? id.replace(TRAILING_SLASH_HASH, '') : '';\n}\n\n\nfunction resolveUrl(baseId, id) {\n  id = normalizeId(id);\n  return url.resolve(baseId, id);\n}\n\n\n/* @this Ajv */\nfunction resolveIds(schema) {\n  /* eslint no-shadow: 0 */\n  /* jshint validthis: true */\n  var id = normalizeId(schema.id);\n  var localRefs = {};\n  _resolveIds.call(this, schema, getFullPath(id, false), id);\n  return localRefs;\n\n  /* @this Ajv */\n  function _resolveIds(schema, fullPath, baseId) {\n    /* jshint validthis: true */\n    if (Array.isArray(schema)) {\n      for (var i=0; i<schema.length; i++)\n        _resolveIds.call(this, schema[i], fullPath+'/'+i, baseId);\n    } else if (schema && typeof schema == 'object') {\n      if (typeof schema.id == 'string') {\n        var id = baseId = baseId\n                          ? url.resolve(baseId, schema.id)\n                          : schema.id;\n        id = normalizeId(id);\n\n        var refVal = this._refs[id];\n        if (typeof refVal == 'string') refVal = this._refs[refVal];\n        if (refVal && refVal.schema) {\n          if (!equal(schema, refVal.schema))\n            throw new Error('id \"' + id + '\" resolves to more than one schema');\n        } else if (id != normalizeId(fullPath)) {\n          if (id[0] == '#') {\n            if (localRefs[id] && !equal(schema, localRefs[id]))\n              throw new Error('id \"' + id + '\" resolves to more than one schema');\n            localRefs[id] = schema;\n          } else {\n            this._refs[id] = fullPath;\n          }\n        }\n      }\n      for (var key in schema)\n        _resolveIds.call(this, schema[key], fullPath+'/'+util.escapeFragment(key), baseId);\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/equal.js":"'use strict';\n\n/*eslint complexity: 0*/\n\nmodule.exports = function equal(a, b) {\n  if (a === b) return true;\n\n  var arrA = Array.isArray(a)\n    , arrB = Array.isArray(b)\n    , i;\n\n  if (arrA && arrB) {\n    if (a.length != b.length) return false;\n    for (i = 0; i < a.length; i++)\n      if (!equal(a[i], b[i])) return false;\n    return true;\n  }\n\n  if (arrA != arrB) return false;\n\n  if (a && b && typeof a === 'object' && typeof b === 'object') {\n    var keys = Object.keys(a);\n    if (keys.length !== Object.keys(b).length) return false;\n\n    var dateA = a instanceof Date\n      , dateB = b instanceof Date;\n    if (dateA && dateB) return a.getTime() == b.getTime();\n    if (dateA != dateB) return false;\n\n    var regexpA = a instanceof RegExp\n      , regexpB = b instanceof RegExp;\n    if (regexpA && regexpB) return a.toString() == b.toString();\n    if (regexpA != regexpB) return false;\n\n    for (i = 0; i < keys.length; i++)\n      if (!Object.prototype.hasOwnProperty.call(b, keys[i])) return false;\n\n    for (i = 0; i < keys.length; i++)\n      if(!equal(a[keys[i]], b[keys[i]])) return false;\n\n    return true;\n  }\n\n  return false;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/util.js":"'use strict';\n\n\nmodule.exports = {\n  copy: copy,\n  checkDataType: checkDataType,\n  checkDataTypes: checkDataTypes,\n  coerceToTypes: coerceToTypes,\n  toHash: toHash,\n  getProperty: getProperty,\n  escapeQuotes: escapeQuotes,\n  ucs2length: require('./ucs2length'),\n  varOccurences: varOccurences,\n  varReplace: varReplace,\n  cleanUpCode: cleanUpCode,\n  cleanUpVarErrors: cleanUpVarErrors,\n  schemaHasRules: schemaHasRules,\n  schemaHasRulesExcept: schemaHasRulesExcept,\n  stableStringify: require('json-stable-stringify'),\n  toQuotedString: toQuotedString,\n  getPathExpr: getPathExpr,\n  getPath: getPath,\n  getData: getData,\n  unescapeFragment: unescapeFragment,\n  escapeFragment: escapeFragment,\n  escapeJsonPointer: escapeJsonPointer\n};\n\n\nfunction copy(o, to) {\n  to = to || {};\n  for (var key in o) to[key] = o[key];\n  return to;\n}\n\n\nfunction checkDataType(dataType, data, negate) {\n  var EQUAL = negate ? ' !== ' : ' === '\n    , AND = negate ? ' || ' : ' && '\n    , OK = negate ? '!' : ''\n    , NOT = negate ? '' : '!';\n  switch (dataType) {\n    case 'null': return data + EQUAL + 'null';\n    case 'array': return OK + 'Array.isArray(' + data + ')';\n    case 'object': return '(' + OK + data + AND +\n                          'typeof ' + data + EQUAL + '\"object\"' + AND +\n                          NOT + 'Array.isArray(' + data + '))';\n    case 'integer': return '(typeof ' + data + EQUAL + '\"number\"' + AND +\n                           NOT + '(' + data + ' % 1)' +\n                           AND + data + EQUAL + data + ')';\n    default: return 'typeof ' + data + EQUAL + '\"' + dataType + '\"';\n  }\n}\n\n\nfunction checkDataTypes(dataTypes, data) {\n  switch (dataTypes.length) {\n    case 1: return checkDataType(dataTypes[0], data, true);\n    default:\n      var code = '';\n      var types = toHash(dataTypes);\n      if (types.array && types.object) {\n        code = types.null ? '(': '(!' + data + ' || ';\n        code += 'typeof ' + data + ' !== \"object\")';\n        delete types.null;\n        delete types.array;\n        delete types.object;\n      }\n      if (types.number) delete types.integer;\n      for (var t in types)\n        code += (code ? ' && ' : '' ) + checkDataType(t, data, true);\n\n      return code;\n  }\n}\n\n\nvar COERCE_TO_TYPES = toHash([ 'string', 'number', 'integer', 'boolean', 'null' ]);\nfunction coerceToTypes(optionCoerceTypes, dataTypes) {\n  if (Array.isArray(dataTypes)) {\n    var types = [];\n    for (var i=0; i<dataTypes.length; i++) {\n      var t = dataTypes[i];\n      if (COERCE_TO_TYPES[t]) types[types.length] = t;\n      else if (optionCoerceTypes === 'array' && t === 'array') types[types.length] = t;\n    }\n    if (types.length) return types;\n  } else if (COERCE_TO_TYPES[dataTypes]) {\n    return [dataTypes];\n  } else if (optionCoerceTypes === 'array' && dataTypes === 'array') {\n    return ['array'];\n  }\n}\n\n\nfunction toHash(arr) {\n  var hash = {};\n  for (var i=0; i<arr.length; i++) hash[arr[i]] = true;\n  return hash;\n}\n\n\nvar IDENTIFIER = /^[a-z$_][a-z$_0-9]*$/i;\nvar SINGLE_QUOTE = /'|\\\\/g;\nfunction getProperty(key) {\n  return typeof key == 'number'\n          ? '[' + key + ']'\n          : IDENTIFIER.test(key)\n            ? '.' + key\n            : \"['\" + escapeQuotes(key) + \"']\";\n}\n\n\nfunction escapeQuotes(str) {\n  return str.replace(SINGLE_QUOTE, '\\\\$&')\n            .replace(/\\n/g, '\\\\n')\n            .replace(/\\r/g, '\\\\r')\n            .replace(/\\f/g, '\\\\f')\n            .replace(/\\t/g, '\\\\t');\n}\n\n\nfunction varOccurences(str, dataVar) {\n  dataVar += '[^0-9]';\n  var matches = str.match(new RegExp(dataVar, 'g'));\n  return matches ? matches.length : 0;\n}\n\n\nfunction varReplace(str, dataVar, expr) {\n  dataVar += '([^0-9])';\n  expr = expr.replace(/\\$/g, '$$$$');\n  return str.replace(new RegExp(dataVar, 'g'), expr + '$1');\n}\n\n\nvar EMPTY_ELSE = /else\\s*{\\s*}/g\n  , EMPTY_IF_NO_ELSE = /if\\s*\\([^)]+\\)\\s*\\{\\s*\\}(?!\\s*else)/g\n  , EMPTY_IF_WITH_ELSE = /if\\s*\\(([^)]+)\\)\\s*\\{\\s*\\}\\s*else(?!\\s*if)/g;\nfunction cleanUpCode(out) {\n  return out.replace(EMPTY_ELSE, '')\n            .replace(EMPTY_IF_NO_ELSE, '')\n            .replace(EMPTY_IF_WITH_ELSE, 'if (!($1))');\n}\n\n\nvar ERRORS_REGEXP = /[^v\\.]errors/g\n  , REMOVE_ERRORS = /var errors = 0;|var vErrors = null;|validate.errors = vErrors;/g\n  , REMOVE_ERRORS_ASYNC = /var errors = 0;|var vErrors = null;/g\n  , RETURN_VALID = 'return errors === 0;'\n  , RETURN_TRUE = 'validate.errors = null; return true;'\n  , RETURN_ASYNC = /if \\(errors === 0\\) return true;\\s*else throw new ValidationError\\(vErrors\\);/\n  , RETURN_TRUE_ASYNC = 'return true;';\n\nfunction cleanUpVarErrors(out, async) {\n  var matches = out.match(ERRORS_REGEXP);\n  if (!matches || matches.length !== 2) return out;\n  return async\n          ? out.replace(REMOVE_ERRORS_ASYNC, '')\n               .replace(RETURN_ASYNC, RETURN_TRUE_ASYNC)\n          : out.replace(REMOVE_ERRORS, '')\n               .replace(RETURN_VALID, RETURN_TRUE);\n}\n\n\nfunction schemaHasRules(schema, rules) {\n  for (var key in schema) if (rules[key]) return true;\n}\n\n\nfunction schemaHasRulesExcept(schema, rules, exceptKeyword) {\n  for (var key in schema) if (key != exceptKeyword && rules[key]) return true;\n}\n\n\nfunction toQuotedString(str) {\n  return '\\'' + escapeQuotes(str) + '\\'';\n}\n\n\nfunction getPathExpr(currentPath, expr, jsonPointers, isNumber) {\n  var path = jsonPointers // false by default\n              ? '\\'/\\' + ' + expr + (isNumber ? '' : '.replace(/~/g, \\'~0\\').replace(/\\\\//g, \\'~1\\')')\n              : (isNumber ? '\\'[\\' + ' + expr + ' + \\']\\'' : '\\'[\\\\\\'\\' + ' + expr + ' + \\'\\\\\\']\\'');\n  return joinPaths(currentPath, path);\n}\n\n\nfunction getPath(currentPath, prop, jsonPointers) {\n  var path = jsonPointers // false by default\n              ? toQuotedString('/' + escapeJsonPointer(prop))\n              : toQuotedString(getProperty(prop));\n  return joinPaths(currentPath, path);\n}\n\n\nvar JSON_POINTER = /^\\/(?:[^~]|~0|~1)*$/;\nvar RELATIVE_JSON_POINTER = /^([0-9]+)(#|\\/(?:[^~]|~0|~1)*)?$/;\nfunction getData($data, lvl, paths) {\n  var up, jsonPointer, data, matches;\n  if ($data === '') return 'rootData';\n  if ($data[0] == '/') {\n    if (!JSON_POINTER.test($data)) throw new Error('Invalid JSON-pointer: ' + $data);\n    jsonPointer = $data;\n    data = 'rootData';\n  } else {\n    matches = $data.match(RELATIVE_JSON_POINTER);\n    if (!matches) throw new Error('Invalid JSON-pointer: ' + $data);\n    up = +matches[1];\n    jsonPointer = matches[2];\n    if (jsonPointer == '#') {\n      if (up >= lvl) throw new Error('Cannot access property/index ' + up + ' levels up, current level is ' + lvl);\n      return paths[lvl - up];\n    }\n\n    if (up > lvl) throw new Error('Cannot access data ' + up + ' levels up, current level is ' + lvl);\n    data = 'data' + ((lvl - up) || '');\n    if (!jsonPointer) return data;\n  }\n\n  var expr = data;\n  var segments = jsonPointer.split('/');\n  for (var i=0; i<segments.length; i++) {\n    var segment = segments[i];\n    if (segment) {\n      data += getProperty(unescapeJsonPointer(segment));\n      expr += ' && ' + data;\n    }\n  }\n  return expr;\n}\n\n\nfunction joinPaths (a, b) {\n  if (a == '\"\"') return b;\n  return (a + ' + ' + b).replace(/' \\+ '/g, '');\n}\n\n\nfunction unescapeFragment(str) {\n  return unescapeJsonPointer(decodeURIComponent(str));\n}\n\n\nfunction escapeFragment(str) {\n  return encodeURIComponent(escapeJsonPointer(str));\n}\n\n\nfunction escapeJsonPointer(str) {\n  return str.replace(/~/g, '~0').replace(/\\//g, '~1');\n}\n\n\nfunction unescapeJsonPointer(str) {\n  return str.replace(/~1/g, '/').replace(/~0/g, '~');\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/ucs2length.js":"'use strict';\n\n// https://mathiasbynens.be/notes/javascript-encoding\n// https://github.com/bestiejs/punycode.js - punycode.ucs2.decode\nmodule.exports = function ucs2length(str) {\n  var length = 0\n    , len = str.length\n    , pos = 0\n    , value;\n  while (pos < len) {\n    length++;\n    value = str.charCodeAt(pos++);\n    if (value >= 0xD800 && value <= 0xDBFF && pos < len) {\n      // high surrogate, and there is a next character\n      value = str.charCodeAt(pos);\n      if ((value & 0xFC00) == 0xDC00) pos++; // low surrogate\n    }\n  }\n  return length;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/node_modules/json-stable-stringify/index.js":"var json = typeof JSON !== 'undefined' ? JSON : require('jsonify');\n\nmodule.exports = function (obj, opts) {\n    if (!opts) opts = {};\n    if (typeof opts === 'function') opts = { cmp: opts };\n    var space = opts.space || '';\n    if (typeof space === 'number') space = Array(space+1).join(' ');\n    var cycles = (typeof opts.cycles === 'boolean') ? opts.cycles : false;\n    var replacer = opts.replacer || function(key, value) { return value; };\n\n    var cmp = opts.cmp && (function (f) {\n        return function (node) {\n            return function (a, b) {\n                var aobj = { key: a, value: node[a] };\n                var bobj = { key: b, value: node[b] };\n                return f(aobj, bobj);\n            };\n        };\n    })(opts.cmp);\n\n    var seen = [];\n    return (function stringify (parent, key, node, level) {\n        var indent = space ? ('\\n' + new Array(level + 1).join(space)) : '';\n        var colonSeparator = space ? ': ' : ':';\n\n        if (node && node.toJSON && typeof node.toJSON === 'function') {\n            node = node.toJSON();\n        }\n\n        node = replacer.call(parent, key, node);\n\n        if (node === undefined) {\n            return;\n        }\n        if (typeof node !== 'object' || node === null) {\n            return json.stringify(node);\n        }\n        if (isArray(node)) {\n            var out = [];\n            for (var i = 0; i < node.length; i++) {\n                var item = stringify(node, i, node[i], level+1) || json.stringify(null);\n                out.push(indent + space + item);\n            }\n            return '[' + out.join(',') + indent + ']';\n        }\n        else {\n            if (seen.indexOf(node) !== -1) {\n                if (cycles) return json.stringify('__cycle__');\n                throw new TypeError('Converting circular structure to JSON');\n            }\n            else seen.push(node);\n\n            var keys = objectKeys(node).sort(cmp && cmp(node));\n            var out = [];\n            for (var i = 0; i < keys.length; i++) {\n                var key = keys[i];\n                var value = stringify(node, key, node[key], level+1);\n\n                if(!value) continue;\n\n                var keyValue = json.stringify(key)\n                    + colonSeparator\n                    + value;\n                ;\n                out.push(indent + space + keyValue);\n            }\n            seen.splice(seen.indexOf(node), 1);\n            return '{' + out.join(',') + indent + '}';\n        }\n    })({ '': obj }, '', obj, 0);\n};\n\nvar isArray = Array.isArray || function (x) {\n    return {}.toString.call(x) === '[object Array]';\n};\n\nvar objectKeys = Object.keys || function (obj) {\n    var has = Object.prototype.hasOwnProperty || function () { return true };\n    var keys = [];\n    for (var key in obj) {\n        if (has.call(obj, key)) keys.push(key);\n    }\n    return keys;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/schema_obj.js":"'use strict';\n\nvar util = require('./util');\n\nmodule.exports = SchemaObject;\n\nfunction SchemaObject(obj) {\n  util.copy(obj, this);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/async.js":"'use strict';\n\nmodule.exports = {\n  setup: setupAsync,\n  compile: compileAsync\n};\n\n\nvar util = require('./compile/util');\n\nvar ASYNC = {\n  '*': checkGenerators,\n  'co*': checkGenerators,\n  'es7': checkAsyncFunction\n};\n\nvar TRANSPILE = {\n  'nodent': getNodent,\n  'regenerator': getRegenerator\n};\n\nvar MODES = [\n  { async: 'co*' },\n  { async: 'es7', transpile: 'nodent' },\n  { async: 'co*', transpile: 'regenerator' }\n];\n\n\nvar regenerator, nodent;\n\n\nfunction setupAsync(opts, required) {\n  if (required !== false) required = true;\n  var async = opts.async\n    , transpile = opts.transpile\n    , check;\n\n  switch (typeof transpile) {\n    case 'string':\n      var get = TRANSPILE[transpile];\n      if (!get) throw new Error('bad transpiler: ' + transpile);\n      return (opts._transpileFunc = get(opts, required));\n    case 'undefined':\n    case 'boolean':\n      if (typeof async == 'string') {\n        check = ASYNC[async];\n        if (!check) throw new Error('bad async mode: ' + async);\n        return (opts.transpile = check(opts, required));\n      }\n\n      for (var i=0; i<MODES.length; i++) {\n        var _opts = MODES[i];\n        if (setupAsync(_opts, false)) {\n          util.copy(_opts, opts);\n          return opts.transpile;\n        }\n      }\n      /* istanbul ignore next */\n      throw new Error('generators, nodent and regenerator are not available');\n    case 'function':\n      return (opts._transpileFunc = opts.transpile);\n    default:\n      throw new Error('bad transpiler: ' + transpile);\n  }\n}\n\n\nfunction checkGenerators(opts, required) {\n  /* jshint evil: true */\n  try {\n    (new Function('(function*(){})()'))();\n    return true;\n  } catch(e) {\n    /* istanbul ignore next */\n    if (required) throw new Error('generators not supported');\n  }\n}\n\n\nfunction checkAsyncFunction(opts, required) {\n  /* jshint evil: true */\n  try {\n    (new Function('(async function(){})()'))();\n    /* istanbul ignore next */\n    return true;\n  } catch(e) {\n    if (required) throw new Error('es7 async functions not supported');\n  }\n}\n\n\nfunction getRegenerator(opts, required) {\n  try {\n    if (!regenerator) {\n      var name = 'regenerator';\n      regenerator = require(name);\n      regenerator.runtime();\n    }\n    if (!opts.async || opts.async === true)\n      opts.async = 'es7';\n    return regeneratorTranspile;\n  } catch(e) {\n    /* istanbul ignore next */\n    if (required) throw new Error('regenerator not available');\n  }\n}\n\n\nfunction regeneratorTranspile(code) {\n  return regenerator.compile(code).code;\n}\n\n\nfunction getNodent(opts, required) {\n  /* jshint evil: true */\n  try {\n    if (!nodent) {\n      var name = 'nodent';\n      nodent = require(name)({ log: false, dontInstallRequireHook: true });\n    }\n    if (opts.async != 'es7') {\n      if (opts.async && opts.async !== true) console.warn('nodent transpiles only es7 async functions');\n      opts.async = 'es7';\n    }\n    return nodentTranspile;\n  } catch(e) {\n    /* istanbul ignore next */\n    if (required) throw new Error('nodent not available');\n  }\n}\n\n\nfunction nodentTranspile(code) {\n  return nodent.compile(code, '', { promises: true, sourcemap: false }).code;\n}\n\n\n/**\n * Creates validating function for passed schema with asynchronous loading of missing schemas.\n * `loadSchema` option should be a function that accepts schema uri and node-style callback.\n * @this  Ajv\n * @param {Object}   schema schema object\n * @param {Function} callback node-style callback, it is always called with 2 parameters: error (or null) and validating function.\n */\nfunction compileAsync(schema, callback) {\n  /* eslint no-shadow: 0 */\n  /* jshint validthis: true */\n  var schemaObj;\n  var self = this;\n  try {\n    schemaObj = this._addSchema(schema);\n  } catch(e) {\n    setTimeout(function() { callback(e); });\n    return;\n  }\n  if (schemaObj.validate) {\n    setTimeout(function() { callback(null, schemaObj.validate); });\n  } else {\n    if (typeof this._opts.loadSchema != 'function')\n      throw new Error('options.loadSchema should be a function');\n    _compileAsync(schema, callback, true);\n  }\n\n\n  function _compileAsync(schema, callback, firstCall) {\n    var validate;\n    try { validate = self.compile(schema); }\n    catch(e) {\n      if (e.missingSchema) loadMissingSchema(e);\n      else deferCallback(e);\n      return;\n    }\n    deferCallback(null, validate);\n\n    function loadMissingSchema(e) {\n      var ref = e.missingSchema;\n      if (self._refs[ref] || self._schemas[ref])\n        return callback(new Error('Schema ' + ref + ' is loaded but ' + e.missingRef + ' cannot be resolved'));\n      var _callbacks = self._loadingSchemas[ref];\n      if (_callbacks) {\n        if (typeof _callbacks == 'function')\n          self._loadingSchemas[ref] = [_callbacks, schemaLoaded];\n        else\n          _callbacks[_callbacks.length] = schemaLoaded;\n      } else {\n        self._loadingSchemas[ref] = schemaLoaded;\n        self._opts.loadSchema(ref, function (err, sch) {\n          var _callbacks = self._loadingSchemas[ref];\n          delete self._loadingSchemas[ref];\n          if (typeof _callbacks == 'function') {\n            _callbacks(err, sch);\n          } else {\n            for (var i=0; i<_callbacks.length; i++)\n              _callbacks[i](err, sch);\n          }\n        });\n      }\n\n      function schemaLoaded(err, sch) {\n        if (err) return callback(err);\n        if (!(self._refs[ref] || self._schemas[ref])) {\n          try {\n            self.addSchema(sch, ref);\n          } catch(e) {\n            callback(e);\n            return;\n          }\n        }\n        _compileAsync(schema, callback);\n      }\n    }\n\n    function deferCallback(err, validate) {\n      if (firstCall) setTimeout(function() { callback(err, validate); });\n      else return callback(err, validate);\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/validate.js":"'use strict';\nmodule.exports = function generate_validate(it, $keyword) {\n  var out = '';\n  var $async = it.schema.$async === true;\n  if (it.isTop) {\n    var $top = it.isTop,\n      $lvl = it.level = 0,\n      $dataLvl = it.dataLevel = 0,\n      $data = 'data';\n    it.rootId = it.resolve.fullPath(it.root.schema.id);\n    it.baseId = it.baseId || it.rootId;\n    if ($async) {\n      it.async = true;\n      var $es7 = it.opts.async == 'es7';\n      it.yieldAwait = $es7 ? 'await' : 'yield';\n    }\n    delete it.isTop;\n    it.dataPathArr = [undefined];\n    out += ' var validate = ';\n    if ($async) {\n      if ($es7) {\n        out += ' (async function ';\n      } else {\n        if (it.opts.async == 'co*') {\n          out += 'co.wrap';\n        }\n        out += '(function* ';\n      }\n    } else {\n      out += ' (function ';\n    }\n    out += ' (data, dataPath, parentData, parentDataProperty, rootData) { \\'use strict\\'; var vErrors = null; ';\n    out += ' var errors = 0;     ';\n    out += ' if (rootData === undefined) rootData = data;';\n  } else {\n    var $lvl = it.level,\n      $dataLvl = it.dataLevel,\n      $data = 'data' + ($dataLvl || '');\n    if (it.schema.id) it.baseId = it.resolve.url(it.baseId, it.schema.id);\n    if ($async && !it.async) throw new Error('async schema in sync schema');\n    out += ' var errs_' + ($lvl) + ' = errors;';\n  }\n  var $valid = 'valid' + $lvl,\n    $breakOnError = !it.opts.allErrors,\n    $closingBraces1 = '',\n    $closingBraces2 = '',\n    $errorKeyword;\n  var $typeSchema = it.schema.type,\n    $typeIsArray = Array.isArray($typeSchema);\n  if ($typeSchema && it.opts.coerceTypes) {\n    var $coerceToTypes = it.util.coerceToTypes(it.opts.coerceTypes, $typeSchema);\n    if ($coerceToTypes) {\n      var $schemaPath = it.schemaPath + '.type',\n        $errSchemaPath = it.errSchemaPath + '/type',\n        $method = $typeIsArray ? 'checkDataTypes' : 'checkDataType';\n      out += ' if (' + (it.util[$method]($typeSchema, $data, true)) + ') {  ';\n      var $dataType = 'dataType' + $lvl,\n        $coerced = 'coerced' + $lvl;\n      out += ' var ' + ($dataType) + ' = typeof ' + ($data) + '; ';\n      if (it.opts.coerceTypes == 'array') {\n        out += ' if (' + ($dataType) + ' == \\'object\\' && Array.isArray(' + ($data) + ')) ' + ($dataType) + ' = \\'array\\'; ';\n      }\n      out += ' var ' + ($coerced) + ' = undefined; ';\n      var $bracesCoercion = '';\n      var arr1 = $coerceToTypes;\n      if (arr1) {\n        var $type, $i = -1,\n          l1 = arr1.length - 1;\n        while ($i < l1) {\n          $type = arr1[$i += 1];\n          if ($i) {\n            out += ' if (' + ($coerced) + ' === undefined) { ';\n            $bracesCoercion += '}';\n          }\n          if (it.opts.coerceTypes == 'array' && $type != 'array') {\n            out += ' if (' + ($dataType) + ' == \\'array\\' && ' + ($data) + '.length == 1) { ' + ($coerced) + ' = ' + ($data) + ' = ' + ($data) + '[0]; ' + ($dataType) + ' = typeof ' + ($data) + ';  } ';\n          }\n          if ($type == 'string') {\n            out += ' if (' + ($dataType) + ' == \\'number\\' || ' + ($dataType) + ' == \\'boolean\\') ' + ($coerced) + ' = \\'\\' + ' + ($data) + '; else if (' + ($data) + ' === null) ' + ($coerced) + ' = \\'\\'; ';\n          } else if ($type == 'number' || $type == 'integer') {\n            out += ' if (' + ($dataType) + ' == \\'boolean\\' || ' + ($data) + ' === null || (' + ($dataType) + ' == \\'string\\' && ' + ($data) + ' && ' + ($data) + ' == +' + ($data) + ' ';\n            if ($type == 'integer') {\n              out += ' && !(' + ($data) + ' % 1)';\n            }\n            out += ')) ' + ($coerced) + ' = +' + ($data) + '; ';\n          } else if ($type == 'boolean') {\n            out += ' if (' + ($data) + ' === \\'false\\' || ' + ($data) + ' === 0 || ' + ($data) + ' === null) ' + ($coerced) + ' = false; else if (' + ($data) + ' === \\'true\\' || ' + ($data) + ' === 1) ' + ($coerced) + ' = true; ';\n          } else if ($type == 'null') {\n            out += ' if (' + ($data) + ' === \\'\\' || ' + ($data) + ' === 0 || ' + ($data) + ' === false) ' + ($coerced) + ' = null; ';\n          } else if (it.opts.coerceTypes == 'array' && $type == 'array') {\n            out += ' if (' + ($dataType) + ' == \\'string\\' || ' + ($dataType) + ' == \\'number\\' || ' + ($dataType) + ' == \\'boolean\\' || ' + ($data) + ' == null) ' + ($coerced) + ' = [' + ($data) + ']; ';\n          }\n        }\n      }\n      out += ' ' + ($bracesCoercion) + ' if (' + ($coerced) + ' === undefined) {   ';\n      var $$outStack = $$outStack || [];\n      $$outStack.push(out);\n      out = ''; /* istanbul ignore else */\n      if (it.createErrors !== false) {\n        out += ' { keyword: \\'' + ($errorKeyword || 'type') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { type: \\'';\n        if ($typeIsArray) {\n          out += '' + ($typeSchema.join(\",\"));\n        } else {\n          out += '' + ($typeSchema);\n        }\n        out += '\\' } ';\n        if (it.opts.messages !== false) {\n          out += ' , message: \\'should be ';\n          if ($typeIsArray) {\n            out += '' + ($typeSchema.join(\",\"));\n          } else {\n            out += '' + ($typeSchema);\n          }\n          out += '\\' ';\n        }\n        if (it.opts.verbose) {\n          out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n        }\n        out += ' } ';\n      } else {\n        out += ' {} ';\n      }\n      var __err = out;\n      out = $$outStack.pop();\n      if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n        if (it.async) {\n          out += ' throw new ValidationError([' + (__err) + ']); ';\n        } else {\n          out += ' validate.errors = [' + (__err) + ']; return false; ';\n        }\n      } else {\n        out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n      }\n      out += ' } else {  ';\n      var $parentData = $dataLvl ? 'data' + (($dataLvl - 1) || '') : 'parentData',\n        $parentDataProperty = $dataLvl ? it.dataPathArr[$dataLvl] : 'parentDataProperty';\n      out += ' ' + ($data) + ' = ' + ($coerced) + '; ';\n      if (!$dataLvl) {\n        out += 'if (' + ($parentData) + ' !== undefined)';\n      }\n      out += ' ' + ($parentData) + '[' + ($parentDataProperty) + '] = ' + ($coerced) + '; } } ';\n    }\n  }\n  var $refKeywords;\n  if (it.schema.$ref && ($refKeywords = it.util.schemaHasRulesExcept(it.schema, it.RULES.all, '$ref'))) {\n    if (it.opts.extendRefs == 'fail') {\n      throw new Error('$ref: validation keywords used in schema at path \"' + it.errSchemaPath + '\"');\n    } else if (it.opts.extendRefs == 'ignore') {\n      $refKeywords = false;\n      console.log('$ref: keywords ignored in schema at path \"' + it.errSchemaPath + '\"');\n    } else if (it.opts.extendRefs !== true) {\n      console.log('$ref: all keywords used in schema at path \"' + it.errSchemaPath + '\". It will change in the next major version, see issue #260. Use option { extendRefs: true } to keep current behaviour');\n    }\n  }\n  if (it.schema.$ref && !$refKeywords) {\n    out += ' ' + (it.RULES.all.$ref.code(it, '$ref')) + ' ';\n    if ($breakOnError) {\n      out += ' } if (errors === ';\n      if ($top) {\n        out += '0';\n      } else {\n        out += 'errs_' + ($lvl);\n      }\n      out += ') { ';\n      $closingBraces2 += '}';\n    }\n  } else {\n    var arr2 = it.RULES;\n    if (arr2) {\n      var $rulesGroup, i2 = -1,\n        l2 = arr2.length - 1;\n      while (i2 < l2) {\n        $rulesGroup = arr2[i2 += 1];\n        if ($shouldUseGroup($rulesGroup)) {\n          if ($rulesGroup.type) {\n            out += ' if (' + (it.util.checkDataType($rulesGroup.type, $data)) + ') { ';\n          }\n          if (it.opts.useDefaults && !it.compositeRule) {\n            if ($rulesGroup.type == 'object' && it.schema.properties) {\n              var $schema = it.schema.properties,\n                $schemaKeys = Object.keys($schema);\n              var arr3 = $schemaKeys;\n              if (arr3) {\n                var $propertyKey, i3 = -1,\n                  l3 = arr3.length - 1;\n                while (i3 < l3) {\n                  $propertyKey = arr3[i3 += 1];\n                  var $sch = $schema[$propertyKey];\n                  if ($sch.default !== undefined) {\n                    var $passData = $data + it.util.getProperty($propertyKey);\n                    out += '  if (' + ($passData) + ' === undefined) ' + ($passData) + ' = ';\n                    if (it.opts.useDefaults == 'shared') {\n                      out += ' ' + (it.useDefault($sch.default)) + ' ';\n                    } else {\n                      out += ' ' + (JSON.stringify($sch.default)) + ' ';\n                    }\n                    out += '; ';\n                  }\n                }\n              }\n            } else if ($rulesGroup.type == 'array' && Array.isArray(it.schema.items)) {\n              var arr4 = it.schema.items;\n              if (arr4) {\n                var $sch, $i = -1,\n                  l4 = arr4.length - 1;\n                while ($i < l4) {\n                  $sch = arr4[$i += 1];\n                  if ($sch.default !== undefined) {\n                    var $passData = $data + '[' + $i + ']';\n                    out += '  if (' + ($passData) + ' === undefined) ' + ($passData) + ' = ';\n                    if (it.opts.useDefaults == 'shared') {\n                      out += ' ' + (it.useDefault($sch.default)) + ' ';\n                    } else {\n                      out += ' ' + (JSON.stringify($sch.default)) + ' ';\n                    }\n                    out += '; ';\n                  }\n                }\n              }\n            }\n          }\n          var arr5 = $rulesGroup.rules;\n          if (arr5) {\n            var $rule, i5 = -1,\n              l5 = arr5.length - 1;\n            while (i5 < l5) {\n              $rule = arr5[i5 += 1];\n              if ($shouldUseRule($rule)) {\n                out += ' ' + ($rule.code(it, $rule.keyword)) + ' ';\n                if ($breakOnError) {\n                  $closingBraces1 += '}';\n                }\n              }\n            }\n          }\n          if ($breakOnError) {\n            out += ' ' + ($closingBraces1) + ' ';\n            $closingBraces1 = '';\n          }\n          if ($rulesGroup.type) {\n            out += ' } ';\n            if ($typeSchema && $typeSchema === $rulesGroup.type) {\n              var $typeChecked = true;\n              out += ' else { ';\n              var $schemaPath = it.schemaPath + '.type',\n                $errSchemaPath = it.errSchemaPath + '/type';\n              var $$outStack = $$outStack || [];\n              $$outStack.push(out);\n              out = ''; /* istanbul ignore else */\n              if (it.createErrors !== false) {\n                out += ' { keyword: \\'' + ($errorKeyword || 'type') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { type: \\'';\n                if ($typeIsArray) {\n                  out += '' + ($typeSchema.join(\",\"));\n                } else {\n                  out += '' + ($typeSchema);\n                }\n                out += '\\' } ';\n                if (it.opts.messages !== false) {\n                  out += ' , message: \\'should be ';\n                  if ($typeIsArray) {\n                    out += '' + ($typeSchema.join(\",\"));\n                  } else {\n                    out += '' + ($typeSchema);\n                  }\n                  out += '\\' ';\n                }\n                if (it.opts.verbose) {\n                  out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n                }\n                out += ' } ';\n              } else {\n                out += ' {} ';\n              }\n              var __err = out;\n              out = $$outStack.pop();\n              if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n                if (it.async) {\n                  out += ' throw new ValidationError([' + (__err) + ']); ';\n                } else {\n                  out += ' validate.errors = [' + (__err) + ']; return false; ';\n                }\n              } else {\n                out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n              }\n              out += ' } ';\n            }\n          }\n          if ($breakOnError) {\n            out += ' if (errors === ';\n            if ($top) {\n              out += '0';\n            } else {\n              out += 'errs_' + ($lvl);\n            }\n            out += ') { ';\n            $closingBraces2 += '}';\n          }\n        }\n      }\n    }\n  }\n  if ($typeSchema && !$typeChecked && !(it.opts.coerceTypes && $coerceToTypes)) {\n    var $schemaPath = it.schemaPath + '.type',\n      $errSchemaPath = it.errSchemaPath + '/type',\n      $method = $typeIsArray ? 'checkDataTypes' : 'checkDataType';\n    out += ' if (' + (it.util[$method]($typeSchema, $data, true)) + ') {   ';\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = ''; /* istanbul ignore else */\n    if (it.createErrors !== false) {\n      out += ' { keyword: \\'' + ($errorKeyword || 'type') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { type: \\'';\n      if ($typeIsArray) {\n        out += '' + ($typeSchema.join(\",\"));\n      } else {\n        out += '' + ($typeSchema);\n      }\n      out += '\\' } ';\n      if (it.opts.messages !== false) {\n        out += ' , message: \\'should be ';\n        if ($typeIsArray) {\n          out += '' + ($typeSchema.join(\",\"));\n        } else {\n          out += '' + ($typeSchema);\n        }\n        out += '\\' ';\n      }\n      if (it.opts.verbose) {\n        out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n      }\n      out += ' } ';\n    } else {\n      out += ' {} ';\n    }\n    var __err = out;\n    out = $$outStack.pop();\n    if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n      if (it.async) {\n        out += ' throw new ValidationError([' + (__err) + ']); ';\n      } else {\n        out += ' validate.errors = [' + (__err) + ']; return false; ';\n      }\n    } else {\n      out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n    }\n    out += ' }';\n  }\n  if ($breakOnError) {\n    out += ' ' + ($closingBraces2) + ' ';\n  }\n  if ($top) {\n    if ($async) {\n      out += ' if (errors === 0) return true;           ';\n      out += ' else throw new ValidationError(vErrors); ';\n    } else {\n      out += ' validate.errors = vErrors; ';\n      out += ' return errors === 0;       ';\n    }\n    out += ' }); return validate;';\n  } else {\n    out += ' var ' + ($valid) + ' = errors === errs_' + ($lvl) + ';';\n  }\n  out = it.util.cleanUpCode(out);\n  if ($top && $breakOnError) {\n    out = it.util.cleanUpVarErrors(out, $async);\n  }\n\n  function $shouldUseGroup($rulesGroup) {\n    for (var i = 0; i < $rulesGroup.rules.length; i++)\n      if ($shouldUseRule($rulesGroup.rules[i])) return true;\n  }\n\n  function $shouldUseRule($rule) {\n    return it.schema[$rule.keyword] !== undefined || ($rule.keyword == 'properties' && (it.schema.additionalProperties === false || typeof it.schema.additionalProperties == 'object' || (it.schema.patternProperties && Object.keys(it.schema.patternProperties).length) || (it.opts.v5 && it.schema.patternGroups && Object.keys(it.schema.patternGroups).length)));\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/node_modules/co/index.js":"\n/**\n * slice() reference.\n */\n\nvar slice = Array.prototype.slice;\n\n/**\n * Expose `co`.\n */\n\nmodule.exports = co['default'] = co.co = co;\n\n/**\n * Wrap the given generator `fn` into a\n * function that returns a promise.\n * This is a separate function so that\n * every `co()` call doesn't create a new,\n * unnecessary closure.\n *\n * @param {GeneratorFunction} fn\n * @return {Function}\n * @api public\n */\n\nco.wrap = function (fn) {\n  createPromise.__generatorFunction__ = fn;\n  return createPromise;\n  function createPromise() {\n    return co.call(this, fn.apply(this, arguments));\n  }\n};\n\n/**\n * Execute the generator function or a generator\n * and return a promise.\n *\n * @param {Function} fn\n * @return {Promise}\n * @api public\n */\n\nfunction co(gen) {\n  var ctx = this;\n  var args = slice.call(arguments, 1)\n\n  // we wrap everything in a promise to avoid promise chaining,\n  // which leads to memory leak errors.\n  // see https://github.com/tj/co/issues/180\n  return new Promise(function(resolve, reject) {\n    if (typeof gen === 'function') gen = gen.apply(ctx, args);\n    if (!gen || typeof gen.next !== 'function') return resolve(gen);\n\n    onFulfilled();\n\n    /**\n     * @param {Mixed} res\n     * @return {Promise}\n     * @api private\n     */\n\n    function onFulfilled(res) {\n      var ret;\n      try {\n        ret = gen.next(res);\n      } catch (e) {\n        return reject(e);\n      }\n      next(ret);\n    }\n\n    /**\n     * @param {Error} err\n     * @return {Promise}\n     * @api private\n     */\n\n    function onRejected(err) {\n      var ret;\n      try {\n        ret = gen.throw(err);\n      } catch (e) {\n        return reject(e);\n      }\n      next(ret);\n    }\n\n    /**\n     * Get the next value in the generator,\n     * return a promise.\n     *\n     * @param {Object} ret\n     * @return {Promise}\n     * @api private\n     */\n\n    function next(ret) {\n      if (ret.done) return resolve(ret.value);\n      var value = toPromise.call(ctx, ret.value);\n      if (value && isPromise(value)) return value.then(onFulfilled, onRejected);\n      return onRejected(new TypeError('You may only yield a function, promise, generator, array, or object, '\n        + 'but the following object was passed: \"' + String(ret.value) + '\"'));\n    }\n  });\n}\n\n/**\n * Convert a `yield`ed value into a promise.\n *\n * @param {Mixed} obj\n * @return {Promise}\n * @api private\n */\n\nfunction toPromise(obj) {\n  if (!obj) return obj;\n  if (isPromise(obj)) return obj;\n  if (isGeneratorFunction(obj) || isGenerator(obj)) return co.call(this, obj);\n  if ('function' == typeof obj) return thunkToPromise.call(this, obj);\n  if (Array.isArray(obj)) return arrayToPromise.call(this, obj);\n  if (isObject(obj)) return objectToPromise.call(this, obj);\n  return obj;\n}\n\n/**\n * Convert a thunk to a promise.\n *\n * @param {Function}\n * @return {Promise}\n * @api private\n */\n\nfunction thunkToPromise(fn) {\n  var ctx = this;\n  return new Promise(function (resolve, reject) {\n    fn.call(ctx, function (err, res) {\n      if (err) return reject(err);\n      if (arguments.length > 2) res = slice.call(arguments, 1);\n      resolve(res);\n    });\n  });\n}\n\n/**\n * Convert an array of \"yieldables\" to a promise.\n * Uses `Promise.all()` internally.\n *\n * @param {Array} obj\n * @return {Promise}\n * @api private\n */\n\nfunction arrayToPromise(obj) {\n  return Promise.all(obj.map(toPromise, this));\n}\n\n/**\n * Convert an object of \"yieldables\" to a promise.\n * Uses `Promise.all()` internally.\n *\n * @param {Object} obj\n * @return {Promise}\n * @api private\n */\n\nfunction objectToPromise(obj){\n  var results = new obj.constructor();\n  var keys = Object.keys(obj);\n  var promises = [];\n  for (var i = 0; i < keys.length; i++) {\n    var key = keys[i];\n    var promise = toPromise.call(this, obj[key]);\n    if (promise && isPromise(promise)) defer(promise, key);\n    else results[key] = obj[key];\n  }\n  return Promise.all(promises).then(function () {\n    return results;\n  });\n\n  function defer(promise, key) {\n    // predefine the key in the result\n    results[key] = undefined;\n    promises.push(promise.then(function (res) {\n      results[key] = res;\n    }));\n  }\n}\n\n/**\n * Check if `obj` is a promise.\n *\n * @param {Object} obj\n * @return {Boolean}\n * @api private\n */\n\nfunction isPromise(obj) {\n  return 'function' == typeof obj.then;\n}\n\n/**\n * Check if `obj` is a generator.\n *\n * @param {Mixed} obj\n * @return {Boolean}\n * @api private\n */\n\nfunction isGenerator(obj) {\n  return 'function' == typeof obj.next && 'function' == typeof obj.throw;\n}\n\n/**\n * Check if `obj` is a generator function.\n *\n * @param {Mixed} obj\n * @return {Boolean}\n * @api private\n */\nfunction isGeneratorFunction(obj) {\n  var constructor = obj.constructor;\n  if (!constructor) return false;\n  if ('GeneratorFunction' === constructor.name || 'GeneratorFunction' === constructor.displayName) return true;\n  return isGenerator(constructor.prototype);\n}\n\n/**\n * Check for plain object.\n *\n * @param {Mixed} val\n * @return {Boolean}\n * @api private\n */\n\nfunction isObject(val) {\n  return Object == val.constructor;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/validation_error.js":"'use strict';\n\nmodule.exports = ValidationError;\n\n\nfunction ValidationError(errors) {\n  this.message = 'validation failed';\n  this.errors = errors;\n  this.ajv = this.validation = true;\n}\n\n\nValidationError.prototype = Object.create(Error.prototype);\nValidationError.prototype.constructor = ValidationError;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/cache.js":"'use strict';\n\n\nvar Cache = module.exports = function Cache() {\n  this._cache = {};\n};\n\n\nCache.prototype.put = function Cache_put(key, value) {\n  this._cache[key] = value;\n};\n\n\nCache.prototype.get = function Cache_get(key) {\n  return this._cache[key];\n};\n\n\nCache.prototype.del = function Cache_del(key) {\n  delete this._cache[key];\n};\n\n\nCache.prototype.clear = function Cache_clear() {\n  this._cache = {};\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/formats.js":"'use strict';\n\nvar util = require('./util');\n\nvar DATE = /^\\d\\d\\d\\d-(\\d\\d)-(\\d\\d)$/;\nvar DAYS = [0,31,29,31,30,31,30,31,31,30,31,30,31];\nvar TIME = /^(\\d\\d):(\\d\\d):(\\d\\d)(\\.\\d+)?(z|[+-]\\d\\d:\\d\\d)?$/i;\nvar HOSTNAME = /^[0-9a-z](?:(?:[-0-9a-z]{0,61})?[0-9a-z])?(\\.[0-9a-z](?:(?:[-0-9a-z]{0,61})?[0-9a-z])?)*$/i;\nvar URI = /^(?:[a-z][a-z0-9+\\-.]*:)?(?:\\/?\\/(?:(?:[a-z0-9\\-._~!$&'()*+,;=:]|%[0-9a-f]{2})*@)?(?:\\[(?:(?:(?:(?:[0-9a-f]{1,4}:){6}|::(?:[0-9a-f]{1,4}:){5}|(?:[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){4}|(?:(?:[0-9a-f]{1,4}:){0,1}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){3}|(?:(?:[0-9a-f]{1,4}:){0,2}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){2}|(?:(?:[0-9a-f]{1,4}:){0,3}[0-9a-f]{1,4})?::[0-9a-f]{1,4}:|(?:(?:[0-9a-f]{1,4}:){0,4}[0-9a-f]{1,4})?::)(?:[0-9a-f]{1,4}:[0-9a-f]{1,4}|(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?))|(?:(?:[0-9a-f]{1,4}:){0,5}[0-9a-f]{1,4})?::[0-9a-f]{1,4}|(?:(?:[0-9a-f]{1,4}:){0,6}[0-9a-f]{1,4})?::)|[Vv][0-9a-f]+\\.[a-z0-9\\-._~!$&'()*+,;=:]+)\\]|(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)|(?:[a-z0-9\\-._~!$&'()*+,;=]|%[0-9a-f]{2})*)(?::\\d*)?(?:\\/(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*|\\/(?:(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})+(?:\\/(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*)?|(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})+(?:\\/(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*)(?:\\?(?:[a-z0-9\\-._~!$&'()*+,;=:@\\/?]|%[0-9a-f]{2})*)?(?:\\#(?:[a-z0-9\\-._~!$&'()*+,;=:@\\/?]|%[0-9a-f]{2})*)?$/i;\nvar UUID = /^(?:urn\\:uuid\\:)?[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12}$/i;\nvar JSON_POINTER = /^(?:\\/(?:[^~\\/]|~0|~1)*)*$|^\\#(?:\\/(?:[a-z0-9_\\-\\.!$&'()*+,;:=@]|%[0-9a-f]{2}|~0|~1)*)*$/i;\nvar RELATIVE_JSON_POINTER = /^(?:0|[1-9][0-9]*)(?:\\#|(?:\\/(?:[^~\\/]|~0|~1)*)*)$/;\n\n\nmodule.exports = formats;\n\nfunction formats(mode) {\n  mode = mode == 'full' ? 'full' : 'fast';\n  var formatDefs = util.copy(formats[mode]);\n  for (var fName in formats.compare) {\n    formatDefs[fName] = {\n      validate: formatDefs[fName],\n      compare: formats.compare[fName]\n    };\n  }\n  return formatDefs;\n}\n\n\nformats.fast = {\n  // date: http://tools.ietf.org/html/rfc3339#section-5.6\n  date: /^\\d\\d\\d\\d-[0-1]\\d-[0-3]\\d$/,\n  // date-time: http://tools.ietf.org/html/rfc3339#section-5.6\n  time: /^[0-2]\\d:[0-5]\\d:[0-5]\\d(?:\\.\\d+)?(?:z|[+-]\\d\\d:\\d\\d)?$/i,\n  'date-time': /^\\d\\d\\d\\d-[0-1]\\d-[0-3]\\d[t\\s][0-2]\\d:[0-5]\\d:[0-5]\\d(?:\\.\\d+)?(?:z|[+-]\\d\\d:\\d\\d)$/i,\n  // uri: https://github.com/mafintosh/is-my-json-valid/blob/master/formats.js\n  uri: /^(?:[a-z][a-z0-9+-.]*)?(?:\\:|\\/)\\/?[^\\s]*$/i,\n  // email (sources from jsen validator):\n  // http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address#answer-8829363\n  // http://www.w3.org/TR/html5/forms.html#valid-e-mail-address (search for 'willful violation')\n  email: /^[a-z0-9.!#$%&'*+\\/=?^_`{|}~-]+@[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?(?:\\.[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)*$/i,\n  hostname: HOSTNAME,\n  // optimized https://www.safaribooksonline.com/library/view/regular-expressions-cookbook/9780596802837/ch07s16.html\n  ipv4: /^(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)$/,\n  // optimized http://stackoverflow.com/questions/53497/regular-expression-that-matches-valid-ipv6-addresses\n  ipv6: /^\\s*(?:(?:(?:[0-9a-f]{1,4}:){7}(?:[0-9a-f]{1,4}|:))|(?:(?:[0-9a-f]{1,4}:){6}(?::[0-9a-f]{1,4}|(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(?:(?:[0-9a-f]{1,4}:){5}(?:(?:(?::[0-9a-f]{1,4}){1,2})|:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(?:(?:[0-9a-f]{1,4}:){4}(?:(?:(?::[0-9a-f]{1,4}){1,3})|(?:(?::[0-9a-f]{1,4})?:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?:(?:[0-9a-f]{1,4}:){3}(?:(?:(?::[0-9a-f]{1,4}){1,4})|(?:(?::[0-9a-f]{1,4}){0,2}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?:(?:[0-9a-f]{1,4}:){2}(?:(?:(?::[0-9a-f]{1,4}){1,5})|(?:(?::[0-9a-f]{1,4}){0,3}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?:(?:[0-9a-f]{1,4}:){1}(?:(?:(?::[0-9a-f]{1,4}){1,6})|(?:(?::[0-9a-f]{1,4}){0,4}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?::(?:(?:(?::[0-9a-f]{1,4}){1,7})|(?:(?::[0-9a-f]{1,4}){0,5}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(?:%.+)?\\s*$/i,\n  regex: regex,\n  // uuid: http://tools.ietf.org/html/rfc4122\n  uuid: UUID,\n  // JSON-pointer: https://tools.ietf.org/html/rfc6901\n  // uri fragment: https://tools.ietf.org/html/rfc3986#appendix-A\n  'json-pointer': JSON_POINTER,\n  // relative JSON-pointer: http://tools.ietf.org/html/draft-luff-relative-json-pointer-00\n  'relative-json-pointer': RELATIVE_JSON_POINTER\n};\n\n\nformats.full = {\n  date: date,\n  time: time,\n  'date-time': date_time,\n  uri: uri,\n  email: /^[a-z0-9!#$%&'*+\\/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&''*+\\/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?$/i,\n  hostname: hostname,\n  ipv4: /^(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)$/,\n  ipv6: /^\\s*(?:(?:(?:[0-9a-f]{1,4}:){7}(?:[0-9a-f]{1,4}|:))|(?:(?:[0-9a-f]{1,4}:){6}(?::[0-9a-f]{1,4}|(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(?:(?:[0-9a-f]{1,4}:){5}(?:(?:(?::[0-9a-f]{1,4}){1,2})|:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(?:(?:[0-9a-f]{1,4}:){4}(?:(?:(?::[0-9a-f]{1,4}){1,3})|(?:(?::[0-9a-f]{1,4})?:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?:(?:[0-9a-f]{1,4}:){3}(?:(?:(?::[0-9a-f]{1,4}){1,4})|(?:(?::[0-9a-f]{1,4}){0,2}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?:(?:[0-9a-f]{1,4}:){2}(?:(?:(?::[0-9a-f]{1,4}){1,5})|(?:(?::[0-9a-f]{1,4}){0,3}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?:(?:[0-9a-f]{1,4}:){1}(?:(?:(?::[0-9a-f]{1,4}){1,6})|(?:(?::[0-9a-f]{1,4}){0,4}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(?::(?:(?:(?::[0-9a-f]{1,4}){1,7})|(?:(?::[0-9a-f]{1,4}){0,5}:(?:(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(?:%.+)?\\s*$/i,\n  regex: regex,\n  uuid: UUID,\n  'json-pointer': JSON_POINTER,\n  'relative-json-pointer': RELATIVE_JSON_POINTER\n};\n\n\nformats.compare = {\n  date: compareDate,\n  time: compareTime,\n  'date-time': compareDateTime\n};\n\n\nfunction date(str) {\n  // full-date from http://tools.ietf.org/html/rfc3339#section-5.6\n  var matches = str.match(DATE);\n  if (!matches) return false;\n\n  var month = +matches[1];\n  var day = +matches[2];\n  return month >= 1 && month <= 12 && day >= 1 && day <= DAYS[month];\n}\n\n\nfunction time(str, full) {\n  var matches = str.match(TIME);\n  if (!matches) return false;\n\n  var hour = matches[1];\n  var minute = matches[2];\n  var second = matches[3];\n  var timeZone = matches[5];\n  return hour <= 23 && minute <= 59 && second <= 59 && (!full || timeZone);\n}\n\n\nvar DATE_TIME_SEPARATOR = /t|\\s/i;\nfunction date_time(str) {\n  // http://tools.ietf.org/html/rfc3339#section-5.6\n  var dateTime = str.split(DATE_TIME_SEPARATOR);\n  return dateTime.length == 2 && date(dateTime[0]) && time(dateTime[1], true);\n}\n\n\nfunction hostname(str) {\n  // https://tools.ietf.org/html/rfc1034#section-3.5\n  // https://tools.ietf.org/html/rfc1123#section-2\n  return str.length <= 255 && HOSTNAME.test(str);\n}\n\n\nvar NOT_URI_FRAGMENT = /\\/|\\:/;\nfunction uri(str) {\n  // http://jmrware.com/articles/2009/uri_regexp/URI_regex.html + optional protocol + required \".\"\n  return NOT_URI_FRAGMENT.test(str) && URI.test(str);\n}\n\n\nfunction regex(str) {\n  try {\n    new RegExp(str);\n    return true;\n  } catch(e) {\n    return false;\n  }\n}\n\n\nfunction compareDate(d1, d2) {\n  if (!(d1 && d2)) return;\n  if (d1 > d2) return 1;\n  if (d1 < d2) return -1;\n  if (d1 === d2) return 0;\n}\n\n\nfunction compareTime(t1, t2) {\n  if (!(t1 && t2)) return;\n  t1 = t1.match(TIME);\n  t2 = t2.match(TIME);\n  if (!(t1 && t2)) return;\n  t1 = t1[1] + t1[2] + t1[3] + (t1[4]||'');\n  t2 = t2[1] + t2[2] + t2[3] + (t2[4]||'');\n  if (t1 > t2) return 1;\n  if (t1 < t2) return -1;\n  if (t1 === t2) return 0;\n}\n\n\nfunction compareDateTime(dt1, dt2) {\n  if (!(dt1 && dt2)) return;\n  dt1 = dt1.split(DATE_TIME_SEPARATOR);\n  dt2 = dt2.split(DATE_TIME_SEPARATOR);\n  var res = compareDate(dt1[0], dt2[0]);\n  if (res === undefined) return;\n  return res || compareTime(dt1[1], dt2[1]);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/rules.js":"'use strict';\n\nvar ruleModules = require('./_rules')\n  , toHash = require('./util').toHash;\n\nmodule.exports = function rules() {\n  var RULES = [\n    { type: 'number',\n      rules: [ 'maximum', 'minimum', 'multipleOf'] },\n    { type: 'string',\n      rules: [ 'maxLength', 'minLength', 'pattern', 'format' ] },\n    { type: 'array',\n      rules: [ 'maxItems', 'minItems', 'uniqueItems', 'items' ] },\n    { type: 'object',\n      rules: [ 'maxProperties', 'minProperties', 'required', 'dependencies', 'properties' ] },\n    { rules: [ '$ref', 'enum', 'not', 'anyOf', 'oneOf', 'allOf' ] }\n  ];\n\n  var ALL = [ 'type', 'additionalProperties', 'patternProperties' ];\n  var KEYWORDS = [ 'additionalItems', '$schema', 'id', 'title', 'description', 'default' ];\n  var TYPES = [ 'number', 'integer', 'string', 'array', 'object', 'boolean', 'null' ];\n  RULES.all = toHash(ALL);\n\n  RULES.forEach(function (group) {\n    group.rules = group.rules.map(function (keyword) {\n      ALL.push(keyword);\n      var rule = RULES.all[keyword] = {\n        keyword: keyword,\n        code: ruleModules[keyword]\n      };\n      return rule;\n    });\n  });\n\n  RULES.keywords = toHash(ALL.concat(KEYWORDS));\n  RULES.types = toHash(TYPES);\n  RULES.custom = {};\n\n  return RULES;\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/compile/_rules.js":"'use strict';\n\n//all requires must be explicit because browserify won't work with dynamic requires\nmodule.exports = {\n  '$ref': require('../dotjs/ref'),\n  allOf: require('../dotjs/allOf'),\n  anyOf: require('../dotjs/anyOf'),\n  dependencies: require('../dotjs/dependencies'),\n  'enum': require('../dotjs/enum'),\n  format: require('../dotjs/format'),\n  items: require('../dotjs/items'),\n  maximum: require('../dotjs/_limit'),\n  minimum: require('../dotjs/_limit'),\n  maxItems: require('../dotjs/_limitItems'),\n  minItems: require('../dotjs/_limitItems'),\n  maxLength: require('../dotjs/_limitLength'),\n  minLength: require('../dotjs/_limitLength'),\n  maxProperties: require('../dotjs/_limitProperties'),\n  minProperties: require('../dotjs/_limitProperties'),\n  multipleOf: require('../dotjs/multipleOf'),\n  not: require('../dotjs/not'),\n  oneOf: require('../dotjs/oneOf'),\n  pattern: require('../dotjs/pattern'),\n  properties: require('../dotjs/properties'),\n  required: require('../dotjs/required'),\n  uniqueItems: require('../dotjs/uniqueItems'),\n  validate: require('../dotjs/validate')\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/ref.js":"'use strict';\nmodule.exports = function generate_ref(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $async, $refCode;\n  if ($schema == '#' || $schema == '#/') {\n    if (it.isRoot) {\n      $async = it.async;\n      $refCode = 'validate';\n    } else {\n      $async = it.root.schema.$async === true;\n      $refCode = 'root.refVal[0]';\n    }\n  } else {\n    var $refVal = it.resolveRef(it.baseId, $schema, it.isRoot);\n    if ($refVal === undefined) {\n      var $message = 'can\\'t resolve reference ' + $schema + ' from id ' + it.baseId;\n      if (it.opts.missingRefs == 'fail') {\n        console.log($message);\n        var $$outStack = $$outStack || [];\n        $$outStack.push(out);\n        out = ''; /* istanbul ignore else */\n        if (it.createErrors !== false) {\n          out += ' { keyword: \\'' + ($errorKeyword || '$ref') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { ref: \\'' + (it.util.escapeQuotes($schema)) + '\\' } ';\n          if (it.opts.messages !== false) {\n            out += ' , message: \\'can\\\\\\'t resolve reference ' + (it.util.escapeQuotes($schema)) + '\\' ';\n          }\n          if (it.opts.verbose) {\n            out += ' , schema: ' + (it.util.toQuotedString($schema)) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n          }\n          out += ' } ';\n        } else {\n          out += ' {} ';\n        }\n        var __err = out;\n        out = $$outStack.pop();\n        if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n          if (it.async) {\n            out += ' throw new ValidationError([' + (__err) + ']); ';\n          } else {\n            out += ' validate.errors = [' + (__err) + ']; return false; ';\n          }\n        } else {\n          out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n        }\n        if ($breakOnError) {\n          out += ' if (false) { ';\n        }\n      } else if (it.opts.missingRefs == 'ignore') {\n        console.log($message);\n        if ($breakOnError) {\n          out += ' if (true) { ';\n        }\n      } else {\n        var $error = new Error($message);\n        $error.missingRef = it.resolve.url(it.baseId, $schema);\n        $error.missingSchema = it.resolve.normalizeId(it.resolve.fullPath($error.missingRef));\n        throw $error;\n      }\n    } else if ($refVal.inline) {\n      var $it = it.util.copy(it);\n      $it.level++;\n      var $nextValid = 'valid' + $it.level;\n      $it.schema = $refVal.schema;\n      $it.schemaPath = '';\n      $it.errSchemaPath = $schema;\n      var $code = it.validate($it).replace(/validate\\.schema/g, $refVal.code);\n      out += ' ' + ($code) + ' ';\n      if ($breakOnError) {\n        out += ' if (' + ($nextValid) + ') { ';\n      }\n    } else {\n      $async = $refVal.$async === true;\n      $refCode = $refVal.code;\n    }\n  }\n  if ($refCode) {\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = '';\n    if (it.opts.passContext) {\n      out += ' ' + ($refCode) + '.call(this, ';\n    } else {\n      out += ' ' + ($refCode) + '( ';\n    }\n    out += ' ' + ($data) + ', (dataPath || \\'\\')';\n    if (it.errorPath != '\"\"') {\n      out += ' + ' + (it.errorPath);\n    }\n    var $parentData = $dataLvl ? 'data' + (($dataLvl - 1) || '') : 'parentData',\n      $parentDataProperty = $dataLvl ? it.dataPathArr[$dataLvl] : 'parentDataProperty';\n    out += ' , ' + ($parentData) + ' , ' + ($parentDataProperty) + ', rootData)  ';\n    var __callValidate = out;\n    out = $$outStack.pop();\n    if ($async) {\n      if (!it.async) throw new Error('async schema referenced by sync schema');\n      out += ' try { ';\n      if ($breakOnError) {\n        out += 'var ' + ($valid) + ' =';\n      }\n      out += ' ' + (it.yieldAwait) + ' ' + (__callValidate) + '; } catch (e) { if (!(e instanceof ValidationError)) throw e; if (vErrors === null) vErrors = e.errors; else vErrors = vErrors.concat(e.errors); errors = vErrors.length; } ';\n      if ($breakOnError) {\n        out += ' if (' + ($valid) + ') { ';\n      }\n    } else {\n      out += ' if (!' + (__callValidate) + ') { if (vErrors === null) vErrors = ' + ($refCode) + '.errors; else vErrors = vErrors.concat(' + ($refCode) + '.errors); errors = vErrors.length; } ';\n      if ($breakOnError) {\n        out += ' else { ';\n      }\n    }\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/allOf.js":"'use strict';\nmodule.exports = function generate_allOf(it, $keyword) {\n  var out = ' ';\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $it = it.util.copy(it);\n  var $closingBraces = '';\n  $it.level++;\n  var $nextValid = 'valid' + $it.level;\n  var $currentBaseId = $it.baseId,\n    $allSchemasEmpty = true;\n  var arr1 = $schema;\n  if (arr1) {\n    var $sch, $i = -1,\n      l1 = arr1.length - 1;\n    while ($i < l1) {\n      $sch = arr1[$i += 1];\n      if (it.util.schemaHasRules($sch, it.RULES.all)) {\n        $allSchemasEmpty = false;\n        $it.schema = $sch;\n        $it.schemaPath = $schemaPath + '[' + $i + ']';\n        $it.errSchemaPath = $errSchemaPath + '/' + $i;\n        out += '  ' + (it.validate($it)) + ' ';\n        $it.baseId = $currentBaseId;\n        if ($breakOnError) {\n          out += ' if (' + ($nextValid) + ') { ';\n          $closingBraces += '}';\n        }\n      }\n    }\n  }\n  if ($breakOnError) {\n    if ($allSchemasEmpty) {\n      out += ' if (true) { ';\n    } else {\n      out += ' ' + ($closingBraces.slice(0, -1)) + ' ';\n    }\n  }\n  out = it.util.cleanUpCode(out);\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/anyOf.js":"'use strict';\nmodule.exports = function generate_anyOf(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $errs = 'errs__' + $lvl;\n  var $it = it.util.copy(it);\n  var $closingBraces = '';\n  $it.level++;\n  var $nextValid = 'valid' + $it.level;\n  var $noEmptySchema = $schema.every(function($sch) {\n    return it.util.schemaHasRules($sch, it.RULES.all);\n  });\n  if ($noEmptySchema) {\n    var $currentBaseId = $it.baseId;\n    out += ' var ' + ($errs) + ' = errors; var ' + ($valid) + ' = false;  ';\n    var $wasComposite = it.compositeRule;\n    it.compositeRule = $it.compositeRule = true;\n    var arr1 = $schema;\n    if (arr1) {\n      var $sch, $i = -1,\n        l1 = arr1.length - 1;\n      while ($i < l1) {\n        $sch = arr1[$i += 1];\n        $it.schema = $sch;\n        $it.schemaPath = $schemaPath + '[' + $i + ']';\n        $it.errSchemaPath = $errSchemaPath + '/' + $i;\n        out += '  ' + (it.validate($it)) + ' ';\n        $it.baseId = $currentBaseId;\n        out += ' ' + ($valid) + ' = ' + ($valid) + ' || ' + ($nextValid) + '; if (!' + ($valid) + ') { ';\n        $closingBraces += '}';\n      }\n    }\n    it.compositeRule = $it.compositeRule = $wasComposite;\n    out += ' ' + ($closingBraces) + ' if (!' + ($valid) + ') {  var err =   '; /* istanbul ignore else */\n    if (it.createErrors !== false) {\n      out += ' { keyword: \\'' + ($errorKeyword || 'anyOf') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: {} ';\n      if (it.opts.messages !== false) {\n        out += ' , message: \\'should match some schema in anyOf\\' ';\n      }\n      if (it.opts.verbose) {\n        out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n      }\n      out += ' } ';\n    } else {\n      out += ' {} ';\n    }\n    out += ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; } else {  errors = ' + ($errs) + '; if (vErrors !== null) { if (' + ($errs) + ') vErrors.length = ' + ($errs) + '; else vErrors = null; } ';\n    if (it.opts.allErrors) {\n      out += ' } ';\n    }\n    out = it.util.cleanUpCode(out);\n  } else {\n    if ($breakOnError) {\n      out += ' if (true) { ';\n    }\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/dependencies.js":"'use strict';\nmodule.exports = function generate_dependencies(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $errs = 'errs__' + $lvl;\n  var $it = it.util.copy(it);\n  var $closingBraces = '';\n  $it.level++;\n  var $nextValid = 'valid' + $it.level;\n  var $schemaDeps = {},\n    $propertyDeps = {};\n  for ($property in $schema) {\n    var $sch = $schema[$property];\n    var $deps = Array.isArray($sch) ? $propertyDeps : $schemaDeps;\n    $deps[$property] = $sch;\n  }\n  out += 'var ' + ($errs) + ' = errors;';\n  var $currentErrorPath = it.errorPath;\n  out += 'var missing' + ($lvl) + ';';\n  for (var $property in $propertyDeps) {\n    $deps = $propertyDeps[$property];\n    out += ' if (' + ($data) + (it.util.getProperty($property)) + ' !== undefined ';\n    if ($breakOnError) {\n      out += ' && ( ';\n      var arr1 = $deps;\n      if (arr1) {\n        var _$property, $i = -1,\n          l1 = arr1.length - 1;\n        while ($i < l1) {\n          _$property = arr1[$i += 1];\n          if ($i) {\n            out += ' || ';\n          }\n          var $prop = it.util.getProperty(_$property);\n          out += ' ( ' + ($data) + ($prop) + ' === undefined && (missing' + ($lvl) + ' = ' + (it.util.toQuotedString(it.opts.jsonPointers ? _$property : $prop)) + ') ) ';\n        }\n      }\n      out += ')) {  ';\n      var $propertyPath = 'missing' + $lvl,\n        $missingProperty = '\\' + ' + $propertyPath + ' + \\'';\n      if (it.opts._errorDataPathProperty) {\n        it.errorPath = it.opts.jsonPointers ? it.util.getPathExpr($currentErrorPath, $propertyPath, true) : $currentErrorPath + ' + ' + $propertyPath;\n      }\n      var $$outStack = $$outStack || [];\n      $$outStack.push(out);\n      out = ''; /* istanbul ignore else */\n      if (it.createErrors !== false) {\n        out += ' { keyword: \\'' + ($errorKeyword || 'dependencies') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { property: \\'' + (it.util.escapeQuotes($property)) + '\\', missingProperty: \\'' + ($missingProperty) + '\\', depsCount: ' + ($deps.length) + ', deps: \\'' + (it.util.escapeQuotes($deps.length == 1 ? $deps[0] : $deps.join(\", \"))) + '\\' } ';\n        if (it.opts.messages !== false) {\n          out += ' , message: \\'should have ';\n          if ($deps.length == 1) {\n            out += 'property ' + (it.util.escapeQuotes($deps[0]));\n          } else {\n            out += 'properties ' + (it.util.escapeQuotes($deps.join(\", \")));\n          }\n          out += ' when property ' + (it.util.escapeQuotes($property)) + ' is present\\' ';\n        }\n        if (it.opts.verbose) {\n          out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n        }\n        out += ' } ';\n      } else {\n        out += ' {} ';\n      }\n      var __err = out;\n      out = $$outStack.pop();\n      if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n        if (it.async) {\n          out += ' throw new ValidationError([' + (__err) + ']); ';\n        } else {\n          out += ' validate.errors = [' + (__err) + ']; return false; ';\n        }\n      } else {\n        out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n      }\n    } else {\n      out += ' ) { ';\n      var arr2 = $deps;\n      if (arr2) {\n        var $reqProperty, i2 = -1,\n          l2 = arr2.length - 1;\n        while (i2 < l2) {\n          $reqProperty = arr2[i2 += 1];\n          var $prop = it.util.getProperty($reqProperty),\n            $missingProperty = it.util.escapeQuotes($reqProperty);\n          if (it.opts._errorDataPathProperty) {\n            it.errorPath = it.util.getPath($currentErrorPath, $reqProperty, it.opts.jsonPointers);\n          }\n          out += ' if (' + ($data) + ($prop) + ' === undefined) {  var err =   '; /* istanbul ignore else */\n          if (it.createErrors !== false) {\n            out += ' { keyword: \\'' + ($errorKeyword || 'dependencies') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { property: \\'' + (it.util.escapeQuotes($property)) + '\\', missingProperty: \\'' + ($missingProperty) + '\\', depsCount: ' + ($deps.length) + ', deps: \\'' + (it.util.escapeQuotes($deps.length == 1 ? $deps[0] : $deps.join(\", \"))) + '\\' } ';\n            if (it.opts.messages !== false) {\n              out += ' , message: \\'should have ';\n              if ($deps.length == 1) {\n                out += 'property ' + (it.util.escapeQuotes($deps[0]));\n              } else {\n                out += 'properties ' + (it.util.escapeQuotes($deps.join(\", \")));\n              }\n              out += ' when property ' + (it.util.escapeQuotes($property)) + ' is present\\' ';\n            }\n            if (it.opts.verbose) {\n              out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n            }\n            out += ' } ';\n          } else {\n            out += ' {} ';\n          }\n          out += ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; } ';\n        }\n      }\n    }\n    out += ' }   ';\n    if ($breakOnError) {\n      $closingBraces += '}';\n      out += ' else { ';\n    }\n  }\n  it.errorPath = $currentErrorPath;\n  var $currentBaseId = $it.baseId;\n  for (var $property in $schemaDeps) {\n    var $sch = $schemaDeps[$property];\n    if (it.util.schemaHasRules($sch, it.RULES.all)) {\n      out += ' ' + ($nextValid) + ' = true; if (' + ($data) + (it.util.getProperty($property)) + ' !== undefined) { ';\n      $it.schema = $sch;\n      $it.schemaPath = $schemaPath + it.util.getProperty($property);\n      $it.errSchemaPath = $errSchemaPath + '/' + it.util.escapeFragment($property);\n      out += '  ' + (it.validate($it)) + ' ';\n      $it.baseId = $currentBaseId;\n      out += ' }  ';\n      if ($breakOnError) {\n        out += ' if (' + ($nextValid) + ') { ';\n        $closingBraces += '}';\n      }\n    }\n  }\n  if ($breakOnError) {\n    out += '   ' + ($closingBraces) + ' if (' + ($errs) + ' == errors) {';\n  }\n  out = it.util.cleanUpCode(out);\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/enum.js":"'use strict';\nmodule.exports = function generate_enum(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $i = 'i' + $lvl,\n    $vSchema = 'schema' + $lvl;\n  if (!$isData) {\n    out += ' var ' + ($vSchema) + ' = validate.schema' + ($schemaPath) + ';';\n  }\n  out += 'var ' + ($valid) + ';';\n  if ($isData) {\n    out += ' if (schema' + ($lvl) + ' === undefined) ' + ($valid) + ' = true; else if (!Array.isArray(schema' + ($lvl) + ')) ' + ($valid) + ' = false; else {';\n  }\n  out += '' + ($valid) + ' = false;for (var ' + ($i) + '=0; ' + ($i) + '<' + ($vSchema) + '.length; ' + ($i) + '++) if (equal(' + ($data) + ', ' + ($vSchema) + '[' + ($i) + '])) { ' + ($valid) + ' = true; break; }';\n  if ($isData) {\n    out += '  }  ';\n  }\n  out += ' if (!' + ($valid) + ') {   ';\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || 'enum') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { allowedValues: schema' + ($lvl) + ' } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should be equal to one of the allowed values\\' ';\n    }\n    if (it.opts.verbose) {\n      out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += ' }';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/format.js":"'use strict';\nmodule.exports = function generate_format(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  if (it.opts.format === false) {\n    if ($breakOnError) {\n      out += ' if (true) { ';\n    }\n    return out;\n  }\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $unknownFormats = it.opts.unknownFormats,\n    $allowUnknown = Array.isArray($unknownFormats);\n  if ($isData) {\n    var $format = 'format' + $lvl;\n    out += ' var ' + ($format) + ' = formats[' + ($schemaValue) + ']; var isObject' + ($lvl) + ' = typeof ' + ($format) + ' == \\'object\\' && !(' + ($format) + ' instanceof RegExp) && ' + ($format) + '.validate; if (isObject' + ($lvl) + ') { ';\n    if (it.async) {\n      out += ' var async' + ($lvl) + ' = ' + ($format) + '.async; ';\n    }\n    out += ' ' + ($format) + ' = ' + ($format) + '.validate; } if (  ';\n    if ($isData) {\n      out += ' (' + ($schemaValue) + ' !== undefined && typeof ' + ($schemaValue) + ' != \\'string\\') || ';\n    }\n    out += ' (';\n    if ($unknownFormats === true || $allowUnknown) {\n      out += ' (' + ($schemaValue) + ' && !' + ($format) + ' ';\n      if ($allowUnknown) {\n        out += ' && self._opts.unknownFormats.indexOf(' + ($schemaValue) + ') == -1 ';\n      }\n      out += ') || ';\n    }\n    out += ' (' + ($format) + ' && !(typeof ' + ($format) + ' == \\'function\\' ? ';\n    if (it.async) {\n      out += ' (async' + ($lvl) + ' ? ' + (it.yieldAwait) + ' ' + ($format) + '(' + ($data) + ') : ' + ($format) + '(' + ($data) + ')) ';\n    } else {\n      out += ' ' + ($format) + '(' + ($data) + ') ';\n    }\n    out += ' : ' + ($format) + '.test(' + ($data) + '))))) {';\n  } else {\n    var $format = it.formats[$schema];\n    if (!$format) {\n      if ($unknownFormats === true || ($allowUnknown && $unknownFormats.indexOf($schema) == -1)) {\n        throw new Error('unknown format \"' + $schema + '\" is used in schema at path \"' + it.errSchemaPath + '\"');\n      } else {\n        if (!$allowUnknown) {\n          console.warn('unknown format \"' + $schema + '\" ignored in schema at path \"' + it.errSchemaPath + '\"');\n          if ($unknownFormats !== 'ignore') console.warn('In the next major version it will throw exception. See option unknownFormats for more information');\n        }\n        if ($breakOnError) {\n          out += ' if (true) { ';\n        }\n        return out;\n      }\n    }\n    var $isObject = typeof $format == 'object' && !($format instanceof RegExp) && $format.validate;\n    if ($isObject) {\n      var $async = $format.async === true;\n      $format = $format.validate;\n    }\n    if ($async) {\n      if (!it.async) throw new Error('async format in sync schema');\n      var $formatRef = 'formats' + it.util.getProperty($schema) + '.validate';\n      out += ' if (!(' + (it.yieldAwait) + ' ' + ($formatRef) + '(' + ($data) + '))) { ';\n    } else {\n      out += ' if (! ';\n      var $formatRef = 'formats' + it.util.getProperty($schema);\n      if ($isObject) $formatRef += '.validate';\n      if (typeof $format == 'function') {\n        out += ' ' + ($formatRef) + '(' + ($data) + ') ';\n      } else {\n        out += ' ' + ($formatRef) + '.test(' + ($data) + ') ';\n      }\n      out += ') { ';\n    }\n  }\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || 'format') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { format:  ';\n    if ($isData) {\n      out += '' + ($schemaValue);\n    } else {\n      out += '' + (it.util.toQuotedString($schema));\n    }\n    out += '  } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should match format \"';\n      if ($isData) {\n        out += '\\' + ' + ($schemaValue) + ' + \\'';\n      } else {\n        out += '' + (it.util.escapeQuotes($schema));\n      }\n      out += '\"\\' ';\n    }\n    if (it.opts.verbose) {\n      out += ' , schema:  ';\n      if ($isData) {\n        out += 'validate.schema' + ($schemaPath);\n      } else {\n        out += '' + (it.util.toQuotedString($schema));\n      }\n      out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += ' } ';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/items.js":"'use strict';\nmodule.exports = function generate_items(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $errs = 'errs__' + $lvl;\n  var $it = it.util.copy(it);\n  var $closingBraces = '';\n  $it.level++;\n  var $nextValid = 'valid' + $it.level;\n  var $idx = 'i' + $lvl,\n    $dataNxt = $it.dataLevel = it.dataLevel + 1,\n    $nextData = 'data' + $dataNxt,\n    $currentBaseId = it.baseId;\n  out += 'var ' + ($errs) + ' = errors;var ' + ($valid) + ';';\n  if (Array.isArray($schema)) {\n    var $additionalItems = it.schema.additionalItems;\n    if ($additionalItems === false) {\n      out += ' ' + ($valid) + ' = ' + ($data) + '.length <= ' + ($schema.length) + '; ';\n      var $currErrSchemaPath = $errSchemaPath;\n      $errSchemaPath = it.errSchemaPath + '/additionalItems';\n      out += '  if (!' + ($valid) + ') {   ';\n      var $$outStack = $$outStack || [];\n      $$outStack.push(out);\n      out = ''; /* istanbul ignore else */\n      if (it.createErrors !== false) {\n        out += ' { keyword: \\'' + ($errorKeyword || 'additionalItems') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { limit: ' + ($schema.length) + ' } ';\n        if (it.opts.messages !== false) {\n          out += ' , message: \\'should NOT have more than ' + ($schema.length) + ' items\\' ';\n        }\n        if (it.opts.verbose) {\n          out += ' , schema: false , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n        }\n        out += ' } ';\n      } else {\n        out += ' {} ';\n      }\n      var __err = out;\n      out = $$outStack.pop();\n      if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n        if (it.async) {\n          out += ' throw new ValidationError([' + (__err) + ']); ';\n        } else {\n          out += ' validate.errors = [' + (__err) + ']; return false; ';\n        }\n      } else {\n        out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n      }\n      out += ' } ';\n      $errSchemaPath = $currErrSchemaPath;\n      if ($breakOnError) {\n        $closingBraces += '}';\n        out += ' else { ';\n      }\n    }\n    var arr1 = $schema;\n    if (arr1) {\n      var $sch, $i = -1,\n        l1 = arr1.length - 1;\n      while ($i < l1) {\n        $sch = arr1[$i += 1];\n        if (it.util.schemaHasRules($sch, it.RULES.all)) {\n          out += ' ' + ($nextValid) + ' = true; if (' + ($data) + '.length > ' + ($i) + ') { ';\n          var $passData = $data + '[' + $i + ']';\n          $it.schema = $sch;\n          $it.schemaPath = $schemaPath + '[' + $i + ']';\n          $it.errSchemaPath = $errSchemaPath + '/' + $i;\n          $it.errorPath = it.util.getPathExpr(it.errorPath, $i, it.opts.jsonPointers, true);\n          $it.dataPathArr[$dataNxt] = $i;\n          var $code = it.validate($it);\n          $it.baseId = $currentBaseId;\n          if (it.util.varOccurences($code, $nextData) < 2) {\n            out += ' ' + (it.util.varReplace($code, $nextData, $passData)) + ' ';\n          } else {\n            out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ' + ($code) + ' ';\n          }\n          out += ' }  ';\n          if ($breakOnError) {\n            out += ' if (' + ($nextValid) + ') { ';\n            $closingBraces += '}';\n          }\n        }\n      }\n    }\n    if (typeof $additionalItems == 'object' && it.util.schemaHasRules($additionalItems, it.RULES.all)) {\n      $it.schema = $additionalItems;\n      $it.schemaPath = it.schemaPath + '.additionalItems';\n      $it.errSchemaPath = it.errSchemaPath + '/additionalItems';\n      out += ' ' + ($nextValid) + ' = true; if (' + ($data) + '.length > ' + ($schema.length) + ') {  for (var ' + ($idx) + ' = ' + ($schema.length) + '; ' + ($idx) + ' < ' + ($data) + '.length; ' + ($idx) + '++) { ';\n      $it.errorPath = it.util.getPathExpr(it.errorPath, $idx, it.opts.jsonPointers, true);\n      var $passData = $data + '[' + $idx + ']';\n      $it.dataPathArr[$dataNxt] = $idx;\n      var $code = it.validate($it);\n      $it.baseId = $currentBaseId;\n      if (it.util.varOccurences($code, $nextData) < 2) {\n        out += ' ' + (it.util.varReplace($code, $nextData, $passData)) + ' ';\n      } else {\n        out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ' + ($code) + ' ';\n      }\n      if ($breakOnError) {\n        out += ' if (!' + ($nextValid) + ') break; ';\n      }\n      out += ' } }  ';\n      if ($breakOnError) {\n        out += ' if (' + ($nextValid) + ') { ';\n        $closingBraces += '}';\n      }\n    }\n  } else if (it.util.schemaHasRules($schema, it.RULES.all)) {\n    $it.schema = $schema;\n    $it.schemaPath = $schemaPath;\n    $it.errSchemaPath = $errSchemaPath;\n    out += '  for (var ' + ($idx) + ' = ' + (0) + '; ' + ($idx) + ' < ' + ($data) + '.length; ' + ($idx) + '++) { ';\n    $it.errorPath = it.util.getPathExpr(it.errorPath, $idx, it.opts.jsonPointers, true);\n    var $passData = $data + '[' + $idx + ']';\n    $it.dataPathArr[$dataNxt] = $idx;\n    var $code = it.validate($it);\n    $it.baseId = $currentBaseId;\n    if (it.util.varOccurences($code, $nextData) < 2) {\n      out += ' ' + (it.util.varReplace($code, $nextData, $passData)) + ' ';\n    } else {\n      out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ' + ($code) + ' ';\n    }\n    if ($breakOnError) {\n      out += ' if (!' + ($nextValid) + ') break; ';\n    }\n    out += ' }  ';\n    if ($breakOnError) {\n      out += ' if (' + ($nextValid) + ') { ';\n      $closingBraces += '}';\n    }\n  }\n  if ($breakOnError) {\n    out += ' ' + ($closingBraces) + ' if (' + ($errs) + ' == errors) {';\n  }\n  out = it.util.cleanUpCode(out);\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/_limit.js":"'use strict';\nmodule.exports = function generate__limit(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $isMax = $keyword == 'maximum',\n    $exclusiveKeyword = $isMax ? 'exclusiveMaximum' : 'exclusiveMinimum',\n    $schemaExcl = it.schema[$exclusiveKeyword],\n    $isDataExcl = it.opts.v5 && $schemaExcl && $schemaExcl.$data,\n    $op = $isMax ? '<' : '>',\n    $notOp = $isMax ? '>' : '<';\n  if ($isDataExcl) {\n    var $schemaValueExcl = it.util.getData($schemaExcl.$data, $dataLvl, it.dataPathArr),\n      $exclusive = 'exclusive' + $lvl,\n      $opExpr = 'op' + $lvl,\n      $opStr = '\\' + ' + $opExpr + ' + \\'';\n    out += ' var schemaExcl' + ($lvl) + ' = ' + ($schemaValueExcl) + '; ';\n    $schemaValueExcl = 'schemaExcl' + $lvl;\n    out += ' var exclusive' + ($lvl) + '; if (typeof ' + ($schemaValueExcl) + ' != \\'boolean\\' && typeof ' + ($schemaValueExcl) + ' != \\'undefined\\') { ';\n    var $errorKeyword = $exclusiveKeyword;\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = ''; /* istanbul ignore else */\n    if (it.createErrors !== false) {\n      out += ' { keyword: \\'' + ($errorKeyword || '_exclusiveLimit') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: {} ';\n      if (it.opts.messages !== false) {\n        out += ' , message: \\'' + ($exclusiveKeyword) + ' should be boolean\\' ';\n      }\n      if (it.opts.verbose) {\n        out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n      }\n      out += ' } ';\n    } else {\n      out += ' {} ';\n    }\n    var __err = out;\n    out = $$outStack.pop();\n    if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n      if (it.async) {\n        out += ' throw new ValidationError([' + (__err) + ']); ';\n      } else {\n        out += ' validate.errors = [' + (__err) + ']; return false; ';\n      }\n    } else {\n      out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n    }\n    out += ' } else if( ';\n    if ($isData) {\n      out += ' (' + ($schemaValue) + ' !== undefined && typeof ' + ($schemaValue) + ' != \\'number\\') || ';\n    }\n    out += ' ((exclusive' + ($lvl) + ' = ' + ($schemaValueExcl) + ' === true) ? ' + ($data) + ' ' + ($notOp) + '= ' + ($schemaValue) + ' : ' + ($data) + ' ' + ($notOp) + ' ' + ($schemaValue) + ') || ' + ($data) + ' !== ' + ($data) + ') { var op' + ($lvl) + ' = exclusive' + ($lvl) + ' ? \\'' + ($op) + '\\' : \\'' + ($op) + '=\\';';\n  } else {\n    var $exclusive = $schemaExcl === true,\n      $opStr = $op;\n    if (!$exclusive) $opStr += '=';\n    var $opExpr = '\\'' + $opStr + '\\'';\n    out += ' if ( ';\n    if ($isData) {\n      out += ' (' + ($schemaValue) + ' !== undefined && typeof ' + ($schemaValue) + ' != \\'number\\') || ';\n    }\n    out += ' ' + ($data) + ' ' + ($notOp);\n    if ($exclusive) {\n      out += '=';\n    }\n    out += ' ' + ($schemaValue) + ' || ' + ($data) + ' !== ' + ($data) + ') {';\n  }\n  var $errorKeyword = $keyword;\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || '_limit') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { comparison: ' + ($opExpr) + ', limit: ' + ($schemaValue) + ', exclusive: ' + ($exclusive) + ' } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should be ' + ($opStr) + ' ';\n      if ($isData) {\n        out += '\\' + ' + ($schemaValue);\n      } else {\n        out += '' + ($schema) + '\\'';\n      }\n    }\n    if (it.opts.verbose) {\n      out += ' , schema:  ';\n      if ($isData) {\n        out += 'validate.schema' + ($schemaPath);\n      } else {\n        out += '' + ($schema);\n      }\n      out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += ' } ';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/_limitItems.js":"'use strict';\nmodule.exports = function generate__limitItems(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $op = $keyword == 'maxItems' ? '>' : '<';\n  out += 'if ( ';\n  if ($isData) {\n    out += ' (' + ($schemaValue) + ' !== undefined && typeof ' + ($schemaValue) + ' != \\'number\\') || ';\n  }\n  out += ' ' + ($data) + '.length ' + ($op) + ' ' + ($schemaValue) + ') { ';\n  var $errorKeyword = $keyword;\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || '_limitItems') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { limit: ' + ($schemaValue) + ' } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should NOT have ';\n      if ($keyword == 'maxItems') {\n        out += 'more';\n      } else {\n        out += 'less';\n      }\n      out += ' than ';\n      if ($isData) {\n        out += '\\' + ' + ($schemaValue) + ' + \\'';\n      } else {\n        out += '' + ($schema);\n      }\n      out += ' items\\' ';\n    }\n    if (it.opts.verbose) {\n      out += ' , schema:  ';\n      if ($isData) {\n        out += 'validate.schema' + ($schemaPath);\n      } else {\n        out += '' + ($schema);\n      }\n      out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += '} ';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/_limitLength.js":"'use strict';\nmodule.exports = function generate__limitLength(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $op = $keyword == 'maxLength' ? '>' : '<';\n  out += 'if ( ';\n  if ($isData) {\n    out += ' (' + ($schemaValue) + ' !== undefined && typeof ' + ($schemaValue) + ' != \\'number\\') || ';\n  }\n  if (it.opts.unicode === false) {\n    out += ' ' + ($data) + '.length ';\n  } else {\n    out += ' ucs2length(' + ($data) + ') ';\n  }\n  out += ' ' + ($op) + ' ' + ($schemaValue) + ') { ';\n  var $errorKeyword = $keyword;\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || '_limitLength') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { limit: ' + ($schemaValue) + ' } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should NOT be ';\n      if ($keyword == 'maxLength') {\n        out += 'longer';\n      } else {\n        out += 'shorter';\n      }\n      out += ' than ';\n      if ($isData) {\n        out += '\\' + ' + ($schemaValue) + ' + \\'';\n      } else {\n        out += '' + ($schema);\n      }\n      out += ' characters\\' ';\n    }\n    if (it.opts.verbose) {\n      out += ' , schema:  ';\n      if ($isData) {\n        out += 'validate.schema' + ($schemaPath);\n      } else {\n        out += '' + ($schema);\n      }\n      out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += '} ';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/_limitProperties.js":"'use strict';\nmodule.exports = function generate__limitProperties(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $op = $keyword == 'maxProperties' ? '>' : '<';\n  out += 'if ( ';\n  if ($isData) {\n    out += ' (' + ($schemaValue) + ' !== undefined && typeof ' + ($schemaValue) + ' != \\'number\\') || ';\n  }\n  out += ' Object.keys(' + ($data) + ').length ' + ($op) + ' ' + ($schemaValue) + ') { ';\n  var $errorKeyword = $keyword;\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || '_limitProperties') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { limit: ' + ($schemaValue) + ' } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should NOT have ';\n      if ($keyword == 'maxProperties') {\n        out += 'more';\n      } else {\n        out += 'less';\n      }\n      out += ' than ';\n      if ($isData) {\n        out += '\\' + ' + ($schemaValue) + ' + \\'';\n      } else {\n        out += '' + ($schema);\n      }\n      out += ' properties\\' ';\n    }\n    if (it.opts.verbose) {\n      out += ' , schema:  ';\n      if ($isData) {\n        out += 'validate.schema' + ($schemaPath);\n      } else {\n        out += '' + ($schema);\n      }\n      out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += '} ';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/multipleOf.js":"'use strict';\nmodule.exports = function generate_multipleOf(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  out += 'var division' + ($lvl) + ';if (';\n  if ($isData) {\n    out += ' ' + ($schemaValue) + ' !== undefined && ( typeof ' + ($schemaValue) + ' != \\'number\\' || ';\n  }\n  out += ' (division' + ($lvl) + ' = ' + ($data) + ' / ' + ($schemaValue) + ', ';\n  if (it.opts.multipleOfPrecision) {\n    out += ' Math.abs(Math.round(division' + ($lvl) + ') - division' + ($lvl) + ') > 1e-' + (it.opts.multipleOfPrecision) + ' ';\n  } else {\n    out += ' division' + ($lvl) + ' !== parseInt(division' + ($lvl) + ') ';\n  }\n  out += ' ) ';\n  if ($isData) {\n    out += '  )  ';\n  }\n  out += ' ) {   ';\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || 'multipleOf') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { multipleOf: ' + ($schemaValue) + ' } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should be multiple of ';\n      if ($isData) {\n        out += '\\' + ' + ($schemaValue);\n      } else {\n        out += '' + ($schema) + '\\'';\n      }\n    }\n    if (it.opts.verbose) {\n      out += ' , schema:  ';\n      if ($isData) {\n        out += 'validate.schema' + ($schemaPath);\n      } else {\n        out += '' + ($schema);\n      }\n      out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += '} ';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/not.js":"'use strict';\nmodule.exports = function generate_not(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $errs = 'errs__' + $lvl;\n  var $it = it.util.copy(it);\n  $it.level++;\n  var $nextValid = 'valid' + $it.level;\n  if (it.util.schemaHasRules($schema, it.RULES.all)) {\n    $it.schema = $schema;\n    $it.schemaPath = $schemaPath;\n    $it.errSchemaPath = $errSchemaPath;\n    out += ' var ' + ($errs) + ' = errors;  ';\n    var $wasComposite = it.compositeRule;\n    it.compositeRule = $it.compositeRule = true;\n    $it.createErrors = false;\n    var $allErrorsOption;\n    if ($it.opts.allErrors) {\n      $allErrorsOption = $it.opts.allErrors;\n      $it.opts.allErrors = false;\n    }\n    out += ' ' + (it.validate($it)) + ' ';\n    $it.createErrors = true;\n    if ($allErrorsOption) $it.opts.allErrors = $allErrorsOption;\n    it.compositeRule = $it.compositeRule = $wasComposite;\n    out += ' if (' + ($nextValid) + ') {   ';\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = ''; /* istanbul ignore else */\n    if (it.createErrors !== false) {\n      out += ' { keyword: \\'' + ($errorKeyword || 'not') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: {} ';\n      if (it.opts.messages !== false) {\n        out += ' , message: \\'should NOT be valid\\' ';\n      }\n      if (it.opts.verbose) {\n        out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n      }\n      out += ' } ';\n    } else {\n      out += ' {} ';\n    }\n    var __err = out;\n    out = $$outStack.pop();\n    if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n      if (it.async) {\n        out += ' throw new ValidationError([' + (__err) + ']); ';\n      } else {\n        out += ' validate.errors = [' + (__err) + ']; return false; ';\n      }\n    } else {\n      out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n    }\n    out += ' } else {  errors = ' + ($errs) + '; if (vErrors !== null) { if (' + ($errs) + ') vErrors.length = ' + ($errs) + '; else vErrors = null; } ';\n    if (it.opts.allErrors) {\n      out += ' } ';\n    }\n  } else {\n    out += '  var err =   '; /* istanbul ignore else */\n    if (it.createErrors !== false) {\n      out += ' { keyword: \\'' + ($errorKeyword || 'not') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: {} ';\n      if (it.opts.messages !== false) {\n        out += ' , message: \\'should NOT be valid\\' ';\n      }\n      if (it.opts.verbose) {\n        out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n      }\n      out += ' } ';\n    } else {\n      out += ' {} ';\n    }\n    out += ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n    if ($breakOnError) {\n      out += ' if (false) { ';\n    }\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/oneOf.js":"'use strict';\nmodule.exports = function generate_oneOf(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $errs = 'errs__' + $lvl;\n  var $it = it.util.copy(it);\n  var $closingBraces = '';\n  $it.level++;\n  var $nextValid = 'valid' + $it.level;\n  out += 'var ' + ($errs) + ' = errors;var prevValid' + ($lvl) + ' = false;var ' + ($valid) + ' = false;';\n  var $currentBaseId = $it.baseId;\n  var $wasComposite = it.compositeRule;\n  it.compositeRule = $it.compositeRule = true;\n  var arr1 = $schema;\n  if (arr1) {\n    var $sch, $i = -1,\n      l1 = arr1.length - 1;\n    while ($i < l1) {\n      $sch = arr1[$i += 1];\n      if (it.util.schemaHasRules($sch, it.RULES.all)) {\n        $it.schema = $sch;\n        $it.schemaPath = $schemaPath + '[' + $i + ']';\n        $it.errSchemaPath = $errSchemaPath + '/' + $i;\n        out += '  ' + (it.validate($it)) + ' ';\n        $it.baseId = $currentBaseId;\n      } else {\n        out += ' var ' + ($nextValid) + ' = true; ';\n      }\n      if ($i) {\n        out += ' if (' + ($nextValid) + ' && prevValid' + ($lvl) + ') ' + ($valid) + ' = false; else { ';\n        $closingBraces += '}';\n      }\n      out += ' if (' + ($nextValid) + ') ' + ($valid) + ' = prevValid' + ($lvl) + ' = true;';\n    }\n  }\n  it.compositeRule = $it.compositeRule = $wasComposite;\n  out += '' + ($closingBraces) + 'if (!' + ($valid) + ') {   ';\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || 'oneOf') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: {} ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should match exactly one schema in oneOf\\' ';\n    }\n    if (it.opts.verbose) {\n      out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += '} else {  errors = ' + ($errs) + '; if (vErrors !== null) { if (' + ($errs) + ') vErrors.length = ' + ($errs) + '; else vErrors = null; }';\n  if (it.opts.allErrors) {\n    out += ' } ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/pattern.js":"'use strict';\nmodule.exports = function generate_pattern(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $regexp = $isData ? '(new RegExp(' + $schemaValue + '))' : it.usePattern($schema);\n  out += 'if ( ';\n  if ($isData) {\n    out += ' (' + ($schemaValue) + ' !== undefined && typeof ' + ($schemaValue) + ' != \\'string\\') || ';\n  }\n  out += ' !' + ($regexp) + '.test(' + ($data) + ') ) {   ';\n  var $$outStack = $$outStack || [];\n  $$outStack.push(out);\n  out = ''; /* istanbul ignore else */\n  if (it.createErrors !== false) {\n    out += ' { keyword: \\'' + ($errorKeyword || 'pattern') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { pattern:  ';\n    if ($isData) {\n      out += '' + ($schemaValue);\n    } else {\n      out += '' + (it.util.toQuotedString($schema));\n    }\n    out += '  } ';\n    if (it.opts.messages !== false) {\n      out += ' , message: \\'should match pattern \"';\n      if ($isData) {\n        out += '\\' + ' + ($schemaValue) + ' + \\'';\n      } else {\n        out += '' + (it.util.escapeQuotes($schema));\n      }\n      out += '\"\\' ';\n    }\n    if (it.opts.verbose) {\n      out += ' , schema:  ';\n      if ($isData) {\n        out += 'validate.schema' + ($schemaPath);\n      } else {\n        out += '' + (it.util.toQuotedString($schema));\n      }\n      out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n    }\n    out += ' } ';\n  } else {\n    out += ' {} ';\n  }\n  var __err = out;\n  out = $$outStack.pop();\n  if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n    if (it.async) {\n      out += ' throw new ValidationError([' + (__err) + ']); ';\n    } else {\n      out += ' validate.errors = [' + (__err) + ']; return false; ';\n    }\n  } else {\n    out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n  }\n  out += '} ';\n  if ($breakOnError) {\n    out += ' else { ';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/properties.js":"'use strict';\nmodule.exports = function generate_properties(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $errs = 'errs__' + $lvl;\n  var $it = it.util.copy(it);\n  var $closingBraces = '';\n  $it.level++;\n  var $nextValid = 'valid' + $it.level;\n  var $key = 'key' + $lvl,\n    $dataNxt = $it.dataLevel = it.dataLevel + 1,\n    $nextData = 'data' + $dataNxt;\n  var $schemaKeys = Object.keys($schema || {}),\n    $pProperties = it.schema.patternProperties || {},\n    $pPropertyKeys = Object.keys($pProperties),\n    $aProperties = it.schema.additionalProperties,\n    $someProperties = $schemaKeys.length || $pPropertyKeys.length,\n    $noAdditional = $aProperties === false,\n    $additionalIsSchema = typeof $aProperties == 'object' && Object.keys($aProperties).length,\n    $removeAdditional = it.opts.removeAdditional,\n    $checkAdditional = $noAdditional || $additionalIsSchema || $removeAdditional,\n    $ownProperties = it.opts.ownProperties,\n    $currentBaseId = it.baseId;\n  var $required = it.schema.required;\n  if ($required && !(it.opts.v5 && $required.$data) && $required.length < it.opts.loopRequired) var $requiredHash = it.util.toHash($required);\n  if (it.opts.v5) {\n    var $pgProperties = it.schema.patternGroups || {},\n      $pgPropertyKeys = Object.keys($pgProperties);\n  }\n  out += 'var ' + ($errs) + ' = errors;var ' + ($nextValid) + ' = true;';\n  if ($checkAdditional) {\n    out += ' for (var ' + ($key) + ' in ' + ($data) + ') {  ';\n    if ($ownProperties) {\n      out += ' if (!Object.prototype.hasOwnProperty.call(' + ($data) + ', ' + ($key) + ')) continue; ';\n    }\n    if ($someProperties) {\n      out += ' var isAdditional' + ($lvl) + ' = !(false ';\n      if ($schemaKeys.length) {\n        if ($schemaKeys.length > 5) {\n          out += ' || validate.schema' + ($schemaPath) + '[' + ($key) + '] ';\n        } else {\n          var arr1 = $schemaKeys;\n          if (arr1) {\n            var $propertyKey, i1 = -1,\n              l1 = arr1.length - 1;\n            while (i1 < l1) {\n              $propertyKey = arr1[i1 += 1];\n              out += ' || ' + ($key) + ' == ' + (it.util.toQuotedString($propertyKey)) + ' ';\n            }\n          }\n        }\n      }\n      if ($pPropertyKeys.length) {\n        var arr2 = $pPropertyKeys;\n        if (arr2) {\n          var $pProperty, $i = -1,\n            l2 = arr2.length - 1;\n          while ($i < l2) {\n            $pProperty = arr2[$i += 1];\n            out += ' || ' + (it.usePattern($pProperty)) + '.test(' + ($key) + ') ';\n          }\n        }\n      }\n      if (it.opts.v5 && $pgPropertyKeys && $pgPropertyKeys.length) {\n        var arr3 = $pgPropertyKeys;\n        if (arr3) {\n          var $pgProperty, $i = -1,\n            l3 = arr3.length - 1;\n          while ($i < l3) {\n            $pgProperty = arr3[$i += 1];\n            out += ' || ' + (it.usePattern($pgProperty)) + '.test(' + ($key) + ') ';\n          }\n        }\n      }\n      out += ' ); if (isAdditional' + ($lvl) + ') { ';\n    }\n    if ($removeAdditional == 'all') {\n      out += ' delete ' + ($data) + '[' + ($key) + ']; ';\n    } else {\n      var $currentErrorPath = it.errorPath;\n      var $additionalProperty = '\\' + ' + $key + ' + \\'';\n      if (it.opts._errorDataPathProperty) {\n        it.errorPath = it.util.getPathExpr(it.errorPath, $key, it.opts.jsonPointers);\n      }\n      if ($noAdditional) {\n        if ($removeAdditional) {\n          out += ' delete ' + ($data) + '[' + ($key) + ']; ';\n        } else {\n          out += ' ' + ($nextValid) + ' = false; ';\n          var $currErrSchemaPath = $errSchemaPath;\n          $errSchemaPath = it.errSchemaPath + '/additionalProperties';\n          var $$outStack = $$outStack || [];\n          $$outStack.push(out);\n          out = ''; /* istanbul ignore else */\n          if (it.createErrors !== false) {\n            out += ' { keyword: \\'' + ($errorKeyword || 'additionalProperties') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { additionalProperty: \\'' + ($additionalProperty) + '\\' } ';\n            if (it.opts.messages !== false) {\n              out += ' , message: \\'should NOT have additional properties\\' ';\n            }\n            if (it.opts.verbose) {\n              out += ' , schema: false , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n            }\n            out += ' } ';\n          } else {\n            out += ' {} ';\n          }\n          var __err = out;\n          out = $$outStack.pop();\n          if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n            if (it.async) {\n              out += ' throw new ValidationError([' + (__err) + ']); ';\n            } else {\n              out += ' validate.errors = [' + (__err) + ']; return false; ';\n            }\n          } else {\n            out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n          }\n          $errSchemaPath = $currErrSchemaPath;\n          if ($breakOnError) {\n            out += ' break; ';\n          }\n        }\n      } else if ($additionalIsSchema) {\n        if ($removeAdditional == 'failing') {\n          out += ' var ' + ($errs) + ' = errors;  ';\n          var $wasComposite = it.compositeRule;\n          it.compositeRule = $it.compositeRule = true;\n          $it.schema = $aProperties;\n          $it.schemaPath = it.schemaPath + '.additionalProperties';\n          $it.errSchemaPath = it.errSchemaPath + '/additionalProperties';\n          $it.errorPath = it.opts._errorDataPathProperty ? it.errorPath : it.util.getPathExpr(it.errorPath, $key, it.opts.jsonPointers);\n          var $passData = $data + '[' + $key + ']';\n          $it.dataPathArr[$dataNxt] = $key;\n          var $code = it.validate($it);\n          $it.baseId = $currentBaseId;\n          if (it.util.varOccurences($code, $nextData) < 2) {\n            out += ' ' + (it.util.varReplace($code, $nextData, $passData)) + ' ';\n          } else {\n            out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ' + ($code) + ' ';\n          }\n          out += ' if (!' + ($nextValid) + ') { errors = ' + ($errs) + '; if (validate.errors !== null) { if (errors) validate.errors.length = errors; else validate.errors = null; } delete ' + ($data) + '[' + ($key) + ']; }  ';\n          it.compositeRule = $it.compositeRule = $wasComposite;\n        } else {\n          $it.schema = $aProperties;\n          $it.schemaPath = it.schemaPath + '.additionalProperties';\n          $it.errSchemaPath = it.errSchemaPath + '/additionalProperties';\n          $it.errorPath = it.opts._errorDataPathProperty ? it.errorPath : it.util.getPathExpr(it.errorPath, $key, it.opts.jsonPointers);\n          var $passData = $data + '[' + $key + ']';\n          $it.dataPathArr[$dataNxt] = $key;\n          var $code = it.validate($it);\n          $it.baseId = $currentBaseId;\n          if (it.util.varOccurences($code, $nextData) < 2) {\n            out += ' ' + (it.util.varReplace($code, $nextData, $passData)) + ' ';\n          } else {\n            out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ' + ($code) + ' ';\n          }\n          if ($breakOnError) {\n            out += ' if (!' + ($nextValid) + ') break; ';\n          }\n        }\n      }\n      it.errorPath = $currentErrorPath;\n    }\n    if ($someProperties) {\n      out += ' } ';\n    }\n    out += ' }  ';\n    if ($breakOnError) {\n      out += ' if (' + ($nextValid) + ') { ';\n      $closingBraces += '}';\n    }\n  }\n  var $useDefaults = it.opts.useDefaults && !it.compositeRule;\n  if ($schemaKeys.length) {\n    var arr4 = $schemaKeys;\n    if (arr4) {\n      var $propertyKey, i4 = -1,\n        l4 = arr4.length - 1;\n      while (i4 < l4) {\n        $propertyKey = arr4[i4 += 1];\n        var $sch = $schema[$propertyKey];\n        if (it.util.schemaHasRules($sch, it.RULES.all)) {\n          var $prop = it.util.getProperty($propertyKey),\n            $passData = $data + $prop,\n            $hasDefault = $useDefaults && $sch.default !== undefined;\n          $it.schema = $sch;\n          $it.schemaPath = $schemaPath + $prop;\n          $it.errSchemaPath = $errSchemaPath + '/' + it.util.escapeFragment($propertyKey);\n          $it.errorPath = it.util.getPath(it.errorPath, $propertyKey, it.opts.jsonPointers);\n          $it.dataPathArr[$dataNxt] = it.util.toQuotedString($propertyKey);\n          var $code = it.validate($it);\n          $it.baseId = $currentBaseId;\n          if (it.util.varOccurences($code, $nextData) < 2) {\n            $code = it.util.varReplace($code, $nextData, $passData);\n            var $useData = $passData;\n          } else {\n            var $useData = $nextData;\n            out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ';\n          }\n          if ($hasDefault) {\n            out += ' ' + ($code) + ' ';\n          } else {\n            if ($requiredHash && $requiredHash[$propertyKey]) {\n              out += ' if (' + ($useData) + ' === undefined) { ' + ($nextValid) + ' = false; ';\n              var $currentErrorPath = it.errorPath,\n                $currErrSchemaPath = $errSchemaPath,\n                $missingProperty = it.util.escapeQuotes($propertyKey);\n              if (it.opts._errorDataPathProperty) {\n                it.errorPath = it.util.getPath($currentErrorPath, $propertyKey, it.opts.jsonPointers);\n              }\n              $errSchemaPath = it.errSchemaPath + '/required';\n              var $$outStack = $$outStack || [];\n              $$outStack.push(out);\n              out = ''; /* istanbul ignore else */\n              if (it.createErrors !== false) {\n                out += ' { keyword: \\'' + ($errorKeyword || 'required') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { missingProperty: \\'' + ($missingProperty) + '\\' } ';\n                if (it.opts.messages !== false) {\n                  out += ' , message: \\'';\n                  if (it.opts._errorDataPathProperty) {\n                    out += 'is a required property';\n                  } else {\n                    out += 'should have required property \\\\\\'' + ($missingProperty) + '\\\\\\'';\n                  }\n                  out += '\\' ';\n                }\n                if (it.opts.verbose) {\n                  out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n                }\n                out += ' } ';\n              } else {\n                out += ' {} ';\n              }\n              var __err = out;\n              out = $$outStack.pop();\n              if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n                if (it.async) {\n                  out += ' throw new ValidationError([' + (__err) + ']); ';\n                } else {\n                  out += ' validate.errors = [' + (__err) + ']; return false; ';\n                }\n              } else {\n                out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n              }\n              $errSchemaPath = $currErrSchemaPath;\n              it.errorPath = $currentErrorPath;\n              out += ' } else { ';\n            } else {\n              if ($breakOnError) {\n                out += ' if (' + ($useData) + ' === undefined) { ' + ($nextValid) + ' = true; } else { ';\n              } else {\n                out += ' if (' + ($useData) + ' !== undefined) { ';\n              }\n            }\n            out += ' ' + ($code) + ' } ';\n          }\n        }\n        if ($breakOnError) {\n          out += ' if (' + ($nextValid) + ') { ';\n          $closingBraces += '}';\n        }\n      }\n    }\n  }\n  var arr5 = $pPropertyKeys;\n  if (arr5) {\n    var $pProperty, i5 = -1,\n      l5 = arr5.length - 1;\n    while (i5 < l5) {\n      $pProperty = arr5[i5 += 1];\n      var $sch = $pProperties[$pProperty];\n      if (it.util.schemaHasRules($sch, it.RULES.all)) {\n        $it.schema = $sch;\n        $it.schemaPath = it.schemaPath + '.patternProperties' + it.util.getProperty($pProperty);\n        $it.errSchemaPath = it.errSchemaPath + '/patternProperties/' + it.util.escapeFragment($pProperty);\n        out += ' for (var ' + ($key) + ' in ' + ($data) + ') {  ';\n        if ($ownProperties) {\n          out += ' if (!Object.prototype.hasOwnProperty.call(' + ($data) + ', ' + ($key) + ')) continue; ';\n        }\n        out += ' if (' + (it.usePattern($pProperty)) + '.test(' + ($key) + ')) { ';\n        $it.errorPath = it.util.getPathExpr(it.errorPath, $key, it.opts.jsonPointers);\n        var $passData = $data + '[' + $key + ']';\n        $it.dataPathArr[$dataNxt] = $key;\n        var $code = it.validate($it);\n        $it.baseId = $currentBaseId;\n        if (it.util.varOccurences($code, $nextData) < 2) {\n          out += ' ' + (it.util.varReplace($code, $nextData, $passData)) + ' ';\n        } else {\n          out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ' + ($code) + ' ';\n        }\n        if ($breakOnError) {\n          out += ' if (!' + ($nextValid) + ') break; ';\n        }\n        out += ' } ';\n        if ($breakOnError) {\n          out += ' else ' + ($nextValid) + ' = true; ';\n        }\n        out += ' }  ';\n        if ($breakOnError) {\n          out += ' if (' + ($nextValid) + ') { ';\n          $closingBraces += '}';\n        }\n      }\n    }\n  }\n  if (it.opts.v5) {\n    var arr6 = $pgPropertyKeys;\n    if (arr6) {\n      var $pgProperty, i6 = -1,\n        l6 = arr6.length - 1;\n      while (i6 < l6) {\n        $pgProperty = arr6[i6 += 1];\n        var $pgSchema = $pgProperties[$pgProperty],\n          $sch = $pgSchema.schema;\n        if (it.util.schemaHasRules($sch, it.RULES.all)) {\n          $it.schema = $sch;\n          $it.schemaPath = it.schemaPath + '.patternGroups' + it.util.getProperty($pgProperty) + '.schema';\n          $it.errSchemaPath = it.errSchemaPath + '/patternGroups/' + it.util.escapeFragment($pgProperty) + '/schema';\n          out += ' var pgPropCount' + ($lvl) + ' = 0; for (var ' + ($key) + ' in ' + ($data) + ') {  ';\n          if ($ownProperties) {\n            out += ' if (!Object.prototype.hasOwnProperty.call(' + ($data) + ', ' + ($key) + ')) continue; ';\n          }\n          out += ' if (' + (it.usePattern($pgProperty)) + '.test(' + ($key) + ')) { pgPropCount' + ($lvl) + '++; ';\n          $it.errorPath = it.util.getPathExpr(it.errorPath, $key, it.opts.jsonPointers);\n          var $passData = $data + '[' + $key + ']';\n          $it.dataPathArr[$dataNxt] = $key;\n          var $code = it.validate($it);\n          $it.baseId = $currentBaseId;\n          if (it.util.varOccurences($code, $nextData) < 2) {\n            out += ' ' + (it.util.varReplace($code, $nextData, $passData)) + ' ';\n          } else {\n            out += ' var ' + ($nextData) + ' = ' + ($passData) + '; ' + ($code) + ' ';\n          }\n          if ($breakOnError) {\n            out += ' if (!' + ($nextValid) + ') break; ';\n          }\n          out += ' } ';\n          if ($breakOnError) {\n            out += ' else ' + ($nextValid) + ' = true; ';\n          }\n          out += ' }  ';\n          if ($breakOnError) {\n            out += ' if (' + ($nextValid) + ') { ';\n            $closingBraces += '}';\n          }\n          var $pgMin = $pgSchema.minimum,\n            $pgMax = $pgSchema.maximum;\n          if ($pgMin !== undefined || $pgMax !== undefined) {\n            out += ' var ' + ($valid) + ' = true; ';\n            var $currErrSchemaPath = $errSchemaPath;\n            if ($pgMin !== undefined) {\n              var $limit = $pgMin,\n                $reason = 'minimum',\n                $moreOrLess = 'less';\n              out += ' ' + ($valid) + ' = pgPropCount' + ($lvl) + ' >= ' + ($pgMin) + '; ';\n              $errSchemaPath = it.errSchemaPath + '/patternGroups/minimum';\n              out += '  if (!' + ($valid) + ') {   ';\n              var $$outStack = $$outStack || [];\n              $$outStack.push(out);\n              out = ''; /* istanbul ignore else */\n              if (it.createErrors !== false) {\n                out += ' { keyword: \\'' + ($errorKeyword || 'patternGroups') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { reason: \\'' + ($reason) + '\\', limit: ' + ($limit) + ', pattern: \\'' + (it.util.escapeQuotes($pgProperty)) + '\\' } ';\n                if (it.opts.messages !== false) {\n                  out += ' , message: \\'should NOT have ' + ($moreOrLess) + ' than ' + ($limit) + ' properties matching pattern \"' + (it.util.escapeQuotes($pgProperty)) + '\"\\' ';\n                }\n                if (it.opts.verbose) {\n                  out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n                }\n                out += ' } ';\n              } else {\n                out += ' {} ';\n              }\n              var __err = out;\n              out = $$outStack.pop();\n              if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n                if (it.async) {\n                  out += ' throw new ValidationError([' + (__err) + ']); ';\n                } else {\n                  out += ' validate.errors = [' + (__err) + ']; return false; ';\n                }\n              } else {\n                out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n              }\n              out += ' } ';\n              if ($pgMax !== undefined) {\n                out += ' else ';\n              }\n            }\n            if ($pgMax !== undefined) {\n              var $limit = $pgMax,\n                $reason = 'maximum',\n                $moreOrLess = 'more';\n              out += ' ' + ($valid) + ' = pgPropCount' + ($lvl) + ' <= ' + ($pgMax) + '; ';\n              $errSchemaPath = it.errSchemaPath + '/patternGroups/maximum';\n              out += '  if (!' + ($valid) + ') {   ';\n              var $$outStack = $$outStack || [];\n              $$outStack.push(out);\n              out = ''; /* istanbul ignore else */\n              if (it.createErrors !== false) {\n                out += ' { keyword: \\'' + ($errorKeyword || 'patternGroups') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { reason: \\'' + ($reason) + '\\', limit: ' + ($limit) + ', pattern: \\'' + (it.util.escapeQuotes($pgProperty)) + '\\' } ';\n                if (it.opts.messages !== false) {\n                  out += ' , message: \\'should NOT have ' + ($moreOrLess) + ' than ' + ($limit) + ' properties matching pattern \"' + (it.util.escapeQuotes($pgProperty)) + '\"\\' ';\n                }\n                if (it.opts.verbose) {\n                  out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n                }\n                out += ' } ';\n              } else {\n                out += ' {} ';\n              }\n              var __err = out;\n              out = $$outStack.pop();\n              if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n                if (it.async) {\n                  out += ' throw new ValidationError([' + (__err) + ']); ';\n                } else {\n                  out += ' validate.errors = [' + (__err) + ']; return false; ';\n                }\n              } else {\n                out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n              }\n              out += ' } ';\n            }\n            $errSchemaPath = $currErrSchemaPath;\n            if ($breakOnError) {\n              out += ' if (' + ($valid) + ') { ';\n              $closingBraces += '}';\n            }\n          }\n        }\n      }\n    }\n  }\n  if ($breakOnError) {\n    out += ' ' + ($closingBraces) + ' if (' + ($errs) + ' == errors) {';\n  }\n  out = it.util.cleanUpCode(out);\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/required.js":"'use strict';\nmodule.exports = function generate_required(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $vSchema = 'schema' + $lvl;\n  if (!$isData) {\n    if ($schema.length < it.opts.loopRequired && it.schema.properties && Object.keys(it.schema.properties).length) {\n      var $required = [];\n      var arr1 = $schema;\n      if (arr1) {\n        var $property, i1 = -1,\n          l1 = arr1.length - 1;\n        while (i1 < l1) {\n          $property = arr1[i1 += 1];\n          var $propertySch = it.schema.properties[$property];\n          if (!($propertySch && it.util.schemaHasRules($propertySch, it.RULES.all))) {\n            $required[$required.length] = $property;\n          }\n        }\n      }\n    } else {\n      var $required = $schema;\n    }\n  }\n  if ($isData || $required.length) {\n    var $currentErrorPath = it.errorPath,\n      $loopRequired = $isData || $required.length >= it.opts.loopRequired;\n    if ($breakOnError) {\n      out += ' var missing' + ($lvl) + '; ';\n      if ($loopRequired) {\n        if (!$isData) {\n          out += ' var ' + ($vSchema) + ' = validate.schema' + ($schemaPath) + '; ';\n        }\n        var $i = 'i' + $lvl,\n          $propertyPath = 'schema' + $lvl + '[' + $i + ']',\n          $missingProperty = '\\' + ' + $propertyPath + ' + \\'';\n        if (it.opts._errorDataPathProperty) {\n          it.errorPath = it.util.getPathExpr($currentErrorPath, $propertyPath, it.opts.jsonPointers);\n        }\n        out += ' var ' + ($valid) + ' = true; ';\n        if ($isData) {\n          out += ' if (schema' + ($lvl) + ' === undefined) ' + ($valid) + ' = true; else if (!Array.isArray(schema' + ($lvl) + ')) ' + ($valid) + ' = false; else {';\n        }\n        out += ' for (var ' + ($i) + ' = 0; ' + ($i) + ' < ' + ($vSchema) + '.length; ' + ($i) + '++) { ' + ($valid) + ' = ' + ($data) + '[' + ($vSchema) + '[' + ($i) + ']] !== undefined; if (!' + ($valid) + ') break; } ';\n        if ($isData) {\n          out += '  }  ';\n        }\n        out += '  if (!' + ($valid) + ') {   ';\n        var $$outStack = $$outStack || [];\n        $$outStack.push(out);\n        out = ''; /* istanbul ignore else */\n        if (it.createErrors !== false) {\n          out += ' { keyword: \\'' + ($errorKeyword || 'required') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { missingProperty: \\'' + ($missingProperty) + '\\' } ';\n          if (it.opts.messages !== false) {\n            out += ' , message: \\'';\n            if (it.opts._errorDataPathProperty) {\n              out += 'is a required property';\n            } else {\n              out += 'should have required property \\\\\\'' + ($missingProperty) + '\\\\\\'';\n            }\n            out += '\\' ';\n          }\n          if (it.opts.verbose) {\n            out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n          }\n          out += ' } ';\n        } else {\n          out += ' {} ';\n        }\n        var __err = out;\n        out = $$outStack.pop();\n        if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n          if (it.async) {\n            out += ' throw new ValidationError([' + (__err) + ']); ';\n          } else {\n            out += ' validate.errors = [' + (__err) + ']; return false; ';\n          }\n        } else {\n          out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n        }\n        out += ' } else { ';\n      } else {\n        out += ' if ( ';\n        var arr2 = $required;\n        if (arr2) {\n          var _$property, $i = -1,\n            l2 = arr2.length - 1;\n          while ($i < l2) {\n            _$property = arr2[$i += 1];\n            if ($i) {\n              out += ' || ';\n            }\n            var $prop = it.util.getProperty(_$property);\n            out += ' ( ' + ($data) + ($prop) + ' === undefined && (missing' + ($lvl) + ' = ' + (it.util.toQuotedString(it.opts.jsonPointers ? _$property : $prop)) + ') ) ';\n          }\n        }\n        out += ') {  ';\n        var $propertyPath = 'missing' + $lvl,\n          $missingProperty = '\\' + ' + $propertyPath + ' + \\'';\n        if (it.opts._errorDataPathProperty) {\n          it.errorPath = it.opts.jsonPointers ? it.util.getPathExpr($currentErrorPath, $propertyPath, true) : $currentErrorPath + ' + ' + $propertyPath;\n        }\n        var $$outStack = $$outStack || [];\n        $$outStack.push(out);\n        out = ''; /* istanbul ignore else */\n        if (it.createErrors !== false) {\n          out += ' { keyword: \\'' + ($errorKeyword || 'required') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { missingProperty: \\'' + ($missingProperty) + '\\' } ';\n          if (it.opts.messages !== false) {\n            out += ' , message: \\'';\n            if (it.opts._errorDataPathProperty) {\n              out += 'is a required property';\n            } else {\n              out += 'should have required property \\\\\\'' + ($missingProperty) + '\\\\\\'';\n            }\n            out += '\\' ';\n          }\n          if (it.opts.verbose) {\n            out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n          }\n          out += ' } ';\n        } else {\n          out += ' {} ';\n        }\n        var __err = out;\n        out = $$outStack.pop();\n        if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n          if (it.async) {\n            out += ' throw new ValidationError([' + (__err) + ']); ';\n          } else {\n            out += ' validate.errors = [' + (__err) + ']; return false; ';\n          }\n        } else {\n          out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n        }\n        out += ' } else { ';\n      }\n    } else {\n      if ($loopRequired) {\n        if (!$isData) {\n          out += ' var ' + ($vSchema) + ' = validate.schema' + ($schemaPath) + '; ';\n        }\n        var $i = 'i' + $lvl,\n          $propertyPath = 'schema' + $lvl + '[' + $i + ']',\n          $missingProperty = '\\' + ' + $propertyPath + ' + \\'';\n        if (it.opts._errorDataPathProperty) {\n          it.errorPath = it.util.getPathExpr($currentErrorPath, $propertyPath, it.opts.jsonPointers);\n        }\n        if ($isData) {\n          out += ' if (' + ($vSchema) + ' && !Array.isArray(' + ($vSchema) + ')) {  var err =   '; /* istanbul ignore else */\n          if (it.createErrors !== false) {\n            out += ' { keyword: \\'' + ($errorKeyword || 'required') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { missingProperty: \\'' + ($missingProperty) + '\\' } ';\n            if (it.opts.messages !== false) {\n              out += ' , message: \\'';\n              if (it.opts._errorDataPathProperty) {\n                out += 'is a required property';\n              } else {\n                out += 'should have required property \\\\\\'' + ($missingProperty) + '\\\\\\'';\n              }\n              out += '\\' ';\n            }\n            if (it.opts.verbose) {\n              out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n            }\n            out += ' } ';\n          } else {\n            out += ' {} ';\n          }\n          out += ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; } else if (' + ($vSchema) + ' !== undefined) { ';\n        }\n        out += ' for (var ' + ($i) + ' = 0; ' + ($i) + ' < ' + ($vSchema) + '.length; ' + ($i) + '++) { if (' + ($data) + '[' + ($vSchema) + '[' + ($i) + ']] === undefined) {  var err =   '; /* istanbul ignore else */\n        if (it.createErrors !== false) {\n          out += ' { keyword: \\'' + ($errorKeyword || 'required') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { missingProperty: \\'' + ($missingProperty) + '\\' } ';\n          if (it.opts.messages !== false) {\n            out += ' , message: \\'';\n            if (it.opts._errorDataPathProperty) {\n              out += 'is a required property';\n            } else {\n              out += 'should have required property \\\\\\'' + ($missingProperty) + '\\\\\\'';\n            }\n            out += '\\' ';\n          }\n          if (it.opts.verbose) {\n            out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n          }\n          out += ' } ';\n        } else {\n          out += ' {} ';\n        }\n        out += ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; } } ';\n        if ($isData) {\n          out += '  }  ';\n        }\n      } else {\n        var arr3 = $required;\n        if (arr3) {\n          var $reqProperty, i3 = -1,\n            l3 = arr3.length - 1;\n          while (i3 < l3) {\n            $reqProperty = arr3[i3 += 1];\n            var $prop = it.util.getProperty($reqProperty),\n              $missingProperty = it.util.escapeQuotes($reqProperty);\n            if (it.opts._errorDataPathProperty) {\n              it.errorPath = it.util.getPath($currentErrorPath, $reqProperty, it.opts.jsonPointers);\n            }\n            out += ' if (' + ($data) + ($prop) + ' === undefined) {  var err =   '; /* istanbul ignore else */\n            if (it.createErrors !== false) {\n              out += ' { keyword: \\'' + ($errorKeyword || 'required') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { missingProperty: \\'' + ($missingProperty) + '\\' } ';\n              if (it.opts.messages !== false) {\n                out += ' , message: \\'';\n                if (it.opts._errorDataPathProperty) {\n                  out += 'is a required property';\n                } else {\n                  out += 'should have required property \\\\\\'' + ($missingProperty) + '\\\\\\'';\n                }\n                out += '\\' ';\n              }\n              if (it.opts.verbose) {\n                out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n              }\n              out += ' } ';\n            } else {\n              out += ' {} ';\n            }\n            out += ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; } ';\n          }\n        }\n      }\n    }\n    it.errorPath = $currentErrorPath;\n  } else if ($breakOnError) {\n    out += ' if (true) {';\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/uniqueItems.js":"'use strict';\nmodule.exports = function generate_uniqueItems(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  if (($schema || $isData) && it.opts.uniqueItems !== false) {\n    if ($isData) {\n      out += ' var ' + ($valid) + '; if (' + ($schemaValue) + ' === false || ' + ($schemaValue) + ' === undefined) ' + ($valid) + ' = true; else if (typeof ' + ($schemaValue) + ' != \\'boolean\\') ' + ($valid) + ' = false; else { ';\n    }\n    out += ' var ' + ($valid) + ' = true; if (' + ($data) + '.length > 1) { var i = ' + ($data) + '.length, j; outer: for (;i--;) { for (j = i; j--;) { if (equal(' + ($data) + '[i], ' + ($data) + '[j])) { ' + ($valid) + ' = false; break outer; } } } } ';\n    if ($isData) {\n      out += '  }  ';\n    }\n    out += ' if (!' + ($valid) + ') {   ';\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = ''; /* istanbul ignore else */\n    if (it.createErrors !== false) {\n      out += ' { keyword: \\'' + ($errorKeyword || 'uniqueItems') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { i: i, j: j } ';\n      if (it.opts.messages !== false) {\n        out += ' , message: \\'should NOT have duplicate items (items ## \\' + j + \\' and \\' + i + \\' are identical)\\' ';\n      }\n      if (it.opts.verbose) {\n        out += ' , schema:  ';\n        if ($isData) {\n          out += 'validate.schema' + ($schemaPath);\n        } else {\n          out += '' + ($schema);\n        }\n        out += '         , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n      }\n      out += ' } ';\n    } else {\n      out += ' {} ';\n    }\n    var __err = out;\n    out = $$outStack.pop();\n    if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n      if (it.async) {\n        out += ' throw new ValidationError([' + (__err) + ']); ';\n      } else {\n        out += ' validate.errors = [' + (__err) + ']; return false; ';\n      }\n    } else {\n      out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n    }\n    out += ' } ';\n    if ($breakOnError) {\n      out += ' else { ';\n    }\n  } else {\n    if ($breakOnError) {\n      out += ' if (true) { ';\n    }\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/v5.js":"'use strict';\n\nvar META_SCHEMA_ID = 'https://raw.githubusercontent.com/epoberezkin/ajv/master/lib/refs/json-schema-v5.json';\n\nmodule.exports = {\n  enable: enableV5,\n  META_SCHEMA_ID: META_SCHEMA_ID\n};\n\n\nfunction enableV5(ajv) {\n  var inlineFunctions = {\n    'switch': require('./dotjs/switch'),\n    'constant': require('./dotjs/constant'),\n    '_formatLimit': require('./dotjs/_formatLimit'),\n    'patternRequired': require('./dotjs/patternRequired')\n  };\n\n  if (ajv._opts.meta !== false) {\n    var metaSchema = require('./refs/json-schema-v5.json');\n    ajv.addMetaSchema(metaSchema, META_SCHEMA_ID);\n  }\n  _addKeyword('constant');\n  ajv.addKeyword('contains', { type: 'array', macro: containsMacro });\n\n  _addKeyword('formatMaximum', 'string', inlineFunctions._formatLimit);\n  _addKeyword('formatMinimum', 'string', inlineFunctions._formatLimit);\n  ajv.addKeyword('formatExclusiveMaximum');\n  ajv.addKeyword('formatExclusiveMinimum');\n\n  ajv.addKeyword('patternGroups'); // implemented in properties.jst\n  _addKeyword('patternRequired', 'object');\n  _addKeyword('switch');\n\n\n  function _addKeyword(keyword, types, inlineFunc) {\n    var definition = {\n      inline: inlineFunc || inlineFunctions[keyword],\n      statements: true,\n      errors: 'full'\n    };\n    if (types) definition.type = types;\n    ajv.addKeyword(keyword, definition);\n  }\n}\n\n\nfunction containsMacro(schema) {\n  return {\n    not: { items: { not: schema } }\n  };\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/keyword.js":"'use strict';\n\nvar IDENTIFIER = /^[a-z_$][a-z0-9_$\\-]*$/i;\nvar customRuleCode = require('./dotjs/custom');\n\nmodule.exports = {\n  add: addKeyword,\n  get: getKeyword,\n  remove: removeKeyword\n};\n\n/**\n * Define custom keyword\n * @this  Ajv\n * @param {String} keyword custom keyword, should be unique (including different from all standard, custom and macro keywords).\n * @param {Object} definition keyword definition object with properties `type` (type(s) which the keyword applies to), `validate` or `compile`.\n */\nfunction addKeyword(keyword, definition) {\n  /* jshint validthis: true */\n  /* eslint no-shadow: 0 */\n  var RULES = this.RULES;\n\n  if (RULES.keywords[keyword])\n    throw new Error('Keyword ' + keyword + ' is already defined');\n\n  if (!IDENTIFIER.test(keyword))\n    throw new Error('Keyword ' + keyword + ' is not a valid identifier');\n\n  if (definition) {\n    if (definition.macro && definition.valid !== undefined)\n      throw new Error('\"valid\" option cannot be used with macro keywords');\n\n    var dataType = definition.type;\n    if (Array.isArray(dataType)) {\n      var i, len = dataType.length;\n      for (i=0; i<len; i++) checkDataType(dataType[i]);\n      for (i=0; i<len; i++) _addRule(keyword, dataType[i], definition);\n    } else {\n      if (dataType) checkDataType(dataType);\n      _addRule(keyword, dataType, definition);\n    }\n\n    var $data = definition.$data === true && this._opts.v5;\n    if ($data && !definition.validate)\n      throw new Error('$data support: \"validate\" function is not defined');\n\n    var metaSchema = definition.metaSchema;\n    if (metaSchema) {\n      if ($data) {\n        metaSchema = {\n          anyOf: [\n            metaSchema,\n            { '$ref': 'https://raw.githubusercontent.com/epoberezkin/ajv/master/lib/refs/json-schema-v5.json#/definitions/$data' }\n          ]\n        };\n      }\n      definition.validateSchema = this.compile(metaSchema, true);\n    }\n  }\n\n  RULES.keywords[keyword] = RULES.all[keyword] = true;\n\n\n  function _addRule(keyword, dataType, definition) {\n    var ruleGroup;\n    for (var i=0; i<RULES.length; i++) {\n      var rg = RULES[i];\n      if (rg.type == dataType) {\n        ruleGroup = rg;\n        break;\n      }\n    }\n\n    if (!ruleGroup) {\n      ruleGroup = { type: dataType, rules: [] };\n      RULES.push(ruleGroup);\n    }\n\n    var rule = {\n      keyword: keyword,\n      definition: definition,\n      custom: true,\n      code: customRuleCode\n    };\n    ruleGroup.rules.push(rule);\n    RULES.custom[keyword] = rule;\n  }\n\n\n  function checkDataType(dataType) {\n    if (!RULES.types[dataType]) throw new Error('Unknown type ' + dataType);\n  }\n}\n\n\n/**\n * Get keyword\n * @this  Ajv\n * @param {String} keyword pre-defined or custom keyword.\n * @return {Object|Boolean} custom keyword definition, `true` if it is a predefined keyword, `false` otherwise.\n */\nfunction getKeyword(keyword) {\n  /* jshint validthis: true */\n  var rule = this.RULES.custom[keyword];\n  return rule ? rule.definition : this.RULES.keywords[keyword] || false;\n}\n\n\n/**\n * Remove keyword\n * @this  Ajv\n * @param {String} keyword pre-defined or custom keyword.\n */\nfunction removeKeyword(keyword) {\n  /* jshint validthis: true */\n  var RULES = this.RULES;\n  delete RULES.keywords[keyword];\n  delete RULES.all[keyword];\n  delete RULES.custom[keyword];\n  for (var i=0; i<RULES.length; i++) {\n    var rules = RULES[i].rules;\n    for (var j=0; j<rules.length; j++) {\n      if (rules[j].keyword == keyword) {\n        rules.splice(j, 1);\n        break;\n      }\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/node_modules/ajv/lib/dotjs/custom.js":"'use strict';\nmodule.exports = function generate_custom(it, $keyword) {\n  var out = ' ';\n  var $lvl = it.level;\n  var $dataLvl = it.dataLevel;\n  var $schema = it.schema[$keyword];\n  var $schemaPath = it.schemaPath + it.util.getProperty($keyword);\n  var $errSchemaPath = it.errSchemaPath + '/' + $keyword;\n  var $breakOnError = !it.opts.allErrors;\n  var $errorKeyword;\n  var $data = 'data' + ($dataLvl || '');\n  var $valid = 'valid' + $lvl;\n  var $errs = 'errs__' + $lvl;\n  var $isData = it.opts.v5 && $schema && $schema.$data,\n    $schemaValue;\n  if ($isData) {\n    out += ' var schema' + ($lvl) + ' = ' + (it.util.getData($schema.$data, $dataLvl, it.dataPathArr)) + '; ';\n    $schemaValue = 'schema' + $lvl;\n  } else {\n    $schemaValue = $schema;\n  }\n  var $rule = this,\n    $definition = 'definition' + $lvl,\n    $rDef = $rule.definition,\n    $validate = $rDef.validate,\n    $compile, $inline, $macro, $ruleValidate, $validateCode;\n  if ($isData && $rDef.$data) {\n    $validateCode = 'keywordValidate' + $lvl;\n    var $validateSchema = $rDef.validateSchema;\n    out += ' var ' + ($definition) + ' = RULES.custom[\\'' + ($keyword) + '\\'].definition; var ' + ($validateCode) + ' = ' + ($definition) + '.validate;';\n  } else {\n    $ruleValidate = it.useCustomRule($rule, $schema, it.schema, it);\n    $schemaValue = 'validate.schema' + $schemaPath;\n    $validateCode = $ruleValidate.code;\n    $compile = $rDef.compile;\n    $inline = $rDef.inline;\n    $macro = $rDef.macro;\n  }\n  var $ruleErrs = $validateCode + '.errors',\n    $i = 'i' + $lvl,\n    $ruleErr = 'ruleErr' + $lvl,\n    $asyncKeyword = $rDef.async;\n  if ($asyncKeyword && !it.async) throw new Error('async keyword in sync schema');\n  if (!($inline || $macro)) {\n    out += '' + ($ruleErrs) + ' = null;';\n  }\n  out += 'var ' + ($errs) + ' = errors;var ' + ($valid) + ';';\n  if ($validateSchema) {\n    out += ' ' + ($valid) + ' = ' + ($definition) + '.validateSchema(' + ($schemaValue) + '); if (' + ($valid) + ') {';\n  }\n  if ($inline) {\n    if ($rDef.statements) {\n      out += ' ' + ($ruleValidate.validate) + ' ';\n    } else {\n      out += ' ' + ($valid) + ' = ' + ($ruleValidate.validate) + '; ';\n    }\n  } else if ($macro) {\n    var $it = it.util.copy(it);\n    $it.level++;\n    var $nextValid = 'valid' + $it.level;\n    $it.schema = $ruleValidate.validate;\n    $it.schemaPath = '';\n    var $wasComposite = it.compositeRule;\n    it.compositeRule = $it.compositeRule = true;\n    var $code = it.validate($it).replace(/validate\\.schema/g, $validateCode);\n    it.compositeRule = $it.compositeRule = $wasComposite;\n    out += ' ' + ($code);\n  } else {\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = '';\n    out += '  ' + ($validateCode) + '.call( ';\n    if (it.opts.passContext) {\n      out += 'this';\n    } else {\n      out += 'self';\n    }\n    if ($compile || $rDef.schema === false) {\n      out += ' , ' + ($data) + ' ';\n    } else {\n      out += ' , ' + ($schemaValue) + ' , ' + ($data) + ' , validate.schema' + (it.schemaPath) + ' ';\n    }\n    out += ' , (dataPath || \\'\\')';\n    if (it.errorPath != '\"\"') {\n      out += ' + ' + (it.errorPath);\n    }\n    var $parentData = $dataLvl ? 'data' + (($dataLvl - 1) || '') : 'parentData',\n      $parentDataProperty = $dataLvl ? it.dataPathArr[$dataLvl] : 'parentDataProperty';\n    out += ' , ' + ($parentData) + ' , ' + ($parentDataProperty) + ' , rootData )  ';\n    var def_callRuleValidate = out;\n    out = $$outStack.pop();\n    if ($rDef.errors === false) {\n      out += ' ' + ($valid) + ' = ';\n      if ($asyncKeyword) {\n        out += '' + (it.yieldAwait);\n      }\n      out += '' + (def_callRuleValidate) + '; ';\n    } else {\n      if ($asyncKeyword) {\n        $ruleErrs = 'customErrors' + $lvl;\n        out += ' var ' + ($ruleErrs) + ' = null; try { ' + ($valid) + ' = ' + (it.yieldAwait) + (def_callRuleValidate) + '; } catch (e) { ' + ($valid) + ' = false; if (e instanceof ValidationError) ' + ($ruleErrs) + ' = e.errors; else throw e; } ';\n      } else {\n        out += ' ' + ($ruleErrs) + ' = null; ' + ($valid) + ' = ' + (def_callRuleValidate) + '; ';\n      }\n    }\n  }\n  if ($rDef.modifying) {\n    out += ' ' + ($data) + ' = ' + ($parentData) + '[' + ($parentDataProperty) + '];';\n  }\n  if ($validateSchema) {\n    out += ' }';\n  }\n  if ($rDef.valid) {\n    if ($breakOnError) {\n      out += ' if (true) { ';\n    }\n  } else {\n    out += ' if ( ';\n    if ($rDef.valid === undefined) {\n      out += ' !';\n      if ($macro) {\n        out += '' + ($nextValid);\n      } else {\n        out += '' + ($valid);\n      }\n    } else {\n      out += ' ' + (!$rDef.valid) + ' ';\n    }\n    out += ') { ';\n    $errorKeyword = $rule.keyword;\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = '';\n    var $$outStack = $$outStack || [];\n    $$outStack.push(out);\n    out = ''; /* istanbul ignore else */\n    if (it.createErrors !== false) {\n      out += ' { keyword: \\'' + ($errorKeyword || 'custom') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { keyword: \\'' + ($rule.keyword) + '\\' } ';\n      if (it.opts.messages !== false) {\n        out += ' , message: \\'should pass \"' + ($rule.keyword) + '\" keyword validation\\' ';\n      }\n      if (it.opts.verbose) {\n        out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n      }\n      out += ' } ';\n    } else {\n      out += ' {} ';\n    }\n    var __err = out;\n    out = $$outStack.pop();\n    if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n      if (it.async) {\n        out += ' throw new ValidationError([' + (__err) + ']); ';\n      } else {\n        out += ' validate.errors = [' + (__err) + ']; return false; ';\n      }\n    } else {\n      out += ' var err = ' + (__err) + ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n    }\n    var def_customError = out;\n    out = $$outStack.pop();\n    if ($inline) {\n      if ($rDef.errors) {\n        if ($rDef.errors != 'full') {\n          out += '  for (var ' + ($i) + '=' + ($errs) + '; ' + ($i) + '<errors; ' + ($i) + '++) { var ' + ($ruleErr) + ' = vErrors[' + ($i) + ']; if (' + ($ruleErr) + '.dataPath === undefined) ' + ($ruleErr) + '.dataPath = (dataPath || \\'\\') + ' + (it.errorPath) + '; if (' + ($ruleErr) + '.schemaPath === undefined) { ' + ($ruleErr) + '.schemaPath = \"' + ($errSchemaPath) + '\"; } ';\n          if (it.opts.verbose) {\n            out += ' ' + ($ruleErr) + '.schema = ' + ($schemaValue) + '; ' + ($ruleErr) + '.data = ' + ($data) + '; ';\n          }\n          out += ' } ';\n        }\n      } else {\n        if ($rDef.errors === false) {\n          out += ' ' + (def_customError) + ' ';\n        } else {\n          out += ' if (' + ($errs) + ' == errors) { ' + (def_customError) + ' } else {  for (var ' + ($i) + '=' + ($errs) + '; ' + ($i) + '<errors; ' + ($i) + '++) { var ' + ($ruleErr) + ' = vErrors[' + ($i) + ']; if (' + ($ruleErr) + '.dataPath === undefined) ' + ($ruleErr) + '.dataPath = (dataPath || \\'\\') + ' + (it.errorPath) + '; if (' + ($ruleErr) + '.schemaPath === undefined) { ' + ($ruleErr) + '.schemaPath = \"' + ($errSchemaPath) + '\"; } ';\n          if (it.opts.verbose) {\n            out += ' ' + ($ruleErr) + '.schema = ' + ($schemaValue) + '; ' + ($ruleErr) + '.data = ' + ($data) + '; ';\n          }\n          out += ' } } ';\n        }\n      }\n    } else if ($macro) {\n      out += '   var err =   '; /* istanbul ignore else */\n      if (it.createErrors !== false) {\n        out += ' { keyword: \\'' + ($errorKeyword || 'custom') + '\\' , dataPath: (dataPath || \\'\\') + ' + (it.errorPath) + ' , schemaPath: ' + (it.util.toQuotedString($errSchemaPath)) + ' , params: { keyword: \\'' + ($rule.keyword) + '\\' } ';\n        if (it.opts.messages !== false) {\n          out += ' , message: \\'should pass \"' + ($rule.keyword) + '\" keyword validation\\' ';\n        }\n        if (it.opts.verbose) {\n          out += ' , schema: validate.schema' + ($schemaPath) + ' , parentSchema: validate.schema' + (it.schemaPath) + ' , data: ' + ($data) + ' ';\n        }\n        out += ' } ';\n      } else {\n        out += ' {} ';\n      }\n      out += ';  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++; ';\n      if (!it.compositeRule && $breakOnError) { /* istanbul ignore if */\n        if (it.async) {\n          out += ' throw new ValidationError(vErrors); ';\n        } else {\n          out += ' validate.errors = vErrors; return false; ';\n        }\n      }\n    } else {\n      if ($rDef.errors === false) {\n        out += ' ' + (def_customError) + ' ';\n      } else {\n        out += ' if (Array.isArray(' + ($ruleErrs) + ')) { if (vErrors === null) vErrors = ' + ($ruleErrs) + '; else vErrors = vErrors.concat(' + ($ruleErrs) + '); errors = vErrors.length;  for (var ' + ($i) + '=' + ($errs) + '; ' + ($i) + '<errors; ' + ($i) + '++) { var ' + ($ruleErr) + ' = vErrors[' + ($i) + ']; if (' + ($ruleErr) + '.dataPath === undefined) ' + ($ruleErr) + '.dataPath = (dataPath || \\'\\') + ' + (it.errorPath) + ';  ' + ($ruleErr) + '.schemaPath = \"' + ($errSchemaPath) + '\";  ';\n        if (it.opts.verbose) {\n          out += ' ' + ($ruleErr) + '.schema = ' + ($schemaValue) + '; ' + ($ruleErr) + '.data = ' + ($data) + '; ';\n        }\n        out += ' } } else { ' + (def_customError) + ' } ';\n      }\n    }\n    out += ' } ';\n    if ($breakOnError) {\n      out += ' else { ';\n    }\n  }\n  return out;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/har-validator/lib/node4/error.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = HARError;\nfunction HARError(errors) {\n  var message = 'validation failed';\n\n  this.name = 'HARError';\n  this.message = message;\n  this.errors = errors;\n\n  if (typeof Error.captureStackTrace === 'function') {\n    Error.captureStackTrace(this, this.constructor);\n  } else {\n    this.stack = new Error(message).stack;\n  }\n}\n\nHARError.prototype = Error.prototype;\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/auth.js":"'use strict'\n\nvar caseless = require('caseless')\n  , uuid = require('uuid')\n  , helpers = require('./helpers')\n\nvar md5 = helpers.md5\n  , toBase64 = helpers.toBase64\n\n\nfunction Auth (request) {\n  // define all public properties here\n  this.request = request\n  this.hasAuth = false\n  this.sentAuth = false\n  this.bearerToken = null\n  this.user = null\n  this.pass = null\n}\n\nAuth.prototype.basic = function (user, pass, sendImmediately) {\n  var self = this\n  if (typeof user !== 'string' || (pass !== undefined && typeof pass !== 'string')) {\n    self.request.emit('error', new Error('auth() received invalid user or password'))\n  }\n  self.user = user\n  self.pass = pass\n  self.hasAuth = true\n  var header = user + ':' + (pass || '')\n  if (sendImmediately || typeof sendImmediately === 'undefined') {\n    var authHeader = 'Basic ' + toBase64(header)\n    self.sentAuth = true\n    return authHeader\n  }\n}\n\nAuth.prototype.bearer = function (bearer, sendImmediately) {\n  var self = this\n  self.bearerToken = bearer\n  self.hasAuth = true\n  if (sendImmediately || typeof sendImmediately === 'undefined') {\n    if (typeof bearer === 'function') {\n      bearer = bearer()\n    }\n    var authHeader = 'Bearer ' + (bearer || '')\n    self.sentAuth = true\n    return authHeader\n  }\n}\n\nAuth.prototype.digest = function (method, path, authHeader) {\n  // TODO: More complete implementation of RFC 2617.\n  //   - handle challenge.domain\n  //   - support qop=\"auth-int\" only\n  //   - handle Authentication-Info (not necessarily?)\n  //   - check challenge.stale (not necessarily?)\n  //   - increase nc (not necessarily?)\n  // For reference:\n  // http://tools.ietf.org/html/rfc2617#section-3\n  // https://github.com/bagder/curl/blob/master/lib/http_digest.c\n\n  var self = this\n\n  var challenge = {}\n  var re = /([a-z0-9_-]+)=(?:\"([^\"]+)\"|([a-z0-9_-]+))/gi\n  for (;;) {\n    var match = re.exec(authHeader)\n    if (!match) {\n      break\n    }\n    challenge[match[1]] = match[2] || match[3]\n  }\n\n  /**\n   * RFC 2617: handle both MD5 and MD5-sess algorithms.\n   *\n   * If the algorithm directive's value is \"MD5\" or unspecified, then HA1 is\n   *   HA1=MD5(username:realm:password)\n   * If the algorithm directive's value is \"MD5-sess\", then HA1 is\n   *   HA1=MD5(MD5(username:realm:password):nonce:cnonce)\n   */\n  var ha1Compute = function (algorithm, user, realm, pass, nonce, cnonce) {\n    var ha1 = md5(user + ':' + realm + ':' + pass)\n    if (algorithm && algorithm.toLowerCase() === 'md5-sess') {\n      return md5(ha1 + ':' + nonce + ':' + cnonce)\n    } else {\n      return ha1\n    }\n  }\n\n  var qop = /(^|,)\\s*auth\\s*($|,)/.test(challenge.qop) && 'auth'\n  var nc = qop && '00000001'\n  var cnonce = qop && uuid().replace(/-/g, '')\n  var ha1 = ha1Compute(challenge.algorithm, self.user, challenge.realm, self.pass, challenge.nonce, cnonce)\n  var ha2 = md5(method + ':' + path)\n  var digestResponse = qop\n    ? md5(ha1 + ':' + challenge.nonce + ':' + nc + ':' + cnonce + ':' + qop + ':' + ha2)\n    : md5(ha1 + ':' + challenge.nonce + ':' + ha2)\n  var authValues = {\n    username: self.user,\n    realm: challenge.realm,\n    nonce: challenge.nonce,\n    uri: path,\n    qop: qop,\n    response: digestResponse,\n    nc: nc,\n    cnonce: cnonce,\n    algorithm: challenge.algorithm,\n    opaque: challenge.opaque\n  }\n\n  authHeader = []\n  for (var k in authValues) {\n    if (authValues[k]) {\n      if (k === 'qop' || k === 'nc' || k === 'algorithm') {\n        authHeader.push(k + '=' + authValues[k])\n      } else {\n        authHeader.push(k + '=\"' + authValues[k] + '\"')\n      }\n    }\n  }\n  authHeader = 'Digest ' + authHeader.join(', ')\n  self.sentAuth = true\n  return authHeader\n}\n\nAuth.prototype.onRequest = function (user, pass, sendImmediately, bearer) {\n  var self = this\n    , request = self.request\n\n  var authHeader\n  if (bearer === undefined && user === undefined) {\n    self.request.emit('error', new Error('no auth mechanism defined'))\n  } else if (bearer !== undefined) {\n    authHeader = self.bearer(bearer, sendImmediately)\n  } else {\n    authHeader = self.basic(user, pass, sendImmediately)\n  }\n  if (authHeader) {\n    request.setHeader('authorization', authHeader)\n  }\n}\n\nAuth.prototype.onResponse = function (response) {\n  var self = this\n    , request = self.request\n\n  if (!self.hasAuth || self.sentAuth) { return null }\n\n  var c = caseless(response.headers)\n\n  var authHeader = c.get('www-authenticate')\n  var authVerb = authHeader && authHeader.split(' ')[0].toLowerCase()\n  request.debug('reauth', authVerb)\n\n  switch (authVerb) {\n    case 'basic':\n      return self.basic(self.user, self.pass, true)\n\n    case 'bearer':\n      return self.bearer(self.bearerToken, true)\n\n    case 'digest':\n      return self.digest(request.method, request.path, authHeader)\n  }\n}\n\nexports.Auth = Auth\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/oauth.js":"'use strict'\n\nvar url = require('url')\n  , qs = require('qs')\n  , caseless = require('caseless')\n  , uuid = require('uuid')\n  , oauth = require('oauth-sign')\n  , crypto = require('crypto')\n  , Buffer = require('safe-buffer').Buffer\n\n\nfunction OAuth (request) {\n  this.request = request\n  this.params = null\n}\n\nOAuth.prototype.buildParams = function (_oauth, uri, method, query, form, qsLib) {\n  var oa = {}\n  for (var i in _oauth) {\n    oa['oauth_' + i] = _oauth[i]\n  }\n  if (!oa.oauth_version) {\n    oa.oauth_version = '1.0'\n  }\n  if (!oa.oauth_timestamp) {\n    oa.oauth_timestamp = Math.floor( Date.now() / 1000 ).toString()\n  }\n  if (!oa.oauth_nonce) {\n    oa.oauth_nonce = uuid().replace(/-/g, '')\n  }\n  if (!oa.oauth_signature_method) {\n    oa.oauth_signature_method = 'HMAC-SHA1'\n  }\n\n  var consumer_secret_or_private_key = oa.oauth_consumer_secret || oa.oauth_private_key\n  delete oa.oauth_consumer_secret\n  delete oa.oauth_private_key\n\n  var token_secret = oa.oauth_token_secret\n  delete oa.oauth_token_secret\n\n  var realm = oa.oauth_realm\n  delete oa.oauth_realm\n  delete oa.oauth_transport_method\n\n  var baseurl = uri.protocol + '//' + uri.host + uri.pathname\n  var params = qsLib.parse([].concat(query, form, qsLib.stringify(oa)).join('&'))\n\n  oa.oauth_signature = oauth.sign(\n    oa.oauth_signature_method,\n    method,\n    baseurl,\n    params,\n    consumer_secret_or_private_key,\n    token_secret)\n\n  if (realm) {\n    oa.realm = realm\n  }\n\n  return oa\n}\n\nOAuth.prototype.buildBodyHash = function(_oauth, body) {\n  if (['HMAC-SHA1', 'RSA-SHA1'].indexOf(_oauth.signature_method || 'HMAC-SHA1') < 0) {\n    this.request.emit('error', new Error('oauth: ' + _oauth.signature_method +\n      ' signature_method not supported with body_hash signing.'))\n  }\n\n  var shasum = crypto.createHash('sha1')\n  shasum.update(body || '')\n  var sha1 = shasum.digest('hex')\n\n  return Buffer.from(sha1).toString('base64')\n}\n\nOAuth.prototype.concatParams = function (oa, sep, wrap) {\n  wrap = wrap || ''\n\n  var params = Object.keys(oa).filter(function (i) {\n    return i !== 'realm' && i !== 'oauth_signature'\n  }).sort()\n\n  if (oa.realm) {\n    params.splice(0, 0, 'realm')\n  }\n  params.push('oauth_signature')\n\n  return params.map(function (i) {\n    return i + '=' + wrap + oauth.rfc3986(oa[i]) + wrap\n  }).join(sep)\n}\n\nOAuth.prototype.onRequest = function (_oauth) {\n  var self = this\n  self.params = _oauth\n\n  var uri = self.request.uri || {}\n    , method = self.request.method || ''\n    , headers = caseless(self.request.headers)\n    , body = self.request.body || ''\n    , qsLib = self.request.qsLib || qs\n\n  var form\n    , query\n    , contentType = headers.get('content-type') || ''\n    , formContentType = 'application/x-www-form-urlencoded'\n    , transport = _oauth.transport_method || 'header'\n\n  if (contentType.slice(0, formContentType.length) === formContentType) {\n    contentType = formContentType\n    form = body\n  }\n  if (uri.query) {\n    query = uri.query\n  }\n  if (transport === 'body' && (method !== 'POST' || contentType !== formContentType)) {\n    self.request.emit('error', new Error('oauth: transport_method of body requires POST ' +\n      'and content-type ' + formContentType))\n  }\n\n  if (!form && typeof _oauth.body_hash === 'boolean') {\n    _oauth.body_hash = self.buildBodyHash(_oauth, self.request.body.toString())\n  }\n\n  var oa = self.buildParams(_oauth, uri, method, query, form, qsLib)\n\n  switch (transport) {\n    case 'header':\n      self.request.setHeader('Authorization', 'OAuth ' + self.concatParams(oa, ',', '\"'))\n      break\n\n    case 'query':\n      var href = self.request.uri.href += (query ? '&' : '?') + self.concatParams(oa, '&')\n      self.request.uri = url.parse(href)\n      self.request.path = self.request.uri.path\n      break\n\n    case 'body':\n      self.request.body = (form ? form + '&' : '') + self.concatParams(oa, '&')\n      break\n\n    default:\n      self.request.emit('error', new Error('oauth: transport_method invalid'))\n  }\n}\n\nexports.OAuth = OAuth\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/oauth-sign/index.js":"var crypto = require('crypto')\n  , qs = require('querystring')\n  ;\n\nfunction sha1 (key, body) {\n  return crypto.createHmac('sha1', key).update(body).digest('base64')\n}\n\nfunction rsa (key, body) {\n  return crypto.createSign(\"RSA-SHA1\").update(body).sign(key, 'base64');\n}\n\nfunction rfc3986 (str) {\n  return encodeURIComponent(str)\n    .replace(/!/g,'%21')\n    .replace(/\\*/g,'%2A')\n    .replace(/\\(/g,'%28')\n    .replace(/\\)/g,'%29')\n    .replace(/'/g,'%27')\n    ;\n}\n\n// Maps object to bi-dimensional array\n// Converts { foo: 'A', bar: [ 'b', 'B' ]} to\n// [ ['foo', 'A'], ['bar', 'b'], ['bar', 'B'] ]\nfunction map (obj) {\n  var key, val, arr = []\n  for (key in obj) {\n    val = obj[key]\n    if (Array.isArray(val))\n      for (var i = 0; i < val.length; i++)\n        arr.push([key, val[i]])\n    else if (typeof val === \"object\")\n      for (var prop in val)\n        arr.push([key + '[' + prop + ']', val[prop]]);\n    else\n      arr.push([key, val])\n  }\n  return arr\n}\n\n// Compare function for sort\nfunction compare (a, b) {\n  return a > b ? 1 : a < b ? -1 : 0\n}\n\nfunction generateBase (httpMethod, base_uri, params) {\n  // adapted from https://dev.twitter.com/docs/auth/oauth and \n  // https://dev.twitter.com/docs/auth/creating-signature\n\n  // Parameter normalization\n  // http://tools.ietf.org/html/rfc5849#section-3.4.1.3.2\n  var normalized = map(params)\n  // 1.  First, the name and value of each parameter are encoded\n  .map(function (p) {\n    return [ rfc3986(p[0]), rfc3986(p[1] || '') ]\n  })\n  // 2.  The parameters are sorted by name, using ascending byte value\n  //     ordering.  If two or more parameters share the same name, they\n  //     are sorted by their value.\n  .sort(function (a, b) {\n    return compare(a[0], b[0]) || compare(a[1], b[1])\n  })\n  // 3.  The name of each parameter is concatenated to its corresponding\n  //     value using an \"=\" character (ASCII code 61) as a separator, even\n  //     if the value is empty.\n  .map(function (p) { return p.join('=') })\n   // 4.  The sorted name/value pairs are concatenated together into a\n   //     single string by using an \"&\" character (ASCII code 38) as\n   //     separator.\n  .join('&')\n\n  var base = [\n    rfc3986(httpMethod ? httpMethod.toUpperCase() : 'GET'),\n    rfc3986(base_uri),\n    rfc3986(normalized)\n  ].join('&')\n\n  return base\n}\n\nfunction hmacsign (httpMethod, base_uri, params, consumer_secret, token_secret) {\n  var base = generateBase(httpMethod, base_uri, params)\n  var key = [\n    consumer_secret || '',\n    token_secret || ''\n  ].map(rfc3986).join('&')\n\n  return sha1(key, base)\n}\n\nfunction rsasign (httpMethod, base_uri, params, private_key, token_secret) {\n  var base = generateBase(httpMethod, base_uri, params)\n  var key = private_key || ''\n\n  return rsa(key, base)\n}\n\nfunction plaintext (consumer_secret, token_secret) {\n  var key = [\n    consumer_secret || '',\n    token_secret || ''\n  ].map(rfc3986).join('&')\n\n  return key\n}\n\nfunction sign (signMethod, httpMethod, base_uri, params, consumer_secret, token_secret) {\n  var method\n  var skipArgs = 1\n\n  switch (signMethod) {\n    case 'RSA-SHA1':\n      method = rsasign\n      break\n    case 'HMAC-SHA1':\n      method = hmacsign\n      break\n    case 'PLAINTEXT':\n      method = plaintext\n      skipArgs = 4\n      break\n    default:\n     throw new Error(\"Signature method not supported: \" + signMethod)\n  }\n\n  return method.apply(null, [].slice.call(arguments, skipArgs))\n}\n\nexports.hmacsign = hmacsign\nexports.rsasign = rsasign\nexports.plaintext = plaintext\nexports.sign = sign\nexports.rfc3986 = rfc3986\nexports.generateBase = generateBase\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/multipart.js":"'use strict'\n\nvar uuid = require('uuid')\n  , CombinedStream = require('combined-stream')\n  , isstream = require('isstream')\n  , Buffer = require('safe-buffer').Buffer\n\n\nfunction Multipart (request) {\n  this.request = request\n  this.boundary = uuid()\n  this.chunked = false\n  this.body = null\n}\n\nMultipart.prototype.isChunked = function (options) {\n  var self = this\n    , chunked = false\n    , parts = options.data || options\n\n  if (!parts.forEach) {\n    self.request.emit('error', new Error('Argument error, options.multipart.'))\n  }\n\n  if (options.chunked !== undefined) {\n    chunked = options.chunked\n  }\n\n  if (self.request.getHeader('transfer-encoding') === 'chunked') {\n    chunked = true\n  }\n\n  if (!chunked) {\n    parts.forEach(function (part) {\n      if (typeof part.body === 'undefined') {\n        self.request.emit('error', new Error('Body attribute missing in multipart.'))\n      }\n      if (isstream(part.body)) {\n        chunked = true\n      }\n    })\n  }\n\n  return chunked\n}\n\nMultipart.prototype.setHeaders = function (chunked) {\n  var self = this\n\n  if (chunked && !self.request.hasHeader('transfer-encoding')) {\n    self.request.setHeader('transfer-encoding', 'chunked')\n  }\n\n  var header = self.request.getHeader('content-type')\n\n  if (!header || header.indexOf('multipart') === -1) {\n    self.request.setHeader('content-type', 'multipart/related; boundary=' + self.boundary)\n  } else {\n    if (header.indexOf('boundary') !== -1) {\n      self.boundary = header.replace(/.*boundary=([^\\s;]+).*/, '$1')\n    } else {\n      self.request.setHeader('content-type', header + '; boundary=' + self.boundary)\n    }\n  }\n}\n\nMultipart.prototype.build = function (parts, chunked) {\n  var self = this\n  var body = chunked ? new CombinedStream() : []\n\n  function add (part) {\n    if (typeof part === 'number') {\n      part = part.toString()\n    }\n    return chunked ? body.append(part) : body.push(Buffer.from(part))\n  }\n\n  if (self.request.preambleCRLF) {\n    add('\\r\\n')\n  }\n\n  parts.forEach(function (part) {\n    var preamble = '--' + self.boundary + '\\r\\n'\n    Object.keys(part).forEach(function (key) {\n      if (key === 'body') { return }\n      preamble += key + ': ' + part[key] + '\\r\\n'\n    })\n    preamble += '\\r\\n'\n    add(preamble)\n    add(part.body)\n    add('\\r\\n')\n  })\n  add('--' + self.boundary + '--')\n\n  if (self.request.postambleCRLF) {\n    add('\\r\\n')\n  }\n\n  return body\n}\n\nMultipart.prototype.onRequest = function (options) {\n  var self = this\n\n  var chunked = self.isChunked(options)\n    , parts = options.data || options\n\n  self.setHeaders(chunked)\n  self.chunked = chunked\n  self.body = self.build(parts, chunked)\n}\n\nexports.Multipart = Multipart\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/redirect.js":"'use strict'\n\nvar url = require('url')\nvar isUrl = /^https?:/\n\nfunction Redirect (request) {\n  this.request = request\n  this.followRedirect = true\n  this.followRedirects = true\n  this.followAllRedirects = false\n  this.followOriginalHttpMethod = false\n  this.allowRedirect = function () {return true}\n  this.maxRedirects = 10\n  this.redirects = []\n  this.redirectsFollowed = 0\n  this.removeRefererHeader = false\n}\n\nRedirect.prototype.onRequest = function (options) {\n  var self = this\n\n  if (options.maxRedirects !== undefined) {\n    self.maxRedirects = options.maxRedirects\n  }\n  if (typeof options.followRedirect === 'function') {\n    self.allowRedirect = options.followRedirect\n  }\n  if (options.followRedirect !== undefined) {\n    self.followRedirects = !!options.followRedirect\n  }\n  if (options.followAllRedirects !== undefined) {\n    self.followAllRedirects = options.followAllRedirects\n  }\n  if (self.followRedirects || self.followAllRedirects) {\n    self.redirects = self.redirects || []\n  }\n  if (options.removeRefererHeader !== undefined) {\n    self.removeRefererHeader = options.removeRefererHeader\n  }\n  if (options.followOriginalHttpMethod !== undefined) {\n    self.followOriginalHttpMethod = options.followOriginalHttpMethod\n  }\n}\n\nRedirect.prototype.redirectTo = function (response) {\n  var self = this\n    , request = self.request\n\n  var redirectTo = null\n  if (response.statusCode >= 300 && response.statusCode < 400 && response.caseless.has('location')) {\n    var location = response.caseless.get('location')\n    request.debug('redirect', location)\n\n    if (self.followAllRedirects) {\n      redirectTo = location\n    } else if (self.followRedirects) {\n      switch (request.method) {\n        case 'PATCH':\n        case 'PUT':\n        case 'POST':\n        case 'DELETE':\n          // Do not follow redirects\n          break\n        default:\n          redirectTo = location\n          break\n      }\n    }\n  } else if (response.statusCode === 401) {\n    var authHeader = request._auth.onResponse(response)\n    if (authHeader) {\n      request.setHeader('authorization', authHeader)\n      redirectTo = request.uri\n    }\n  }\n  return redirectTo\n}\n\nRedirect.prototype.onResponse = function (response) {\n  var self = this\n    , request = self.request\n\n  var redirectTo = self.redirectTo(response)\n  if (!redirectTo || !self.allowRedirect.call(request, response)) {\n    return false\n  }\n\n  request.debug('redirect to', redirectTo)\n\n  // ignore any potential response body.  it cannot possibly be useful\n  // to us at this point.\n  // response.resume should be defined, but check anyway before calling. Workaround for browserify.\n  if (response.resume) {\n    response.resume()\n  }\n\n  if (self.redirectsFollowed >= self.maxRedirects) {\n    request.emit('error', new Error('Exceeded maxRedirects. Probably stuck in a redirect loop ' + request.uri.href))\n    return false\n  }\n  self.redirectsFollowed += 1\n\n  if (!isUrl.test(redirectTo)) {\n    redirectTo = url.resolve(request.uri.href, redirectTo)\n  }\n\n  var uriPrev = request.uri\n  request.uri = url.parse(redirectTo)\n\n  // handle the case where we change protocol from https to http or vice versa\n  if (request.uri.protocol !== uriPrev.protocol) {\n    delete request.agent\n  }\n\n  self.redirects.push(\n    { statusCode : response.statusCode\n    , redirectUri: redirectTo\n    }\n  )\n  if (self.followAllRedirects && request.method !== 'HEAD'\n    && response.statusCode !== 401 && response.statusCode !== 307) {\n    request.method = self.followOriginalHttpMethod ? request.method : 'GET'\n  }\n  // request.method = 'GET' // Force all redirects to use GET || commented out fixes #215\n  delete request.src\n  delete request.req\n  delete request._started\n  if (response.statusCode !== 401 && response.statusCode !== 307) {\n    // Remove parameters from the previous response, unless this is the second request\n    // for a server that requires digest authentication.\n    delete request.body\n    delete request._form\n    if (request.headers) {\n      request.removeHeader('host')\n      request.removeHeader('content-type')\n      request.removeHeader('content-length')\n      if (request.uri.hostname !== request.originalHost.split(':')[0]) {\n        // Remove authorization if changing hostnames (but not if just\n        // changing ports or protocols).  This matches the behavior of curl:\n        // https://github.com/bagder/curl/blob/6beb0eee/lib/http.c#L710\n        request.removeHeader('authorization')\n      }\n    }\n  }\n\n  if (!self.removeRefererHeader) {\n    request.setHeader('referer', uriPrev.href)\n  }\n\n  request.emit('redirect')\n\n  request.init()\n\n  return true\n}\n\nexports.Redirect = Redirect\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/lib/tunnel.js":"'use strict'\n\nvar url = require('url')\n  , tunnel = require('tunnel-agent')\n\nvar defaultProxyHeaderWhiteList = [\n  'accept',\n  'accept-charset',\n  'accept-encoding',\n  'accept-language',\n  'accept-ranges',\n  'cache-control',\n  'content-encoding',\n  'content-language',\n  'content-location',\n  'content-md5',\n  'content-range',\n  'content-type',\n  'connection',\n  'date',\n  'expect',\n  'max-forwards',\n  'pragma',\n  'referer',\n  'te',\n  'user-agent',\n  'via'\n]\n\nvar defaultProxyHeaderExclusiveList = [\n  'proxy-authorization'\n]\n\nfunction constructProxyHost(uriObject) {\n  var port = uriObject.port\n    , protocol = uriObject.protocol\n    , proxyHost = uriObject.hostname + ':'\n\n  if (port) {\n    proxyHost += port\n  } else if (protocol === 'https:') {\n    proxyHost += '443'\n  } else {\n    proxyHost += '80'\n  }\n\n  return proxyHost\n}\n\nfunction constructProxyHeaderWhiteList(headers, proxyHeaderWhiteList) {\n  var whiteList = proxyHeaderWhiteList\n    .reduce(function (set, header) {\n      set[header.toLowerCase()] = true\n      return set\n    }, {})\n\n  return Object.keys(headers)\n    .filter(function (header) {\n      return whiteList[header.toLowerCase()]\n    })\n    .reduce(function (set, header) {\n      set[header] = headers[header]\n      return set\n    }, {})\n}\n\nfunction constructTunnelOptions (request, proxyHeaders) {\n  var proxy = request.proxy\n\n  var tunnelOptions = {\n    proxy : {\n      host      : proxy.hostname,\n      port      : +proxy.port,\n      proxyAuth : proxy.auth,\n      headers   : proxyHeaders\n    },\n    headers            : request.headers,\n    ca                 : request.ca,\n    cert               : request.cert,\n    key                : request.key,\n    passphrase         : request.passphrase,\n    pfx                : request.pfx,\n    ciphers            : request.ciphers,\n    rejectUnauthorized : request.rejectUnauthorized,\n    secureOptions      : request.secureOptions,\n    secureProtocol     : request.secureProtocol\n  }\n\n  return tunnelOptions\n}\n\nfunction constructTunnelFnName(uri, proxy) {\n  var uriProtocol = (uri.protocol === 'https:' ? 'https' : 'http')\n  var proxyProtocol = (proxy.protocol === 'https:' ? 'Https' : 'Http')\n  return [uriProtocol, proxyProtocol].join('Over')\n}\n\nfunction getTunnelFn(request) {\n  var uri = request.uri\n  var proxy = request.proxy\n  var tunnelFnName = constructTunnelFnName(uri, proxy)\n  return tunnel[tunnelFnName]\n}\n\n\nfunction Tunnel (request) {\n  this.request = request\n  this.proxyHeaderWhiteList = defaultProxyHeaderWhiteList\n  this.proxyHeaderExclusiveList = []\n  if (typeof request.tunnel !== 'undefined') {\n    this.tunnelOverride = request.tunnel\n  }\n}\n\nTunnel.prototype.isEnabled = function () {\n  var self = this\n    , request = self.request\n  // Tunnel HTTPS by default. Allow the user to override this setting.\n\n  // If self.tunnelOverride is set (the user specified a value), use it.\n  if (typeof self.tunnelOverride !== 'undefined') {\n    return self.tunnelOverride\n  }\n\n  // If the destination is HTTPS, tunnel.\n  if (request.uri.protocol === 'https:') {\n    return true\n  }\n\n  // Otherwise, do not use tunnel.\n  return false\n}\n\nTunnel.prototype.setup = function (options) {\n  var self = this\n    , request = self.request\n\n  options = options || {}\n\n  if (typeof request.proxy === 'string') {\n    request.proxy = url.parse(request.proxy)\n  }\n\n  if (!request.proxy || !request.tunnel) {\n    return false\n  }\n\n  // Setup Proxy Header Exclusive List and White List\n  if (options.proxyHeaderWhiteList) {\n    self.proxyHeaderWhiteList = options.proxyHeaderWhiteList\n  }\n  if (options.proxyHeaderExclusiveList) {\n    self.proxyHeaderExclusiveList = options.proxyHeaderExclusiveList\n  }\n\n  var proxyHeaderExclusiveList = self.proxyHeaderExclusiveList.concat(defaultProxyHeaderExclusiveList)\n  var proxyHeaderWhiteList = self.proxyHeaderWhiteList.concat(proxyHeaderExclusiveList)\n\n  // Setup Proxy Headers and Proxy Headers Host\n  // Only send the Proxy White Listed Header names\n  var proxyHeaders = constructProxyHeaderWhiteList(request.headers, proxyHeaderWhiteList)\n  proxyHeaders.host = constructProxyHost(request.uri)\n\n  proxyHeaderExclusiveList.forEach(request.removeHeader, request)\n\n  // Set Agent from Tunnel Data\n  var tunnelFn = getTunnelFn(request)\n  var tunnelOptions = constructTunnelOptions(request, proxyHeaders)\n  request.agent = tunnelFn(tunnelOptions)\n\n  return true\n}\n\nTunnel.defaultProxyHeaderWhiteList = defaultProxyHeaderWhiteList\nTunnel.defaultProxyHeaderExclusiveList = defaultProxyHeaderExclusiveList\nexports.Tunnel = Tunnel\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/tunnel-agent/index.js":"'use strict'\n\nvar net = require('net')\n  , tls = require('tls')\n  , http = require('http')\n  , https = require('https')\n  , events = require('events')\n  , assert = require('assert')\n  , util = require('util')\n  , Buffer = require('safe-buffer').Buffer\n  ;\n\nexports.httpOverHttp = httpOverHttp\nexports.httpsOverHttp = httpsOverHttp\nexports.httpOverHttps = httpOverHttps\nexports.httpsOverHttps = httpsOverHttps\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = http.request\n  return agent\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = http.request\n  agent.createSocket = createSecureSocket\n  agent.defaultPort = 443\n  return agent\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = https.request\n  return agent\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = https.request\n  agent.createSocket = createSecureSocket\n  agent.defaultPort = 443\n  return agent\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this\n  self.options = options || {}\n  self.proxyOptions = self.options.proxy || {}\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets\n  self.requests = []\n  self.sockets = []\n\n  self.on('free', function onFree(socket, host, port) {\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i]\n      if (pending.host === host && pending.port === port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1)\n        pending.request.onSocket(socket)\n        return\n      }\n    }\n    socket.destroy()\n    self.removeSocket(socket)\n  })\n}\nutil.inherits(TunnelingAgent, events.EventEmitter)\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, options) {\n  var self = this\n\n   // Legacy API: addRequest(req, host, port, path)\n  if (typeof options === 'string') {\n    options = {\n      host: options,\n      port: arguments[2],\n      path: arguments[3]\n    };\n  }\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push({host: options.host, port: options.port, request: req})\n    return\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createConnection({host: options.host, port: options.port, request: req})\n}\n\nTunnelingAgent.prototype.createConnection = function createConnection(pending) {\n  var self = this\n\n  self.createSocket(pending, function(socket) {\n    socket.on('free', onFree)\n    socket.on('close', onCloseOrRemove)\n    socket.on('agentRemove', onCloseOrRemove)\n    pending.request.onSocket(socket)\n\n    function onFree() {\n      self.emit('free', socket, pending.host, pending.port)\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket)\n      socket.removeListener('free', onFree)\n      socket.removeListener('close', onCloseOrRemove)\n      socket.removeListener('agentRemove', onCloseOrRemove)\n    }\n  })\n}\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this\n  var placeholder = {}\n  self.sockets.push(placeholder)\n\n  var connectOptions = mergeOptions({}, self.proxyOptions,\n    { method: 'CONNECT'\n    , path: options.host + ':' + options.port\n    , agent: false\n    }\n  )\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {}\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        Buffer.from(connectOptions.proxyAuth).toString('base64')\n  }\n\n  debug('making CONNECT request')\n  var connectReq = self.request(connectOptions)\n  connectReq.useChunkedEncodingByDefault = false // for v0.6\n  connectReq.once('response', onResponse) // for v0.6\n  connectReq.once('upgrade', onUpgrade)   // for v0.6\n  connectReq.once('connect', onConnect)   // for v0.7 or later\n  connectReq.once('error', onError)\n  connectReq.end()\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head)\n    })\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners()\n    socket.removeAllListeners()\n\n    if (res.statusCode === 200) {\n      assert.equal(head.length, 0)\n      debug('tunneling connection has established')\n      self.sockets[self.sockets.indexOf(placeholder)] = socket\n      cb(socket)\n    } else {\n      debug('tunneling socket could not be established, statusCode=%d', res.statusCode)\n      var error = new Error('tunneling socket could not be established, ' + 'statusCode=' + res.statusCode)\n      error.code = 'ECONNRESET'\n      options.request.emit('error', error)\n      self.removeSocket(placeholder)\n    }\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners()\n\n    debug('tunneling socket could not be established, cause=%s\\n', cause.message, cause.stack)\n    var error = new Error('tunneling socket could not be established, ' + 'cause=' + cause.message)\n    error.code = 'ECONNRESET'\n    options.request.emit('error', error)\n    self.removeSocket(placeholder)\n  }\n}\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) return\n\n  this.sockets.splice(pos, 1)\n\n  var pending = this.requests.shift()\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createConnection(pending)\n  }\n}\n\nfunction createSecureSocket(options, cb) {\n  var self = this\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, mergeOptions({}, self.options,\n      { servername: options.host\n      , socket: socket\n      }\n    ))\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket\n    cb(secureSocket)\n  })\n}\n\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i]\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides)\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j]\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k]\n        }\n      }\n    }\n  }\n  return target\n}\n\n\nvar debug\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments)\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0]\n    } else {\n      args.unshift('TUNNEL:')\n    }\n    console.error.apply(console, args)\n  }\n} else {\n  debug = function() {}\n}\nexports.debug = debug // for test\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/request/node_modules/performance-now/lib/performance-now.js":"// Generated by CoffeeScript 1.7.1\n(function() {\n  var getNanoSeconds, hrtime, loadTime;\n\n  if ((typeof performance !== \"undefined\" && performance !== null) && performance.now) {\n    module.exports = function() {\n      return performance.now();\n    };\n  } else if ((typeof process !== \"undefined\" && process !== null) && process.hrtime) {\n    module.exports = function() {\n      return (getNanoSeconds() - loadTime) / 1e6;\n    };\n    hrtime = process.hrtime;\n    getNanoSeconds = function() {\n      var hr;\n      hr = hrtime();\n      return hr[0] * 1e9 + hr[1];\n    };\n    loadTime = getNanoSeconds();\n  } else if (Date.now) {\n    module.exports = function() {\n      return Date.now() - loadTime;\n    };\n    loadTime = Date.now();\n  } else {\n    module.exports = function() {\n      return new Date().getTime() - loadTime;\n    };\n    loadTime = new Date().getTime();\n  }\n\n}).call(this);\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/doctor/get-latest-npm-version.js":"var log = require('npmlog')\nvar fetchPackageMetadata = require('../fetch-package-metadata')\n\nfunction getLatestNpmVersion (cb) {\n  var tracker = log.newItem('getLatestNpmVersion', 1)\n  tracker.info('getLatestNpmVersion', 'Getting npm package information')\n  fetchPackageMetadata('npm@latest', '.', {fullMetadata: true}, function (e, d) {\n    tracker.finish()\n    cb(e, d.version)\n  })\n}\n\nmodule.exports = getLatestNpmVersion\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/edit.js":"// npm edit <pkg>\n// open the package folder in the $EDITOR\n\nmodule.exports = edit\nedit.usage = 'npm edit <pkg>[@<version>]'\n\nedit.completion = require('./utils/completion/installed-shallow.js')\n\nvar npm = require('./npm.js')\nvar path = require('path')\nvar fs = require('graceful-fs')\nvar editor = require('editor')\nvar noProgressTillDone = require('./utils/no-progress-while-running').tillDone\n\nfunction edit (args, cb) {\n  var p = args[0]\n  if (args.length !== 1 || !p) return cb(edit.usage)\n  var e = npm.config.get('editor')\n  if (!e) {\n    return cb(new Error(\n      \"No editor set.  Set the 'editor' config, or $EDITOR environ.\"\n    ))\n  }\n  p = p.split('/')\n       .join('/node_modules/')\n       .replace(/(\\/node_modules)+/, '/node_modules')\n  var f = path.resolve(npm.dir, p)\n  fs.lstat(f, function (er) {\n    if (er) return cb(er)\n    editor(f, { editor: e }, noProgressTillDone(function (er) {\n      if (er) return cb(er)\n      npm.commands.rebuild(args, cb)\n    }))\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/completion/installed-shallow.js":"\nmodule.exports = installedShallow\n\nvar npm = require('../../npm.js')\nvar fs = require('graceful-fs')\nvar path = require('path')\nvar readJson = require('read-package-json')\nvar asyncMap = require('slide').asyncMap\n\nfunction installedShallow (opts, filter, cb) {\n  if (typeof cb !== 'function') {\n    cb = filter\n    filter = null\n  }\n  var conf = opts.conf\n  var args = conf.argv.remain\n  if (args.length > 3) return cb()\n  var local\n  var global\n  var localDir = npm.dir\n  var globalDir = npm.globalDir\n  if (npm.config.get('global')) {\n    local = []\n    next()\n  } else {\n    fs.readdir(localDir, function (er, pkgs) {\n      local = (pkgs || []).filter(function (p) {\n        return p.charAt(0) !== '.'\n      })\n      next()\n    })\n  }\n\n  fs.readdir(globalDir, function (er, pkgs) {\n    global = (pkgs || []).filter(function (p) {\n      return p.charAt(0) !== '.'\n    })\n    next()\n  })\n  function next () {\n    if (!local || !global) return\n    filterInstalled(local, global, filter, cb)\n  }\n}\n\nfunction filterInstalled (local, global, filter, cb) {\n  var fl\n  var fg\n\n  if (!filter) {\n    fl = local\n    fg = global\n    return next()\n  }\n\n  asyncMap(local, function (p, cb) {\n    readJson(path.join(npm.dir, p, 'package.json'), function (er, d) {\n      if (!d || !filter(d)) return cb(null, [])\n      return cb(null, d.name)\n    })\n  }, function (er, local) {\n    fl = local || []\n    next()\n  })\n\n  var globalDir = npm.globalDir\n  asyncMap(global, function (p, cb) {\n    readJson(path.join(globalDir, p, 'package.json'), function (er, d) {\n      if (!d || !filter(d)) return cb(null, [])\n      return cb(null, d.name)\n    })\n  }, function (er, global) {\n    fg = global || []\n    next()\n  })\n\n  function next () {\n    if (!fg || !fl) return\n    if (!npm.config.get('global')) {\n      fg = fg.map(function (g) {\n        return [g, '-g']\n      })\n    }\n    console.error('filtered', fl, fg)\n    return cb(null, fl.concat(fg))\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/explore.js":"// npm explore <pkg>[@<version>]\n// open a subshell to the package folder.\n\nmodule.exports = explore\nexplore.usage = 'npm explore <pkg> [ -- <cmd>]'\nexplore.completion = require('./utils/completion/installed-shallow.js')\n\nvar npm = require('./npm.js')\nvar spawn = require('./utils/spawn')\nvar path = require('path')\nvar fs = require('graceful-fs')\nvar isWindowsShell = require('./utils/is-windows-shell.js')\nvar escapeExecPath = require('./utils/escape-exec-path.js')\nvar escapeArg = require('./utils/escape-arg.js')\nvar output = require('./utils/output.js')\n\nfunction explore (args, cb) {\n  if (args.length < 1 || !args[0]) return cb(explore.usage)\n  var p = args.shift()\n\n  var cwd = path.resolve(npm.dir, p)\n  var opts = {cwd: cwd, stdio: 'inherit'}\n\n  var shellArgs = []\n  if (args) {\n    if (isWindowsShell) {\n      var execCmd = escapeExecPath(args.shift())\n      var execArgs = [execCmd].concat(args.map(escapeArg))\n      opts.windowsVerbatimArguments = true\n      shellArgs = ['/d', '/s', '/c'].concat(execArgs)\n    } else {\n      shellArgs.unshift('-c')\n      shellArgs = ['-c', args.map(escapeArg).join(' ').trim()]\n    }\n  }\n\n  var sh = npm.config.get('shell')\n  fs.stat(cwd, function (er, s) {\n    if (er || !s.isDirectory()) {\n      return cb(new Error(\n        \"It doesn't look like \" + p + ' is installed.'\n      ))\n    }\n\n    if (!shellArgs.length) {\n      output(\n        '\\nExploring ' + cwd + '\\n' +\n          \"Type 'exit' or ^D when finished\\n\"\n      )\n    }\n\n    var shell = spawn(sh, shellArgs, opts)\n    shell.on('close', function (er) {\n      // only fail if non-interactive.\n      if (!shellArgs.length) return cb()\n      cb(er)\n    })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/escape-exec-path.js":"'use strict'\nvar path = require('path')\nvar isWindowsShell = require('./is-windows-shell.js')\n\n/*\nEscape the name of an executable suitable for passing to the system shell.\n\nWindows is easy, wrap in double quotes and you're done, as there's no\nfacility to create files with quotes in their names.\n\nUnix-likes are a little more complicated, wrap in single quotes and escape\nany single quotes in the filename.\n*/\n\nmodule.exports = escapify\n\nfunction windowsQuotes (str) {\n  if (!/ /.test(str)) return str\n  return '\"' + str + '\"'\n}\n\nfunction escapify (str) {\n  if (isWindowsShell) {\n    return path.normalize(str).split(/\\\\/).map(windowsQuotes).join('\\\\')\n  } else if (/[^-_.~/\\w]/.test(str)) {\n    return \"'\" + str.replace(/'/g, \"'\\\"'\\\"'\") + \"'\"\n  } else {\n    return str\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/escape-arg.js":"'use strict'\nvar path = require('path')\nvar isWindowsShell = require('./is-windows-shell.js')\n\n/*\nEscape the name of an executable suitable for passing to the system shell.\n\nWindows is easy, wrap in double quotes and you're done, as there's no\nfacility to create files with quotes in their names.\n\nUnix-likes are a little more complicated, wrap in single quotes and escape\nany single quotes in the filename.\n*/\n\nmodule.exports = escapify\n\nfunction escapify (str) {\n  if (isWindowsShell) {\n    return '\"' + path.normalize(str) + '\"'\n  } else {\n    if (/[^-_.~/\\w]/.test(str)) {\n      return \"'\" + str.replace(/'/g, \"'\\\"'\\\"'\") + \"'\"\n    } else {\n      return str\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/get.js":"\nmodule.exports = get\n\nget.usage = 'npm get <key> <value> (See `npm config`)'\n\nvar npm = require('./npm.js')\n\nget.completion = npm.commands.config.completion\n\nfunction get (args, cb) {\n  npm.commands.config(['get'].concat(args), cb)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/help-search.js":"\nmodule.exports = helpSearch\n\nvar fs = require('graceful-fs')\nvar path = require('path')\nvar asyncMap = require('slide').asyncMap\nvar npm = require('./npm.js')\nvar glob = require('glob')\nvar color = require('ansicolors')\nvar output = require('./utils/output.js')\n\nhelpSearch.usage = 'npm help-search <text>'\n\nfunction helpSearch (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n  if (!args.length) return cb(helpSearch.usage)\n\n  var docPath = path.resolve(__dirname, '..', 'doc')\n  return glob(docPath + '/*/*.md', function (er, files) {\n    if (er) return cb(er)\n    readFiles(files, function (er, data) {\n      if (er) return cb(er)\n      searchFiles(args, data, function (er, results) {\n        if (er) return cb(er)\n        formatResults(args, results, cb)\n      })\n    })\n  })\n}\n\nfunction readFiles (files, cb) {\n  var res = {}\n  asyncMap(files, function (file, cb) {\n    fs.readFile(file, 'utf8', function (er, data) {\n      res[file] = data\n      return cb(er)\n    })\n  }, function (er) {\n    return cb(er, res)\n  })\n}\n\nfunction searchFiles (args, files, cb) {\n  var results = []\n  Object.keys(files).forEach(function (file) {\n    var data = files[file]\n\n    // skip if no matches at all\n    var match\n    for (var a = 0, l = args.length; a < l && !match; a++) {\n      match = data.toLowerCase().indexOf(args[a].toLowerCase()) !== -1\n    }\n    if (!match) return\n\n    var lines = data.split(/\\n+/)\n\n    // if a line has a search term, then skip it and the next line.\n    // if the next line has a search term, then skip all 3\n    // otherwise, set the line to null.  then remove the nulls.\n    l = lines.length\n    for (var i = 0; i < l; i++) {\n      var line = lines[i]\n      var nextLine = lines[i + 1]\n      var ll\n\n      match = false\n      if (nextLine) {\n        for (a = 0, ll = args.length; a < ll && !match; a++) {\n          match = nextLine.toLowerCase()\n                  .indexOf(args[a].toLowerCase()) !== -1\n        }\n        if (match) {\n          // skip over the next line, and the line after it.\n          i += 2\n          continue\n        }\n      }\n\n      match = false\n      for (a = 0, ll = args.length; a < ll && !match; a++) {\n        match = line.toLowerCase().indexOf(args[a].toLowerCase()) !== -1\n      }\n      if (match) {\n        // skip over the next line\n        i++\n        continue\n      }\n\n      lines[i] = null\n    }\n\n    // now squish any string of nulls into a single null\n    lines = lines.reduce(function (l, r) {\n      if (!(r === null && l[l.length - 1] === null)) l.push(r)\n      return l\n    }, [])\n\n    if (lines[lines.length - 1] === null) lines.pop()\n    if (lines[0] === null) lines.shift()\n\n    // now see how many args were found at all.\n    var found = {}\n    var totalHits = 0\n    lines.forEach(function (line) {\n      args.forEach(function (arg) {\n        var hit = (line || '').toLowerCase()\n                  .split(arg.toLowerCase()).length - 1\n        if (hit > 0) {\n          found[arg] = (found[arg] || 0) + hit\n          totalHits += hit\n        }\n      })\n    })\n\n    var cmd = 'npm help '\n    if (path.basename(path.dirname(file)) === 'api') {\n      cmd = 'npm apihelp '\n    }\n    cmd += path.basename(file, '.md').replace(/^npm-/, '')\n    results.push({\n      file: file,\n      cmd: cmd,\n      lines: lines,\n      found: Object.keys(found),\n      hits: found,\n      totalHits: totalHits\n    })\n  })\n\n  // if only one result, then just show that help section.\n  if (results.length === 1) {\n    return npm.commands.help([results[0].file.replace(/\\.md$/, '')], cb)\n  }\n\n  if (results.length === 0) {\n    output('No results for ' + args.map(JSON.stringify).join(' '))\n    return cb()\n  }\n\n  // sort results by number of results found, then by number of hits\n  // then by number of matching lines\n  results = results.sort(function (a, b) {\n    return a.found.length > b.found.length ? -1\n         : a.found.length < b.found.length ? 1\n         : a.totalHits > b.totalHits ? -1\n         : a.totalHits < b.totalHits ? 1\n         : a.lines.length > b.lines.length ? -1\n         : a.lines.length < b.lines.length ? 1\n         : 0\n  })\n\n  cb(null, results)\n}\n\nfunction formatResults (args, results, cb) {\n  if (!results) return cb(null)\n\n  var cols = Math.min(process.stdout.columns || Infinity, 80) + 1\n\n  var out = results.map(function (res) {\n    var out = res.cmd\n    var r = Object.keys(res.hits)\n      .map(function (k) {\n        return k + ':' + res.hits[k]\n      }).sort(function (a, b) {\n        return a > b ? 1 : -1\n      }).join(' ')\n\n    out += ((new Array(Math.max(1, cols - out.length - r.length)))\n             .join(' ')) + r\n\n    if (!npm.config.get('long')) return out\n\n    out = '\\n\\n' + out + '\\n' +\n      (new Array(cols)).join('') + '\\n' +\n      res.lines.map(function (line, i) {\n        if (line === null || i > 3) return ''\n        for (var out = line, a = 0, l = args.length; a < l; a++) {\n          var finder = out.toLowerCase().split(args[a].toLowerCase())\n          var newOut = ''\n          var p = 0\n\n          finder.forEach(function (f) {\n            newOut += out.substr(p, f.length)\n\n            var hilit = out.substr(p + f.length, args[a].length)\n            if (npm.color) hilit = color.bgBlack(color.red(hilit))\n            newOut += hilit\n\n            p += f.length + args[a].length\n          })\n        }\n\n        return newOut\n      }).join('\\n').trim()\n    return out\n  }).join('\\n')\n\n  if (results.length && !npm.config.get('long')) {\n    out = 'Top hits for ' + (args.map(JSON.stringify).join(' ')) + '\\n' +\n          (new Array(cols)).join('') + '\\n' +\n          out + '\\n' +\n          (new Array(cols)).join('') + '\\n' +\n          '(run with -l or --long to see more context)'\n  }\n\n  output(out.trim())\n  cb(null, results)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/help.js":"\nmodule.exports = help\n\nhelp.completion = function (opts, cb) {\n  if (opts.conf.argv.remain.length > 2) return cb(null, [])\n  getSections(cb)\n}\n\nvar path = require('path')\nvar spawn = require('./utils/spawn')\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar opener = require('opener')\nvar glob = require('glob')\nvar cmdList = require('./config/cmd-list').cmdList\nvar shorthands = require('./config/cmd-list').shorthands\nvar commands = cmdList.concat(Object.keys(shorthands))\nvar output = require('./utils/output.js')\n\nfunction help (args, cb) {\n  var argv = npm.config.get('argv').cooked\n\n  var argnum = 0\n  if (args.length === 2 && ~~args[0]) {\n    argnum = ~~args.shift()\n  }\n\n  // npm help foo bar baz: search topics\n  if (args.length > 1 && args[0]) {\n    return npm.commands['help-search'](args, argnum, cb)\n  }\n\n  var section = npm.deref(args[0]) || args[0]\n\n  // npm help <noargs>:  show basic usage\n  if (!section) {\n    var valid = argv[0] === 'help' ? 0 : 1\n    return npmUsage(valid, cb)\n  }\n\n  // npm <cmd> -h: show command usage\n  if (npm.config.get('usage') &&\n      npm.commands[section] &&\n      npm.commands[section].usage) {\n    npm.config.set('loglevel', 'silent')\n    log.level = 'silent'\n    output(npm.commands[section].usage)\n    return cb()\n  }\n\n  // npm apihelp <section>: Prefer section 3 over section 1\n  var apihelp = argv.length && argv[0].indexOf('api') !== -1\n  var pref = apihelp ? [3, 1, 5, 7] : [1, 3, 5, 7]\n  if (argnum) {\n    pref = [ argnum ].concat(pref.filter(function (n) {\n      return n !== argnum\n    }))\n  }\n\n  // npm help <section>: Try to find the path\n  var manroot = path.resolve(__dirname, '..', 'man')\n\n  // legacy\n  if (section === 'global') section = 'folders'\n  else if (section === 'json') section = 'package.json'\n\n  // find either /section.n or /npm-section.n\n  // The glob is used in the glob.  The regexp is used much\n  // further down.  Globs and regexps are different\n  var compextglob = '.+(gz|bz2|lzma|[FYzZ]|xz)'\n  var compextre = '\\\\.(gz|bz2|lzma|[FYzZ]|xz)$'\n  var f = '+(npm-' + section + '|' + section + ').[0-9]?(' + compextglob + ')'\n  return glob(manroot + '/*/' + f, function (er, mans) {\n    if (er) return cb(er)\n\n    if (!mans.length) return npm.commands['help-search'](args, cb)\n\n    mans = mans.map(function (man) {\n      var ext = path.extname(man)\n      if (man.match(new RegExp(compextre))) man = path.basename(man, ext)\n\n      return man\n    })\n\n    viewMan(pickMan(mans, pref), cb)\n  })\n}\n\nfunction pickMan (mans, pref_) {\n  var nre = /([0-9]+)$/\n  var pref = {}\n  pref_.forEach(function (sect, i) {\n    pref[sect] = i\n  })\n  mans = mans.sort(function (a, b) {\n    var an = a.match(nre)[1]\n    var bn = b.match(nre)[1]\n    return an === bn ? (a > b ? -1 : 1)\n         : pref[an] < pref[bn] ? -1\n         : 1\n  })\n  return mans[0]\n}\n\nfunction viewMan (man, cb) {\n  var nre = /([0-9]+)$/\n  var num = man.match(nre)[1]\n  var section = path.basename(man, '.' + num)\n\n  // at this point, we know that the specified man page exists\n  var manpath = path.join(__dirname, '..', 'man')\n  var env = {}\n  Object.keys(process.env).forEach(function (i) {\n    env[i] = process.env[i]\n  })\n  env.MANPATH = manpath\n  var viewer = npm.config.get('viewer')\n\n  var conf\n  switch (viewer) {\n    case 'woman':\n      var a = ['-e', '(woman-find-file \\'' + man + '\\')']\n      conf = { env: env, stdio: 'inherit' }\n      var woman = spawn('emacsclient', a, conf)\n      woman.on('close', cb)\n      break\n\n    case 'browser':\n      opener(htmlMan(man), { command: npm.config.get('browser') }, cb)\n      break\n\n    default:\n      conf = { env: env, stdio: 'inherit' }\n      var manProcess = spawn('man', [num, section], conf)\n      manProcess.on('close', cb)\n      break\n  }\n}\n\nfunction htmlMan (man) {\n  var sect = +man.match(/([0-9]+)$/)[1]\n  var f = path.basename(man).replace(/([0-9]+)$/, 'html')\n  switch (sect) {\n    case 1:\n      sect = 'cli'\n      break\n    case 3:\n      sect = 'api'\n      break\n    case 5:\n      sect = 'files'\n      break\n    case 7:\n      sect = 'misc'\n      break\n    default:\n      throw new Error('invalid man section: ' + sect)\n  }\n  return path.resolve(__dirname, '..', 'html', 'doc', sect, f)\n}\n\nfunction npmUsage (valid, cb) {\n  npm.config.set('loglevel', 'silent')\n  log.level = 'silent'\n  output([\n    '\\nUsage: npm <command>',\n    '',\n    'where <command> is one of:',\n    npm.config.get('long') ? usages()\n        : '    ' + wrap(commands),\n    '',\n    'npm <cmd> -h     quick help on <cmd>',\n    'npm -l           display full usage info',\n    'npm help <term>  search for help on <term>',\n    'npm help npm     involved overview',\n    '',\n    'Specify configs in the ini-formatted file:',\n    '    ' + npm.config.get('userconfig'),\n    'or on the command line via: npm <command> --key value',\n    'Config info can be viewed via: npm help config',\n    '',\n    'npm@' + npm.version + ' ' + path.dirname(__dirname)\n  ].join('\\n'))\n  cb(valid)\n}\n\nfunction usages () {\n  // return a string of <cmd>: <usage>\n  var maxLen = 0\n  return Object.keys(npm.commands).filter(function (c) {\n    return c === npm.deref(c)\n  }).reduce(function (set, c) {\n    set.push([c, npm.commands[c].usage || ''])\n    maxLen = Math.max(maxLen, c.length)\n    return set\n  }, []).map(function (item) {\n    var c = item[0]\n    var usage = item[1]\n    return '\\n    ' +\n      c + (new Array(maxLen - c.length + 2).join(' ')) +\n      (usage.split('\\n').join('\\n' + (new Array(maxLen + 6).join(' '))))\n  }).join('\\n')\n}\n\nfunction wrap (arr) {\n  var out = ['']\n  var l = 0\n  var line\n\n  line = process.stdout.columns\n  if (!line) {\n    line = 60\n  } else {\n    line = Math.min(60, Math.max(line - 16, 24))\n  }\n\n  arr.sort(function (a, b) { return a < b ? -1 : 1 })\n    .forEach(function (c) {\n      if (out[l].length + c.length + 2 < line) {\n        out[l] += ', ' + c\n      } else {\n        out[l++] += ','\n        out[l] = c\n      }\n    })\n  return out.join('\\n    ').substr(2)\n}\n\nfunction getSections (cb) {\n  var g = path.resolve(__dirname, '../man/man[0-9]/*.[0-9]')\n  glob(g, function (er, files) {\n    if (er) return cb(er)\n\n    cb(null, Object.keys(files.reduce(function (acc, file) {\n      file = path.basename(file).replace(/\\.[0-9]+$/, '')\n      file = file.replace(/^npm-/, '')\n      acc[file] = true\n      return acc\n    }, { help: true })))\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/init.js":"// initialize a package.json file\n\nmodule.exports = init\n\nvar log = require('npmlog')\nvar npm = require('./npm.js')\nvar initJson = require('init-package-json')\nvar output = require('./utils/output.js')\nvar noProgressTillDone = require('./utils/no-progress-while-running').tillDone\n\ninit.usage = 'npm init [--force|-f|--yes|-y]'\n\nfunction init (args, cb) {\n  var dir = process.cwd()\n  log.pause()\n  var initFile = npm.config.get('init-module')\n  if (!initJson.yes(npm.config)) {\n    output([\n      'This utility will walk you through creating a package.json file.',\n      'It only covers the most common items, and tries to guess sensible defaults.',\n      '',\n      'See `npm help json` for definitive documentation on these fields',\n      'and exactly what they do.',\n      '',\n      'Use `npm install <pkg> --save` afterwards to install a package and',\n      'save it as a dependency in the package.json file.',\n      '',\n      'Press ^C at any time to quit.'\n    ].join('\\n'))\n  }\n  initJson(dir, initFile, npm.config, noProgressTillDone(function (er, data) {\n    log.resume()\n    log.silly('package data', data)\n    if (er && er.message === 'canceled') {\n      log.warn('init', 'canceled')\n      return cb(null, data)\n    }\n    log.info('init', 'written successfully')\n    cb(er, data)\n  }))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/init-package-json/init-package-json.js":"\nmodule.exports = init\nmodule.exports.yes = yes\n\nvar PZ = require('promzard').PromZard\nvar path = require('path')\nvar def = require.resolve('./default-input.js')\n\nvar fs = require('fs')\nvar semver = require('semver')\nvar read = require('read')\n\n// to validate the data object at the end as a worthwhile package\n// and assign default values for things.\n// readJson.extras(file, data, cb)\nvar readJson = require('read-package-json')\n\nfunction yes (conf) {\n  return !!(\n    conf.get('yes') || conf.get('y') ||\n    conf.get('force') || conf.get('f')\n  )\n}\n\nfunction init (dir, input, config, cb) {\n  if (typeof config === 'function')\n    cb = config, config = {}\n\n  // accept either a plain-jane object, or a config object\n  // with a \"get\" method.\n  if (typeof config.get !== 'function') {\n    var data = config\n    config = {\n      get: function (k) {\n        return data[k]\n      },\n      toJSON: function () {\n        return data\n      }\n    }\n  }\n\n  var packageFile = path.resolve(dir, 'package.json')\n  input = path.resolve(input)\n  var pkg\n  var ctx = { yes: yes(config) }\n\n  var es = readJson.extraSet\n  readJson.extraSet = es.filter(function (fn) {\n    return fn.name !== 'authors' && fn.name !== 'mans'\n  })\n  readJson(packageFile, function (er, d) {\n    readJson.extraSet = es\n\n    if (er) pkg = {}\n    else pkg = d\n\n    ctx.filename = packageFile\n    ctx.dirname = path.dirname(packageFile)\n    ctx.basename = path.basename(ctx.dirname)\n    if (!pkg.version || !semver.valid(pkg.version))\n      delete pkg.version\n\n    ctx.package = pkg\n    ctx.config = config || {}\n\n    // make sure that the input is valid.\n    // if not, use the default\n    var pz = new PZ(input, ctx)\n    pz.backupFile = def\n    pz.on('error', cb)\n    pz.on('data', function (data) {\n      Object.keys(data).forEach(function (k) {\n        if (data[k] !== undefined && data[k] !== null) pkg[k] = data[k]\n      })\n\n      // only do a few of these.\n      // no need for mans or contributors if they're in the files\n      var es = readJson.extraSet\n      readJson.extraSet = es.filter(function (fn) {\n        return fn.name !== 'authors' && fn.name !== 'mans'\n      })\n      readJson.extras(packageFile, pkg, function (er, pkg) {\n        readJson.extraSet = es\n        if (er) return cb(er, pkg)\n        pkg = unParsePeople(pkg)\n        // no need for the readme now.\n        delete pkg.readme\n        delete pkg.readmeFilename\n\n        // really don't want to have this lying around in the file\n        delete pkg._id\n\n        // ditto\n        delete pkg.gitHead\n\n        // if the repo is empty, remove it.\n        if (!pkg.repository)\n          delete pkg.repository\n\n        // readJson filters out empty descriptions, but init-package-json\n        // traditionally leaves them alone\n        if (!pkg.description)\n          pkg.description = data.description\n\n        var d = JSON.stringify(pkg, null, 2) + '\\n'\n        function write (yes) {\n          fs.writeFile(packageFile, d, 'utf8', function (er) {\n            if (!er && yes && !config.get('silent')) {\n              console.log('Wrote to %s:\\n\\n%s\\n', packageFile, d)\n            }\n            return cb(er, pkg)\n          })\n        }\n        if (ctx.yes) {\n          return write(true)\n        }\n        console.log('About to write to %s:\\n\\n%s\\n', packageFile, d)\n        read({prompt:'Is this ok? ', default: 'yes'}, function (er, ok) {\n          if (!ok || ok.toLowerCase().charAt(0) !== 'y') {\n            console.log('Aborted.')\n          } else {\n            return write()\n          }\n        })\n      })\n    })\n  })\n\n}\n\n// turn the objects into somewhat more humane strings.\nfunction unParsePeople (data) {\n  if (data.author) data.author = unParsePerson(data.author)\n  ;[\"maintainers\", \"contributors\"].forEach(function (set) {\n    if (!Array.isArray(data[set])) return;\n    data[set] = data[set].map(unParsePerson)\n  })\n  return data\n}\n\nfunction unParsePerson (person) {\n  if (typeof person === \"string\") return person\n  var name = person.name || \"\"\n  var u = person.url || person.web\n  var url = u ? (\" (\"+u+\")\") : \"\"\n  var e = person.email || person.mail\n  var email = e ? (\" <\"+e+\">\") : \"\"\n  return name+email+url\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/init-package-json/node_modules/promzard/promzard.js":"module.exports = promzard\npromzard.PromZard = PromZard\n\nvar fs = require('fs')\nvar vm = require('vm')\nvar util = require('util')\nvar files = {}\nvar crypto = require('crypto')\nvar EventEmitter = require('events').EventEmitter\nvar read = require('read')\n\nvar Module = require('module').Module\nvar path = require('path')\n\nfunction promzard (file, ctx, cb) {\n  if (typeof ctx === 'function') cb = ctx, ctx = null;\n  if (!ctx) ctx = {};\n  var pz = new PromZard(file, ctx)\n  pz.on('error', cb)\n  pz.on('data', function (data) {\n    cb(null, data)\n  })\n}\npromzard.fromBuffer = function (buf, ctx, cb) {\n  var filename = 0\n  do {\n    filename = '\\0' + Math.random();\n  } while (files[filename])\n  files[filename] = buf\n  var ret = promzard(filename, ctx, cb)\n  delete files[filename]\n  return ret\n}\n\nfunction PromZard (file, ctx) {\n  if (!(this instanceof PromZard))\n    return new PromZard(file, ctx)\n  EventEmitter.call(this)\n  this.file = file\n  this.ctx = ctx\n  this.unique = crypto.randomBytes(8).toString('hex')\n  this.load()\n}\n\nPromZard.prototype = Object.create(\n  EventEmitter.prototype,\n  { constructor: {\n      value: PromZard,\n      readable: true,\n      configurable: true,\n      writable: true,\n      enumerable: false } } )\n\nPromZard.prototype.load = function () {\n  if (files[this.file])\n    return this.loaded()\n\n  fs.readFile(this.file, 'utf8', function (er, d) {\n    if (er && this.backupFile) {\n      this.file = this.backupFile\n      delete this.backupFile\n      return this.load()\n    }\n    if (er)\n      return this.emit('error', this.error = er)\n    files[this.file] = d\n    this.loaded()\n  }.bind(this))\n}\n\nPromZard.prototype.loaded = function () {\n  this.ctx.prompt = this.makePrompt()\n  this.ctx.__filename = this.file\n  this.ctx.__dirname = path.dirname(this.file)\n  this.ctx.__basename = path.basename(this.file)\n  var mod = this.ctx.module = this.makeModule()\n  this.ctx.require = function (path) {\n    return mod.require(path)\n  }\n  this.ctx.require.resolve = function(path) {\n    return Module._resolveFilename(path, mod);\n  }\n  this.ctx.exports = mod.exports\n\n  this.script = this.wrap(files[this.file])\n  var fn = vm.runInThisContext(this.script, this.file)\n  var args = Object.keys(this.ctx).map(function (k) {\n    return this.ctx[k]\n  }.bind(this))\n  try { var res = fn.apply(this.ctx, args) }\n  catch (er) { this.emit('error', er) }\n  if (res &&\n      typeof res === 'object' &&\n      exports === mod.exports &&\n      Object.keys(exports).length === 1) {\n    this.result = res\n  } else {\n    this.result = mod.exports\n  }\n  this.walk()\n}\n\nPromZard.prototype.makeModule = function () {\n  var mod = new Module(this.file, module)\n  mod.loaded = true\n  mod.filename = this.file\n  mod.id = this.file\n  mod.paths = Module._nodeModulePaths(path.dirname(this.file))\n  return mod\n}\n\nPromZard.prototype.wrap = function (body) {\n  var s = '(function( %s ) { %s\\n })'\n  var args = Object.keys(this.ctx).join(', ')\n  return util.format(s, args, body)\n}\n\nPromZard.prototype.makePrompt = function () {\n  this.prompts = []\n  return prompt.bind(this)\n  function prompt () {\n    var p, d, t\n    for (var i = 0; i < arguments.length; i++) {\n      var a = arguments[i]\n      if (typeof a === 'string' && p)\n        d = a\n      else if (typeof a === 'string')\n        p = a\n      else if (typeof a === 'function')\n        t = a\n      else if (a && typeof a === 'object') {\n        p = a.prompt || p\n        d = a.default || d\n        t = a.transform || t\n      }\n    }\n\n    try { return this.unique + '-' + this.prompts.length }\n    finally { this.prompts.push([p, d, t]) }\n  }\n}\n\nPromZard.prototype.walk = function (o, cb) {\n  o = o || this.result\n  cb = cb || function (er, res) {\n    if (er)\n      return this.emit('error', this.error = er)\n    this.result = res\n    return this.emit('data', res)\n  }\n  cb = cb.bind(this)\n  var keys = Object.keys(o)\n  var i = 0\n  var len = keys.length\n\n  L.call(this)\n  function L () {\n    if (this.error)\n      return\n    while (i < len) {\n      var k = keys[i]\n      var v = o[k]\n      i++\n\n      if (v && typeof v === 'object') {\n        return this.walk(v, function (er, res) {\n          if (er) return cb(er)\n          o[k] = res\n          L.call(this)\n        }.bind(this))\n      } else if (v &&\n                 typeof v === 'string' &&\n                 v.indexOf(this.unique) === 0) {\n        var n = +v.substr(this.unique.length + 1)\n        var prompt = this.prompts[n]\n        if (isNaN(n) || !prompt)\n          continue\n\n        // default to the key\n        if (undefined === prompt[0])\n          prompt[0] = k\n\n        // default to the ctx value, if there is one\n        if (undefined === prompt[1])\n          prompt[1] = this.ctx[k]\n\n        return this.prompt(prompt, function (er, res) {\n          if (er) {\n            if (!er.notValid) {\n              return this.emit('error', this.error = er);\n            }\n            console.log(er.message)\n            i --\n            return L.call(this)\n          }\n          o[k] = res\n          L.call(this)\n        }.bind(this))\n      } else if (typeof v === 'function') {\n        try { return v.call(this.ctx, function (er, res) {\n          if (er)\n            return this.emit('error', this.error = er)\n          o[k] = res\n          // back up so that we process this one again.\n          // this is because it might return a prompt() call in the cb.\n          i --\n          L.call(this)\n        }.bind(this)) }\n        catch (er) { this.emit('error', er) }\n      }\n    }\n    // made it to the end of the loop, maybe\n    if (i >= len)\n      return cb(null, o)\n  }\n}\n\nPromZard.prototype.prompt = function (pdt, cb) {\n  var prompt = pdt[0]\n  var def = pdt[1]\n  var tx = pdt[2]\n\n  if (tx) {\n    cb = function (cb) { return function (er, data) {\n      try {\n        var res = tx(data)\n        if (!er && res instanceof Error && !!res.notValid) {\n          return cb(res, null)\n        }\n        return cb(er, res)\n      }\n      catch (er) { this.emit('error', er) }\n    }}(cb).bind(this)\n  }\n\n  read({ prompt: prompt + ':' , default: def }, cb)\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read/lib/read.js":"\nmodule.exports = read\n\nvar readline = require('readline')\nvar Mute = require('mute-stream')\n\nfunction read (opts, cb) {\n  if (opts.num) {\n    throw new Error('read() no longer accepts a char number limit')\n  }\n\n  if (typeof opts.default !== 'undefined' &&\n      typeof opts.default !== 'string' &&\n      typeof opts.default !== 'number') {\n    throw new Error('default value must be string or number')\n  }\n\n  var input = opts.input || process.stdin\n  var output = opts.output || process.stdout\n  var prompt = (opts.prompt || '').trim() + ' '\n  var silent = opts.silent\n  var editDef = false\n  var timeout = opts.timeout\n\n  var def = opts.default || ''\n  if (def) {\n    if (silent) {\n      prompt += '(<default hidden>) '\n    } else if (opts.edit) {\n      editDef = true\n    } else {\n      prompt += '(' + def + ') '\n    }\n  }\n  var terminal = !!(opts.terminal || output.isTTY)\n\n  var m = new Mute({ replace: opts.replace, prompt: prompt })\n  m.pipe(output, {end: false})\n  output = m\n  var rlOpts = { input: input, output: output, terminal: terminal }\n\n  if (process.version.match(/^v0\\.6/)) {\n    var rl = readline.createInterface(rlOpts.input, rlOpts.output)\n  } else {\n    var rl = readline.createInterface(rlOpts)\n  }\n\n\n  output.unmute()\n  rl.setPrompt(prompt)\n  rl.prompt()\n  if (silent) {\n    output.mute()\n  } else if (editDef) {\n    rl.line = def\n    rl.cursor = def.length\n    rl._refreshLine()\n  }\n\n  var called = false\n  rl.on('line', onLine)\n  rl.on('error', onError)\n\n  rl.on('SIGINT', function () {\n    rl.close()\n    onError(new Error('canceled'))\n  })\n\n  var timer\n  if (timeout) {\n    timer = setTimeout(function () {\n      onError(new Error('timed out'))\n    }, timeout)\n  }\n\n  function done () {\n    called = true\n    rl.close()\n\n    if (process.version.match(/^v0\\.6/)) {\n      rl.input.removeAllListeners('data')\n      rl.input.removeAllListeners('keypress')\n      rl.input.pause()\n    }\n\n    clearTimeout(timer)\n    output.mute()\n    output.end()\n  }\n\n  function onError (er) {\n    if (called) return\n    done()\n    return cb(er)\n  }\n\n  function onLine (line) {\n    if (called) return\n    if (silent && terminal) {\n      output.unmute()\n      output.write('\\r\\n')\n    }\n    done()\n    // truncate the \\n at the end.\n    line = line.replace(/\\r?\\n$/, '')\n    var isDefault = !!(editDef && line === def)\n    if (def && !line) {\n      isDefault = true\n      line = def\n    }\n    cb(null, line, isDefault)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read/node_modules/mute-stream/mute.js":"var Stream = require('stream')\n\nmodule.exports = MuteStream\n\n// var out = new MuteStream(process.stdout)\n// argument auto-pipes\nfunction MuteStream (opts) {\n  Stream.apply(this)\n  opts = opts || {}\n  this.writable = this.readable = true\n  this.muted = false\n  this.on('pipe', this._onpipe)\n  this.replace = opts.replace\n\n  // For readline-type situations\n  // This much at the start of a line being redrawn after a ctrl char\n  // is seen (such as backspace) won't be redrawn as the replacement\n  this._prompt = opts.prompt || null\n  this._hadControl = false\n}\n\nMuteStream.prototype = Object.create(Stream.prototype)\n\nObject.defineProperty(MuteStream.prototype, 'constructor', {\n  value: MuteStream,\n  enumerable: false\n})\n\nMuteStream.prototype.mute = function () {\n  this.muted = true\n}\n\nMuteStream.prototype.unmute = function () {\n  this.muted = false\n}\n\nObject.defineProperty(MuteStream.prototype, '_onpipe', {\n  value: onPipe,\n  enumerable: false,\n  writable: true,\n  configurable: true\n})\n\nfunction onPipe (src) {\n  this._src = src\n}\n\nObject.defineProperty(MuteStream.prototype, 'isTTY', {\n  get: getIsTTY,\n  set: setIsTTY,\n  enumerable: true,\n  configurable: true\n})\n\nfunction getIsTTY () {\n  return( (this._dest) ? this._dest.isTTY\n        : (this._src) ? this._src.isTTY\n        : false\n        )\n}\n\n// basically just get replace the getter/setter with a regular value\nfunction setIsTTY (isTTY) {\n  Object.defineProperty(this, 'isTTY', {\n    value: isTTY,\n    enumerable: true,\n    writable: true,\n    configurable: true\n  })\n}\n\nObject.defineProperty(MuteStream.prototype, 'rows', {\n  get: function () {\n    return( this._dest ? this._dest.rows\n          : this._src ? this._src.rows\n          : undefined )\n  }, enumerable: true, configurable: true })\n\nObject.defineProperty(MuteStream.prototype, 'columns', {\n  get: function () {\n    return( this._dest ? this._dest.columns\n          : this._src ? this._src.columns\n          : undefined )\n  }, enumerable: true, configurable: true })\n\n\nMuteStream.prototype.pipe = function (dest) {\n  this._dest = dest\n  return Stream.prototype.pipe.call(this, dest)\n}\n\nMuteStream.prototype.pause = function () {\n  if (this._src) return this._src.pause()\n}\n\nMuteStream.prototype.resume = function () {\n  if (this._src) return this._src.resume()\n}\n\nMuteStream.prototype.write = function (c) {\n  if (this.muted) {\n    if (!this.replace) return true\n    if (c.match(/^\\u001b/)) {\n      this._hadControl = true\n      return this.emit('data', c)\n    } else {\n      if (this._prompt && this._hadControl &&\n          c.indexOf(this._prompt) === 0) {\n        this._hadControl = false\n        this.emit('data', this._prompt)\n        c = c.substr(this._prompt.length)\n      }\n      c = c.toString().replace(/./g, this.replace)\n    }\n  }\n  this.emit('data', c)\n}\n\nMuteStream.prototype.end = function (c) {\n  if (this.muted) {\n    if (c && this.replace) {\n      c = c.toString().replace(/./g, this.replace)\n    } else {\n      c = null\n    }\n  }\n  if (c) this.emit('data', c)\n  this.emit('end')\n}\n\nfunction proxy (fn) { return function () {\n  var d = this._dest\n  var s = this._src\n  if (d && d[fn]) d[fn].apply(d, arguments)\n  if (s && s[fn]) s[fn].apply(s, arguments)\n}}\n\nMuteStream.prototype.destroy = proxy('destroy')\nMuteStream.prototype.destroySoon = proxy('destroySoon')\nMuteStream.prototype.close = proxy('close')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/link.js":"// link with no args: symlink the folder to the global location\n// link with package arg: symlink the global to the local\n\nvar npm = require('./npm.js')\nvar symlink = require('./utils/link.js')\nvar fs = require('graceful-fs')\nvar log = require('npmlog')\nvar asyncMap = require('slide').asyncMap\nvar chain = require('slide').chain\nvar path = require('path')\nvar build = require('./build.js')\nvar npa = require('npm-package-arg')\nvar usage = require('./utils/usage')\nvar output = require('./utils/output.js')\n\nmodule.exports = link\n\nlink.usage = usage(\n  'link',\n  'npm link (in package dir)' +\n  '\\nnpm link [<@scope>/]<pkg>[@<version>]'\n)\n\nlink.completion = function (opts, cb) {\n  var dir = npm.globalDir\n  fs.readdir(dir, function (er, files) {\n    cb(er, files.filter(function (f) {\n      return !f.match(/^[\\._-]/)\n    }))\n  })\n}\n\nfunction link (args, cb) {\n  if (process.platform === 'win32') {\n    var semver = require('semver')\n    if (!semver.gte(process.version, '0.7.9')) {\n      var msg = 'npm link not supported on windows prior to node 0.7.9'\n      var e = new Error(msg)\n      e.code = 'ENOTSUP'\n      e.errno = require('constants').ENOTSUP\n      return cb(e)\n    }\n  }\n\n  if (npm.config.get('global')) {\n    return cb(new Error(\n      'link should never be --global.\\n' +\n      'Please re-run this command with --local'\n    ))\n  }\n\n  if (args.length === 1 && args[0] === '.') args = []\n  if (args.length) return linkInstall(args, cb)\n  linkPkg(npm.prefix, cb)\n}\n\nfunction parentFolder (id, folder) {\n  if (id[0] === '@') {\n    return path.resolve(folder, '..', '..')\n  } else {\n    return path.resolve(folder, '..')\n  }\n}\n\nfunction linkInstall (pkgs, cb) {\n  asyncMap(pkgs, function (pkg, cb) {\n    var t = path.resolve(npm.globalDir, '..')\n    var pp = path.resolve(npm.globalDir, pkg)\n    var rp = null\n    var target = path.resolve(npm.dir, pkg)\n\n    function n (er, data) {\n      if (er) return cb(er, data)\n      // we want the ONE thing that was installed into the global dir\n      var installed = data.filter(function (info) {\n        var id = info[0]\n        var folder = info[1]\n        return parentFolder(id, folder) === npm.globalDir\n      })\n      var id = installed[0][0]\n      pp = installed[0][1]\n      var what = npa(id)\n      pkg = what.name\n      target = path.resolve(npm.dir, pkg)\n      next()\n    }\n\n    // if it's a folder, a random not-installed thing, or not a scoped package,\n    // then link or install it first\n    if (pkg[0] !== '@' && (pkg.indexOf('/') !== -1 || pkg.indexOf('\\\\') !== -1)) {\n      return fs.lstat(path.resolve(pkg), function (er, st) {\n        if (er || !st.isDirectory()) {\n          npm.commands.install(t, pkg, n)\n        } else {\n          rp = path.resolve(pkg)\n          linkPkg(rp, n)\n        }\n      })\n    }\n\n    fs.lstat(pp, function (er, st) {\n      if (er) {\n        rp = pp\n        return npm.commands.install(t, [pkg], n)\n      } else if (!st.isSymbolicLink()) {\n        rp = pp\n        next()\n      } else {\n        return fs.realpath(pp, function (er, real) {\n          if (er) log.warn('invalid symbolic link', pkg)\n          else rp = real\n          next()\n        })\n      }\n    })\n\n    function next () {\n      if (npm.config.get('dry-run')) return resultPrinter(pkg, pp, target, rp, cb)\n      chain(\n        [\n          [ function (cb) {\n            log.verbose('link', 'symlinking %s to %s', pp, target)\n            cb()\n          } ],\n          [symlink, pp, target],\n          // do not run any scripts\n          rp && [build, [target], npm.config.get('global'), build._noLC, true],\n          [resultPrinter, pkg, pp, target, rp]\n        ],\n        cb\n      )\n    }\n  }, cb)\n}\n\nfunction linkPkg (folder, cb_) {\n  var me = folder || npm.prefix\n  var readJson = require('read-package-json')\n\n  log.verbose('linkPkg', folder)\n\n  readJson(path.resolve(me, 'package.json'), function (er, d) {\n    function cb (er) {\n      return cb_(er, [[d && d._id, target, null, null]])\n    }\n    if (er) return cb(er)\n    if (!d.name) {\n      er = new Error('Package must have a name field to be linked')\n      return cb(er)\n    }\n    if (npm.config.get('dry-run')) return resultPrinter(path.basename(me), me, target, cb)\n    var target = path.resolve(npm.globalDir, d.name)\n    symlink(me, target, false, true, function (er) {\n      if (er) return cb(er)\n      log.verbose('link', 'build target', target)\n      // also install missing dependencies.\n      npm.commands.install(me, [], function (er) {\n        if (er) return cb(er)\n        // build the global stuff.  Don't run *any* scripts, because\n        // install command already will have done that.\n        build([target], true, build._noLC, true, function (er) {\n          if (er) return cb(er)\n          resultPrinter(path.basename(me), me, target, cb)\n        })\n      })\n    })\n  })\n}\n\nfunction resultPrinter (pkg, src, dest, rp, cb) {\n  if (typeof cb !== 'function') {\n    cb = rp\n    rp = null\n  }\n  var where = dest\n  rp = (rp || '').trim()\n  src = (src || '').trim()\n  // XXX If --json is set, then look up the data from the package.json\n  if (npm.config.get('parseable')) {\n    return parseableOutput(dest, rp || src, cb)\n  }\n  if (rp === src) rp = null\n  output(where + ' -> ' + src + (rp ? ' -> ' + rp : ''))\n  cb()\n}\n\nfunction parseableOutput (dest, rp, cb) {\n  // XXX this should match ls --parseable and install --parseable\n  // look up the data from package.json, format it the same way.\n  //\n  // link is always effectively 'long', since it doesn't help much to\n  // *just* print the target folder.\n  // However, we don't actually ever read the version number, so\n  // the second field is always blank.\n  output(dest + '::' + rp)\n  cb()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/link.js":"module.exports = link\nlink.ifExists = linkIfExists\n\nvar fs = require('graceful-fs')\nvar chain = require('slide').chain\nvar mkdir = require('mkdirp')\nvar rm = require('./gently-rm.js')\nvar path = require('path')\nvar npm = require('../npm.js')\n\nfunction linkIfExists (from, to, gently, cb) {\n  fs.stat(from, function (er) {\n    if (er) return cb()\n    fs.readlink(to, function (er, fromOnDisk) {\n      // if the link already exists and matches what we would do,\n      // we don't need to do anything\n      if (!er) {\n        var toDir = path.dirname(to)\n        var absoluteFrom = path.resolve(toDir, from)\n        var absoluteFromOnDisk = path.resolve(toDir, fromOnDisk)\n        if (absoluteFrom === absoluteFromOnDisk) return cb()\n      }\n      link(from, to, gently, cb)\n    })\n  })\n}\n\nfunction resolveIfSymlink (maybeSymlinkPath, cb) {\n  fs.lstat(maybeSymlinkPath, function (err, stat) {\n    if (err) return cb.apply(this, arguments)\n    if (!stat.isSymbolicLink()) return cb(null, maybeSymlinkPath)\n    fs.readlink(maybeSymlinkPath, cb)\n  })\n}\n\nfunction ensureFromIsNotSource (from, to, cb) {\n  resolveIfSymlink(from, function (err, fromDestination) {\n    if (err) return cb.apply(this, arguments)\n    if (path.resolve(path.dirname(from), fromDestination) === path.resolve(to)) {\n      return cb(new Error('Link target resolves to the same directory as link source: ' + to))\n    }\n    cb.apply(this, arguments)\n  })\n}\n\nfunction link (from, to, gently, abs, cb) {\n  if (typeof cb !== 'function') {\n    cb = abs\n    abs = false\n  }\n  if (typeof cb !== 'function') {\n    cb = gently\n    gently = null\n  }\n  if (npm.config.get('force')) gently = false\n\n  to = path.resolve(to)\n  var toDir = path.dirname(to)\n  var absTarget = path.resolve(toDir, from)\n  var relativeTarget = path.relative(toDir, absTarget)\n  var target = abs ? absTarget : relativeTarget\n\n  chain(\n    [\n      [ensureFromIsNotSource, absTarget, to],\n      [fs, 'stat', absTarget],\n      [rm, to, gently],\n      [mkdir, path.dirname(to)],\n      [fs, 'symlink', target, to, 'junction']\n    ],\n    cb\n  )\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/build.js":"// npm build command\n\n// everything about the installation after the creation of\n// the .npm/{name}/{version}/package folder.\n// linking the modules into the npm.root,\n// resolving dependencies, etc.\n\n// This runs AFTER install or link are completed.\n\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar chain = require('slide').chain\nvar fs = require('graceful-fs')\nvar path = require('path')\nvar lifecycle = require('./utils/lifecycle.js')\nvar readJson = require('read-package-json')\nvar link = require('./utils/link.js')\nvar linkIfExists = link.ifExists\nvar cmdShim = require('cmd-shim')\nvar cmdShimIfExists = cmdShim.ifExists\nvar asyncMap = require('slide').asyncMap\nvar ini = require('ini')\nvar writeFile = require('write-file-atomic')\nvar packageId = require('./utils/package-id.js')\nvar output = require('./utils/output.js')\n\nmodule.exports = build\nbuild.usage = 'npm build [<folder>]'\n\nbuild._didBuild = {}\nbuild._noLC = {}\nfunction build (args, global, didPre, didRB, cb) {\n  if (typeof cb !== 'function') {\n    cb = didRB\n    didRB = false\n  }\n  if (typeof cb !== 'function') {\n    cb = didPre\n    didPre = false\n  }\n  if (typeof cb !== 'function') {\n    cb = global\n    global = npm.config.get('global')\n  }\n\n  // it'd be nice to asyncMap these, but actually, doing them\n  // in parallel generally munges up the output from node-waf\n  var builder = build_(global, didPre, didRB)\n  chain(args.map(function (arg) {\n    return function (cb) {\n      builder(arg, cb)\n    }\n  }), cb)\n}\n\nfunction build_ (global, didPre, didRB) {\n  return function (folder, cb) {\n    folder = path.resolve(folder)\n    if (build._didBuild[folder]) log.info('build', 'already built', folder)\n    build._didBuild[folder] = true\n    log.info('build', folder)\n    readJson(path.resolve(folder, 'package.json'), function (er, pkg) {\n      if (er) return cb(er)\n      chain([\n        !didPre && [lifecycle, pkg, 'preinstall', folder],\n        [linkStuff, pkg, folder, global, didRB],\n        [writeBuiltinConf, pkg, folder],\n        didPre !== build._noLC && [lifecycle, pkg, 'install', folder],\n        didPre !== build._noLC && [lifecycle, pkg, 'postinstall', folder]\n      ],\n      cb)\n    })\n  }\n}\n\nvar writeBuiltinConf = build.writeBuiltinConf = function (pkg, folder, cb) {\n  // the builtin config is \"sticky\". Any time npm installs\n  // itself globally, it puts its builtin config file there\n  var parent = path.dirname(folder)\n  var dir = npm.globalDir\n\n  if (pkg.name !== 'npm' ||\n      !npm.config.get('global') ||\n      !npm.config.usingBuiltin ||\n      dir !== parent) {\n    return cb()\n  }\n\n  var data = ini.stringify(npm.config.sources.builtin.data)\n  writeFile(path.resolve(folder, 'npmrc'), data, cb)\n}\n\nvar linkStuff = build.linkStuff = function (pkg, folder, global, didRB, cb) {\n  // allow to opt out of linking binaries.\n  if (npm.config.get('bin-links') === false) return cb()\n\n  // if it's global, and folder is in {prefix}/node_modules,\n  // then bins are in {prefix}/bin\n  // otherwise, then bins are in folder/../.bin\n  var parent = pkg.name && pkg.name[0] === '@' ? path.dirname(path.dirname(folder)) : path.dirname(folder)\n  var gnm = global && npm.globalDir\n  var gtop = parent === gnm\n\n  log.info('linkStuff', packageId(pkg))\n  log.silly('linkStuff', packageId(pkg), 'has', parent, 'as its parent node_modules')\n  if (global) log.silly('linkStuff', packageId(pkg), 'is part of a global install')\n  if (gnm) log.silly('linkStuff', packageId(pkg), 'is installed into a global node_modules')\n  if (gtop) log.silly('linkStuff', packageId(pkg), 'is installed into the top-level global node_modules')\n\n  shouldWarn(pkg, folder, global, function () {\n    asyncMap(\n      [linkBins, linkMans, !didRB && rebuildBundles],\n      function (fn, cb) {\n        if (!fn) return cb()\n        log.verbose(fn.name, packageId(pkg))\n        fn(pkg, folder, parent, gtop, cb)\n      },\n      cb\n    )\n  })\n}\n\nfunction shouldWarn (pkg, folder, global, cb) {\n  var parent = path.dirname(folder)\n  var top = parent === npm.dir\n  var cwd = npm.localPrefix\n\n  readJson(path.resolve(cwd, 'package.json'), function (er, topPkg) {\n    if (er) return cb(er)\n\n    var linkedPkg = path.basename(cwd)\n    var currentPkg = path.basename(folder)\n\n    // current searched package is the linked package on first call\n    if (linkedPkg !== currentPkg) {\n      // don't generate a warning if it's listed in dependencies\n      if (Object.keys(topPkg.dependencies || {})\n          .concat(Object.keys(topPkg.devDependencies || {}))\n          .indexOf(currentPkg) === -1) {\n        if (top && pkg.preferGlobal && !global) {\n          log.warn('prefer global', packageId(pkg) + ' should be installed with -g')\n        }\n      }\n    }\n\n    cb()\n  })\n}\n\nfunction rebuildBundles (pkg, folder, parent, gtop, cb) {\n  if (!npm.config.get('rebuild-bundle')) return cb()\n\n  var deps = Object.keys(pkg.dependencies || {})\n             .concat(Object.keys(pkg.devDependencies || {}))\n  var bundles = pkg.bundleDependencies || pkg.bundledDependencies || []\n\n  fs.readdir(path.resolve(folder, 'node_modules'), function (er, files) {\n    // error means no bundles\n    if (er) return cb()\n\n    log.verbose('rebuildBundles', files)\n    // don't asyncMap these, because otherwise build script output\n    // gets interleaved and is impossible to read\n    chain(files.filter(function (file) {\n      // rebuild if:\n      // not a .folder, like .bin or .hooks\n      return !file.match(/^[\\._-]/) &&\n          // not some old 0.x style bundle\n          file.indexOf('@') === -1 &&\n          // either not a dep, or explicitly bundled\n          (deps.indexOf(file) === -1 || bundles.indexOf(file) !== -1)\n    }).map(function (file) {\n      file = path.resolve(folder, 'node_modules', file)\n      return function (cb) {\n        if (build._didBuild[file]) return cb()\n        log.verbose('rebuild bundle', file)\n        // if file is not a package dir, then don't do it.\n        fs.lstat(path.resolve(file, 'package.json'), function (er) {\n          if (er) return cb()\n          build_(false)(file, cb)\n        })\n      }\n    }), cb)\n  })\n}\n\nfunction linkBins (pkg, folder, parent, gtop, cb) {\n  if (!pkg.bin || !gtop && path.basename(parent) !== 'node_modules') {\n    return cb()\n  }\n  var binRoot = gtop ? npm.globalBin\n                     : path.resolve(parent, '.bin')\n  log.verbose('linkBins', [pkg.bin, binRoot, gtop])\n\n  asyncMap(Object.keys(pkg.bin), function (b, cb) {\n    linkBin(\n      path.resolve(folder, pkg.bin[b]),\n      path.resolve(binRoot, b),\n      gtop && folder,\n      function (er) {\n        if (er) return cb(er)\n        // bins should always be executable.\n        // XXX skip chmod on windows?\n        var src = path.resolve(folder, pkg.bin[b])\n        fs.chmod(src, npm.modes.exec, function (er) {\n          if (er && er.code === 'ENOENT' && npm.config.get('ignore-scripts')) {\n            return cb()\n          }\n          if (er || !gtop) return cb(er)\n          var dest = path.resolve(binRoot, b)\n          var out = npm.config.get('parseable')\n                  ? dest + '::' + src + ':BINFILE'\n                  : dest + ' -> ' + src\n          output(out)\n          cb()\n        })\n      }\n    )\n  }, cb)\n}\n\nfunction linkBin (from, to, gently, cb) {\n  if (process.platform !== 'win32') {\n    return linkIfExists(from, to, gently, cb)\n  } else {\n    return cmdShimIfExists(from, to, cb)\n  }\n}\n\nfunction linkMans (pkg, folder, parent, gtop, cb) {\n  if (!pkg.man || !gtop || process.platform === 'win32') return cb()\n\n  var manRoot = path.resolve(npm.config.get('prefix'), 'share', 'man')\n  log.verbose('linkMans', 'man files are', pkg.man, 'in', manRoot)\n\n  // make sure that the mans are unique.\n  // otherwise, if there are dupes, it'll fail with EEXIST\n  var set = pkg.man.reduce(function (acc, man) {\n    acc[path.basename(man)] = man\n    return acc\n  }, {})\n  pkg.man = pkg.man.filter(function (man) {\n    return set[path.basename(man)] === man\n  })\n\n  asyncMap(pkg.man, function (man, cb) {\n    if (typeof man !== 'string') return cb()\n    log.silly('linkMans', 'preparing to link', man)\n    var parseMan = man.match(/(.*\\.([0-9]+)(\\.gz)?)$/)\n    if (!parseMan) {\n      return cb(new Error(\n        man + ' is not a valid name for a man file.  ' +\n        'Man files must end with a number, ' +\n        'and optionally a .gz suffix if they are compressed.'\n      ))\n    }\n\n    var stem = parseMan[1]\n    var sxn = parseMan[2]\n    var bn = path.basename(stem)\n    var manSrc = path.resolve(folder, man)\n    var manDest = path.join(manRoot, 'man' + sxn, bn)\n\n    linkIfExists(manSrc, manDest, gtop && folder, cb)\n  }, cb)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/cmd-shim/index.js":"// On windows, create a .cmd file.\n// Read the #! in the file to see what it uses.  The vast majority\n// of the time, this will be either:\n// \"#!/usr/bin/env <prog> <args...>\"\n// or:\n// \"#!<prog> <args...>\"\n//\n// Write a binroot/pkg.bin + \".cmd\" file that has this line in it:\n// @<prog> <args...> %~dp0<target> %*\n\nmodule.exports = cmdShim\ncmdShim.ifExists = cmdShimIfExists\n\nvar fs = require(\"graceful-fs\")\n\nvar mkdir = require(\"mkdirp\")\n  , path = require(\"path\")\n  , shebangExpr = /^#\\!\\s*(?:\\/usr\\/bin\\/env)?\\s*([^ \\t]+)(.*)$/\n\nfunction cmdShimIfExists (from, to, cb) {\n  fs.stat(from, function (er) {\n    if (er) return cb()\n    cmdShim(from, to, cb)\n  })\n}\n\n// Try to unlink, but ignore errors.\n// Any problems will surface later.\nfunction rm (path, cb) {\n  fs.unlink(path, function(er) {\n    cb()\n  })\n}\n\nfunction cmdShim (from, to, cb) {\n  fs.stat(from, function (er, stat) {\n    if (er)\n      return cb(er)\n\n    cmdShim_(from, to, cb)\n  })\n}\n\nfunction cmdShim_ (from, to, cb) {\n  var then = times(2, next, cb)\n  rm(to, then)\n  rm(to + \".cmd\", then)\n\n  function next(er) {\n    writeShim(from, to, cb)\n  }\n}\n\nfunction writeShim (from, to, cb) {\n  // make a cmd file and a sh script\n  // First, check if the bin is a #! of some sort.\n  // If not, then assume it's something that'll be compiled, or some other\n  // sort of script, and just call it directly.\n  mkdir(path.dirname(to), function (er) {\n    if (er)\n      return cb(er)\n    fs.readFile(from, \"utf8\", function (er, data) {\n      if (er) return writeShim_(from, to, null, null, cb)\n      var firstLine = data.trim().split(/\\r*\\n/)[0]\n        , shebang = firstLine.match(shebangExpr)\n      if (!shebang) return writeShim_(from, to, null, null, cb)\n      var prog = shebang[1]\n        , args = shebang[2] || \"\"\n      return writeShim_(from, to, prog, args, cb)\n    })\n  })\n}\n\nfunction writeShim_ (from, to, prog, args, cb) {\n  var shTarget = path.relative(path.dirname(to), from)\n    , target = shTarget.split(\"/\").join(\"\\\\\")\n    , longProg\n    , shProg = prog && prog.split(\"\\\\\").join(\"/\")\n    , shLongProg\n  shTarget = shTarget.split(\"\\\\\").join(\"/\")\n  args = args || \"\"\n  if (!prog) {\n    prog = \"\\\"%~dp0\\\\\" + target + \"\\\"\"\n    shProg = \"\\\"$basedir/\" + shTarget + \"\\\"\"\n    args = \"\"\n    target = \"\"\n    shTarget = \"\"\n  } else {\n    longProg = \"\\\"%~dp0\\\\\" + prog + \".exe\\\"\"\n    shLongProg = \"\\\"$basedir/\" + prog + \"\\\"\"\n    target = \"\\\"%~dp0\\\\\" + target + \"\\\"\"\n    shTarget = \"\\\"$basedir/\" + shTarget + \"\\\"\"\n  }\n\n  // @IF EXIST \"%~dp0\\node.exe\" (\n  //   \"%~dp0\\node.exe\" \"%~dp0\\.\\node_modules\\npm\\bin\\npm-cli.js\" %*\n  // ) ELSE (\n  //   SETLOCAL\n  //   SET PATHEXT=%PATHEXT:;.JS;=;%\n  //   node \"%~dp0\\.\\node_modules\\npm\\bin\\npm-cli.js\" %*\n  // )\n  var cmd\n  if (longProg) {\n    cmd = \"@IF EXIST \" + longProg + \" (\\r\\n\"\n        + \"  \" + longProg + \" \" + args + \" \" + target + \" %*\\r\\n\"\n        + \") ELSE (\\r\\n\"\n        + \"  @SETLOCAL\\r\\n\"\n        + \"  @SET PATHEXT=%PATHEXT:;.JS;=;%\\r\\n\"\n        + \"  \" + prog + \" \" + args + \" \" + target + \" %*\\r\\n\"\n        + \")\"\n  } else {\n    cmd = \"@\" + prog + \" \" + args + \" \" + target + \" %*\\r\\n\"\n  }\n\n  // #!/bin/sh\n  // basedir=`dirname \"$0\"`\n  //\n  // case `uname` in\n  //     *CYGWIN*) basedir=`cygpath -w \"$basedir\"`;;\n  // esac\n  //\n  // if [ -x \"$basedir/node.exe\" ]; then\n  //   \"$basedir/node.exe\" \"$basedir/node_modules/npm/bin/npm-cli.js\" \"$@\"\n  //   ret=$?\n  // else\n  //   node \"$basedir/node_modules/npm/bin/npm-cli.js\" \"$@\"\n  //   ret=$?\n  // fi\n  // exit $ret\n\n  var sh = \"#!/bin/sh\\n\"\n\n  if (shLongProg) {\n    sh = sh\n        + \"basedir=$(dirname \\\"$(echo \\\"$0\\\" | sed -e 's,\\\\\\\\,/,g')\\\")\\n\"\n        + \"\\n\"\n        + \"case `uname` in\\n\"\n        + \"    *CYGWIN*) basedir=`cygpath -w \\\"$basedir\\\"`;;\\n\"\n        + \"esac\\n\"\n        + \"\\n\"\n\n    sh = sh\n       + \"if [ -x \"+shLongProg+\" ]; then\\n\"\n       + \"  \" + shLongProg + \" \" + args + \" \" + shTarget + \" \\\"$@\\\"\\n\"\n       + \"  ret=$?\\n\"\n       + \"else \\n\"\n       + \"  \" + shProg + \" \" + args + \" \" + shTarget + \" \\\"$@\\\"\\n\"\n       + \"  ret=$?\\n\"\n       + \"fi\\n\"\n       + \"exit $ret\\n\"\n  } else {\n    sh = shProg + \" \" + args + \" \" + shTarget + \" \\\"$@\\\"\\n\"\n       + \"exit $?\\n\"\n  }\n\n  var then = times(2, next, cb)\n  fs.writeFile(to + \".cmd\", cmd, \"utf8\", then)\n  fs.writeFile(to, sh, \"utf8\", then)\n  function next () {\n    chmodShim(to, cb)\n  }\n}\n\nfunction chmodShim (to, cb) {\n  var then = times(2, cb, cb)\n  fs.chmod(to, 0755, then)\n  fs.chmod(to + \".cmd\", 0755, then)\n}\n\nfunction times(n, ok, cb) {\n  var errState = null\n  return function(er) {\n    if (!errState) {\n      if (er)\n        cb(errState = er)\n      else if (--n === 0)\n        ok()\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/logout.js":"module.exports = logout\n\nvar dezalgo = require('dezalgo')\nvar log = require('npmlog')\n\nvar npm = require('./npm.js')\nvar mapToRegistry = require('./utils/map-to-registry.js')\n\nlogout.usage = 'npm logout [--registry=<url>] [--scope=<@scope>]'\n\nfunction afterLogout (normalized, cb) {\n  var scope = npm.config.get('scope')\n\n  if (scope) npm.config.del(scope + ':registry')\n\n  npm.config.clearCredentialsByURI(normalized)\n  npm.config.save('user', cb)\n}\n\nfunction logout (args, cb) {\n  cb = dezalgo(cb)\n\n  mapToRegistry('/', npm.config, function (err, uri, auth, normalized) {\n    if (err) return cb(err)\n\n    if (auth.token) {\n      log.verbose('logout', 'clearing session token for', normalized)\n      npm.registry.logout(normalized, { auth: auth }, function (err) {\n        if (err) return cb(err)\n\n        afterLogout(normalized, cb)\n      })\n    } else if (auth.username || auth.password) {\n      log.verbose('logout', 'clearing user credentials for', normalized)\n\n      afterLogout(normalized, cb)\n    } else {\n      cb(new Error(\n        'Not logged in to', normalized + ',', \"so can't log out.\"\n      ))\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/outdated.js":"/*\n\nnpm outdated [pkg]\n\nDoes the following:\n\n1. check for a new version of pkg\n\nIf no packages are specified, then run for all installed\npackages.\n\n--parseable creates output like this:\n<fullpath>:<name@wanted>:<name@installed>:<name@latest>\n\n*/\n\nmodule.exports = outdated\n\noutdated.usage = 'npm outdated [[<@scope>/]<pkg> ...]'\n\noutdated.completion = require('./utils/completion/installed-deep.js')\n\nvar os = require('os')\nvar url = require('url')\nvar path = require('path')\nvar log = require('npmlog')\nvar readPackageTree = require('read-package-tree')\nvar readJson = require('read-package-json')\nvar asyncMap = require('slide').asyncMap\nvar color = require('ansicolors')\nvar styles = require('ansistyles')\nvar table = require('text-table')\nvar semver = require('semver')\nvar npa = require('npm-package-arg')\nvar mutateIntoLogicalTree = require('./install/mutate-into-logical-tree.js')\nvar cache = require('./cache.js')\nvar npm = require('./npm.js')\nvar long = npm.config.get('long')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar isExtraneous = require('./install/is-extraneous.js')\nvar recalculateMetadata = require('./install/deps.js').recalculateMetadata\nvar moduleName = require('./utils/module-name.js')\nvar output = require('./utils/output.js')\nvar ansiTrim = require('./utils/ansi-trim')\n\nfunction uniqName (item) {\n  return item[0].path + '|' + item[1] + '|' + item[7]\n}\n\nfunction uniq (list) {\n  var uniqed = []\n  var seen = {}\n  list.forEach(function (item) {\n    var name = uniqName(item)\n    if (seen[name]) return\n    seen[name] = true\n    uniqed.push(item)\n  })\n  return uniqed\n}\n\nfunction andRecalculateMetadata (next) {\n  return function (er, tree) {\n    if (er) return next(er)\n    recalculateMetadata(tree, log, next)\n  }\n}\n\nfunction outdated (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n  var dir = path.resolve(npm.dir, '..')\n\n  // default depth for `outdated` is 0 (cf. `ls`)\n  if (npm.config.get('depth') === Infinity) npm.config.set('depth', 0)\n\n  readPackageTree(dir, andRecalculateMetadata(function (er, tree) {\n    if (!tree) return cb(er)\n    mutateIntoLogicalTree(tree)\n    outdated_(args, '', tree, {}, 0, function (er, list) {\n      list = uniq(list || []).sort(function (aa, bb) {\n        return aa[0].path.localeCompare(bb[0].path) ||\n          aa[1].localeCompare(bb[1])\n      })\n      if (er || silent || list.length === 0) return cb(er, list)\n      if (npm.config.get('json')) {\n        output(makeJSON(list))\n      } else if (npm.config.get('parseable')) {\n        output(makeParseable(list))\n      } else {\n        var outList = list.map(makePretty)\n        var outHead = [ 'Package',\n                        'Current',\n                        'Wanted',\n                        'Latest',\n                        'Location'\n                      ]\n        if (long) outHead.push('Package Type')\n        var outTable = [outHead].concat(outList)\n\n        if (npm.color) {\n          outTable[0] = outTable[0].map(function (heading) {\n            return styles.underline(heading)\n          })\n        }\n\n        var tableOpts = {\n          align: ['l', 'r', 'r', 'r', 'l'],\n          stringLength: function (s) { return ansiTrim(s).length }\n        }\n        output(table(outTable, tableOpts))\n      }\n      process.exitCode = 1\n      cb(null, list.map(function (item) { return [item[0].parent.path].concat(item.slice(1, 7)) }))\n    })\n  }))\n}\n\n// [[ dir, dep, has, want, latest, type ]]\nfunction makePretty (p) {\n  var dep = p[0]\n  var depname = p[1]\n  var dir = dep.path\n  var has = p[2]\n  var want = p[3]\n  var latest = p[4]\n  var type = p[6]\n  var deppath = p[7]\n\n  if (!npm.config.get('global')) {\n    dir = path.relative(process.cwd(), dir)\n  }\n\n  var columns = [ depname,\n                  has || 'MISSING',\n                  want,\n                  latest,\n                  deppath\n                ]\n  if (long) columns[5] = type\n\n  if (npm.color) {\n    columns[0] = color[has === want || want === 'linked' ? 'yellow' : 'red'](columns[0]) // dep\n    columns[2] = color.green(columns[2]) // want\n    columns[3] = color.magenta(columns[3]) // latest\n  }\n\n  return columns\n}\n\nfunction makeParseable (list) {\n  return list.map(function (p) {\n    var dep = p[0]\n    var depname = p[1]\n    var dir = dep.path\n    var has = p[2]\n    var want = p[3]\n    var latest = p[4]\n    var type = p[6]\n\n    var out = [\n      dir,\n      depname + '@' + want,\n      (has ? (depname + '@' + has) : 'MISSING'),\n      depname + '@' + latest\n    ]\n    if (long) out.push(type)\n\n    return out.join(':')\n  }).join(os.EOL)\n}\n\nfunction makeJSON (list) {\n  var out = {}\n  list.forEach(function (p) {\n    var dep = p[0]\n    var depname = p[1]\n    var dir = dep.path\n    var has = p[2]\n    var want = p[3]\n    var latest = p[4]\n    var type = p[6]\n    if (!npm.config.get('global')) {\n      dir = path.relative(process.cwd(), dir)\n    }\n    out[depname] = { current: has,\n                  wanted: want,\n                  latest: latest,\n                  location: dir\n                }\n    if (long) out[depname].type = type\n  })\n  return JSON.stringify(out, null, 2)\n}\n\nfunction outdated_ (args, path, tree, parentHas, depth, cb) {\n  if (!tree.package) tree.package = {}\n  if (path && tree.package.name) path += ' > ' + tree.package.name\n  if (!path && tree.package.name) path = tree.package.name\n  if (depth > npm.config.get('depth')) {\n    return cb(null, [])\n  }\n  var types = {}\n  var pkg = tree.package\n\n  var deps = tree.children.filter(function (child) { return !isExtraneous(child) }) || []\n\n  deps.forEach(function (dep) {\n    types[moduleName(dep)] = 'dependencies'\n  })\n\n  Object.keys(tree.missingDeps).forEach(function (name) {\n    deps.push({\n      package: { name: name },\n      path: tree.path,\n      parent: tree,\n      isMissing: true\n    })\n    types[name] = 'dependencies'\n  })\n\n  // If we explicitly asked for dev deps OR we didn't ask for production deps\n  // AND we asked to save dev-deps OR we didn't ask to save anything that's NOT\n  // dev deps then\n  // (All the save checking here is because this gets called from npm-update currently\n  // and that requires this logic around dev deps.)\n  // FIXME: Refactor npm update to not be in terms of outdated.\n  var dev = npm.config.get('dev') || /^dev(elopment)?$/.test(npm.config.get('also'))\n  var prod = npm.config.get('production') || /^prod(uction)?$/.test(npm.config.get('only'))\n  if ((dev || !prod) &&\n      (npm.config.get('save-dev') || (\n        !npm.config.get('save') && !npm.config.get('save-optional')))) {\n    Object.keys(tree.missingDevDeps).forEach(function (name) {\n      deps.push({\n        package: { name: name },\n        path: tree.path,\n        parent: tree,\n        isMissing: true\n      })\n      if (!types[name]) {\n        types[name] = 'devDependencies'\n      }\n    })\n  }\n\n  if (npm.config.get('save-dev')) {\n    deps = deps.filter(function (dep) { return pkg.devDependencies[moduleName(dep)] })\n    deps.forEach(function (dep) {\n      types[moduleName(dep)] = 'devDependencies'\n    })\n  } else if (npm.config.get('save')) {\n    // remove optional dependencies from dependencies during --save.\n    deps = deps.filter(function (dep) { return !pkg.optionalDependencies[moduleName(dep)] })\n  } else if (npm.config.get('save-optional')) {\n    deps = deps.filter(function (dep) { return pkg.optionalDependencies[moduleName(dep)] })\n    deps.forEach(function (dep) {\n      types[moduleName(dep)] = 'optionalDependencies'\n    })\n  }\n  var doUpdate = dev || (\n    !prod &&\n    !Object.keys(parentHas).length &&\n    !npm.config.get('global')\n  )\n  if (doUpdate) {\n    Object.keys(pkg.devDependencies).forEach(function (k) {\n      if (!(k in parentHas)) {\n        deps[k] = pkg.devDependencies[k]\n        types[k] = 'devDependencies'\n      }\n    })\n  }\n\n  var has = Object.create(parentHas)\n  tree.children.forEach(function (child) {\n    if (child.package.name && child.package.private) {\n      deps = deps.filter(function (dep) { return dep !== child })\n    }\n    has[child.package.name] = {\n      version: child.package.version,\n      from: child.package._from\n    }\n  })\n\n  // now get what we should have, based on the dep.\n  // if has[dep] !== shouldHave[dep], then cb with the data\n  // otherwise dive into the folder\n  asyncMap(deps, function (dep, cb) {\n    var name = moduleName(dep)\n    var required = (tree.package.dependencies)[name] ||\n                   (tree.package.optionalDependencies)[name] ||\n                   (tree.package.devDependencies)[name] ||\n                   dep.package._requested && dep.package._requested.spec ||\n                   '*'\n    if (!long) return shouldUpdate(args, dep, name, has, required, depth, path, cb)\n\n    shouldUpdate(args, dep, name, has, required, depth, path, cb, types[name])\n  }, cb)\n}\n\nfunction shouldUpdate (args, tree, dep, has, req, depth, pkgpath, cb, type) {\n  // look up the most recent version.\n  // if that's what we already have, or if it's not on the args list,\n  // then dive into it.  Otherwise, cb() with the data.\n\n  // { version: , from: }\n  var curr = has[dep]\n\n  function skip (er) {\n    // show user that no viable version can be found\n    if (er) return cb(er)\n    outdated_(args,\n              pkgpath,\n              tree,\n              has,\n              depth + 1,\n              cb)\n  }\n\n  function doIt (wanted, latest) {\n    if (!long) {\n      return cb(null, [[tree, dep, curr && curr.version, wanted, latest, req, null, pkgpath]])\n    }\n    cb(null, [[tree, dep, curr && curr.version, wanted, latest, req, type, pkgpath]])\n  }\n\n  if (args.length && args.indexOf(dep) === -1) return skip()\n  var parsed = npa(dep + '@' + req)\n  if (tree.isLink && tree.parent && tree.parent.isTop) {\n    return doIt('linked', 'linked')\n  }\n  if (parsed.type === 'git' || parsed.type === 'hosted') {\n    return doIt('git', 'git')\n  }\n\n  // search for the latest package\n  mapToRegistry(dep, npm.config, function (er, uri, auth) {\n    if (er) return cb(er)\n\n    npm.registry.get(uri, { auth: auth }, updateDeps)\n  })\n\n  function updateLocalDeps (latestRegistryVersion) {\n    readJson(path.resolve(parsed.spec, 'package.json'), function (er, localDependency) {\n      if (er) return cb()\n\n      var wanted = localDependency.version\n      var latest = localDependency.version\n\n      if (latestRegistryVersion) {\n        latest = latestRegistryVersion\n        if (semver.lt(wanted, latestRegistryVersion)) {\n          wanted = latestRegistryVersion\n          req = dep + '@' + latest\n        }\n      }\n\n      if (!curr || curr.version !== wanted) {\n        doIt(wanted, latest)\n      } else {\n        skip()\n      }\n    })\n  }\n\n  function updateDeps (er, d) {\n    if (er) {\n      if (parsed.type !== 'local') return cb(er)\n      return updateLocalDeps()\n    }\n\n    if (!d || !d['dist-tags'] || !d.versions) return cb()\n    var l = d.versions[d['dist-tags'].latest]\n    if (!l) return cb()\n\n    var r = req\n    if (d['dist-tags'][req]) {\n      r = d['dist-tags'][req]\n    }\n\n    if (semver.validRange(r, true)) {\n      // some kind of semver range.\n      // see if it's in the doc.\n      var vers = Object.keys(d.versions)\n      var v = semver.maxSatisfying(vers, r, true)\n      if (v) {\n        return onCacheAdd(null, d.versions[v])\n      }\n    }\n\n    // We didn't find the version in the doc.  See if cache can find it.\n    cache.add(dep, req, null, false, onCacheAdd)\n\n    function onCacheAdd (er, d) {\n      // if this fails, then it means we can't update this thing.\n      // it's probably a thing that isn't published.\n      if (er) {\n        if (er.code && er.code === 'ETARGET') {\n          // no viable version found\n          return skip(er)\n        }\n        return skip()\n      }\n\n      // check that the url origin hasn't changed (#1727) and that\n      // there is no newer version available\n      var dFromUrl = d._from && url.parse(d._from).protocol\n      var cFromUrl = curr && curr.from && url.parse(curr.from).protocol\n\n      if (!curr ||\n          dFromUrl && cFromUrl && d._from !== curr.from ||\n          d.version !== curr.version ||\n          d.version !== l.version) {\n        if (parsed.type === 'local') return updateLocalDeps(l.version)\n\n        doIt(d.version, l.version)\n      } else {\n        skip()\n      }\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/completion/installed-deep.js":"module.exports = installedDeep\n\nvar npm = require('../../npm.js')\nvar readInstalled = require('read-installed')\n\nfunction installedDeep (opts, cb) {\n  var local\n  var global\n  var depth = npm.config.get('depth')\n  var opt = { depth: depth, dev: true }\n\n  if (npm.config.get('global')) {\n    local = []\n    next()\n  } else {\n    readInstalled(npm.prefix, opt, function (er, data) {\n      local = getNames(data || {})\n      next()\n    })\n  }\n\n  readInstalled(npm.config.get('prefix'), opt, function (er, data) {\n    global = getNames(data || {})\n    next()\n  })\n\n  function getNames_ (d, n) {\n    if (d.realName && n) {\n      if (n[d.realName]) return n\n      n[d.realName] = true\n    }\n    if (!n) n = {}\n    Object.keys(d.dependencies || {}).forEach(function (dep) {\n      getNames_(d.dependencies[dep], n)\n    })\n    return n\n  }\n  function getNames (d) {\n    return Object.keys(getNames_(d))\n  }\n\n  function next () {\n    if (!local || !global) return\n    if (!npm.config.get('global')) {\n      global = global.map(function (g) {\n        return [g, '-g']\n      })\n    }\n    var names = local.concat(global)\n    return cb(null, names)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read-installed/read-installed.js":"\n// Walk through the file-system \"database\" of installed\n// packages, and create a data object related to the\n// installed versions of each package.\n\n/*\nThis will traverse through all node_modules folders,\nresolving the dependencies object to the object corresponding to\nthe package that meets that dep, or just the version/range if\nunmet.\n\nAssuming that you had this folder structure:\n\n/path/to\n+-- package.json { name = \"root\" }\n`-- node_modules\n    +-- foo {bar, baz, asdf}\n    | +-- node_modules\n    |   +-- bar { baz }\n    |   `-- baz\n    `-- asdf\n\nwhere \"foo\" depends on bar, baz, and asdf, bar depends on baz,\nand bar and baz are bundled with foo, whereas \"asdf\" is at\nthe higher level (sibling to foo), you'd get this object structure:\n\n{ <package.json data>\n, path: \"/path/to\"\n, parent: null\n, dependencies:\n  { foo :\n    { version: \"1.2.3\"\n    , path: \"/path/to/node_modules/foo\"\n    , parent: <Circular: root>\n    , dependencies:\n      { bar:\n        { parent: <Circular: foo>\n        , path: \"/path/to/node_modules/foo/node_modules/bar\"\n        , version: \"2.3.4\"\n        , dependencies: { baz: <Circular: foo.dependencies.baz> }\n        }\n      , baz: { ... }\n      , asdf: <Circular: asdf>\n      }\n    }\n  , asdf: { ... }\n  }\n}\n\nUnmet deps are left as strings.\nExtraneous deps are marked with extraneous:true\ndeps that don't meet a requirement are marked with invalid:true\ndeps that don't meet a peer requirement are marked with peerInvalid:true\n\nto READ(packagefolder, parentobj, name, reqver)\nobj = read package.json\ninstalled = ./node_modules/*\nif parentobj is null, and no package.json\n  obj = {dependencies:{<installed>:ANY}}\ndeps = Object.keys(obj.dependencies)\nobj.path = packagefolder\nobj.parent = parentobj\nif name, && obj.name !== name, obj.invalid = true\nif reqver, && obj.version !satisfies reqver, obj.invalid = true\nif !reqver && parentobj, obj.extraneous = true\nfor each folder in installed\n  obj.dependencies[folder] = READ(packagefolder+node_modules+folder,\n                                  obj, folder, obj.dependencies[folder])\n# walk tree to find unmet deps\nfor each dep in obj.dependencies not in installed\n  r = obj.parent\n  while r\n    if r.dependencies[dep]\n      if r.dependencies[dep].verion !satisfies obj.dependencies[dep]\n        WARN\n        r.dependencies[dep].invalid = true\n      obj.dependencies[dep] = r.dependencies[dep]\n      r = null\n    else r = r.parent\nreturn obj\n\n\nTODO:\n1. Find unmet deps in parent directories, searching as node does up\nas far as the left-most node_modules folder.\n2. Ignore anything in node_modules that isn't a package folder.\n\n*/\n\ntry {\n  var fs = require(\"graceful-fs\")\n} catch (er) {\n  var fs = require(\"fs\")\n}\n\nvar path = require(\"path\")\nvar asyncMap = require(\"slide\").asyncMap\nvar semver = require(\"semver\")\nvar readJson = require(\"read-package-json\")\nvar url = require(\"url\")\nvar util = require(\"util\")\nvar extend = require(\"util-extend\")\n\nvar debug = require(\"debuglog\")(\"read-installed\")\n\nvar readdir = require(\"readdir-scoped-modules\")\n\n// Sentinel catch-all version constraint used when a dependency is not\n// listed in the package.json file.\nvar ANY = {}\n\nmodule.exports = readInstalled\n\nfunction readInstalled (folder, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  } else {\n    opts = extend({}, opts)\n  }\n\n  if (typeof opts.depth !== 'number')\n    opts.depth = Infinity\n\n  opts.depth = Math.max(0, opts.depth)\n\n  if (typeof opts.log !== 'function')\n    opts.log = function () {}\n\n  opts.dev = !!opts.dev\n  opts.realpathSeen = {}\n  opts.findUnmetSeen = []\n\n\n  readInstalled_(folder, null, null, null, 0, opts, function (er, obj) {\n    if (er) return cb(er)\n    // now obj has all the installed things, where they're installed\n    // figure out the inheritance links, now that the object is built.\n    resolveInheritance(obj, opts)\n    obj.root = true\n    unmarkExtraneous(obj, opts)\n    cb(null, obj)\n  })\n}\n\nfunction readInstalled_ (folder, parent, name, reqver, depth, opts, cb) {\n  var installed\n    , obj\n    , real\n    , link\n    , realpathSeen = opts.realpathSeen\n\n  readdir(path.resolve(folder, \"node_modules\"), function (er, i) {\n    // error indicates that nothing is installed here\n    if (er) i = []\n    installed = i.filter(function (f) { return f.charAt(0) !== \".\" })\n    next()\n  })\n\n  readJson(path.resolve(folder, \"package.json\"), function (er, data) {\n    obj = copy(data)\n\n    if (!parent) {\n      obj = obj || true\n      er = null\n    }\n    return next(er)\n  })\n\n  fs.lstat(folder, function (er, st) {\n    if (er) {\n      if (!parent) real = true\n      return next(er)\n    }\n    fs.realpath(folder, function (er, rp) {\n      debug(\"realpath(%j) = %j\", folder, rp)\n      real = rp\n      if (st.isSymbolicLink()) link = rp\n      next(er)\n    })\n  })\n\n  var errState = null\n    , called = false\n  function next (er) {\n    if (errState) return\n    if (er) {\n      errState = er\n      return cb(null, [])\n    }\n    debug('next', installed, obj && typeof obj, name, real)\n    if (!installed || !obj || !real || called) return\n    called = true\n    if (realpathSeen[real]) return cb(null, realpathSeen[real])\n    if (obj === true) {\n      obj = {dependencies:{}, path:folder}\n      installed.forEach(function (i) { obj.dependencies[i] = ANY })\n    }\n    if (name && obj.name !== name) obj.invalid = true\n    obj.realName = name || obj.name\n    obj.dependencies = obj.dependencies || {}\n\n    // At this point, figure out what dependencies we NEED to get met\n    obj._dependencies = copy(obj.dependencies)\n\n    if (reqver === ANY) {\n      // We were unable to determine the required version of this\n      // dependency from the package.json file, but we now know its actual\n      // version, so treat that version as the required version to avoid\n      // marking the dependency as invalid below. See #40.\n      reqver = obj.version;\n    }\n\n    // \"foo\":\"http://blah\" and \"foo\":\"latest\" are always presumed valid\n    if (reqver\n        && semver.validRange(reqver, true)\n        && !semver.satisfies(obj.version, reqver, true)) {\n      obj.invalid = true\n    }\n\n    // Mark as extraneous at this point.\n    // This will be un-marked in unmarkExtraneous, where we mark as\n    // not-extraneous everything that is required in some way from\n    // the root object.\n    obj.extraneous = true\n\n    obj.path = obj.path || folder\n    obj.realPath = real\n    obj.link = link\n    if (parent && !obj.link) obj.parent = parent\n    realpathSeen[real] = obj\n    obj.depth = depth\n    //if (depth >= opts.depth) return cb(null, obj)\n    asyncMap(installed, function (pkg, cb) {\n      var rv = obj.dependencies[pkg]\n      if (!rv && obj.devDependencies && opts.dev)\n        rv = obj.devDependencies[pkg]\n\n      if (depth > opts.depth) {\n        obj.dependencies = {}\n        return cb(null, obj)\n      }\n\n      readInstalled_( path.resolve(folder, \"node_modules/\"+pkg)\n                    , obj, pkg, obj.dependencies[pkg], depth + 1, opts\n                    , cb )\n\n    }, function (er, installedData) {\n      if (er) return cb(er)\n      installedData.forEach(function (dep) {\n        obj.dependencies[dep.realName] = dep\n      })\n\n      // any strings here are unmet things.  however, if it's\n      // optional, then that's fine, so just delete it.\n      if (obj.optionalDependencies) {\n        Object.keys(obj.optionalDependencies).forEach(function (dep) {\n          if (typeof obj.dependencies[dep] === \"string\") {\n            delete obj.dependencies[dep]\n          }\n        })\n      }\n      return cb(null, obj)\n    })\n  }\n}\n\n// starting from a root object, call findUnmet on each layer of children\nvar riSeen = []\nfunction resolveInheritance (obj, opts) {\n  if (typeof obj !== \"object\") return\n  if (riSeen.indexOf(obj) !== -1) return\n  riSeen.push(obj)\n  if (typeof obj.dependencies !== \"object\") {\n    obj.dependencies = {}\n  }\n  Object.keys(obj.dependencies).forEach(function (dep) {\n    findUnmet(obj.dependencies[dep], opts)\n  })\n  Object.keys(obj.dependencies).forEach(function (dep) {\n    if (typeof obj.dependencies[dep] === \"object\") {\n      resolveInheritance(obj.dependencies[dep], opts)\n    } else {\n      debug(\"unmet dep! %s %s@%s\", obj.name, dep, obj.dependencies[dep])\n    }\n  })\n  findUnmet(obj, opts)\n}\n\n// find unmet deps by walking up the tree object.\n// No I/O\nfunction findUnmet (obj, opts) {\n  var findUnmetSeen = opts.findUnmetSeen\n  if (findUnmetSeen.indexOf(obj) !== -1) return\n  findUnmetSeen.push(obj)\n  debug(\"find unmet parent=%s obj=\", obj.parent && obj.parent.name, obj.name || obj)\n  var deps = obj.dependencies = obj.dependencies || {}\n\n  debug(deps)\n  Object.keys(deps)\n    .filter(function (d) { return typeof deps[d] === \"string\" })\n    .forEach(function (d) {\n      var found = findDep(obj, d)\n      debug(\"finding dep %j\", d, found && found.name || found)\n      // \"foo\":\"http://blah\" and \"foo\":\"latest\" are always presumed valid\n      if (typeof deps[d] === \"string\" &&\n          semver.validRange(deps[d], true) &&\n          found &&\n          !semver.satisfies(found.version, deps[d], true)) {\n        // the bad thing will happen\n        opts.log( \"unmet dependency\"\n                , obj.path + \" requires \"+d+\"@'\"+deps[d]\n                + \"' but will load\\n\"\n                + found.path+\",\\nwhich is version \"+found.version )\n        found.invalid = true\n      }\n      if (found) {\n        deps[d] = found\n      }\n    })\n\n  var peerDeps = obj.peerDependencies = obj.peerDependencies || {}\n  Object.keys(peerDeps).forEach(function (d) {\n    var dependency\n\n    if (!obj.parent) {\n      dependency = obj.dependencies[d]\n\n      // read it as a missing dep\n      if (!dependency) {\n        obj.dependencies[d] = peerDeps[d]\n      }\n    } else {\n      var r = obj.parent\n      while (r && !dependency) {\n        dependency = r.dependencies && r.dependencies[d]\n        r = r.link ? null : r.parent\n      }\n    }\n\n    if (!dependency) {\n      // mark as a missing dep!\n      obj.dependencies[d] = peerDeps[d]\n    } else if (!semver.satisfies(dependency.version, peerDeps[d], true)) {\n      dependency.peerInvalid = true\n    }\n  })\n\n  return obj\n}\n\nfunction unmarkExtraneous (obj, opts) {\n  // Mark all non-required deps as extraneous.\n  // start from the root object and mark as non-extraneous all modules\n  // that haven't been previously flagged as extraneous then propagate\n  // to all their dependencies\n\n  obj.extraneous = false\n\n  var deps = obj._dependencies || []\n  if (opts.dev && obj.devDependencies && (obj.root || obj.link)) {\n    Object.keys(obj.devDependencies).forEach(function (k) {\n      deps[k] = obj.devDependencies[k]\n    })\n  }\n\n  if (obj.peerDependencies) {\n    Object.keys(obj.peerDependencies).forEach(function (k) {\n      deps[k] = obj.peerDependencies[k]\n    })\n  }\n\n  debug(\"not extraneous\", obj._id, deps)\n  Object.keys(deps).forEach(function (d) {\n    var dep = findDep(obj, d)\n    if (dep && dep.extraneous) {\n      unmarkExtraneous(dep, opts)\n    }\n  })\n}\n\n// Find the one that will actually be loaded by require()\n// so we can make sure it's valid etc.\nfunction findDep (obj, d) {\n  var r = obj\n    , found = null\n  while (r && !found) {\n    // if r is a valid choice, then use that.\n    // kinda weird if a pkg depends on itself, but after the first\n    // iteration of this loop, it indicates a dep cycle.\n    if (typeof r.dependencies[d] === \"object\") {\n      found = r.dependencies[d]\n    }\n    if (!found && r.realName === d) found = r\n    r = r.link ? null : r.parent\n  }\n  return found\n}\n\nfunction copy (obj) {\n  if (!obj || typeof obj !== 'object') return obj\n  if (Array.isArray(obj)) return obj.map(copy)\n\n  var o = {}\n  for (var i in obj) o[i] = copy(obj[i])\n  return o\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/read-installed/node_modules/util-extend/extend.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = extend;\nfunction extend(origin, add) {\n  // Don't do anything if add isn't an object\n  if (!add || typeof add !== 'object') return origin;\n\n  var keys = Object.keys(add);\n  var i = keys.length;\n  while (i--) {\n    origin[keys[i]] = add[keys[i]];\n  }\n  return origin;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/owner.js":"module.exports = owner\n\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar readLocalPkg = require('./utils/read-local-package.js')\nvar usage = require('./utils/usage')\nvar output = require('./utils/output.js')\n\nowner.usage = usage(\n  'owner',\n  'npm owner add <user> [<@scope>/]<pkg>' +\n  '\\nnpm owner rm <user> [<@scope>/]<pkg>' +\n  '\\nnpm owner ls [<@scope>/]<pkg>'\n)\nowner.completion = function (opts, cb) {\n  var argv = opts.conf.argv.remain\n  if (argv.length > 4) return cb()\n  if (argv.length <= 2) {\n    var subs = ['add', 'rm']\n    if (opts.partialWord === 'l') subs.push('ls')\n    else subs.push('ls', 'list')\n    return cb(null, subs)\n  }\n\n  npm.commands.whoami([], true, function (er, username) {\n    if (er) return cb()\n\n    var un = encodeURIComponent(username)\n    var byUser, theUser\n    switch (argv[2]) {\n      case 'ls':\n        // FIXME: there used to be registry completion here, but it stopped\n        // making sense somewhere around 50,000 packages on the registry\n        return cb()\n\n      case 'rm':\n        if (argv.length > 3) {\n          theUser = encodeURIComponent(argv[3])\n          byUser = '-/by-user/' + theUser + '|' + un\n          return mapToRegistry(byUser, npm.config, function (er, uri, auth) {\n            if (er) return cb(er)\n\n            console.error(uri)\n            npm.registry.get(uri, { auth: auth }, function (er, d) {\n              if (er) return cb(er)\n              // return the intersection\n              return cb(null, d[theUser].filter(function (p) {\n                // kludge for server adminery.\n                return un === 'isaacs' || d[un].indexOf(p) === -1\n              }))\n            })\n          })\n        }\n        // else fallthrough\n        /*eslint no-fallthrough:0*/\n      case 'add':\n        if (argv.length > 3) {\n          theUser = encodeURIComponent(argv[3])\n          byUser = '-/by-user/' + theUser + '|' + un\n          return mapToRegistry(byUser, npm.config, function (er, uri, auth) {\n            if (er) return cb(er)\n\n            console.error(uri)\n            npm.registry.get(uri, { auth: auth }, function (er, d) {\n              console.error(uri, er || d)\n              // return mine that they're not already on.\n              if (er) return cb(er)\n              var mine = d[un] || []\n              var theirs = d[theUser] || []\n              return cb(null, mine.filter(function (p) {\n                return theirs.indexOf(p) === -1\n              }))\n            })\n          })\n        }\n        // just list all users who aren't me.\n        return mapToRegistry('-/users', npm.config, function (er, uri, auth) {\n          if (er) return cb(er)\n\n          npm.registry.get(uri, { auth: auth }, function (er, list) {\n            if (er) return cb()\n            return cb(null, Object.keys(list).filter(function (n) {\n              return n !== un\n            }))\n          })\n        })\n\n      default:\n        return cb()\n    }\n  })\n}\n\nfunction owner (args, cb) {\n  var action = args.shift()\n  switch (action) {\n    case 'ls': case 'list': return ls(args[0], cb)\n    case 'add': return add(args[0], args[1], cb)\n    case 'rm': case 'remove': return rm(args[0], args[1], cb)\n    default: return unknown(action, cb)\n  }\n}\n\nfunction ls (pkg, cb) {\n  if (!pkg) {\n    return readLocalPkg(function (er, pkg) {\n      if (er) return cb(er)\n      if (!pkg) return cb(owner.usage)\n      ls(pkg, cb)\n    })\n  }\n\n  mapToRegistry(pkg, npm.config, function (er, uri, auth) {\n    if (er) return cb(er)\n\n    npm.registry.get(uri, { auth: auth }, function (er, data) {\n      var msg = ''\n      if (er) {\n        log.error('owner ls', \"Couldn't get owner data\", pkg)\n        return cb(er)\n      }\n      var owners = data.maintainers\n      if (!owners || !owners.length) {\n        msg = 'admin party!'\n      } else {\n        msg = owners.map(function (o) {\n          return o.name + ' <' + o.email + '>'\n        }).join('\\n')\n      }\n      output(msg)\n      cb(er, owners)\n    })\n  })\n}\n\nfunction add (user, pkg, cb) {\n  if (!user) return cb(owner.usage)\n  if (!pkg) {\n    return readLocalPkg(function (er, pkg) {\n      if (er) return cb(er)\n      if (!pkg) return cb(new Error(owner.usage))\n      add(user, pkg, cb)\n    })\n  }\n\n  log.verbose('owner add', '%s to %s', user, pkg)\n  mutate(pkg, user, function (u, owners) {\n    if (!owners) owners = []\n    for (var i = 0, l = owners.length; i < l; i++) {\n      var o = owners[i]\n      if (o.name === u.name) {\n        log.info(\n          'owner add',\n          'Already a package owner: ' + o.name + ' <' + o.email + '>'\n        )\n        return false\n      }\n    }\n    owners.push(u)\n    return owners\n  }, cb)\n}\n\nfunction rm (user, pkg, cb) {\n  if (!pkg) {\n    return readLocalPkg(function (er, pkg) {\n      if (er) return cb(er)\n      if (!pkg) return cb(new Error(owner.usage))\n      rm(user, pkg, cb)\n    })\n  }\n\n  log.verbose('owner rm', '%s from %s', user, pkg)\n  mutate(pkg, user, function (u, owners) {\n    var found = false\n    var m = owners.filter(function (o) {\n      var match = (o.name === user)\n      found = found || match\n      return !match\n    })\n\n    if (!found) {\n      log.info('owner rm', 'Not a package owner: ' + user)\n      return false\n    }\n\n    if (!m.length) {\n      return new Error(\n        'Cannot remove all owners of a package.  Add someone else first.'\n      )\n    }\n\n    return m\n  }, cb)\n}\n\nfunction mutate (pkg, user, mutation, cb) {\n  if (user) {\n    var byUser = '-/user/org.couchdb.user:' + user\n    mapToRegistry(byUser, npm.config, function (er, uri, auth) {\n      if (er) return cb(er)\n\n      npm.registry.get(uri, { auth: auth }, mutate_)\n    })\n  } else {\n    mutate_(null, null)\n  }\n\n  function mutate_ (er, u) {\n    if (!er && user && (!u || u.error)) {\n      er = new Error(\n        \"Couldn't get user data for \" + user + ': ' + JSON.stringify(u)\n      )\n    }\n\n    if (er) {\n      log.error('owner mutate', 'Error getting user data for %s', user)\n      return cb(er)\n    }\n\n    if (u) u = { name: u.name, email: u.email }\n    mapToRegistry(pkg, npm.config, function (er, uri, auth) {\n      if (er) return cb(er)\n\n      npm.registry.get(uri, { auth: auth }, function (er, data) {\n        if (er) {\n          log.error('owner mutate', 'Error getting package data for %s', pkg)\n          return cb(er)\n        }\n\n        // save the number of maintainers before mutation so that we can figure\n        // out if maintainers were added or removed\n        var beforeMutation = data.maintainers.length\n\n        var m = mutation(u, data.maintainers)\n        if (!m) return cb() // handled\n        if (m instanceof Error) return cb(m) // error\n\n        data = {\n          _id: data._id,\n          _rev: data._rev,\n          maintainers: m\n        }\n        var dataPath = pkg.replace('/', '%2f') + '/-rev/' + data._rev\n        mapToRegistry(dataPath, npm.config, function (er, uri, auth) {\n          if (er) return cb(er)\n\n          var params = {\n            method: 'PUT',\n            body: data,\n            auth: auth\n          }\n          npm.registry.request(uri, params, function (er, data) {\n            if (!er && data.error) {\n              er = new Error('Failed to update package metadata: ' + JSON.stringify(data))\n            }\n\n            if (er) {\n              log.error('owner mutate', 'Failed to update package metadata')\n            } else if (m.length > beforeMutation) {\n              output('+ %s (%s)', user, pkg)\n            } else if (m.length < beforeMutation) {\n              output('- %s (%s)', user, pkg)\n            }\n\n            cb(er, data)\n          })\n        })\n      })\n    })\n  }\n}\n\nfunction unknown (action, cb) {\n  cb('Usage: \\n' + owner.usage)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/read-local-package.js":"exports = module.exports = readLocalPkg\n\nvar npm = require('../npm.js')\nvar readJson = require('read-package-json')\n\nfunction readLocalPkg (cb) {\n  if (npm.config.get('global')) return cb()\n  var path = require('path')\n  readJson(path.resolve(npm.prefix, 'package.json'), function (er, d) {\n    return cb(er, d && d.name)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/pack.js":"// npm pack <pkg>\n// Packs the specified package into a .tgz file, which can then\n// be installed.\n\nmodule.exports = pack\n\nvar install = require('./install.js')\nvar cache = require('./cache.js')\nvar fs = require('graceful-fs')\nvar chain = require('slide').chain\nvar path = require('path')\nvar cwd = process.cwd()\nvar writeStreamAtomic = require('fs-write-stream-atomic')\nvar cachedPackageRoot = require('./cache/cached-package-root.js')\nvar output = require('./utils/output.js')\n\npack.usage = 'npm pack [[<@scope>/]<pkg>...]'\n\n// if it can be installed, it can be packed.\npack.completion = install.completion\n\nfunction pack (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n\n  if (args.length === 0) args = ['.']\n\n  chain(\n    args.map(function (arg) { return function (cb) { pack_(arg, cb) } }),\n    function (er, files) {\n      if (er || silent) return cb(er, files)\n      printFiles(files, cb)\n    }\n  )\n}\n\nfunction printFiles (files, cb) {\n  files = files.map(function (file) {\n    return path.relative(cwd, file)\n  })\n  output(files.join('\\n'))\n  cb()\n}\n\n// add to cache, then cp to the cwd\nfunction pack_ (pkg, cb) {\n  cache.add(pkg, null, null, false, function (er, data) {\n    if (er) return cb(er)\n\n    // scoped packages get special treatment\n    var name = data.name\n    if (name[0] === '@') name = name.substr(1).replace(/\\//g, '-')\n    var fname = name + '-' + data.version + '.tgz'\n\n    var cached = path.join(cachedPackageRoot(data), 'package.tgz')\n    var from = fs.createReadStream(cached)\n    var to = writeStreamAtomic(fname)\n    var errState = null\n\n    from.on('error', cb_)\n    to.on('error', cb_)\n    to.on('close', cb_)\n    from.pipe(to)\n\n    function cb_ (er) {\n      if (errState) return\n      if (er) return cb(errState = er)\n      cb(null, fname)\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/prefix.js":"module.exports = prefix\n\nvar npm = require('./npm.js')\nvar output = require('./utils/output.js')\n\nprefix.usage = 'npm prefix [-g]'\n\nfunction prefix (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n  if (!silent) output(npm.prefix)\n  process.nextTick(cb.bind(this, null, npm.prefix))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/prune.js":"// prune extraneous packages.\n\nmodule.exports = prune\nmodule.exports.Pruner = Pruner\n\nprune.usage = 'npm prune [[<@scope>/]<pkg>...] [--production]'\n\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar util = require('util')\nvar moduleName = require('./utils/module-name.js')\nvar Installer = require('./install.js').Installer\nvar isExtraneous = require('./install/is-extraneous.js')\nvar isDev = require('./install/is-dev-dep.js')\nvar removeDeps = require('./install/deps.js').removeDeps\nvar loadExtraneous = require('./install/deps.js').loadExtraneous\nvar chain = require('slide').chain\n\nprune.completion = require('./utils/completion/installed-deep.js')\n\nfunction prune (args, cb) {\n  var dryrun = !!npm.config.get('dry-run')\n  new Pruner('.', dryrun, args).run(cb)\n}\n\nfunction Pruner (where, dryrun, args) {\n  Installer.call(this, where, dryrun, args)\n}\nutil.inherits(Pruner, Installer)\n\nPruner.prototype.loadAllDepsIntoIdealTree = function (cb) {\n  log.silly('uninstall', 'loadAllDepsIntoIdealtree')\n\n  var cg = this.progress.loadAllDepsIntoIdealTree\n  var steps = []\n\n  var self = this\n  var excludeDev = npm.config.get('production') || /^prod(uction)?$/.test(npm.config.get('only'))\n  function shouldPrune (child) {\n    if (isExtraneous(child)) return true\n    if (!excludeDev) return false\n    var childName = moduleName(child)\n    var isChildDev = function (parent) { return isDev(parent, childName) }\n    if (child.requiredBy.every(isChildDev)) return true\n  }\n  function getModuleName (child) {\n    // wrapping because moduleName doesn't like extra args and we're called\n    // from map.\n    return moduleName(child)\n  }\n  function matchesArg (name) {\n    return self.args.length === 0 || self.args.indexOf(name) !== -1\n  }\n  function nameObj (name) {\n    return {name: name}\n  }\n  var toPrune = this.currentTree.children.filter(shouldPrune).map(getModuleName).filter(matchesArg).map(nameObj)\n\n  steps.push(\n    [removeDeps, toPrune, this.idealTree, null, cg.newGroup('removeDeps')],\n    [loadExtraneous, this.idealTree, cg.newGroup('loadExtraneous')])\n  chain(steps, cb)\n}\n\nPruner.prototype.runPreinstallTopLevelLifecycles = function (cb) { cb() }\nPruner.prototype.runPostinstallTopLevelLifecycles = function (cb) { cb() }\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/publish.js":"\nmodule.exports = publish\n\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar path = require('path')\nvar readJson = require('read-package-json')\nvar lifecycle = require('./utils/lifecycle.js')\nvar chain = require('slide').chain\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar cachedPackageRoot = require('./cache/cached-package-root.js')\nvar createReadStream = require('graceful-fs').createReadStream\nvar npa = require('npm-package-arg')\nvar semver = require('semver')\nvar getPublishConfig = require('./utils/get-publish-config.js')\nvar output = require('./utils/output.js')\n\npublish.usage = 'npm publish [<tarball>|<folder>] [--tag <tag>] [--access <public|restricted>]' +\n                \"\\n\\nPublishes '.' if no argument supplied\" +\n                '\\n\\nSets tag `latest` if no --tag specified'\n\npublish.completion = function (opts, cb) {\n  // publish can complete to a folder with a package.json\n  // or a tarball, or a tarball url.\n  // for now, not yet implemented.\n  return cb()\n}\n\nfunction publish (args, isRetry, cb) {\n  if (typeof cb !== 'function') {\n    cb = isRetry\n    isRetry = false\n  }\n  if (args.length === 0) args = ['.']\n  if (args.length !== 1) return cb(publish.usage)\n\n  log.verbose('publish', args)\n\n  var t = npm.config.get('tag').trim()\n  if (semver.validRange(t)) {\n    var er = new Error('Tag name must not be a valid SemVer range: ' + t)\n    return cb(er)\n  }\n\n  var arg = args[0]\n  // if it's a local folder, then run the prepublish there, first.\n  readJson(path.resolve(arg, 'package.json'), function (er, data) {\n    if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n\n    if (data) {\n      if (!data.name) return cb(new Error('No name provided'))\n      if (!data.version) return cb(new Error('No version provided'))\n    }\n\n    // if readJson errors, the argument might be a tarball or package URL\n    if (er) {\n      npm.commands.cache.add(arg, null, null, false, function (er, data) {\n        if (er) return cb(er)\n        log.silly('publish', data)\n        var cached = path.resolve(cachedPackageRoot(data), 'package') + '.tgz'\n        // *publish* lifecycle scripts aren't run when publishing a built artifact\n        // go to the next step directly\n        publish_(arg, data, isRetry, cached, cb)\n      })\n    } else {\n      var dir = arg\n      npm.commands.cache.add(dir, null, null, false, function (er, data) {\n        if (er) return cb(er)\n        log.silly('publish', data)\n        var cached = path.resolve(cachedPackageRoot(data), 'package') + '.tgz'\n        // `prepublish` and `prepare` are run by cache.add\n        chain(\n          [\n            [lifecycle, data, 'prepublishOnly', dir],\n            [publish_, dir, data, isRetry, cached],\n            [lifecycle, data, 'publish', dir],\n            [lifecycle, data, 'postpublish', dir]\n          ],\n          cb\n        )\n      })\n    }\n  })\n}\n\nfunction publish_ (arg, data, isRetry, cached, cb) {\n  if (!data) return cb(new Error('no package.json file found'))\n\n  var mappedConfig = getPublishConfig(\n    data.publishConfig,\n    npm.config,\n    npm.registry\n  )\n  var config = mappedConfig.config\n  var registry = mappedConfig.client\n\n  data._npmVersion = npm.version\n  data._nodeVersion = process.versions.node\n\n  delete data.modules\n  if (data.private) {\n    return cb(new Error(\n      'This package has been marked as private\\n' +\n      \"Remove the 'private' field from the package.json to publish it.\"\n    ))\n  }\n\n  mapToRegistry(data.name, config, function (er, registryURI, auth, registryBase) {\n    if (er) return cb(er)\n\n    // we just want the base registry URL in this case\n    log.verbose('publish', 'registryBase', registryBase)\n    log.silly('publish', 'uploading', cached)\n\n    data._npmUser = {\n      name: auth.username,\n      email: auth.email\n    }\n\n    var params = {\n      metadata: data,\n      body: createReadStream(cached),\n      auth: auth\n    }\n\n    // registry-frontdoor cares about the access level, which is only\n    // configurable for scoped packages\n    if (config.get('access')) {\n      if (!npa(data.name).scope && config.get('access') === 'restricted') {\n        return cb(new Error(\"Can't restrict access to unscoped packages.\"))\n      }\n\n      params.access = config.get('access')\n    }\n\n    log.showProgress('publish:' + data._id)\n    registry.publish(registryBase, params, function (er) {\n      if (er && er.code === 'EPUBLISHCONFLICT' &&\n          npm.config.get('force') && !isRetry) {\n        log.warn('publish', 'Forced publish over ' + data._id)\n        return npm.commands.unpublish([data._id], function (er) {\n          // ignore errors.  Use the force.  Reach out with your feelings.\n          // but if it fails again, then report the first error.\n          publish([arg], er || true, cb)\n        })\n      }\n      // report the unpublish error if this was a retry and unpublish failed\n      if (er && isRetry && isRetry !== true) return cb(isRetry)\n      if (er) return cb(er)\n      output('+ ' + data._id)\n      cb()\n    })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/get-publish-config.js":"var Conf = require('../config/core.js').Conf\nvar CachingRegClient = require('../cache/caching-client.js')\nvar log = require('npmlog')\n\nmodule.exports = getPublishConfig\n\nfunction getPublishConfig (publishConfig, defaultConfig, defaultClient) {\n  var config = defaultConfig\n  var client = defaultClient\n  log.verbose('getPublishConfig', publishConfig)\n  if (publishConfig) {\n    config = new Conf(defaultConfig)\n    config.save = defaultConfig.save.bind(defaultConfig)\n\n    // don't modify the actual publishConfig object, in case we have\n    // to set a login token or some other data.\n    config.unshift(Object.keys(publishConfig).reduce(function (s, k) {\n      s[k] = publishConfig[k]\n      return s\n    }, {}))\n    client = new CachingRegClient(config)\n  }\n\n  return { config: config, client: client }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/cache/caching-client.js":"module.exports = CachingRegistryClient\n\nvar path = require('path')\nvar fs = require('graceful-fs')\nvar url = require('url')\nvar assert = require('assert')\nvar inherits = require('util').inherits\n\nvar RegistryClient = require('npm-registry-client')\nvar npm = require('../npm.js')\nvar log = require('npmlog')\nvar getCacheStat = require('./get-stat.js')\nvar cacheFile = require('npm-cache-filename')\nvar mkdirp = require('mkdirp')\nvar rimraf = require('rimraf')\nvar chownr = require('chownr')\nvar writeFile = require('write-file-atomic')\nvar parseJSON = require('../utils/parse-json')\n\nfunction CachingRegistryClient (config) {\n  RegistryClient.call(this, adaptConfig(config))\n\n  this._mapToCache = cacheFile(config.get('cache'))\n\n  // swizzle in our custom cache invalidation logic\n  this._request = this.request\n  this.request = this._invalidatingRequest\n  this.get = get\n}\ninherits(CachingRegistryClient, RegistryClient)\n\nCachingRegistryClient.prototype._invalidatingRequest = function (uri, params, cb) {\n  var client = this\n  this._request(uri, params, function () {\n    var args = arguments\n\n    var method = params.method\n    if (method !== 'HEAD' && method !== 'GET') {\n      var invalidated = client._mapToCache(uri)\n      // invalidate cache\n      //\n      // This is irrelevant for commands that do etag / last-modified caching,\n      // but ls and view also have a timed cache, so this keeps the user from\n      // thinking that it didn't work when it did.\n      // Note that failure is an acceptable option here, since the only\n      // result will be a stale cache for some helper commands.\n      log.verbose('request', 'invalidating', invalidated, 'on', method)\n      return rimraf(invalidated, function () {\n        cb.apply(undefined, args)\n      })\n    }\n\n    cb.apply(undefined, args)\n  })\n}\n\nfunction get (uri, params, cb) {\n  assert(typeof uri === 'string', 'must pass registry URI to get')\n  assert(params && typeof params === 'object', 'must pass params to get')\n  assert(typeof cb === 'function', 'must pass callback to get')\n\n  var parsed = url.parse(uri)\n  assert(\n    parsed.protocol === 'http:' || parsed.protocol === 'https:',\n    'must have a URL that starts with http: or https:'\n  )\n\n  var cacheBase = cacheFile(npm.config.get('cache'))(uri)\n  var cachePath = path.join(cacheBase, '.cache.json')\n\n  // If the GET is part of a write operation (PUT or DELETE), then\n  // skip past the cache entirely, but still save the results.\n  if (uri.match(/\\?write=true$/)) {\n    log.verbose('get', 'GET as part of write; not caching result')\n    return get_.call(this, uri, cachePath, params, cb)\n  }\n\n  if (params.skipCache) {\n    return get_.call(this, uri, cachePath, params, cb)\n  }\n\n  var client = this\n  fs.stat(cachePath, function (er, stat) {\n    if (!er) {\n      fs.readFile(cachePath, function (er, data) {\n        data = parseJSON.noExceptions(data)\n\n        params.stat = stat\n        params.data = data\n\n        get_.call(client, uri, cachePath, params, cb)\n      })\n    } else {\n      get_.call(client, uri, cachePath, params, cb)\n    }\n  })\n}\n\nfunction get_ (uri, cachePath, params, cb) {\n  var staleOk = params.staleOk === undefined ? false : params.staleOk\n  var timeout = params.timeout === undefined ? -1 : params.timeout\n  var data = params.data\n  var stat = params.stat\n  var etag\n  var lastModified\n\n  timeout = Math.min(timeout, npm.config.get('cache-max') || 0)\n  timeout = Math.max(timeout, npm.config.get('cache-min') || -Infinity)\n  if (process.env.COMP_CWORD !== undefined &&\n      process.env.COMP_LINE !== undefined &&\n      process.env.COMP_POINT !== undefined) {\n    timeout = Math.max(timeout, 60000)\n  }\n\n  if (data) {\n    if (data._etag) etag = data._etag\n    if (data._lastModified) lastModified = data._lastModified\n\n    data._cached = true\n\n    if (stat && timeout && timeout > 0) {\n      if ((Date.now() - stat.mtime.getTime()) / 1000 < timeout) {\n        log.verbose('get', uri, 'not expired, no request')\n        delete data._etag\n        delete data._lastModified\n        return cb(null, data, JSON.stringify(data), { statusCode: 304 })\n      }\n\n      if (staleOk) {\n        log.verbose('get', uri, 'staleOk, background update')\n        delete data._etag\n        delete data._lastModified\n        process.nextTick(\n          cb.bind(null, null, data, JSON.stringify(data), { statusCode: 304 })\n        )\n        cb = function () {}\n      }\n    }\n  }\n\n  var options = {\n    etag: etag,\n    lastModified: lastModified,\n    follow: params.follow,\n    auth: params.auth\n  }\n  this.request(uri, options, function (er, remoteData, raw, response) {\n    // if we get an error talking to the registry, but we have it\n    // from the cache, then just pretend we got it.\n    if (er && cachePath && data && !data.error) {\n      er = null\n      response = { statusCode: 304 }\n    }\n\n    if (response) {\n      log.silly('get', 'cb', [response.statusCode, response.headers])\n      if (response.statusCode === 304 && (etag || lastModified)) {\n        remoteData = data\n        log.verbose(etag ? 'etag' : 'lastModified', uri + ' from cache')\n      }\n    }\n\n    data = remoteData\n    if (!data) er = er || new Error('failed to fetch from registry: ' + uri)\n\n    if (er) return cb(er, data, raw, response)\n\n    saveToCache(cachePath, data, saved)\n\n    // just give the write the old college try.  if it fails, whatever.\n    function saved () {\n      delete data._etag\n      delete data._lastModified\n      cb(er, data, raw, response)\n    }\n\n    function saveToCache (cachePath, data, saved) {\n      log.verbose('get', 'saving', data.name, 'to', cachePath)\n      getCacheStat(function (er, st) {\n        mkdirp(path.dirname(cachePath), function (er, made) {\n          if (er) return saved()\n\n          writeFile(cachePath, JSON.stringify(data), function (er) {\n            if (er) return saved()\n\n            chownr(made || cachePath, st.uid, st.gid, saved)\n          })\n        })\n      })\n    }\n  })\n}\n\nfunction adaptConfig (config) {\n  return {\n    proxy: {\n      http: config.get('proxy'),\n      https: config.get('https-proxy'),\n      localAddress: config.get('local-address')\n    },\n    ssl: {\n      certificate: config.get('cert'),\n      key: config.get('key'),\n      ca: config.get('ca'),\n      strict: config.get('strict-ssl')\n    },\n    retry: {\n      retries: config.get('fetch-retries'),\n      factor: config.get('fetch-retry-factor'),\n      minTimeout: config.get('fetch-retry-mintimeout'),\n      maxTimeout: config.get('fetch-retry-maxtimeout')\n    },\n    userAgent: config.get('user-agent'),\n    log: log,\n    defaultTag: config.get('tag'),\n    couchToken: config.get('_token'),\n    maxSockets: config.get('maxsockets'),\n    scope: npm.projectScope\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/npm-registry-client/index.js":"// utilities for working with the js-registry site.\n\nmodule.exports = RegClient\n\nvar npmlog\ntry {\n  npmlog = require('npmlog')\n} catch (er) {\n  npmlog = {\n    error: noop,\n    warn: noop,\n    info: noop,\n    verbose: noop,\n    silly: noop,\n    http: noop,\n    pause: noop,\n    resume: noop\n  }\n}\n\nfunction noop () {}\n\nfunction RegClient (config) {\n  this.config = Object.create(config || {})\n\n  this.config.proxy = this.config.proxy || {}\n  if (!this.config.proxy.https && this.config.proxy.http) {\n    this.config.proxy.https = this.config.proxy.http\n  }\n\n  this.config.ssl = this.config.ssl || {}\n  if (this.config.ssl.strict === undefined) this.config.ssl.strict = true\n\n  this.config.retry = this.config.retry || {}\n  if (typeof this.config.retry.retries !== 'number') this.config.retry.retries = 2\n  if (typeof this.config.retry.factor !== 'number') this.config.retry.factor = 10\n  if (typeof this.config.retry.minTimeout !== 'number') this.config.retry.minTimeout = 10000\n  if (typeof this.config.retry.maxTimeout !== 'number') this.config.retry.maxTimeout = 60000\n  if (typeof this.config.maxSockets !== 'number') this.config.maxSockets = 50\n\n  this.config.userAgent = this.config.userAgent || 'node/' + process.version\n  this.config.defaultTag = this.config.defaultTag || 'latest'\n\n  this.log = this.config.log || npmlog\n  delete this.config.log\n\n  var client = this\n  client.access = require('./lib/access')\n  client.adduser = require('./lib/adduser')\n  client.attempt = require('./lib/attempt')\n  client.authify = require('./lib/authify')\n  client.deprecate = require('./lib/deprecate')\n  client.distTags = Object.create(client)\n  client.distTags.add = require('./lib/dist-tags/add')\n  client.distTags.fetch = require('./lib/dist-tags/fetch')\n  client.distTags.rm = require('./lib/dist-tags/rm')\n  client.distTags.set = require('./lib/dist-tags/set')\n  client.distTags.update = require('./lib/dist-tags/update')\n  client.fetch = require('./lib/fetch')\n  client.get = require('./lib/get')\n  client.initialize = require('./lib/initialize')\n  client.logout = require('./lib/logout')\n  client.ping = require('./lib/ping')\n  client.publish = require('./lib/publish')\n  client.request = require('./lib/request')\n  client.sendAnonymousCLIMetrics = require('./lib/send-anonymous-CLI-metrics')\n  client.star = require('./lib/star')\n  client.stars = require('./lib/stars')\n  client.tag = require('./lib/tag')\n  client.team = require('./lib/team')\n  client.unpublish = require('./lib/unpublish')\n  client.whoami = require('./lib/whoami')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/rebuild.js":"\nmodule.exports = rebuild\n\nvar readInstalled = require('read-installed')\nvar semver = require('semver')\nvar log = require('npmlog')\nvar npm = require('./npm.js')\nvar npa = require('npm-package-arg')\nvar usage = require('./utils/usage')\nvar output = require('./utils/output.js')\n\nrebuild.usage = usage(\n  'rebuild',\n  'npm rebuild [[<@scope>/<name>]...]'\n)\n\nrebuild.completion = require('./utils/completion/installed-deep.js')\n\nfunction rebuild (args, cb) {\n  var opt = { depth: npm.config.get('depth'), dev: true }\n  readInstalled(npm.prefix, opt, function (er, data) {\n    log.info('readInstalled', typeof data)\n    if (er) return cb(er)\n    var set = filter(data, args)\n    var folders = Object.keys(set).filter(function (f) {\n      return f !== npm.prefix\n    })\n    if (!folders.length) return cb()\n    log.silly('rebuild set', folders)\n    cleanBuild(folders, set, cb)\n  })\n}\n\nfunction cleanBuild (folders, set, cb) {\n  npm.commands.build(folders, function (er) {\n    if (er) return cb(er)\n    output(folders.map(function (f) {\n      return set[f] + ' ' + f\n    }).join('\\n'))\n    cb()\n  })\n}\n\nfunction filter (data, args, set, seen) {\n  if (!set) set = {}\n  if (!seen) seen = {}\n  if (set.hasOwnProperty(data.path)) return set\n  if (seen.hasOwnProperty(data.path)) return set\n  seen[data.path] = true\n  var pass\n  if (!args.length) pass = true // rebuild everything\n  else if (data.name && data._id) {\n    for (var i = 0, l = args.length; i < l; i++) {\n      var arg = args[i]\n      var nv = npa(arg)\n      var n = nv.name\n      var v = nv.rawSpec\n      if (n !== data.name) continue\n      if (!semver.satisfies(data.version, v, true)) continue\n      pass = true\n      break\n    }\n  }\n  if (pass && data._id) {\n    log.verbose('rebuild', 'path, id', [data.path, data._id])\n    set[data.path] = data._id\n  }\n  // need to also dive through kids, always.\n  // since this isn't an install these won't get auto-built unless\n  // they're not dependencies.\n  Object.keys(data.dependencies || {}).forEach(function (d) {\n    // return\n    var dep = data.dependencies[d]\n    if (typeof dep === 'string') return\n    filter(dep, args, set, seen)\n  })\n  return set\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/repo.js":"module.exports = repo\n\nrepo.usage = 'npm repo [<pkg>]'\n\nvar npm = require('./npm.js')\nvar opener = require('opener')\nvar hostedGitInfo = require('hosted-git-info')\nvar url_ = require('url')\nvar fetchPackageMetadata = require('./fetch-package-metadata.js')\n\nrepo.completion = function (opts, cb) {\n  // FIXME: there used to be registry completion here, but it stopped making\n  // sense somewhere around 50,000 packages on the registry\n  cb()\n}\n\nfunction repo (args, cb) {\n  var n = args.length ? args[0] : '.'\n  fetchPackageMetadata(n, '.', {fullMetadata: true}, function (er, d) {\n    if (er) return cb(er)\n    getUrlAndOpen(d, cb)\n  })\n}\n\nfunction getUrlAndOpen (d, cb) {\n  var r = d.repository\n  if (!r) return cb(new Error('no repository'))\n  // XXX remove this when npm@v1.3.10 from node 0.10 is deprecated\n  // from https://github.com/npm/npm-www/issues/418\n  var info = hostedGitInfo.fromUrl(r.url)\n  var url = info ? info.browse() : unknownHostedUrl(r.url)\n\n  if (!url) return cb(new Error('no repository: could not get url'))\n\n  opener(url, { command: npm.config.get('browser') }, cb)\n}\n\nfunction unknownHostedUrl (url) {\n  try {\n    var idx = url.indexOf('@')\n    if (idx !== -1) {\n      url = url.slice(idx + 1).replace(/:([^\\d]+)/, '/$1')\n    }\n    url = url_.parse(url)\n    var protocol = url.protocol === 'https:'\n                 ? 'https:'\n                 : 'http:'\n    return protocol + '//' + (url.host || '') +\n      url.path.replace(/\\.git$/, '')\n  } catch (e) {}\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/restart.js":"module.exports = require('./utils/lifecycle.js').cmd('restart')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/root.js":"module.exports = root\n\nvar npm = require('./npm.js')\nvar output = require('./utils/output.js')\n\nroot.usage = 'npm root [-g]'\n\nfunction root (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n  if (!silent) output(npm.dir)\n  process.nextTick(cb.bind(this, null, npm.dir))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/run-script.js":"module.exports = runScript\n\nvar lifecycle = require('./utils/lifecycle.js')\nvar npm = require('./npm.js')\nvar path = require('path')\nvar readJson = require('read-package-json')\nvar log = require('npmlog')\nvar chain = require('slide').chain\nvar usage = require('./utils/usage')\nvar output = require('./utils/output.js')\n\nrunScript.usage = usage(\n  'run-script',\n  'npm run-script <command> [-- <args>...]'\n)\n\nrunScript.completion = function (opts, cb) {\n  // see if there's already a package specified.\n  var argv = opts.conf.argv.remain\n\n  if (argv.length >= 4) return cb()\n\n  if (argv.length === 3) {\n    // either specified a script locally, in which case, done,\n    // or a package, in which case, complete against its scripts\n    var json = path.join(npm.localPrefix, 'package.json')\n    return readJson(json, function (er, d) {\n      if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n      if (er) d = {}\n      var scripts = Object.keys(d.scripts || {})\n      console.error('local scripts', scripts)\n      if (scripts.indexOf(argv[2]) !== -1) return cb()\n      // ok, try to find out which package it was, then\n      var pref = npm.config.get('global') ? npm.config.get('prefix')\n               : npm.localPrefix\n      var pkgDir = path.resolve(pref, 'node_modules', argv[2], 'package.json')\n      readJson(pkgDir, function (er, d) {\n        if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n        if (er) d = {}\n        var scripts = Object.keys(d.scripts || {})\n        return cb(null, scripts)\n      })\n    })\n  }\n\n  readJson(path.join(npm.localPrefix, 'package.json'), function (er, d) {\n    if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n    d = d || {}\n    cb(null, Object.keys(d.scripts || {}))\n  })\n}\n\nfunction runScript (args, cb) {\n  if (!args.length) return list(cb)\n\n  var pkgdir = npm.localPrefix\n  var cmd = args.shift()\n\n  readJson(path.resolve(pkgdir, 'package.json'), function (er, d) {\n    if (er) return cb(er)\n    run(d, pkgdir, cmd, args, cb)\n  })\n}\n\nfunction list (cb) {\n  var json = path.join(npm.localPrefix, 'package.json')\n  var cmdList = [\n    'publish',\n    'install',\n    'uninstall',\n    'test',\n    'stop',\n    'start',\n    'restart',\n    'version'\n  ].reduce(function (l, p) {\n    return l.concat(['pre' + p, p, 'post' + p])\n  }, [])\n  return readJson(json, function (er, d) {\n    if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n    if (er) d = {}\n    var allScripts = Object.keys(d.scripts || {})\n    var scripts = []\n    var runScripts = []\n    allScripts.forEach(function (script) {\n      if (cmdList.indexOf(script) !== -1) scripts.push(script)\n      else runScripts.push(script)\n    })\n\n    if (log.level === 'silent') {\n      return cb(null, allScripts)\n    }\n\n    if (npm.config.get('json')) {\n      output(JSON.stringify(d.scripts || {}, null, 2))\n      return cb(null, allScripts)\n    }\n\n    if (npm.config.get('parseable')) {\n      allScripts.forEach(function (script) {\n        output(script + ':' + d.scripts[script])\n      })\n      return cb(null, allScripts)\n    }\n\n    var s = '\\n    '\n    var prefix = '  '\n    if (scripts.length) {\n      output('Lifecycle scripts included in %s:', d.name)\n    }\n    scripts.forEach(function (script) {\n      output(prefix + script + s + d.scripts[script])\n    })\n    if (!scripts.length && runScripts.length) {\n      output('Scripts available in %s via `npm run-script`:', d.name)\n    } else if (runScripts.length) {\n      output('\\navailable via `npm run-script`:')\n    }\n    runScripts.forEach(function (script) {\n      output(prefix + script + s + d.scripts[script])\n    })\n    return cb(null, allScripts)\n  })\n}\n\nfunction run (pkg, wd, cmd, args, cb) {\n  if (!pkg.scripts) pkg.scripts = {}\n\n  var cmds\n  if (cmd === 'restart' && !pkg.scripts.restart) {\n    cmds = [\n      'prestop', 'stop', 'poststop',\n      'restart',\n      'prestart', 'start', 'poststart'\n    ]\n  } else {\n    if (!pkg.scripts[cmd]) {\n      if (cmd === 'test') {\n        pkg.scripts.test = 'echo \\'Error: no test specified\\''\n      } else if (cmd === 'env') {\n        if (process.platform === 'win32') {\n          log.verbose('run-script using default platform env: SET (Windows)')\n          pkg.scripts[cmd] = 'SET'\n        } else {\n          log.verbose('run-script using default platform env: env (Unix)')\n          pkg.scripts[cmd] = 'env'\n        }\n      } else if (npm.config.get('if-present')) {\n        return cb(null)\n      } else {\n        return cb(new Error('missing script: ' + cmd))\n      }\n    }\n    cmds = [cmd]\n  }\n\n  if (!cmd.match(/^(pre|post)/)) {\n    cmds = ['pre' + cmd].concat(cmds).concat('post' + cmd)\n  }\n\n  log.verbose('run-script', cmds)\n  chain(cmds.map(function (c) {\n    // pass cli arguments after -- to script.\n    if (pkg.scripts[c] && c === cmd) {\n      pkg.scripts[c] = pkg.scripts[c] + joinArgs(args)\n    }\n\n    // when running scripts explicitly, assume that they're trusted.\n    return [lifecycle, pkg, c, wd, true]\n  }), cb)\n}\n\n// join arguments after '--' and pass them to script,\n// handle special characters such as ', \", ' '.\nfunction joinArgs (args) {\n  var joinedArgs = ''\n  args.forEach(function (arg) {\n    joinedArgs += ' \"' + arg.replace(/\"/g, '\\\\\"') + '\"'\n  })\n  return joinedArgs\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/search.js":"'use strict'\n\nmodule.exports = exports = search\n\nvar npm = require('./npm.js')\nvar allPackageSearch = require('./search/all-package-search')\nvar esearch = require('./search/esearch.js')\nvar formatPackageStream = require('./search/format-package-stream.js')\nvar usage = require('./utils/usage')\nvar output = require('./utils/output.js')\nvar log = require('npmlog')\nvar ms = require('mississippi')\n\nsearch.usage = usage(\n  'search',\n  'npm search [--long] [search terms ...]'\n)\n\nsearch.completion = function (opts, cb) {\n  cb(null, [])\n}\n\nfunction search (args, cb) {\n  var searchOpts = {\n    description: npm.config.get('description'),\n    exclude: prepareExcludes(npm.config.get('searchexclude')),\n    include: prepareIncludes(args, npm.config.get('searchopts')),\n    limit: npm.config.get('searchlimit'),\n    log: log,\n    staleness: npm.config.get('searchstaleness'),\n    unicode: npm.config.get('unicode')\n  }\n\n  if (searchOpts.include.length === 0) {\n    return cb(new Error('search must be called with arguments'))\n  }\n\n  // Used later to figure out whether we had any packages go out\n  var anyOutput = false\n\n  var entriesStream = ms.through.obj()\n\n  var esearchWritten = false\n  esearch(searchOpts).on('data', function (pkg) {\n    entriesStream.write(pkg)\n    !esearchWritten && (esearchWritten = true)\n  }).on('error', function (e) {\n    if (esearchWritten) {\n      // If esearch errored after already starting output, we can't fall back.\n      return entriesStream.emit('error', e)\n    }\n    log.warn('search', 'fast search endpoint errored. Using old search.')\n    allPackageSearch(searchOpts).on('data', function (pkg) {\n      entriesStream.write(pkg)\n    }).on('error', function (e) {\n      entriesStream.emit('error', e)\n    }).on('end', function () {\n      entriesStream.end()\n    })\n  }).on('end', function () {\n    entriesStream.end()\n  })\n\n  // Grab a configured output stream that will spit out packages in the\n  // desired format.\n  var outputStream = formatPackageStream({\n    args: args, // --searchinclude options are not highlighted\n    long: npm.config.get('long'),\n    description: npm.config.get('description'),\n    json: npm.config.get('json'),\n    parseable: npm.config.get('parseable'),\n    color: npm.color\n  })\n  outputStream.on('data', function (chunk) {\n    if (!anyOutput) { anyOutput = true }\n    output(chunk.toString('utf8'))\n  })\n\n  log.silly('search', 'searching packages')\n  ms.pipe(entriesStream, outputStream, function (er) {\n    if (er) return cb(er)\n    if (!anyOutput && !npm.config.get('json') && !npm.config.get('parseable')) {\n      output('No matches found for ' + (args.map(JSON.stringify).join(' ')))\n    }\n    log.silly('search', 'search completed')\n    log.clearProgress()\n    cb(null, {})\n  })\n}\n\nfunction prepareIncludes (args, searchopts) {\n  if (typeof searchopts !== 'string') searchopts = ''\n  return searchopts.split(/\\s+/).concat(args).map(function (s) {\n    return s.toLowerCase()\n  }).filter(function (s) { return s })\n}\n\nfunction prepareExcludes (searchexclude) {\n  var exclude\n  if (typeof searchexclude === 'string') {\n    exclude = searchexclude.split(/\\s+/)\n  } else {\n    exclude = []\n  }\n  return exclude.map(function (s) {\n    return s.toLowerCase()\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/search/all-package-search.js":"var ms = require('mississippi')\nvar allPackageMetadata = require('./all-package-metadata')\nvar packageFilter = require('./package-filter.js')\n\nmodule.exports = allPackageSearch\nfunction allPackageSearch (opts) {\n  var searchSection = (opts.unicode ? ' ' : '') + 'search'\n\n  // Get a stream with *all* the packages. This takes care of dealing\n  // with the local cache as well, but that's an internal detail.\n  var allEntriesStream = allPackageMetadata(opts.staleness)\n\n  // Grab a stream that filters those packages according to given params.\n  var filterStream = streamFilter(function (pkg) {\n    opts.log.gauge.pulse('search')\n    opts.log.gauge.show({section: searchSection, logline: 'scanning ' + pkg.name})\n    // Simply 'true' if the package matches search parameters.\n    var match = packageFilter(pkg, opts.include, opts.exclude, {\n      description: opts.description\n    })\n    return match\n  })\n  return ms.pipeline.obj(allEntriesStream, filterStream)\n}\n\nfunction streamFilter (filter) {\n  return ms.through.obj(function (data, enc, cb) {\n    if (filter(data)) {\n      this.push(standardizePkg(data))\n    }\n    cb()\n  })\n}\n\nfunction standardizePkg (data) {\n  return {\n    name: data.name,\n    description: data.description,\n    maintainers: (data.maintainers || []).map(function (m) {\n      return { username: m.name, email: m.email }\n    }),\n    keywords: data.keywords || [],\n    version: Object.keys(data.versions || {})[0] || [],\n    date: (\n      data.time &&\n      data.time.modified &&\n      new Date(data.time.modified)\n    ) || null\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/index.js":"module.exports.pipe = require('pump')\nmodule.exports.each = require('stream-each')\nmodule.exports.pipeline = require('pumpify')\nmodule.exports.duplex = require('duplexify')\nmodule.exports.through = require('through2')\nmodule.exports.concat = require('concat-stream')\nmodule.exports.finished = require('end-of-stream')\nmodule.exports.from = require('from2')\nmodule.exports.to = require('flush-write-stream')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/pump/index.js":"var once = require('once')\nvar eos = require('end-of-stream')\nvar fs = require('fs') // we only need fs to get the ReadStream and WriteStream prototypes\n\nvar noop = function () {}\n\nvar isFn = function (fn) {\n  return typeof fn === 'function'\n}\n\nvar isFS = function (stream) {\n  if (!fs) return false // browser\n  return (stream instanceof (fs.ReadStream || noop) || stream instanceof (fs.WriteStream || noop)) && isFn(stream.close)\n}\n\nvar isRequest = function (stream) {\n  return stream.setHeader && isFn(stream.abort)\n}\n\nvar destroyer = function (stream, reading, writing, callback) {\n  callback = once(callback)\n\n  var closed = false\n  stream.on('close', function () {\n    closed = true\n  })\n\n  eos(stream, {readable: reading, writable: writing}, function (err) {\n    if (err) return callback(err)\n    closed = true\n    callback()\n  })\n\n  var destroyed = false\n  return function (err) {\n    if (closed) return\n    if (destroyed) return\n    destroyed = true\n\n    if (isFS(stream)) return stream.close() // use close for fs streams to avoid fd leaks\n    if (isRequest(stream)) return stream.abort() // request.destroy just do .end - .abort is what we want\n\n    if (isFn(stream.destroy)) return stream.destroy()\n\n    callback(err || new Error('stream was destroyed'))\n  }\n}\n\nvar call = function (fn) {\n  fn()\n}\n\nvar pipe = function (from, to) {\n  return from.pipe(to)\n}\n\nvar pump = function () {\n  var streams = Array.prototype.slice.call(arguments)\n  var callback = isFn(streams[streams.length - 1] || noop) && streams.pop() || noop\n\n  if (Array.isArray(streams[0])) streams = streams[0]\n  if (streams.length < 2) throw new Error('pump requires two streams per minimum')\n\n  var error\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1\n    var writing = i > 0\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err\n      if (err) destroys.forEach(call)\n      if (reading) return\n      destroys.forEach(call)\n      callback(error)\n    })\n  })\n\n  return streams.reduce(pipe)\n}\n\nmodule.exports = pump\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/end-of-stream/index.js":"var once = require('once');\n\nvar noop = function() {};\n\nvar isRequest = function(stream) {\n\treturn stream.setHeader && typeof stream.abort === 'function';\n};\n\nvar isChildProcess = function(stream) {\n\treturn stream.stdio && Array.isArray(stream.stdio) && stream.stdio.length === 3\n};\n\nvar eos = function(stream, opts, callback) {\n\tif (typeof opts === 'function') return eos(stream, null, opts);\n\tif (!opts) opts = {};\n\n\tcallback = once(callback || noop);\n\n\tvar ws = stream._writableState;\n\tvar rs = stream._readableState;\n\tvar readable = opts.readable || (opts.readable !== false && stream.readable);\n\tvar writable = opts.writable || (opts.writable !== false && stream.writable);\n\n\tvar onlegacyfinish = function() {\n\t\tif (!stream.writable) onfinish();\n\t};\n\n\tvar onfinish = function() {\n\t\twritable = false;\n\t\tif (!readable) callback();\n\t};\n\n\tvar onend = function() {\n\t\treadable = false;\n\t\tif (!writable) callback();\n\t};\n\n\tvar onexit = function(exitCode) {\n\t\tcallback(exitCode ? new Error('exited with error code: ' + exitCode) : null);\n\t};\n\n\tvar onclose = function() {\n\t\tif (readable && !(rs && rs.ended)) return callback(new Error('premature close'));\n\t\tif (writable && !(ws && ws.ended)) return callback(new Error('premature close'));\n\t};\n\n\tvar onrequest = function() {\n\t\tstream.req.on('finish', onfinish);\n\t};\n\n\tif (isRequest(stream)) {\n\t\tstream.on('complete', onfinish);\n\t\tstream.on('abort', onclose);\n\t\tif (stream.req) onrequest();\n\t\telse stream.on('request', onrequest);\n\t} else if (writable && !ws) { // legacy streams\n\t\tstream.on('end', onlegacyfinish);\n\t\tstream.on('close', onlegacyfinish);\n\t}\n\n\tif (isChildProcess(stream)) stream.on('exit', onexit);\n\n\tstream.on('end', onend);\n\tstream.on('finish', onfinish);\n\tif (opts.error !== false) stream.on('error', callback);\n\tstream.on('close', onclose);\n\n\treturn function() {\n\t\tstream.removeListener('complete', onfinish);\n\t\tstream.removeListener('abort', onclose);\n\t\tstream.removeListener('request', onrequest);\n\t\tif (stream.req) stream.req.removeListener('finish', onfinish);\n\t\tstream.removeListener('end', onlegacyfinish);\n\t\tstream.removeListener('close', onlegacyfinish);\n\t\tstream.removeListener('finish', onfinish);\n\t\tstream.removeListener('exit', onexit);\n\t\tstream.removeListener('end', onend);\n\t\tstream.removeListener('error', callback);\n\t\tstream.removeListener('close', onclose);\n\t};\n};\n\nmodule.exports = eos;","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/end-of-stream/node_modules/once/once.js":"var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/stream-each/index.js":"var eos = require('end-of-stream')\nvar shift = require('stream-shift')\n\nmodule.exports = each\n\nfunction each (stream, fn, cb) {\n  var want = true\n  var error = null\n  var ended = false\n  var running = false\n\n  stream.on('readable', onreadable)\n  onreadable()\n\n  if (cb) eos(stream, {readable: true, writable: false}, done)\n  return stream\n\n  function done (err) {\n    if (!error) error = err\n    ended = true\n    if (!running) cb(error)\n  }\n\n  function onreadable () {\n    if (want) read()\n  }\n\n  function afterRead (err) {\n    running = false\n\n    if (err) {\n      error = err\n      if (ended) return cb(error)\n      stream.destroy(err)\n      return\n    }\n    if (ended) return cb(error)\n    read()\n  }\n\n  function read () {\n    if (ended || running) return\n    want = false\n\n    var data = shift(stream)\n    if (!data) {\n      want = true\n      return\n    }\n\n    running = true\n    fn(data, afterRead)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/stream-each/node_modules/stream-shift/index.js":"module.exports = shift\n\nfunction shift (stream) {\n  var rs = stream._readableState\n  if (!rs) return null\n  return rs.objectMode ? stream.read() : stream.read(getStateLength(rs))\n}\n\nfunction getStateLength (state) {\n  if (state.buffer.length) {\n    // Since node 6.3.0 state.buffer is a BufferList not an array\n    if (state.buffer.head) {\n      return state.buffer.head.data.length\n    }\n\n    return state.buffer[0].length\n  }\n\n  return state.length\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/pumpify/index.js":"var pump = require('pump')\nvar inherits = require('inherits')\nvar Duplexify = require('duplexify')\n\nvar toArray = function(args) {\n  if (!args.length) return []\n  return Array.isArray(args[0]) ? args[0] : Array.prototype.slice.call(args)\n}\n\nvar define = function(opts) {\n  var Pumpify = function() {\n    var streams = toArray(arguments)\n    if (!(this instanceof Pumpify)) return new Pumpify(streams)\n    Duplexify.call(this, null, null, opts)\n    if (streams.length) this.setPipeline(streams)\n  }\n\n  inherits(Pumpify, Duplexify)\n\n  Pumpify.prototype.setPipeline = function() {\n    var streams = toArray(arguments)\n    var self = this\n    var ended = false\n    var w = streams[0]\n    var r = streams[streams.length-1]\n\n    r = r.readable ? r : null\n    w = w.writable ? w : null\n\n    var onclose = function() {\n      streams[0].emit('error', new Error('stream was destroyed'))\n    }\n\n    this.on('close', onclose)\n    this.on('prefinish', function() {\n      if (!ended) self.cork()\n    })\n\n    pump(streams, function(err) {\n      self.removeListener('close', onclose)\n      if (err) return self.destroy(err)\n      ended = true\n      self.uncork()\n    })\n\n    if (this.destroyed) return onclose()\n    this.setWritable(w)\n    this.setReadable(r)\n  }\n\n  return Pumpify\n}\n\nmodule.exports = define({destroy:false})\nmodule.exports.obj = define({destroy:false, objectMode:true, highWaterMark:16})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/duplexify/index.js":"var stream = require('readable-stream')\nvar eos = require('end-of-stream')\nvar inherits = require('inherits')\nvar shift = require('stream-shift')\n\nvar SIGNAL_FLUSH = new Buffer([0])\n\nvar onuncork = function(self, fn) {\n  if (self._corked) self.once('uncork', fn)\n  else fn()\n}\n\nvar destroyer = function(self, end) {\n  return function(err) {\n    if (err) self.destroy(err.message === 'premature close' ? null : err)\n    else if (end && !self._ended) self.end()\n  }\n}\n\nvar end = function(ws, fn) {\n  if (!ws) return fn()\n  if (ws._writableState && ws._writableState.finished) return fn()\n  if (ws._writableState) return ws.end(fn)\n  ws.end()\n  fn()\n}\n\nvar toStreams2 = function(rs) {\n  return new (stream.Readable)({objectMode:true, highWaterMark:16}).wrap(rs)\n}\n\nvar Duplexify = function(writable, readable, opts) {\n  if (!(this instanceof Duplexify)) return new Duplexify(writable, readable, opts)\n  stream.Duplex.call(this, opts)\n\n  this._writable = null\n  this._readable = null\n  this._readable2 = null\n\n  this._forwardDestroy = !opts || opts.destroy !== false\n  this._forwardEnd = !opts || opts.end !== false\n  this._corked = 1 // start corked\n  this._ondrain = null\n  this._drained = false\n  this._forwarding = false\n  this._unwrite = null\n  this._unread = null\n  this._ended = false\n\n  this.destroyed = false\n\n  if (writable) this.setWritable(writable)\n  if (readable) this.setReadable(readable)\n}\n\ninherits(Duplexify, stream.Duplex)\n\nDuplexify.obj = function(writable, readable, opts) {\n  if (!opts) opts = {}\n  opts.objectMode = true\n  opts.highWaterMark = 16\n  return new Duplexify(writable, readable, opts)\n}\n\nDuplexify.prototype.cork = function() {\n  if (++this._corked === 1) this.emit('cork')\n}\n\nDuplexify.prototype.uncork = function() {\n  if (this._corked && --this._corked === 0) this.emit('uncork')\n}\n\nDuplexify.prototype.setWritable = function(writable) {\n  if (this._unwrite) this._unwrite()\n\n  if (this.destroyed) {\n    if (writable && writable.destroy) writable.destroy()\n    return\n  }\n\n  if (writable === null || writable === false) {\n    this.end()\n    return\n  }\n\n  var self = this\n  var unend = eos(writable, {writable:true, readable:false}, destroyer(this, this._forwardEnd))\n\n  var ondrain = function() {\n    var ondrain = self._ondrain\n    self._ondrain = null\n    if (ondrain) ondrain()\n  }\n\n  var clear = function() {\n    self._writable.removeListener('drain', ondrain)\n    unend()\n  }\n\n  if (this._unwrite) process.nextTick(ondrain) // force a drain on stream reset to avoid livelocks\n\n  this._writable = writable\n  this._writable.on('drain', ondrain)\n  this._unwrite = clear\n\n  this.uncork() // always uncork setWritable\n}\n\nDuplexify.prototype.setReadable = function(readable) {\n  if (this._unread) this._unread()\n\n  if (this.destroyed) {\n    if (readable && readable.destroy) readable.destroy()\n    return\n  }\n\n  if (readable === null || readable === false) {\n    this.push(null)\n    this.resume()\n    return\n  }\n\n  var self = this\n  var unend = eos(readable, {writable:false, readable:true}, destroyer(this))\n\n  var onreadable = function() {\n    self._forward()\n  }\n\n  var onend = function() {\n    self.push(null)\n  }\n\n  var clear = function() {\n    self._readable2.removeListener('readable', onreadable)\n    self._readable2.removeListener('end', onend)\n    unend()\n  }\n\n  this._drained = true\n  this._readable = readable\n  this._readable2 = readable._readableState ? readable : toStreams2(readable)\n  this._readable2.on('readable', onreadable)\n  this._readable2.on('end', onend)\n  this._unread = clear\n\n  this._forward()\n}\n\nDuplexify.prototype._read = function() {\n  this._drained = true\n  this._forward()\n}\n\nDuplexify.prototype._forward = function() {\n  if (this._forwarding || !this._readable2 || !this._drained) return\n  this._forwarding = true\n\n  var data\n\n  while (this._drained && (data = shift(this._readable2)) !== null) {\n    if (this.destroyed) continue\n    this._drained = this.push(data)\n  }\n\n  this._forwarding = false\n}\n\nDuplexify.prototype.destroy = function(err) {\n  if (this.destroyed) return\n  this.destroyed = true\n\n  var self = this\n  process.nextTick(function() {\n    self._destroy(err)\n  })\n}\n\nDuplexify.prototype._destroy = function(err) {\n  if (err) {\n    var ondrain = this._ondrain\n    this._ondrain = null\n    if (ondrain) ondrain(err)\n    else this.emit('error', err)\n  }\n\n  if (this._forwardDestroy) {\n    if (this._readable && this._readable.destroy) this._readable.destroy()\n    if (this._writable && this._writable.destroy) this._writable.destroy()\n  }\n\n  this.emit('close')\n}\n\nDuplexify.prototype._write = function(data, enc, cb) {\n  if (this.destroyed) return cb()\n  if (this._corked) return onuncork(this, this._write.bind(this, data, enc, cb))\n  if (data === SIGNAL_FLUSH) return this._finish(cb)\n  if (!this._writable) return cb()\n\n  if (this._writable.write(data) === false) this._ondrain = cb\n  else cb()\n}\n\n\nDuplexify.prototype._finish = function(cb) {\n  var self = this\n  this.emit('preend')\n  onuncork(this, function() {\n    end(self._forwardEnd && self._writable, function() {\n      // haxx to not emit prefinish twice\n      if (self._writableState.prefinished === false) self._writableState.prefinished = true\n      self.emit('prefinish')\n      onuncork(self, cb)\n    })\n  })\n}\n\nDuplexify.prototype.end = function(data, enc, cb) {\n  if (typeof data === 'function') return this.end(null, null, data)\n  if (typeof enc === 'function') return this.end(data, null, enc)\n  this._ended = true\n  if (data) this.write(data)\n  if (!this._writableState.ending) this.write(SIGNAL_FLUSH)\n  return stream.Writable.prototype.end.call(this, cb)\n}\n\nmodule.exports = Duplexify\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/duplexify/node_modules/end-of-stream/index.js":"var once = require('once');\n\nvar noop = function() {};\n\nvar isRequest = function(stream) {\n\treturn stream.setHeader && typeof stream.abort === 'function';\n};\n\nvar eos = function(stream, opts, callback) {\n\tif (typeof opts === 'function') return eos(stream, null, opts);\n\tif (!opts) opts = {};\n\n\tcallback = once(callback || noop);\n\n\tvar ws = stream._writableState;\n\tvar rs = stream._readableState;\n\tvar readable = opts.readable || (opts.readable !== false && stream.readable);\n\tvar writable = opts.writable || (opts.writable !== false && stream.writable);\n\n\tvar onlegacyfinish = function() {\n\t\tif (!stream.writable) onfinish();\n\t};\n\n\tvar onfinish = function() {\n\t\twritable = false;\n\t\tif (!readable) callback();\n\t};\n\n\tvar onend = function() {\n\t\treadable = false;\n\t\tif (!writable) callback();\n\t};\n\n\tvar onclose = function() {\n\t\tif (readable && !(rs && rs.ended)) return callback(new Error('premature close'));\n\t\tif (writable && !(ws && ws.ended)) return callback(new Error('premature close'));\n\t};\n\n\tvar onrequest = function() {\n\t\tstream.req.on('finish', onfinish);\n\t};\n\n\tif (isRequest(stream)) {\n\t\tstream.on('complete', onfinish);\n\t\tstream.on('abort', onclose);\n\t\tif (stream.req) onrequest();\n\t\telse stream.on('request', onrequest);\n\t} else if (writable && !ws) { // legacy streams\n\t\tstream.on('end', onlegacyfinish);\n\t\tstream.on('close', onlegacyfinish);\n\t}\n\n\tstream.on('end', onend);\n\tstream.on('finish', onfinish);\n\tif (opts.error !== false) stream.on('error', callback);\n\tstream.on('close', onclose);\n\n\treturn function() {\n\t\tstream.removeListener('complete', onfinish);\n\t\tstream.removeListener('abort', onclose);\n\t\tstream.removeListener('request', onrequest);\n\t\tif (stream.req) stream.req.removeListener('finish', onfinish);\n\t\tstream.removeListener('end', onlegacyfinish);\n\t\tstream.removeListener('close', onlegacyfinish);\n\t\tstream.removeListener('finish', onfinish);\n\t\tstream.removeListener('end', onend);\n\t\tstream.removeListener('error', callback);\n\t\tstream.removeListener('close', onclose);\n\t};\n};\n\nmodule.exports = eos;","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/duplexify/node_modules/end-of-stream/node_modules/once/once.js":"var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/duplexify/node_modules/stream-shift/index.js":"module.exports = shift\n\nfunction shift (stream) {\n  var rs = stream._readableState\n  if (!rs) return null\n  return rs.objectMode ? stream.read() : stream.read(getStateLength(rs))\n}\n\nfunction getStateLength (state) {\n  if (state.buffer.length) {\n    // Since node 6.3.0 state.buffer is a BufferList not an array\n    if (state.buffer.head) {\n      return state.buffer.head.data.length\n    }\n\n    return state.buffer[0].length\n  }\n\n  return state.length\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/through2/through2.js":"var Transform = require('readable-stream/transform')\n  , inherits  = require('util').inherits\n  , xtend     = require('xtend')\n\nfunction DestroyableTransform(opts) {\n  Transform.call(this, opts)\n  this._destroyed = false\n}\n\ninherits(DestroyableTransform, Transform)\n\nDestroyableTransform.prototype.destroy = function(err) {\n  if (this._destroyed) return\n  this._destroyed = true\n  \n  var self = this\n  process.nextTick(function() {\n    if (err)\n      self.emit('error', err)\n    self.emit('close')\n  })\n}\n\n// a noop _transform function\nfunction noop (chunk, enc, callback) {\n  callback(null, chunk)\n}\n\n\n// create a new export function, used by both the main export and\n// the .ctor export, contains common logic for dealing with arguments\nfunction through2 (construct) {\n  return function (options, transform, flush) {\n    if (typeof options == 'function') {\n      flush     = transform\n      transform = options\n      options   = {}\n    }\n\n    if (typeof transform != 'function')\n      transform = noop\n\n    if (typeof flush != 'function')\n      flush = null\n\n    return construct(options, transform, flush)\n  }\n}\n\n\n// main export, just make me a transform stream!\nmodule.exports = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(options)\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n\n\n// make me a reusable prototype that I can `new`, or implicitly `new`\n// with a constructor call\nmodule.exports.ctor = through2(function (options, transform, flush) {\n  function Through2 (override) {\n    if (!(this instanceof Through2))\n      return new Through2(override)\n\n    this.options = xtend(options, override)\n\n    DestroyableTransform.call(this, this.options)\n  }\n\n  inherits(Through2, DestroyableTransform)\n\n  Through2.prototype._transform = transform\n\n  if (flush)\n    Through2.prototype._flush = flush\n\n  return Through2\n})\n\n\nmodule.exports.obj = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(xtend({ objectMode: true, highWaterMark: 16 }, options))\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/readable-stream/transform.js":"module.exports = require(\"./lib/_stream_transform.js\")\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/through2/node_modules/xtend/immutable.js":"module.exports = extend\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction extend() {\n    var target = {}\n\n    for (var i = 0; i < arguments.length; i++) {\n        var source = arguments[i]\n\n        for (var key in source) {\n            if (hasOwnProperty.call(source, key)) {\n                target[key] = source[key]\n            }\n        }\n    }\n\n    return target\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/concat-stream/index.js":"var Writable = require('readable-stream').Writable\nvar inherits = require('inherits')\n\nif (typeof Uint8Array === 'undefined') {\n  var U8 = require('typedarray').Uint8Array\n} else {\n  var U8 = Uint8Array\n}\n\nfunction ConcatStream(opts, cb) {\n  if (!(this instanceof ConcatStream)) return new ConcatStream(opts, cb)\n\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  }\n  if (!opts) opts = {}\n\n  var encoding = opts.encoding\n  var shouldInferEncoding = false\n\n  if (!encoding) {\n    shouldInferEncoding = true\n  } else {\n    encoding =  String(encoding).toLowerCase()\n    if (encoding === 'u8' || encoding === 'uint8') {\n      encoding = 'uint8array'\n    }\n  }\n\n  Writable.call(this, { objectMode: true })\n\n  this.encoding = encoding\n  this.shouldInferEncoding = shouldInferEncoding\n\n  if (cb) this.on('finish', function () { cb(this.getBody()) })\n  this.body = []\n}\n\nmodule.exports = ConcatStream\ninherits(ConcatStream, Writable)\n\nConcatStream.prototype._write = function(chunk, enc, next) {\n  this.body.push(chunk)\n  next()\n}\n\nConcatStream.prototype.inferEncoding = function (buff) {\n  var firstBuffer = buff === undefined ? this.body[0] : buff;\n  if (Buffer.isBuffer(firstBuffer)) return 'buffer'\n  if (typeof Uint8Array !== 'undefined' && firstBuffer instanceof Uint8Array) return 'uint8array'\n  if (Array.isArray(firstBuffer)) return 'array'\n  if (typeof firstBuffer === 'string') return 'string'\n  if (Object.prototype.toString.call(firstBuffer) === \"[object Object]\") return 'object'\n  return 'buffer'\n}\n\nConcatStream.prototype.getBody = function () {\n  if (!this.encoding && this.body.length === 0) return []\n  if (this.shouldInferEncoding) this.encoding = this.inferEncoding()\n  if (this.encoding === 'array') return arrayConcat(this.body)\n  if (this.encoding === 'string') return stringConcat(this.body)\n  if (this.encoding === 'buffer') return bufferConcat(this.body)\n  if (this.encoding === 'uint8array') return u8Concat(this.body)\n  return this.body\n}\n\nvar isArray = Array.isArray || function (arr) {\n  return Object.prototype.toString.call(arr) == '[object Array]'\n}\n\nfunction isArrayish (arr) {\n  return /Array\\]$/.test(Object.prototype.toString.call(arr))\n}\n\nfunction isBufferish (p) {\n  return typeof p === 'string' || isArrayish(p) || (p && typeof p.subarray === 'function')\n}\n\nfunction stringConcat (parts) {\n  var strings = []\n  var needsToString = false\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (typeof p === 'string') {\n      strings.push(p)\n    } else if (Buffer.isBuffer(p)) {\n      strings.push(p)\n    } else if (isBufferish(p)) {\n      strings.push(new Buffer(p))\n    } else {\n      strings.push(new Buffer(String(p)))\n    }\n  }\n  if (Buffer.isBuffer(parts[0])) {\n    strings = Buffer.concat(strings)\n    strings = strings.toString('utf8')\n  } else {\n    strings = strings.join('')\n  }\n  return strings\n}\n\nfunction bufferConcat (parts) {\n  var bufs = []\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (Buffer.isBuffer(p)) {\n      bufs.push(p)\n    } else if (isBufferish(p)) {\n      bufs.push(new Buffer(p))\n    } else {\n      bufs.push(new Buffer(String(p)))\n    }\n  }\n  return Buffer.concat(bufs)\n}\n\nfunction arrayConcat (parts) {\n  var res = []\n  for (var i = 0; i < parts.length; i++) {\n    res.push.apply(res, parts[i])\n  }\n  return res\n}\n\nfunction u8Concat (parts) {\n  var len = 0\n  for (var i = 0; i < parts.length; i++) {\n    if (typeof parts[i] === 'string') {\n      parts[i] = new Buffer(parts[i])\n    }\n    len += parts[i].length\n  }\n  var u8 = new U8(len)\n  for (var i = 0, offset = 0; i < parts.length; i++) {\n    var part = parts[i]\n    for (var j = 0; j < part.length; j++) {\n      u8[offset++] = part[j]\n    }\n  }\n  return u8\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/from2/index.js":"var Readable = require('readable-stream').Readable\nvar inherits = require('inherits')\n\nmodule.exports = from2\n\nfrom2.ctor = ctor\nfrom2.obj = obj\n\nvar Proto = ctor()\n\nfunction toFunction(list) {\n  list = list.slice()\n  return function (_, cb) {\n    var err = null\n    var item = list.length ? list.shift() : null\n    if (item instanceof Error) {\n      err = item\n      item = null\n    }\n\n    cb(err, item)\n  }\n}\n\nfunction from2(opts, read) {\n  if (typeof opts !== 'object' || Array.isArray(opts)) {\n    read = opts\n    opts = {}\n  }\n\n  var rs = new Proto(opts)\n  rs._from = Array.isArray(read) ? toFunction(read) : (read || noop)\n  return rs\n}\n\nfunction ctor(opts, read) {\n  if (typeof opts === 'function') {\n    read = opts\n    opts = {}\n  }\n\n  opts = defaults(opts)\n\n  inherits(Class, Readable)\n  function Class(override) {\n    if (!(this instanceof Class)) return new Class(override)\n    this._reading = false\n    this._callback = check\n    this.destroyed = false\n    Readable.call(this, override || opts)\n\n    var self = this\n    var hwm = this._readableState.highWaterMark\n\n    function check(err, data) {\n      if (self.destroyed) return\n      if (err) return self.destroy(err)\n      if (data === null) return self.push(null)\n      self._reading = false\n      if (self.push(data)) self._read(hwm)\n    }\n  }\n\n  Class.prototype._from = read || noop\n  Class.prototype._read = function(size) {\n    if (this._reading || this.destroyed) return\n    this._reading = true\n    this._from(size, this._callback)\n  }\n\n  Class.prototype.destroy = function(err) {\n    if (this.destroyed) return\n    this.destroyed = true\n\n    var self = this\n    process.nextTick(function() {\n      if (err) self.emit('error', err)\n      self.emit('close')\n    })\n  }\n\n  return Class\n}\n\nfunction obj(opts, read) {\n  if (typeof opts === 'function' || Array.isArray(opts)) {\n    read = opts\n    opts = {}\n  }\n\n  opts = defaults(opts)\n  opts.objectMode = true\n  opts.highWaterMark = 16\n\n  return from2(opts, read)\n}\n\nfunction noop () {}\n\nfunction defaults(opts) {\n  opts = opts || {}\n  return opts\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/mississippi/node_modules/flush-write-stream/index.js":"var stream = require('readable-stream')\nvar inherits = require('inherits')\n\nvar SIGNAL_FLUSH = new Buffer([0])\n\nmodule.exports = WriteStream\n\nfunction WriteStream (opts, write, flush) {\n  if (!(this instanceof WriteStream)) return new WriteStream(opts, write, flush)\n\n  if (typeof opts === 'function') {\n    flush = write\n    write = opts\n    opts = {}\n  }\n\n  stream.Writable.call(this, opts)\n\n  this.destroyed = false\n  this._worker = write || null\n  this._flush = flush || null\n}\n\ninherits(WriteStream, stream.Writable)\n\nWriteStream.obj = function (opts, worker, flush) {\n  if (typeof opts === 'function') return WriteStream.obj(null, opts, worker)\n  if (!opts) opts = {}\n  opts.objectMode = true\n  return new WriteStream(opts, worker, flush)\n}\n\nWriteStream.prototype._write = function (data, enc, cb) {\n  if (SIGNAL_FLUSH === data) this._flush(cb)\n  else this._worker(data, enc, cb)\n}\n\nWriteStream.prototype.end = function (data, enc, cb) {\n  if (!this._flush) return stream.Writable.prototype.end.apply(this, arguments)\n  if (typeof data === 'function') return this.end(null, null, data)\n  if (typeof enc === 'function') return this.end(data, null, enc)\n  if (data) this.write(data)\n  if (!this._writableState.ending) this.write(SIGNAL_FLUSH)\n  return stream.Writable.prototype.end.call(this, cb)\n}\n\nWriteStream.prototype.destroy = function (err) {\n  if (this.destroyed) return\n  this.destroyed = true\n  if (err) this.emit('error', err)\n  this.emit('close')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/search/all-package-metadata.js":"'use strict'\n\nvar fs = require('graceful-fs')\nvar path = require('path')\nvar mkdir = require('mkdirp')\nvar chownr = require('chownr')\nvar npm = require('../npm.js')\nvar log = require('npmlog')\nvar cacheFile = require('npm-cache-filename')\nvar getCacheStat = require('../cache/get-stat.js')\nvar mapToRegistry = require('../utils/map-to-registry.js')\nvar jsonstream = require('JSONStream')\nvar writeStreamAtomic = require('fs-write-stream-atomic')\nvar ms = require('mississippi')\nvar sortedUnionStream = require('sorted-union-stream')\nvar once = require('once')\nvar gunzip = require('../utils/gunzip-maybe')\n\n// Returns a sorted stream of all package metadata. Internally, takes care of\n// maintaining its metadata cache and making partial or full remote requests,\n// according to staleness, validity, etc.\n//\n// The local cache must hold certain invariants:\n// 1. It must be a proper JSON object\n// 2. It must have its keys lexically sorted\n// 3. The first entry must be `_updated` with a millisecond timestamp as a val.\n// 4. It must include all entries that exist in the metadata endpoint as of\n//    the value in `_updated`\nmodule.exports = allPackageMetadata\nfunction allPackageMetadata (staleness) {\n  var stream = ms.through.obj()\n\n  mapToRegistry('-/all', npm.config, function (er, uri, auth) {\n    if (er) return stream.emit('error', er)\n\n    var cacheBase = cacheFile(npm.config.get('cache'))(uri)\n    var cachePath = path.join(cacheBase, '.cache.json')\n\n    createEntryStream(cachePath, uri, auth, staleness, function (err, entryStream, latest, newEntries) {\n      if (err) return stream.emit('error', err)\n      log.silly('all-package-metadata', 'entry stream created')\n      if (entryStream && newEntries) {\n        createCacheWriteStream(cachePath, latest, function (err, writeStream) {\n          if (err) return stream.emit('error', err)\n          log.silly('all-package-metadata', 'output stream created')\n          ms.pipeline.obj(entryStream, writeStream, stream)\n        })\n      } else if (entryStream) {\n        ms.pipeline.obj(entryStream, stream)\n      } else {\n        stream.emit('error', new Error('No search sources available'))\n      }\n    })\n  })\n  return stream\n}\n\n// Creates a stream of the latest available package metadata.\n// Metadata will come from a combination of the local cache and remote data.\nmodule.exports._createEntryStream = createEntryStream\nfunction createEntryStream (cachePath, uri, auth, staleness, cb) {\n  createCacheEntryStream(cachePath, function (err, cacheStream, cacheLatest) {\n    cacheLatest = cacheLatest || 0\n    if (err) {\n      log.warn('', 'Failed to read search cache. Rebuilding')\n      log.silly('all-package-metadata', 'cache read error: ', err)\n    }\n    createEntryUpdateStream(uri, auth, staleness, cacheLatest, function (err, updateStream, updatedLatest) {\n      updatedLatest = updatedLatest || 0\n      var latest = updatedLatest || cacheLatest\n      if (!cacheStream && !updateStream) {\n        return cb(new Error('No search sources available'))\n      }\n      if (err) {\n        log.warn('', 'Search data request failed, search might be stale')\n        log.silly('all-package-metadata', 'update request error: ', err)\n      }\n      if (cacheStream && updateStream) {\n        // Deduped, unioned, sorted stream from the combination of both.\n        cb(null,\n          createMergedStream(cacheStream, updateStream),\n          latest,\n          !!updatedLatest)\n      } else {\n        // Either one works if one or the other failed\n        cb(null, cacheStream || updateStream, latest, !!updatedLatest)\n      }\n    })\n  })\n}\n\n// Merges `a` and `b` into one stream, dropping duplicates in favor of entries\n// in `b`. Both input streams should already be individually sorted, and the\n// returned output stream will have semantics resembling the merge step of a\n// plain old merge sort.\nmodule.exports._createMergedStream = createMergedStream\nfunction createMergedStream (a, b) {\n  linkStreams(a, b)\n  return sortedUnionStream(b, a, function (pkg) { return pkg.name })\n}\n\n// Reads the local index and returns a stream that spits out package data.\nmodule.exports._createCacheEntryStream = createCacheEntryStream\nfunction createCacheEntryStream (cacheFile, cb) {\n  log.verbose('all-package-metadata', 'creating entry stream from local cache')\n  log.verbose('all-package-metadata', cacheFile)\n  fs.stat(cacheFile, function (err, stat) {\n    if (err) return cb(err)\n    // TODO - This isn't very helpful if `cacheFile` is empty or just `{}`\n    var entryStream = ms.pipeline.obj(\n      fs.createReadStream(cacheFile),\n      jsonstream.parse('*'),\n      // I believe this passthrough is necessary cause `jsonstream` returns\n      // weird custom streams that behave funny sometimes.\n      ms.through.obj()\n    )\n    extractUpdated(entryStream, 'cached-entry-stream', cb)\n  })\n}\n\n// Stream of entry updates from the server. If `latest` is `0`, streams the\n// entire metadata object from the registry.\nmodule.exports._createEntryUpdateStream = createEntryUpdateStream\nfunction createEntryUpdateStream (all, auth, staleness, latest, cb) {\n  log.verbose('all-package-metadata', 'creating remote entry stream')\n  var params = {\n    timeout: 600,\n    follow: true,\n    staleOk: true,\n    auth: auth,\n    streaming: true\n  }\n  var partialUpdate = false\n  if (latest && (Date.now() - latest < (staleness * 1000))) {\n    // Skip the request altogether if our `latest` isn't stale.\n    log.verbose('all-package-metadata', 'Local data up to date, skipping update')\n    return cb(null)\n  } else if (latest === 0) {\n    log.warn('', 'Building the local index for the first time, please be patient')\n    log.verbose('all-package-metadata', 'No cached data: requesting full metadata db')\n  } else {\n    log.verbose('all-package-metadata', 'Cached data present with timestamp:', latest, 'requesting partial index update')\n    all += '/since?stale=update_after&startkey=' + latest\n    partialUpdate = true\n  }\n  npm.registry.request(all, params, function (er, res) {\n    if (er) return cb(er)\n    log.silly('all-package-metadata', 'request stream opened, code:', res.statusCode)\n    // NOTE - The stream returned by `request` seems to be very persnickety\n    //        and this is almost a magic incantation to get it to work.\n    //        Modify how `res` is used here at your own risk.\n    var entryStream = ms.pipeline.obj(\n      res,\n      ms.through(function (chunk, enc, cb) {\n        cb(null, chunk)\n      }),\n      gunzip(),\n      jsonstream.parse('*', function (pkg, key) {\n        if (key[0] === '_updated' || key[0][0] !== '_') {\n          return pkg\n        }\n      })\n    )\n    if (partialUpdate) {\n      // The `/all/since` endpoint doesn't return `_updated`, so we\n      // just use the request's own timestamp.\n      cb(null, entryStream, Date.parse(res.headers.date))\n    } else {\n      extractUpdated(entryStream, 'entry-update-stream', cb)\n    }\n  })\n}\n\n// Both the (full) remote requests and the local index have `_updated` as their\n// first returned entries. This is the \"latest\" unix timestamp for the metadata\n// in question. This code does a bit of juggling with the data streams\n// so that we can pretend that field doesn't exist, but still extract `latest`\nfunction extractUpdated (entryStream, label, cb) {\n  cb = once(cb)\n  log.silly('all-package-metadata', 'extracting latest')\n  function nope (msg) {\n    return function () {\n      log.warn('all-package-metadata', label, msg)\n      entryStream.removeAllListeners()\n      entryStream.destroy()\n      cb(new Error(msg))\n    }\n  }\n  var onErr = nope('Failed to read stream')\n  var onEnd = nope('Empty or invalid stream')\n  entryStream.on('error', onErr)\n  entryStream.on('end', onEnd)\n  entryStream.once('data', function (latest) {\n    log.silly('all-package-metadata', 'got first stream entry for', label, latest)\n    entryStream.removeListener('error', onErr)\n    entryStream.removeListener('end', onEnd)\n    // Because `.once()` unpauses the stream, we re-pause it after the first\n    // entry so we don't vomit entries into the void.\n    entryStream.pause()\n    if (typeof latest === 'number') {\n      // The extra pipeline is to return a stream that will implicitly unpause\n      // after having an `.on('data')` listener attached, since using this\n      // `data` event broke its initial state.\n      cb(null, ms.pipeline.obj(entryStream, ms.through.obj()), latest)\n    } else {\n      cb(new Error('expected first entry to be _updated'))\n    }\n  })\n}\n\n// Creates a stream that writes input metadata to the current cache.\n// Cache updates are atomic, and the stream closes when *everything* is done.\n// The stream is also passthrough, so entries going through it will also\n// be output from it.\nmodule.exports._createCacheWriteStream = createCacheWriteStream\nfunction createCacheWriteStream (cacheFile, latest, cb) {\n  _ensureCacheDirExists(cacheFile, function (err) {\n    if (err) return cb(err)\n    log.silly('all-package-metadata', 'creating output stream')\n    var outStream = _createCacheOutStream()\n    var cacheFileStream = writeStreamAtomic(cacheFile)\n    var inputStream = _createCacheInStream(cacheFileStream, outStream, latest)\n\n    // Glue together the various streams so they fail together.\n    // `cacheFileStream` errors are already handled by the `inputStream`\n    // pipeline\n    var errEmitted = false\n    linkStreams(inputStream, outStream, function () { errEmitted = true })\n\n    cacheFileStream.on('close', function () { !errEmitted && outStream.end() })\n\n    cb(null, ms.duplex.obj(inputStream, outStream))\n  })\n}\n\nfunction _ensureCacheDirExists (cacheFile, cb) {\n  var cacheBase = path.dirname(cacheFile)\n  log.silly('all-package-metadata', 'making sure cache dir exists at', cacheBase)\n  getCacheStat(function (er, st) {\n    if (er) return cb(er)\n    mkdir(cacheBase, function (er, made) {\n      if (er) return cb(er)\n      chownr(made || cacheBase, st.uid, st.gid, cb)\n    })\n  })\n}\n\nfunction _createCacheOutStream () {\n  return ms.pipeline.obj(\n    // These two passthrough `through` streams compensate for some\n    // odd behavior with `jsonstream`.\n    ms.through(),\n    jsonstream.parse('*', function (obj, key) {\n      // This stream happens to get _updated passed through it, for\n      // implementation reasons. We make sure to filter it out cause\n      // the fact that it comes t\n      if (typeof obj === 'object') {\n        return obj\n      }\n    }),\n    ms.through.obj()\n  )\n}\n\nfunction _createCacheInStream (writer, outStream, latest) {\n  var updatedWritten = false\n  var inStream = ms.pipeline.obj(\n    ms.through.obj(function (pkg, enc, cb) {\n      if (!updatedWritten && typeof pkg === 'number') {\n        // This is the `_updated` value getting sent through.\n        updatedWritten = true\n        return cb(null, ['_updated', pkg])\n      } else if (typeof pkg !== 'object') {\n        this.emit('error', new Error('invalid value written to input stream'))\n      } else {\n        // The [key, val] format is expected by `jsonstream` for object writing\n        cb(null, [pkg.name, pkg])\n      }\n    }),\n    jsonstream.stringifyObject('{', ',', '}'),\n    ms.through(function (chunk, enc, cb) {\n      // This tees off the buffer data to `outStream`, and then continues\n      // the pipeline as usual\n      outStream.write(chunk, enc, function () {\n        cb(null, chunk)\n      })\n    }),\n    // And finally, we write to the cache file.\n    writer\n  )\n  inStream.write(latest)\n  return inStream\n}\n\n// Links errors between `a` and `b`, preventing cycles, and calls `cb` if\n// an error happens, once per error.\nfunction linkStreams (a, b, cb) {\n  var lastError = null\n  a.on('error', function (err) {\n    if (err !== lastError) {\n      lastError = err\n      b.emit('error', err)\n      cb(err)\n    }\n  })\n  b.on('error', function (err) {\n    if (err !== lastError) {\n      lastError = err\n      a.emit('error', err)\n      cb(err)\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/JSONStream/index.js":"#! /usr/bin/env node\n\n'use strict'\n\nvar Parser = require('jsonparse')\n  , through = require('through')\n\n/*\n\n  the value of this.stack that creationix's jsonparse has is weird.\n\n  it makes this code ugly, but his problem is way harder that mine,\n  so i'll forgive him.\n\n*/\n\nexports.parse = function (path, map) {\n  var header, footer\n  var parser = new Parser()\n  var stream = through(function (chunk) {\n    if('string' === typeof chunk)\n      chunk = new Buffer(chunk)\n    parser.write(chunk)\n  },\n  function (data) {\n    if(data)\n      stream.write(data)\n    if (header)\n        stream.emit('header', header)\n    if (footer)\n      stream.emit('footer', footer)\n    stream.queue(null)\n  })\n\n  if('string' === typeof path)\n    path = path.split('.').map(function (e) {\n      if (e === '$*')\n        return {emitKey: true}\n      else if (e === '*')\n        return true\n      else if (e === '') // '..'.split('.') returns an empty string\n        return {recurse: true}\n      else\n        return e\n    })\n\n\n  var count = 0, _key\n  if(!path || !path.length)\n    path = null\n\n  parser.onValue = function (value) {\n    if (!this.root)\n      stream.root = value\n\n    if(! path) return\n\n    var i = 0 // iterates on path\n    var j  = 0 // iterates on stack\n    var emitKey = false;\n    var emitPath = false;\n    while (i < path.length) {\n      var key = path[i]\n      var c\n      j++\n\n      if (key && !key.recurse) {\n        c = (j === this.stack.length) ? this : this.stack[j]\n        if (!c) return\n        if (! check(key, c.key)) {\n          setHeaderFooter(c.key, value)\n          return\n        }\n        emitKey = !!key.emitKey;\n        emitPath = !!key.emitPath;\n        i++\n      } else {\n        i++\n        var nextKey = path[i]\n        if (! nextKey) return\n        while (true) {\n          c = (j === this.stack.length) ? this : this.stack[j]\n          if (!c) return\n          if (check(nextKey, c.key)) {\n            i++;\n            if (!Object.isFrozen(this.stack[j]))\n              this.stack[j].value = null\n            break\n          } else {\n            setHeaderFooter(c.key, value)\n          }\n          j++\n        }\n      }\n\n    }\n\n    // emit header\n    if (header) {\n      stream.emit('header', header);\n      header = false;\n    }\n    if (j !== this.stack.length) return\n\n    count ++\n    var actualPath = this.stack.slice(1).map(function(element) { return element.key }).concat([this.key])\n    var data = this.value[this.key]\n    if(null != data)\n      if(null != (data = map ? map(data, actualPath) : data)) {\n        if (emitKey || emitPath) {\n          data = { value: data };\n          if (emitKey)\n            data[\"key\"] = this.key;\n          if (emitPath)\n            data[\"path\"] = actualPath;\n        }\n\n        stream.queue(data)\n      }\n    delete this.value[this.key]\n    for(var k in this.stack)\n      if (!Object.isFrozen(this.stack[k]))\n        this.stack[k].value = null\n  }\n  parser._onToken = parser.onToken;\n\n  parser.onToken = function (token, value) {\n    parser._onToken(token, value);\n    if (this.stack.length === 0) {\n      if (stream.root) {\n        if(!path)\n          stream.queue(stream.root)\n        count = 0;\n        stream.root = null;\n      }\n    }\n  }\n\n  parser.onError = function (err) {\n    if(err.message.indexOf(\"at position\") > -1)\n      err.message = \"Invalid JSON (\" + err.message + \")\";\n    stream.emit('error', err)\n  }\n\n  return stream\n\n  function setHeaderFooter(key, value) {\n    // header has not been emitted yet\n    if (header !== false) {\n      header = header || {}\n      header[key] = value\n    }\n\n    // footer has not been emitted yet but header has\n    if (footer !== false && header === false) {\n      footer = footer || {}\n      footer[key] = value\n    }\n  }\n}\n\nfunction check (x, y) {\n  if ('string' === typeof x)\n    return y == x\n  else if (x && 'function' === typeof x.exec)\n    return x.exec(y)\n  else if ('boolean' === typeof x || 'object' === typeof x)\n    return x\n  else if ('function' === typeof x)\n    return x(y)\n  return false\n}\n\nexports.stringify = function (op, sep, cl, indent) {\n  indent = indent || 0\n  if (op === false){\n    op = ''\n    sep = '\\n'\n    cl = ''\n  } else if (op == null) {\n\n    op = '[\\n'\n    sep = '\\n,\\n'\n    cl = '\\n]\\n'\n\n  }\n\n  //else, what ever you like\n\n  var stream\n    , first = true\n    , anyData = false\n  stream = through(function (data) {\n    anyData = true\n    try {\n      var json = JSON.stringify(data, null, indent)\n    } catch (err) {\n      return stream.emit('error', err)\n    }\n    if(first) { first = false ; stream.queue(op + json)}\n    else stream.queue(sep + json)\n  },\n  function (data) {\n    if(!anyData)\n      stream.queue(op)\n    stream.queue(cl)\n    stream.queue(null)\n  })\n\n  return stream\n}\n\nexports.stringifyObject = function (op, sep, cl, indent) {\n  indent = indent || 0\n  if (op === false){\n    op = ''\n    sep = '\\n'\n    cl = ''\n  } else if (op == null) {\n\n    op = '{\\n'\n    sep = '\\n,\\n'\n    cl = '\\n}\\n'\n\n  }\n\n  //else, what ever you like\n\n  var first = true\n  var anyData = false\n  var stream = through(function (data) {\n    anyData = true\n    var json = JSON.stringify(data[0]) + ':' + JSON.stringify(data[1], null, indent)\n    if(first) { first = false ; this.queue(op + json)}\n    else this.queue(sep + json)\n  },\n  function (data) {\n    if(!anyData) this.queue(op)\n    this.queue(cl)\n\n    this.queue(null)\n  })\n\n  return stream\n}\n\nif(!module.parent && process.title !== 'browser') {\n  process.stdin\n    .pipe(exports.parse(process.argv[2]))\n    .pipe(exports.stringify('[', ',\\n', ']\\n', 2))\n    .pipe(process.stdout)\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/JSONStream/node_modules/jsonparse/jsonparse.js":"/*global Buffer*/\n// Named constants with unique integer values\nvar C = {};\n// Tokens\nvar LEFT_BRACE    = C.LEFT_BRACE    = 0x1;\nvar RIGHT_BRACE   = C.RIGHT_BRACE   = 0x2;\nvar LEFT_BRACKET  = C.LEFT_BRACKET  = 0x3;\nvar RIGHT_BRACKET = C.RIGHT_BRACKET = 0x4;\nvar COLON         = C.COLON         = 0x5;\nvar COMMA         = C.COMMA         = 0x6;\nvar TRUE          = C.TRUE          = 0x7;\nvar FALSE         = C.FALSE         = 0x8;\nvar NULL          = C.NULL          = 0x9;\nvar STRING        = C.STRING        = 0xa;\nvar NUMBER        = C.NUMBER        = 0xb;\n// Tokenizer States\nvar START   = C.START   = 0x11;\nvar STOP    = C.STOP    = 0x12;\nvar TRUE1   = C.TRUE1   = 0x21;\nvar TRUE2   = C.TRUE2   = 0x22;\nvar TRUE3   = C.TRUE3   = 0x23;\nvar FALSE1  = C.FALSE1  = 0x31;\nvar FALSE2  = C.FALSE2  = 0x32;\nvar FALSE3  = C.FALSE3  = 0x33;\nvar FALSE4  = C.FALSE4  = 0x34;\nvar NULL1   = C.NULL1   = 0x41;\nvar NULL2   = C.NULL2   = 0x42;\nvar NULL3   = C.NULL3   = 0x43;\nvar NUMBER1 = C.NUMBER1 = 0x51;\nvar NUMBER3 = C.NUMBER3 = 0x53;\nvar STRING1 = C.STRING1 = 0x61;\nvar STRING2 = C.STRING2 = 0x62;\nvar STRING3 = C.STRING3 = 0x63;\nvar STRING4 = C.STRING4 = 0x64;\nvar STRING5 = C.STRING5 = 0x65;\nvar STRING6 = C.STRING6 = 0x66;\n// Parser States\nvar VALUE   = C.VALUE   = 0x71;\nvar KEY     = C.KEY     = 0x72;\n// Parser Modes\nvar OBJECT  = C.OBJECT  = 0x81;\nvar ARRAY   = C.ARRAY   = 0x82;\n// Character constants\nvar BACK_SLASH =      \"\\\\\".charCodeAt(0);\nvar FORWARD_SLASH =   \"\\/\".charCodeAt(0);\nvar BACKSPACE =       \"\\b\".charCodeAt(0);\nvar FORM_FEED =       \"\\f\".charCodeAt(0);\nvar NEWLINE =         \"\\n\".charCodeAt(0);\nvar CARRIAGE_RETURN = \"\\r\".charCodeAt(0);\nvar TAB =             \"\\t\".charCodeAt(0);\n\nvar STRING_BUFFER_SIZE = 64 * 1024;\n\nfunction Parser() {\n  this.tState = START;\n  this.value = undefined;\n\n  this.string = undefined; // string data\n  this.stringBuffer = Buffer.alloc ? Buffer.alloc(STRING_BUFFER_SIZE) : new Buffer(STRING_BUFFER_SIZE);\n  this.stringBufferOffset = 0;\n  this.unicode = undefined; // unicode escapes\n\n  this.key = undefined;\n  this.mode = undefined;\n  this.stack = [];\n  this.state = VALUE;\n  this.bytes_remaining = 0; // number of bytes remaining in multi byte utf8 char to read after split boundary\n  this.bytes_in_sequence = 0; // bytes in multi byte utf8 char to read\n  this.temp_buffs = { \"2\": new Buffer(2), \"3\": new Buffer(3), \"4\": new Buffer(4) }; // for rebuilding chars split before boundary is reached\n\n  // Stream offset\n  this.offset = -1;\n}\n\n// Slow code to string converter (only used when throwing syntax errors)\nParser.toknam = function (code) {\n  var keys = Object.keys(C);\n  for (var i = 0, l = keys.length; i < l; i++) {\n    var key = keys[i];\n    if (C[key] === code) { return key; }\n  }\n  return code && (\"0x\" + code.toString(16));\n};\n\nvar proto = Parser.prototype;\nproto.onError = function (err) { throw err; };\nproto.charError = function (buffer, i) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + JSON.stringify(String.fromCharCode(buffer[i])) + \" at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n};\nproto.appendStringChar = function (char) {\n  if (this.stringBufferOffset >= STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8');\n    this.stringBufferOffset = 0;\n  }\n\n  this.stringBuffer[this.stringBufferOffset++] = char;\n};\nproto.appendStringBuf = function (buf, start, end) {\n  var size = buf.length;\n  if (typeof start === 'number') {\n    if (typeof end === 'number') {\n      if (end < 0) {\n        // adding a negative end decreeses the size\n        size = buf.length - start + end;\n      } else {\n        size = end - start;\n      }\n    } else {\n      size = buf.length - start;\n    }\n  }\n\n  if (size < 0) {\n    size = 0;\n  }\n\n  if (this.stringBufferOffset + size > STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n    this.stringBufferOffset = 0;\n  }\n\n  buf.copy(this.stringBuffer, this.stringBufferOffset, start, end);\n  this.stringBufferOffset += size;\n};\nproto.write = function (buffer) {\n  if (typeof buffer === \"string\") buffer = new Buffer(buffer);\n  var n;\n  for (var i = 0, l = buffer.length; i < l; i++) {\n    if (this.tState === START){\n      n = buffer[i];\n      this.offset++;\n      if(n === 0x7b){ this.onToken(LEFT_BRACE, \"{\"); // {\n      }else if(n === 0x7d){ this.onToken(RIGHT_BRACE, \"}\"); // }\n      }else if(n === 0x5b){ this.onToken(LEFT_BRACKET, \"[\"); // [\n      }else if(n === 0x5d){ this.onToken(RIGHT_BRACKET, \"]\"); // ]\n      }else if(n === 0x3a){ this.onToken(COLON, \":\");  // :\n      }else if(n === 0x2c){ this.onToken(COMMA, \",\"); // ,\n      }else if(n === 0x74){ this.tState = TRUE1;  // t\n      }else if(n === 0x66){ this.tState = FALSE1;  // f\n      }else if(n === 0x6e){ this.tState = NULL1; // n\n      }else if(n === 0x22){ // \"\n        this.string = \"\";\n        this.stringBufferOffset = 0;\n        this.tState = STRING1;\n      }else if(n === 0x2d){ this.string = \"-\"; this.tState = NUMBER1; // -\n      }else{\n        if (n >= 0x30 && n < 0x40) { // 1-9\n          this.string = String.fromCharCode(n); this.tState = NUMBER3;\n        } else if (n === 0x20 || n === 0x09 || n === 0x0a || n === 0x0d) {\n          // whitespace\n        } else {\n          return this.charError(buffer, i);\n        }\n      }\n    }else if (this.tState === STRING1){ // After open quote\n      n = buffer[i]; // get current byte from buffer\n      // check for carry over of a multi byte char split between data chunks\n      // & fill temp buffer it with start of this data chunk up to the boundary limit set in the last iteration\n      if (this.bytes_remaining > 0) {\n        for (var j = 0; j < this.bytes_remaining; j++) {\n          this.temp_buffs[this.bytes_in_sequence][this.bytes_in_sequence - this.bytes_remaining + j] = buffer[j];\n        }\n\n        this.appendStringBuf(this.temp_buffs[this.bytes_in_sequence]);\n        this.bytes_in_sequence = this.bytes_remaining = 0;\n        i = i + j - 1;\n      } else if (this.bytes_remaining === 0 && n >= 128) { // else if no remainder bytes carried over, parse multi byte (>=128) chars one at a time\n        if (n <= 193 || n > 244) {\n          return this.onError(new Error(\"Invalid UTF-8 character at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n        }\n        if ((n >= 194) && (n <= 223)) this.bytes_in_sequence = 2;\n        if ((n >= 224) && (n <= 239)) this.bytes_in_sequence = 3;\n        if ((n >= 240) && (n <= 244)) this.bytes_in_sequence = 4;\n        if ((this.bytes_in_sequence + i) > buffer.length) { // if bytes needed to complete char fall outside buffer length, we have a boundary split\n          for (var k = 0; k <= (buffer.length - 1 - i); k++) {\n            this.temp_buffs[this.bytes_in_sequence][k] = buffer[i + k]; // fill temp buffer of correct size with bytes available in this chunk\n          }\n          this.bytes_remaining = (i + this.bytes_in_sequence) - buffer.length;\n          i = buffer.length - 1;\n        } else {\n          this.appendStringBuf(buffer, i, i + this.bytes_in_sequence);\n          i = i + this.bytes_in_sequence - 1;\n        }\n      } else if (n === 0x22) {\n        this.tState = START;\n        this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n        this.stringBufferOffset = 0;\n        this.onToken(STRING, this.string);\n        this.offset += Buffer.byteLength(this.string, 'utf8') + 1;\n        this.string = undefined;\n      }\n      else if (n === 0x5c) {\n        this.tState = STRING2;\n      }\n      else if (n >= 0x20) { this.appendStringChar(n); }\n      else {\n          return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING2){ // After backslash\n      n = buffer[i];\n      if(n === 0x22){ this.appendStringChar(n); this.tState = STRING1;\n      }else if(n === 0x5c){ this.appendStringChar(BACK_SLASH); this.tState = STRING1;\n      }else if(n === 0x2f){ this.appendStringChar(FORWARD_SLASH); this.tState = STRING1;\n      }else if(n === 0x62){ this.appendStringChar(BACKSPACE); this.tState = STRING1;\n      }else if(n === 0x66){ this.appendStringChar(FORM_FEED); this.tState = STRING1;\n      }else if(n === 0x6e){ this.appendStringChar(NEWLINE); this.tState = STRING1;\n      }else if(n === 0x72){ this.appendStringChar(CARRIAGE_RETURN); this.tState = STRING1;\n      }else if(n === 0x74){ this.appendStringChar(TAB); this.tState = STRING1;\n      }else if(n === 0x75){ this.unicode = \"\"; this.tState = STRING3;\n      }else{\n        return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING3 || this.tState === STRING4 || this.tState === STRING5 || this.tState === STRING6){ // unicode hex codes\n      n = buffer[i];\n      // 0-9 A-F a-f\n      if ((n >= 0x30 && n < 0x40) || (n > 0x40 && n <= 0x46) || (n > 0x60 && n <= 0x66)) {\n        this.unicode += String.fromCharCode(n);\n        if (this.tState++ === STRING6) {\n          this.appendStringBuf(Buffer(String.fromCharCode(parseInt(this.unicode, 16))));\n          this.unicode = undefined;\n          this.tState = STRING1;\n        }\n      } else {\n        return this.charError(buffer, i);\n      }\n    } else if (this.tState === NUMBER1 || this.tState === NUMBER3) {\n        n = buffer[i];\n\n        switch (n) {\n          case 0x30: // 0\n          case 0x31: // 1\n          case 0x32: // 2\n          case 0x33: // 3\n          case 0x34: // 4\n          case 0x35: // 5\n          case 0x36: // 6\n          case 0x37: // 7\n          case 0x38: // 8\n          case 0x39: // 9\n          case 0x2e: // .\n          case 0x65: // e\n          case 0x45: // E\n          case 0x2b: // +\n          case 0x2d: // -\n            this.string += String.fromCharCode(n);\n            this.tState = NUMBER3;\n            break;\n          default:\n            this.tState = START;\n            var result = Number(this.string);\n\n            if (isNaN(result)){\n              return this.charError(buffer, i);\n            }\n\n            if ((this.string.match(/[0-9]+/) == this.string) && (result.toString() != this.string)) {\n              // Long string of digits which is an ID string and not valid and/or safe JavaScript integer Number\n              this.onToken(STRING, this.string);\n            } else {\n              this.onToken(NUMBER, result);\n            }\n\n            this.offset += this.string.length - 1;\n            this.string = undefined;\n            i--;\n            break;\n        }\n    }else if (this.tState === TRUE1){ // r\n      if (buffer[i] === 0x72) { this.tState = TRUE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE2){ // u\n      if (buffer[i] === 0x75) { this.tState = TRUE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE3){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(TRUE, true); this.offset+= 3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE1){ // a\n      if (buffer[i] === 0x61) { this.tState = FALSE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE2){ // l\n      if (buffer[i] === 0x6c) { this.tState = FALSE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE3){ // s\n      if (buffer[i] === 0x73) { this.tState = FALSE4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE4){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(FALSE, false); this.offset+= 4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL1){ // u\n      if (buffer[i] === 0x75) { this.tState = NULL2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL2){ // l\n      if (buffer[i] === 0x6c) { this.tState = NULL3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL3){ // l\n      if (buffer[i] === 0x6c) { this.tState = START; this.onToken(NULL, null); this.offset += 3; }\n      else { return this.charError(buffer, i); }\n    }\n  }\n};\nproto.onToken = function (token, value) {\n  // Override this to get events\n};\n\nproto.parseError = function (token, value) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + Parser.toknam(token) + (value ? (\"(\" + JSON.stringify(value) + \")\") : \"\") + \" in state \" + Parser.toknam(this.state)));\n};\nproto.push = function () {\n  this.stack.push({value: this.value, key: this.key, mode: this.mode});\n};\nproto.pop = function () {\n  var value = this.value;\n  var parent = this.stack.pop();\n  this.value = parent.value;\n  this.key = parent.key;\n  this.mode = parent.mode;\n  this.emit(value);\n  if (!this.mode) { this.state = VALUE; }\n};\nproto.emit = function (value) {\n  if (this.mode) { this.state = COMMA; }\n  this.onValue(value);\n};\nproto.onValue = function (value) {\n  // Override me\n};\nproto.onToken = function (token, value) {\n  if(this.state === VALUE){\n    if(token === STRING || token === NUMBER || token === TRUE || token === FALSE || token === NULL){\n      if (this.value) {\n        this.value[this.key] = value;\n      }\n      this.emit(value);\n    }else if(token === LEFT_BRACE){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = {};\n      } else {\n        this.value = {};\n      }\n      this.key = undefined;\n      this.state = KEY;\n      this.mode = OBJECT;\n    }else if(token === LEFT_BRACKET){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = [];\n      } else {\n        this.value = [];\n      }\n      this.key = 0;\n      this.mode = ARRAY;\n      this.state = VALUE;\n    }else if(token === RIGHT_BRACE){\n      if (this.mode === OBJECT) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else if(token === RIGHT_BRACKET){\n      if (this.mode === ARRAY) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else{\n      return this.parseError(token, value);\n    }\n  }else if(this.state === KEY){\n    if (token === STRING) {\n      this.key = value;\n      this.state = COLON;\n    } else if (token === RIGHT_BRACE) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else if(this.state === COLON){\n    if (token === COLON) { this.state = VALUE; }\n    else { return this.parseError(token, value); }\n  }else if(this.state === COMMA){\n    if (token === COMMA) {\n      if (this.mode === ARRAY) { this.key++; this.state = VALUE; }\n      else if (this.mode === OBJECT) { this.state = KEY; }\n\n    } else if (token === RIGHT_BRACKET && this.mode === ARRAY || token === RIGHT_BRACE && this.mode === OBJECT) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else{\n    return this.parseError(token, value);\n  }\n};\n\nParser.C = C;\n\nmodule.exports = Parser;\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/JSONStream/node_modules/through/index.js":"var Stream = require('stream')\n\n// through\n//\n// a stream that does nothing but re-emit the input.\n// useful for aggregating a series of changing but not ending streams into one stream)\n\nexports = module.exports = through\nthrough.through = through\n\n//create a readable writable stream.\n\nfunction through (write, end, opts) {\n  write = write || function (data) { this.queue(data) }\n  end = end || function () { this.queue(null) }\n\n  var ended = false, destroyed = false, buffer = [], _ended = false\n  var stream = new Stream()\n  stream.readable = stream.writable = true\n  stream.paused = false\n\n//  stream.autoPause   = !(opts && opts.autoPause   === false)\n  stream.autoDestroy = !(opts && opts.autoDestroy === false)\n\n  stream.write = function (data) {\n    write.call(this, data)\n    return !stream.paused\n  }\n\n  function drain() {\n    while(buffer.length && !stream.paused) {\n      var data = buffer.shift()\n      if(null === data)\n        return stream.emit('end')\n      else\n        stream.emit('data', data)\n    }\n  }\n\n  stream.queue = stream.push = function (data) {\n//    console.error(ended)\n    if(_ended) return stream\n    if(data === null) _ended = true\n    buffer.push(data)\n    drain()\n    return stream\n  }\n\n  //this will be registered as the first 'end' listener\n  //must call destroy next tick, to make sure we're after any\n  //stream piped from here.\n  //this is only a problem if end is not emitted synchronously.\n  //a nicer way to do this is to make sure this is the last listener for 'end'\n\n  stream.on('end', function () {\n    stream.readable = false\n    if(!stream.writable && stream.autoDestroy)\n      process.nextTick(function () {\n        stream.destroy()\n      })\n  })\n\n  function _end () {\n    stream.writable = false\n    end.call(stream)\n    if(!stream.readable && stream.autoDestroy)\n      stream.destroy()\n  }\n\n  stream.end = function (data) {\n    if(ended) return\n    ended = true\n    if(arguments.length) stream.write(data)\n    _end() // will emit or queue\n    return stream\n  }\n\n  stream.destroy = function () {\n    if(destroyed) return\n    destroyed = true\n    ended = true\n    buffer.length = 0\n    stream.writable = stream.readable = false\n    stream.emit('close')\n    return stream\n  }\n\n  stream.pause = function () {\n    if(stream.paused) return\n    stream.paused = true\n    return stream\n  }\n\n  stream.resume = function () {\n    if(stream.paused) {\n      stream.paused = false\n      stream.emit('resume')\n    }\n    drain()\n    //may have become paused again,\n    //as drain emits 'data'.\n    if(!stream.paused)\n      stream.emit('drain')\n    return stream\n  }\n  return stream\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/index.js":"var iterate = require('stream-iterate')\nvar from = require('from2')\n\nvar defaultKey = function (val) {\n  return val.key || val\n}\n\nvar union = function (streamA, streamB, toKey) {\n  var readA = iterate(streamA)\n  var readB = iterate(streamB)\n\n  if (!toKey) toKey = defaultKey\n\n  var stream = from.obj(function loop (size, cb) {\n    readA(function (err, dataA, nextA) {\n      if (err) return cb(err)\n      readB(function (err, dataB, nextB) {\n        if (err) return cb(err)\n\n        if (!dataA && !dataB) return cb(null, null)\n\n        if (!dataA) {\n          nextB()\n          return cb(null, dataB)\n        }\n\n        if (!dataB) {\n          nextA()\n          return cb(null, dataA)\n        }\n\n        var keyA = toKey(dataA)\n        var keyB = toKey(dataB)\n\n        if (keyA === keyB) {\n          nextB()\n          return loop(size, cb)\n        }\n\n        if (keyA < keyB) {\n          nextA()\n          return cb(null, dataA)\n        }\n\n        nextB()\n        cb(null, dataB)\n      })\n    })\n  })\n\n  stream.on('close', function () {\n    if (streamA.destroy) streamA.destroy()\n    if (streamB.destroy) streamB.destroy()\n  })\n\n  return stream\n}\n\nmodule.exports = union\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/stream-iterate/index.js":"var Readable = require('stream').Readable\n\nvar stream2 = function (stream) {\n  if (stream._readableState) return stream\n  return new Readable({objectMode: true, highWaterMark: 16}).wrap(stream)\n}\n\nmodule.exports = function (stream) {\n  stream = stream2(stream)\n\n  var ended = false\n  var data = null\n  var err = null\n  var destroyed = false\n  var fn = null\n\n  var consume = function (e) {\n    if (e) {\n      destroyed = true\n      if (stream.destroy) stream.destroy(e)\n      return\n    }\n\n    data = null\n    err = null\n  }\n\n  var onresult = function () {\n    if (!fn) return\n    var tmp = fn\n    fn = undefined\n    tmp(err, data, consume)\n  }\n\n  var update = function () {\n    if (!fn) return\n    data = stream.read()\n    if (data === null && !ended) return\n    onresult()\n  }\n\n  var onend = function () {\n    ended = true\n    onresult()\n  }\n\n  stream.on('readable', update)\n\n  stream.on('error', function (e) {\n    err = e\n    onresult()\n  })\n\n  stream.on('close', function () {\n    if (stream._readableState.ended) return\n    onend()\n  })\n\n  stream.on('end', onend)\n\n  return function (callback) {\n    if (destroyed) return\n    if (err) return callback(err, null, consume)\n    if (data) return callback(null, data, consume)\n    if (ended) return callback(null, null, consume)\n    fn = callback\n    update()\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/index.js":"var Readable = require('readable-stream').Readable\nvar inherits = require('inherits')\n\nmodule.exports = from2\n\nfrom2.ctor = ctor\nfrom2.obj = obj\n\nvar Proto = ctor()\n\nfunction toFunction(list) {\n  list = list.slice()\n  return function (_, cb) {\n    cb(null, list.length ? list.shift() : null)\n  }\n}\n\nfunction from2(opts, read) {\n  if (typeof opts !== 'object' || Array.isArray(opts)) {\n    read = opts\n    opts = {}\n  }\n  \n  if (Array.isArray(read)) read = toFunction(read)\n\n  var rs = new Proto(opts)\n  rs._from = read\n  return rs\n}\n\nfunction ctor(opts, read) {\n  if (typeof opts === 'function') {\n    read = opts\n    opts = {}\n  }\n\n  opts = defaults(opts)\n\n  inherits(Class, Readable)\n  function Class(override) {\n    if (!(this instanceof Class)) return new Class(override)\n    this._reading = false\n    this.destroyed = false\n    Readable.call(this, override || opts)\n  }\n\n  Class.prototype._from = read\n  Class.prototype._read = function(size) {\n    var self = this\n\n    if (this._reading || this.destroyed) return\n    this._reading = true\n    this._from(size, check)\n    function check(err, data) {\n      if (self.destroyed) return\n      if (err) return self.destroy(err)\n      if (data === null) return self.push(null)\n      self._reading = false\n      if (self.push(data)) self._read()\n    }\n  }\n\n  Class.prototype.destroy = function(err) {\n    if (this.destroyed) return\n    this.destroyed = true\n\n    var self = this\n    process.nextTick(function() {\n      if (err) self.emit('error', err)\n      self.emit('close')\n    })\n  }\n\n  return Class\n}\n\nfunction obj(opts, read) {\n  if (typeof opts === 'function' || Array.isArray(opts)) {\n    read = opts\n    opts = {}\n  }\n\n  opts = defaults(opts)\n  opts.objectMode = true\n  opts.highWaterMark = 16\n\n  return from2(opts, read)\n}\n\nfunction defaults(opts) {\n  opts = opts || {}\n  return opts\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/readable.js":"exports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = require('stream');\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\nif (!process.browser && process.env.READABLE_STREAM === 'disable') {\n  module.exports = require('stream');\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/lib/_stream_readable.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar Buffer = require('buffer').Buffer;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\nvar EE = require('events').EventEmitter;\n\n/*<replacement>*/\nif (!EE.listenerCount) EE.listenerCount = function(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\nvar Stream = require('stream');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar StringDecoder;\n\n\n/*<replacement>*/\nvar debug = require('util');\nif (debug && debug.debuglog) {\n  debug = debug.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\n\nutil.inherits(Readable, Stream);\n\nfunction ReadableState(options, stream) {\n  var Duplex = require('./_stream_duplex');\n\n  options = options || {};\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var defaultHwm = options.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.buffer = [];\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex)\n    this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // when piping, we only care about 'readable' events that happen\n  // after read()ing all the bytes and not getting any pushback.\n  this.ranOut = false;\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder)\n      StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  var Duplex = require('./_stream_duplex');\n\n  if (!(this instanceof Readable))\n    return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  Stream.call(this);\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function(chunk, encoding) {\n  var state = this._readableState;\n\n  if (util.isString(chunk) && !state.objectMode) {\n    encoding = encoding || state.defaultEncoding;\n    if (encoding !== state.encoding) {\n      chunk = new Buffer(chunk, encoding);\n      encoding = '';\n    }\n  }\n\n  return readableAddChunk(this, state, chunk, encoding, false);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function(chunk) {\n  var state = this._readableState;\n  return readableAddChunk(this, state, chunk, '', true);\n};\n\nfunction readableAddChunk(stream, state, chunk, encoding, addToFront) {\n  var er = chunkInvalid(state, chunk);\n  if (er) {\n    stream.emit('error', er);\n  } else if (util.isNullOrUndefined(chunk)) {\n    state.reading = false;\n    if (!state.ended)\n      onEofChunk(stream, state);\n  } else if (state.objectMode || chunk && chunk.length > 0) {\n    if (state.ended && !addToFront) {\n      var e = new Error('stream.push() after EOF');\n      stream.emit('error', e);\n    } else if (state.endEmitted && addToFront) {\n      var e = new Error('stream.unshift() after end event');\n      stream.emit('error', e);\n    } else {\n      if (state.decoder && !addToFront && !encoding)\n        chunk = state.decoder.write(chunk);\n\n      if (!addToFront)\n        state.reading = false;\n\n      // if we want the data now, just emit it.\n      if (state.flowing && state.length === 0 && !state.sync) {\n        stream.emit('data', chunk);\n        stream.read(0);\n      } else {\n        // update the buffer info.\n        state.length += state.objectMode ? 1 : chunk.length;\n        if (addToFront)\n          state.buffer.unshift(chunk);\n        else\n          state.buffer.push(chunk);\n\n        if (state.needReadable)\n          emitReadable(stream);\n      }\n\n      maybeReadMore(stream, state);\n    }\n  } else if (!addToFront) {\n    state.reading = false;\n  }\n\n  return needMoreData(state);\n}\n\n\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended &&\n         (state.needReadable ||\n          state.length < state.highWaterMark ||\n          state.length === 0);\n}\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function(enc) {\n  if (!StringDecoder)\n    StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 128MB\nvar MAX_HWM = 0x800000;\nfunction roundUpToNextPowerOf2(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2\n    n--;\n    for (var p = 1; p < 32; p <<= 1) n |= n >> p;\n    n++;\n  }\n  return n;\n}\n\nfunction howMuchToRead(n, state) {\n  if (state.length === 0 && state.ended)\n    return 0;\n\n  if (state.objectMode)\n    return n === 0 ? 0 : 1;\n\n  if (isNaN(n) || util.isNull(n)) {\n    // only flow one buffer at a time\n    if (state.flowing && state.buffer.length)\n      return state.buffer[0].length;\n    else\n      return state.length;\n  }\n\n  if (n <= 0)\n    return 0;\n\n  // If we're asking for more than the target buffer level,\n  // then raise the water mark.  Bump up to the next highest\n  // power of 2, to prevent increasing it excessively in tiny\n  // amounts.\n  if (n > state.highWaterMark)\n    state.highWaterMark = roundUpToNextPowerOf2(n);\n\n  // don't have that much.  return null, unless we've ended.\n  if (n > state.length) {\n    if (!state.ended) {\n      state.needReadable = true;\n      return 0;\n    } else\n      return state.length;\n  }\n\n  return n;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function(n) {\n  debug('read', n);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (!util.isNumber(n) || n > 0)\n    state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 &&\n      state.needReadable &&\n      (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended)\n      endReadable(this);\n    else\n      emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0)\n      endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  }\n\n  if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0)\n      state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n  }\n\n  // If _read pushed data synchronously, then `reading` will be false,\n  // and we need to re-evaluate how much data we can return to the user.\n  if (doRead && !state.reading)\n    n = howMuchToRead(nOrig, state);\n\n  var ret;\n  if (n > 0)\n    ret = fromList(n, state);\n  else\n    ret = null;\n\n  if (util.isNull(ret)) {\n    state.needReadable = true;\n    n = 0;\n  }\n\n  state.length -= n;\n\n  // If we have nothing in the buffer, then we want to know\n  // as soon as we *do* get something into the buffer.\n  if (state.length === 0 && !state.ended)\n    state.needReadable = true;\n\n  // If we tried to read() past the EOF, then emit end on the next tick.\n  if (nOrig !== n && state.ended && state.length === 0)\n    endReadable(this);\n\n  if (!util.isNull(ret))\n    this.emit('data', ret);\n\n  return ret;\n};\n\nfunction chunkInvalid(state, chunk) {\n  var er = null;\n  if (!util.isBuffer(chunk) &&\n      !util.isString(chunk) &&\n      !util.isNullOrUndefined(chunk) &&\n      !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n\nfunction onEofChunk(stream, state) {\n  if (state.decoder && !state.ended) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync)\n      process.nextTick(function() {\n        emitReadable_(stream);\n      });\n    else\n      emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(function() {\n      maybeReadMore_(stream, state);\n    });\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended &&\n         state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;\n    else\n      len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function(n) {\n  this.emit('error', new Error('not implemented'));\n};\n\nReadable.prototype.pipe = function(dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) &&\n              dest !== process.stdout &&\n              dest !== process.stderr;\n\n  var endFn = doEnd ? onend : cleanup;\n  if (state.endEmitted)\n    process.nextTick(endFn);\n  else\n    src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable) {\n    debug('onunpipe');\n    if (readable === src) {\n      cleanup();\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', cleanup);\n    src.removeListener('data', ondata);\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain &&\n        (!dest._writableState || dest._writableState.needDrain))\n      ondrain();\n  }\n\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    if (false === ret) {\n      debug('false write response, pause',\n            src._readableState.awaitDrain);\n      src._readableState.awaitDrain++;\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EE.listenerCount(dest, 'error') === 0)\n      dest.emit('error', er);\n  }\n  // This is a brutally ugly hack to make sure that our error handler\n  // is attached before any userland ones.  NEVER DO THIS.\n  if (!dest._events || !dest._events.error)\n    dest.on('error', onerror);\n  else if (isArray(dest._events.error))\n    dest._events.error.unshift(onerror);\n  else\n    dest._events.error = [onerror, dest._events.error];\n\n\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain)\n      state.awaitDrain--;\n    if (state.awaitDrain === 0 && EE.listenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\n\nReadable.prototype.unpipe = function(dest) {\n  var state = this._readableState;\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0)\n    return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes)\n      return this;\n\n    if (!dest)\n      dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest)\n      dest.emit('unpipe', this);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++)\n      dests[i].emit('unpipe', this);\n    return this;\n  }\n\n  // try to find the right one.\n  var i = indexOf(state.pipes, dest);\n  if (i === -1)\n    return this;\n\n  state.pipes.splice(i, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1)\n    state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function(ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  // If listening to data, and it has not explicitly been paused,\n  // then call resume to start the flow of data on the next tick.\n  if (ev === 'data' && false !== this._readableState.flowing) {\n    this.resume();\n  }\n\n  if (ev === 'readable' && this.readable) {\n    var state = this._readableState;\n    if (!state.readableListening) {\n      state.readableListening = true;\n      state.emittedReadable = false;\n      state.needReadable = true;\n      if (!state.reading) {\n        var self = this;\n        process.nextTick(function() {\n          debug('readable nexttick read 0');\n          self.read(0);\n        });\n      } else if (state.length) {\n        emitReadable(this, state);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function() {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    if (!state.reading) {\n      debug('resume read 0');\n      this.read(0);\n    }\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(function() {\n      resume_(stream, state);\n    });\n  }\n}\n\nfunction resume_(stream, state) {\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading)\n    stream.read(0);\n}\n\nReadable.prototype.pause = function() {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  if (state.flowing) {\n    do {\n      var chunk = stream.read();\n    } while (null !== chunk && state.flowing);\n  }\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function(stream) {\n  var state = this._readableState;\n  var paused = false;\n\n  var self = this;\n  stream.on('end', function() {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length)\n        self.push(chunk);\n    }\n\n    self.push(null);\n  });\n\n  stream.on('data', function(chunk) {\n    debug('wrapped data');\n    if (state.decoder)\n      chunk = state.decoder.write(chunk);\n    if (!chunk || !state.objectMode && !chunk.length)\n      return;\n\n    var ret = self.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (util.isFunction(stream[i]) && util.isUndefined(this[i])) {\n      this[i] = function(method) { return function() {\n        return stream[method].apply(stream, arguments);\n      }}(i);\n    }\n  }\n\n  // proxy certain important events.\n  var events = ['error', 'close', 'destroy', 'pause', 'resume'];\n  forEach(events, function(ev) {\n    stream.on(ev, self.emit.bind(self, ev));\n  });\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  self._read = function(n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return self;\n};\n\n\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\nfunction fromList(n, state) {\n  var list = state.buffer;\n  var length = state.length;\n  var stringMode = !!state.decoder;\n  var objectMode = !!state.objectMode;\n  var ret;\n\n  // nothing in the list, definitely empty.\n  if (list.length === 0)\n    return null;\n\n  if (length === 0)\n    ret = null;\n  else if (objectMode)\n    ret = list.shift();\n  else if (!n || n >= length) {\n    // read it all, truncate the array.\n    if (stringMode)\n      ret = list.join('');\n    else\n      ret = Buffer.concat(list, length);\n    list.length = 0;\n  } else {\n    // read just some of it.\n    if (n < list[0].length) {\n      // just take a part of the first list item.\n      // slice is the same for buffers and strings.\n      var buf = list[0];\n      ret = buf.slice(0, n);\n      list[0] = buf.slice(n);\n    } else if (n === list[0].length) {\n      // first list is a perfect match\n      ret = list.shift();\n    } else {\n      // complex case.\n      // we have enough to cover it, but it spans past the first buffer.\n      if (stringMode)\n        ret = '';\n      else\n        ret = new Buffer(n);\n\n      var c = 0;\n      for (var i = 0, l = list.length; i < l && c < n; i++) {\n        var buf = list[0];\n        var cpy = Math.min(n - c, buf.length);\n\n        if (stringMode)\n          ret += buf.slice(0, cpy);\n        else\n          buf.copy(ret, c, 0, cpy);\n\n        if (cpy < buf.length)\n          list[0] = buf.slice(cpy);\n        else\n          list.shift();\n\n        c += cpy;\n      }\n    }\n  }\n\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0)\n    throw new Error('endReadable called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(function() {\n      // Check that we didn't get one last unshift.\n      if (!state.endEmitted && state.length === 0) {\n        state.endEmitted = true;\n        stream.readable = false;\n        stream.emit('end');\n      }\n    });\n  }\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n\nfunction indexOf (xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/node_modules/isarray/index.js":"module.exports = Array.isArray || function (arr) {\n  return Object.prototype.toString.call(arr) == '[object Array]';\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/node_modules/core-util-is/lib/util.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/lib/_stream_writable.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, cb), and it'll handle all\n// the drain event emission and buffering.\n\nmodule.exports = Writable;\n\n/*<replacement>*/\nvar Buffer = require('buffer').Buffer;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Stream = require('stream');\n\nutil.inherits(Writable, Stream);\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n}\n\nfunction WritableState(options, stream) {\n  var Duplex = require('./_stream_duplex');\n\n  options = options || {};\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var defaultHwm = options.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : defaultHwm;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex)\n    this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function(er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.buffer = [];\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n}\n\nfunction Writable(options) {\n  var Duplex = require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, though they're not\n  // instanceof Writable, they're instanceof Readable.\n  if (!(this instanceof Writable) && !(this instanceof Duplex))\n    return new Writable(options);\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function() {\n  this.emit('error', new Error('Cannot pipe. Not readable.'));\n};\n\n\nfunction writeAfterEnd(stream, state, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  process.nextTick(function() {\n    cb(er);\n  });\n}\n\n// If we get something that is not a buffer, string, null, or undefined,\n// and we're not in objectMode, then that's an error.\n// Otherwise stream chunks are all considered to be of length=1, and the\n// watermarks determine how many objects to keep in the buffer, rather than\n// how many bytes or characters.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  if (!util.isBuffer(chunk) &&\n      !util.isString(chunk) &&\n      !util.isNullOrUndefined(chunk) &&\n      !state.objectMode) {\n    var er = new TypeError('Invalid non-string/buffer chunk');\n    stream.emit('error', er);\n    process.nextTick(function() {\n      cb(er);\n    });\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function(chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  if (util.isFunction(encoding)) {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (util.isBuffer(chunk))\n    encoding = 'buffer';\n  else if (!encoding)\n    encoding = state.defaultEncoding;\n\n  if (!util.isFunction(cb))\n    cb = function() {};\n\n  if (state.ended)\n    writeAfterEnd(this, state, cb);\n  else if (validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function() {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function() {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing &&\n        !state.corked &&\n        !state.finished &&\n        !state.bufferProcessing &&\n        state.buffer.length)\n      clearBuffer(this, state);\n  }\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode &&\n      state.decodeStrings !== false &&\n      util.isString(chunk)) {\n    chunk = new Buffer(chunk, encoding);\n  }\n  return chunk;\n}\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, chunk, encoding, cb) {\n  chunk = decodeChunk(state, chunk, encoding);\n  if (util.isBuffer(chunk))\n    encoding = 'buffer';\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret)\n    state.needDrain = true;\n\n  if (state.writing || state.corked)\n    state.buffer.push(new WriteReq(chunk, encoding, cb));\n  else\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev)\n    stream._writev(chunk, state.onwrite);\n  else\n    stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  if (sync)\n    process.nextTick(function() {\n      state.pendingcb--;\n      cb(er);\n    });\n  else {\n    state.pendingcb--;\n    cb(er);\n  }\n\n  stream._writableState.errorEmitted = true;\n  stream.emit('error', er);\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er)\n    onwriteError(stream, state, sync, er, cb);\n  else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(stream, state);\n\n    if (!finished &&\n        !state.corked &&\n        !state.bufferProcessing &&\n        state.buffer.length) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(function() {\n        afterWrite(stream, state, finished, cb);\n      });\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished)\n    onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n\n  if (stream._writev && state.buffer.length > 1) {\n    // Fast case, write everything using _writev()\n    var cbs = [];\n    for (var c = 0; c < state.buffer.length; c++)\n      cbs.push(state.buffer[c].callback);\n\n    // count the one we are adding, as well.\n    // TODO(isaacs) clean this up\n    state.pendingcb++;\n    doWrite(stream, state, true, state.length, state.buffer, '', function(err) {\n      for (var i = 0; i < cbs.length; i++) {\n        state.pendingcb--;\n        cbs[i](err);\n      }\n    });\n\n    // Clear buffer\n    state.buffer = [];\n  } else {\n    // Slow case, write chunks one-by-one\n    for (var c = 0; c < state.buffer.length; c++) {\n      var entry = state.buffer[c];\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        c++;\n        break;\n      }\n    }\n\n    if (c < state.buffer.length)\n      state.buffer = state.buffer.slice(c);\n    else\n      state.buffer.length = 0;\n  }\n\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function(chunk, encoding, cb) {\n  cb(new Error('not implemented'));\n\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function(chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (util.isFunction(chunk)) {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (util.isFunction(encoding)) {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (!util.isNullOrUndefined(chunk))\n    this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished)\n    endWritable(this, state, cb);\n};\n\n\nfunction needFinish(stream, state) {\n  return (state.ending &&\n          state.length === 0 &&\n          !state.finished &&\n          !state.writing);\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished) {\n    state.prefinished = true;\n    stream.emit('prefinish');\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(stream, state);\n  if (need) {\n    if (state.pendingcb === 0) {\n      prefinish(stream, state);\n      state.finished = true;\n      stream.emit('finish');\n    } else\n      prefinish(stream, state);\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished)\n      process.nextTick(cb);\n    else\n      stream.once('finish', cb);\n  }\n  state.ended = true;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/lib/_stream_duplex.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) keys.push(key);\n  return keys;\n}\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\nforEach(objectKeys(Writable.prototype), function(method) {\n  if (!Duplex.prototype[method])\n    Duplex.prototype[method] = Writable.prototype[method];\n});\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex))\n    return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false)\n    this.readable = false;\n\n  if (options && options.writable === false)\n    this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false)\n    this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended)\n    return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  process.nextTick(this.end.bind(this));\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/lib/_stream_transform.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\n\nfunction TransformState(options, stream) {\n  this.afterTransform = function(er, data) {\n    return afterTransform(stream, er, data);\n  };\n\n  this.needTransform = false;\n  this.transforming = false;\n  this.writecb = null;\n  this.writechunk = null;\n}\n\nfunction afterTransform(stream, er, data) {\n  var ts = stream._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb)\n    return stream.emit('error', new Error('no writecb in Transform class'));\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (!util.isNullOrUndefined(data))\n    stream.push(data);\n\n  if (cb)\n    cb(er);\n\n  var rs = stream._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    stream._read(rs.highWaterMark);\n  }\n}\n\n\nfunction Transform(options) {\n  if (!(this instanceof Transform))\n    return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = new TransformState(options, this);\n\n  // when the writable side finishes, then flush out anything remaining.\n  var stream = this;\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  this.once('prefinish', function() {\n    if (util.isFunction(this._flush))\n      this._flush(function(er) {\n        done(stream, er);\n      });\n    else\n      done(stream);\n  });\n}\n\nTransform.prototype.push = function(chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function(chunk, encoding, cb) {\n  throw new Error('not implemented');\n};\n\nTransform.prototype._write = function(chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform ||\n        rs.needReadable ||\n        rs.length < rs.highWaterMark)\n      this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function(n) {\n  var ts = this._transformState;\n\n  if (!util.isNull(ts.writechunk) && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\n\nfunction done(stream, er) {\n  if (er)\n    return stream.emit('error', er);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  var ws = stream._writableState;\n  var ts = stream._transformState;\n\n  if (ws.length)\n    throw new Error('calling transform done when ws.length != 0');\n\n  if (ts.transforming)\n    throw new Error('calling transform done when still transforming');\n\n  return stream.push(null);\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/sorted-union-stream/node_modules/from2/node_modules/readable-stream/lib/_stream_passthrough.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough))\n    return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function(chunk, encoding, cb) {\n  cb(null, chunk);\n};\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/utils/gunzip-maybe.js":"var duplex = require('mississippi').duplex\nvar through = require('mississippi').through\nvar zlib = require('zlib')\n\nfunction hasGzipHeader (c) {\n  return c[0] === 0x1F && c[1] === 0x8B && c[2] === 0x08\n}\n\nmodule.exports = gunzip\nfunction gunzip () {\n  var stream = duplex()\n  var peeker = through(function (chunk, enc, cb) {\n    var newStream = hasGzipHeader(chunk)\n    ? zlib.createGunzip()\n    : through()\n    stream.setReadable(newStream)\n    stream.setWritable(newStream)\n    stream.write(chunk)\n  })\n  stream.setWritable(peeker)\n  return stream\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/search/package-filter.js":"'use strict'\n\nmodule.exports = filter\nfunction filter (data, include, exclude, opts) {\n  return typeof data === 'object' &&\n         filterWords(data, include, exclude, opts)\n}\n\nfunction getWords (data, opts) {\n  return [ data.name ]\n  .concat((opts && opts.description) ? data.description : [])\n  .concat((data.maintainers || []).map(function (m) {\n    return '=' + m.name\n  }))\n  .concat(data.versions && data.versions.length && data.url && ('<' + data.url + '>'))\n  .concat(data.keywords || [])\n  .map(function (f) { return f && f.trim && f.trim() })\n  .filter(function (f) { return f })\n  .join(' ')\n  .toLowerCase()\n}\n\nfunction filterWords (data, include, exclude, opts) {\n  var words = getWords(data, opts)\n  for (var i = 0, l = include.length; i < l; i++) {\n    if (!match(words, include[i])) return false\n  }\n  for (i = 0, l = exclude.length; i < l; i++) {\n    if (match(words, exclude[i])) return false\n  }\n  return true\n}\n\nfunction match (words, pattern) {\n  if (pattern.charAt(0) === '/') {\n    pattern = pattern.replace(/\\/$/, '')\n    pattern = new RegExp(pattern.substr(1, pattern.length - 1))\n    return words.match(pattern)\n  }\n  return words.indexOf(pattern) !== -1\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/search/esearch.js":"'use strict'\n\nvar npm = require('../npm.js')\nvar log = require('npmlog')\nvar mapToRegistry = require('../utils/map-to-registry.js')\nvar jsonstream = require('JSONStream')\nvar ms = require('mississippi')\nvar gunzip = require('../utils/gunzip-maybe')\n\nmodule.exports = esearch\n\nfunction esearch (opts) {\n  var stream = ms.through.obj()\n\n  mapToRegistry('-/v1/search', npm.config, function (er, uri, auth) {\n    if (er) return stream.emit('error', er)\n    createResultStream(uri, auth, opts, function (err, resultStream) {\n      if (err) return stream.emit('error', err)\n      ms.pipeline.obj(resultStream, stream)\n    })\n  })\n  return stream\n}\n\nfunction createResultStream (uri, auth, opts, cb) {\n  log.verbose('esearch', 'creating remote entry stream')\n  var params = {\n    timeout: 600,\n    follow: true,\n    staleOk: true,\n    auth: auth,\n    streaming: true\n  }\n  var q = buildQuery(opts)\n  npm.registry.request(uri + '?text=' + encodeURIComponent(q) + '&size=' + opts.limit, params, function (err, res) {\n    if (err) return cb(err)\n    log.silly('esearch', 'request stream opened, code:', res.statusCode)\n    // NOTE - The stream returned by `request` seems to be very persnickety\n    //        and this is almost a magic incantation to get it to work.\n    //        Modify how `res` is used here at your own risk.\n    var entryStream = ms.pipeline.obj(\n      res,\n      ms.through(function (chunk, enc, cb) {\n        cb(null, chunk)\n      }),\n      gunzip(),\n      jsonstream.parse('objects.*.package', function (data) {\n        return {\n          name: data.name,\n          description: data.description,\n          maintainers: data.maintainers,\n          keywords: data.keywords,\n          version: data.version,\n          date: data.date ? new Date(data.date) : null\n        }\n      })\n    )\n    return cb(null, entryStream)\n  })\n}\n\nfunction buildQuery (opts) {\n  return opts.include.join(' ')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/search/format-package-stream.js":"'use strict'\n\nvar ms = require('mississippi')\nvar jsonstream = require('JSONStream')\nvar columnify = require('columnify')\n\n// This module consumes package data in the following format:\n//\n// {\n//   name: String,\n//   description: String,\n//   maintainers: [{ username: String, email: String }],\n//   keywords: String | [String],\n//   version: String,\n//   date: Date // can be null,\n// }\n//\n// The returned stream will format this package data\n// into a byte stream of formatted, displayable output.\n\nmodule.exports = formatPackageStream\nfunction formatPackageStream (opts) {\n  opts = opts || {}\n  if (opts.json) {\n    return jsonOutputStream()\n  } else {\n    return textOutputStream(opts)\n  }\n}\n\nfunction jsonOutputStream () {\n  return ms.pipeline.obj(\n    ms.through.obj(),\n    jsonstream.stringify('[', ',', ']'),\n    ms.through()\n  )\n}\n\nfunction textOutputStream (opts) {\n  var line = 0\n  return ms.through.obj(function (pkg, enc, cb) {\n    cb(null, prettify(pkg, ++line, opts))\n  })\n}\n\nfunction prettify (data, num, opts) {\n  opts = opts || {}\n  var truncate = !opts.long\n\n  var pkg = normalizePackage(data, opts)\n\n  var columns = opts.description\n  ? ['name', 'description', 'author', 'date', 'version', 'keywords']\n  : ['name', 'author', 'date', 'version', 'keywords']\n\n  if (opts.parseable) {\n    return columns.map(function (col) {\n      return pkg[col] && ('' + pkg[col]).replace(/\\t/g, ' ')\n    }).join('\\t')\n  }\n\n  var output = columnify(\n    [pkg],\n    {\n      include: columns,\n      showHeaders: num <= 1,\n      columnSplitter: ' | ',\n      truncate: truncate,\n      config: {\n        name: { minWidth: 25, maxWidth: 25, truncate: false, truncateMarker: '' },\n        description: { minWidth: 20, maxWidth: 20 },\n        author: { minWidth: 15, maxWidth: 15 },\n        date: { maxWidth: 11 },\n        version: { minWidth: 8, maxWidth: 8 },\n        keywords: { maxWidth: Infinity }\n      }\n    }\n  )\n  output = trimToMaxWidth(output)\n  if (opts.color) {\n    output = highlightSearchTerms(output, opts.args)\n  }\n  return output\n}\n\nvar colors = [31, 33, 32, 36, 34, 35]\nvar cl = colors.length\n\nfunction addColorMarker (str, arg, i) {\n  var m = i % cl + 1\n  var markStart = String.fromCharCode(m)\n  var markEnd = String.fromCharCode(0)\n\n  if (arg.charAt(0) === '/') {\n    return str.replace(\n      new RegExp(arg.substr(1, arg.length - 2), 'gi'),\n      function (bit) { return markStart + bit + markEnd }\n    )\n  }\n\n  // just a normal string, do the split/map thing\n  var pieces = str.toLowerCase().split(arg.toLowerCase())\n  var p = 0\n\n  return pieces.map(function (piece) {\n    piece = str.substr(p, piece.length)\n    var mark = markStart +\n               str.substr(p + piece.length, arg.length) +\n               markEnd\n    p += piece.length + arg.length\n    return piece + mark\n  }).join('')\n}\n\nfunction colorize (line) {\n  for (var i = 0; i < cl; i++) {\n    var m = i + 1\n    var color = '\\u001B[' + colors[i] + 'm'\n    line = line.split(String.fromCharCode(m)).join(color)\n  }\n  var uncolor = '\\u001B[0m'\n  return line.split('\\u0000').join(uncolor)\n}\n\nfunction getMaxWidth () {\n  var cols\n  try {\n    var tty = require('tty')\n    var stdout = process.stdout\n    cols = !tty.isatty(stdout.fd) ? Infinity : process.stdout.getWindowSize()[0]\n    cols = (cols === 0) ? Infinity : cols\n  } catch (ex) { cols = Infinity }\n  return cols\n}\n\nfunction trimToMaxWidth (str) {\n  var maxWidth = getMaxWidth()\n  return str.split('\\n').map(function (line) {\n    return line.slice(0, maxWidth)\n  }).join('\\n')\n}\n\nfunction highlightSearchTerms (str, terms) {\n  terms.forEach(function (arg, i) {\n    str = addColorMarker(str, arg, i)\n  })\n\n  return colorize(str).trim()\n}\n\nfunction normalizePackage (data, opts) {\n  opts = opts || {}\n  return {\n    name: data.name,\n    description: opts.description ? data.description : '',\n    author: (data.maintainers || []).map(function (m) {\n      return '=' + m.username\n    }).join(' '),\n    keywords: Array.isArray(data.keywords)\n    ? data.keywords.join(' ')\n    : typeof data.keywords === 'string'\n    ? data.keywords.replace(/[,\\s]+/, ' ')\n    : '',\n    version: data.version,\n    date: data.date &&\n          (data.date.toISOString() // remove time\n            .split('T').join(' ')\n            .replace(/:[0-9]{2}\\.[0-9]{3}Z$/, ''))\n            .slice(0, -5) ||\n          'prehistoric'\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/columnify/columnify.js":"\"use strict\";\n\nvar wcwidth = require('./width');\n\nvar _require = require('./utils');\n\nvar padRight = _require.padRight;\nvar padCenter = _require.padCenter;\nvar padLeft = _require.padLeft;\nvar splitIntoLines = _require.splitIntoLines;\nvar splitLongWords = _require.splitLongWords;\nvar truncateString = _require.truncateString;\n\nvar DEFAULT_HEADING_TRANSFORM = function DEFAULT_HEADING_TRANSFORM(key) {\n  return key.toUpperCase();\n};\n\nvar DEFAULT_DATA_TRANSFORM = function DEFAULT_DATA_TRANSFORM(cell, column, index) {\n  return cell;\n};\n\nvar DEFAULTS = Object.freeze({\n  maxWidth: Infinity,\n  minWidth: 0,\n  columnSplitter: ' ',\n  truncate: false,\n  truncateMarker: '',\n  preserveNewLines: false,\n  paddingChr: ' ',\n  showHeaders: true,\n  headingTransform: DEFAULT_HEADING_TRANSFORM,\n  dataTransform: DEFAULT_DATA_TRANSFORM\n});\n\nmodule.exports = function (items) {\n  var options = arguments.length <= 1 || arguments[1] === undefined ? {} : arguments[1];\n\n  var columnConfigs = options.config || {};\n  delete options.config; // remove config so doesn't appear on every column.\n\n  var maxLineWidth = options.maxLineWidth || Infinity;\n  if (maxLineWidth === 'auto') maxLineWidth = process.stdout.columns || Infinity;\n  delete options.maxLineWidth; // this is a line control option, don't pass it to column\n\n  // Option defaults inheritance:\n  // options.config[columnName] => options => DEFAULTS\n  options = mixin({}, DEFAULTS, options);\n\n  options.config = options.config || Object.create(null);\n\n  options.spacing = options.spacing || '\\n'; // probably useless\n  options.preserveNewLines = !!options.preserveNewLines;\n  options.showHeaders = !!options.showHeaders;\n  options.columns = options.columns || options.include; // alias include/columns, prefer columns if supplied\n  var columnNames = options.columns || []; // optional user-supplied columns to include\n\n  items = toArray(items, columnNames);\n\n  // if not suppled column names, automatically determine columns from data keys\n  if (!columnNames.length) {\n    items.forEach(function (item) {\n      for (var columnName in item) {\n        if (columnNames.indexOf(columnName) === -1) columnNames.push(columnName);\n      }\n    });\n  }\n\n  // initialize column defaults (each column inherits from options.config)\n  var columns = columnNames.reduce(function (columns, columnName) {\n    var column = Object.create(options);\n    columns[columnName] = mixin(column, columnConfigs[columnName]);\n    return columns;\n  }, Object.create(null));\n\n  // sanitize column settings\n  columnNames.forEach(function (columnName) {\n    var column = columns[columnName];\n    column.name = columnName;\n    column.maxWidth = Math.ceil(column.maxWidth);\n    column.minWidth = Math.ceil(column.minWidth);\n    column.truncate = !!column.truncate;\n    column.align = column.align || 'left';\n  });\n\n  // sanitize data\n  items = items.map(function (item) {\n    var result = Object.create(null);\n    columnNames.forEach(function (columnName) {\n      // null/undefined -> ''\n      result[columnName] = item[columnName] != null ? item[columnName] : '';\n      // toString everything\n      result[columnName] = '' + result[columnName];\n      if (columns[columnName].preserveNewLines) {\n        // merge non-newline whitespace chars\n        result[columnName] = result[columnName].replace(/[^\\S\\n]/gmi, ' ');\n      } else {\n        // merge all whitespace chars\n        result[columnName] = result[columnName].replace(/\\s/gmi, ' ');\n      }\n    });\n    return result;\n  });\n\n  // transform data cells\n  columnNames.forEach(function (columnName) {\n    var column = columns[columnName];\n    items = items.map(function (item, index) {\n      var col = Object.create(column);\n      item[columnName] = column.dataTransform(item[columnName], col, index);\n\n      var changedKeys = Object.keys(col);\n      // disable default heading transform if we wrote to column.name\n      if (changedKeys.indexOf('name') !== -1) {\n        if (column.headingTransform !== DEFAULT_HEADING_TRANSFORM) return;\n        column.headingTransform = function (heading) {\n          return heading;\n        };\n      }\n      changedKeys.forEach(function (key) {\n        return column[key] = col[key];\n      });\n      return item;\n    });\n  });\n\n  // add headers\n  var headers = {};\n  if (options.showHeaders) {\n    columnNames.forEach(function (columnName) {\n      var column = columns[columnName];\n\n      if (!column.showHeaders) {\n        headers[columnName] = '';\n        return;\n      }\n\n      headers[columnName] = column.headingTransform(column.name);\n    });\n    items.unshift(headers);\n  }\n  // get actual max-width between min & max\n  // based on length of data in columns\n  columnNames.forEach(function (columnName) {\n    var column = columns[columnName];\n    column.width = items.map(function (item) {\n      return item[columnName];\n    }).reduce(function (min, cur) {\n      // if already at maxWidth don't bother testing\n      if (min >= column.maxWidth) return min;\n      return Math.max(min, Math.min(column.maxWidth, Math.max(column.minWidth, wcwidth(cur))));\n    }, 0);\n  });\n\n  // split long words so they can break onto multiple lines\n  columnNames.forEach(function (columnName) {\n    var column = columns[columnName];\n    items = items.map(function (item) {\n      item[columnName] = splitLongWords(item[columnName], column.width, column.truncateMarker);\n      return item;\n    });\n  });\n\n  // wrap long lines. each item is now an array of lines.\n  columnNames.forEach(function (columnName) {\n    var column = columns[columnName];\n    items = items.map(function (item, index) {\n      var cell = item[columnName];\n      item[columnName] = splitIntoLines(cell, column.width);\n\n      // if truncating required, only include first line + add truncation char\n      if (column.truncate && item[columnName].length > 1) {\n        item[columnName] = splitIntoLines(cell, column.width - wcwidth(column.truncateMarker));\n        var firstLine = item[columnName][0];\n        if (!endsWith(firstLine, column.truncateMarker)) item[columnName][0] += column.truncateMarker;\n        item[columnName] = item[columnName].slice(0, 1);\n      }\n      return item;\n    });\n  });\n\n  // recalculate column widths from truncated output/lines\n  columnNames.forEach(function (columnName) {\n    var column = columns[columnName];\n    column.width = items.map(function (item) {\n      return item[columnName].reduce(function (min, cur) {\n        if (min >= column.maxWidth) return min;\n        return Math.max(min, Math.min(column.maxWidth, Math.max(column.minWidth, wcwidth(cur))));\n      }, 0);\n    }).reduce(function (min, cur) {\n      if (min >= column.maxWidth) return min;\n      return Math.max(min, Math.min(column.maxWidth, Math.max(column.minWidth, cur)));\n    }, 0);\n  });\n\n  var rows = createRows(items, columns, columnNames, options.paddingChr); // merge lines into rows\n  // conceive output\n  return rows.reduce(function (output, row) {\n    return output.concat(row.reduce(function (rowOut, line) {\n      return rowOut.concat(line.join(options.columnSplitter));\n    }, []));\n  }, []).map(function (line) {\n    return truncateString(line, maxLineWidth);\n  }).join(options.spacing);\n};\n\n/**\n * Convert wrapped lines into rows with padded values.\n *\n * @param Array items data to process\n * @param Array columns column width settings for wrapping\n * @param Array columnNames column ordering\n * @return Array items wrapped in arrays, corresponding to lines\n */\n\nfunction createRows(items, columns, columnNames, paddingChr) {\n  return items.map(function (item) {\n    var row = [];\n    var numLines = 0;\n    columnNames.forEach(function (columnName) {\n      numLines = Math.max(numLines, item[columnName].length);\n    });\n    // combine matching lines of each rows\n\n    var _loop = function _loop(i) {\n      row[i] = row[i] || [];\n      columnNames.forEach(function (columnName) {\n        var column = columns[columnName];\n        var val = item[columnName][i] || ''; // || '' ensures empty columns get padded\n        if (column.align === 'right') row[i].push(padLeft(val, column.width, paddingChr));else if (column.align === 'center' || column.align === 'centre') row[i].push(padCenter(val, column.width, paddingChr));else row[i].push(padRight(val, column.width, paddingChr));\n      });\n    };\n\n    for (var i = 0; i < numLines; i++) {\n      _loop(i);\n    }\n    return row;\n  });\n}\n\n/**\n * Object.assign\n *\n * @return Object Object with properties mixed in.\n */\n\nfunction mixin() {\n  var _Object;\n\n  if (Object.assign) return (_Object = Object).assign.apply(_Object, arguments);\n  return ObjectAssign.apply(undefined, arguments);\n}\n\nfunction ObjectAssign(target, firstSource) {\n  \"use strict\";\n\n  if (target === undefined || target === null) throw new TypeError(\"Cannot convert first argument to object\");\n\n  var to = Object(target);\n\n  var hasPendingException = false;\n  var pendingException;\n\n  for (var i = 1; i < arguments.length; i++) {\n    var nextSource = arguments[i];\n    if (nextSource === undefined || nextSource === null) continue;\n\n    var keysArray = Object.keys(Object(nextSource));\n    for (var nextIndex = 0, len = keysArray.length; nextIndex < len; nextIndex++) {\n      var nextKey = keysArray[nextIndex];\n      try {\n        var desc = Object.getOwnPropertyDescriptor(nextSource, nextKey);\n        if (desc !== undefined && desc.enumerable) to[nextKey] = nextSource[nextKey];\n      } catch (e) {\n        if (!hasPendingException) {\n          hasPendingException = true;\n          pendingException = e;\n        }\n      }\n    }\n\n    if (hasPendingException) throw pendingException;\n  }\n  return to;\n}\n\n/**\n * Adapted from String.prototype.endsWith polyfill.\n */\n\nfunction endsWith(target, searchString, position) {\n  position = position || target.length;\n  position = position - searchString.length;\n  var lastIndex = target.lastIndexOf(searchString);\n  return lastIndex !== -1 && lastIndex === position;\n}\n\nfunction toArray(items, columnNames) {\n  if (Array.isArray(items)) return items;\n  var rows = [];\n  for (var key in items) {\n    var item = {};\n    item[columnNames[0] || 'key'] = key;\n    item[columnNames[1] || 'value'] = items[key];\n    rows.push(item);\n  }\n  return rows;\n}\n\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/columnify/width.js":"var stripAnsi = require('strip-ansi')\nvar wcwidth = require('wcwidth')\n\nmodule.exports = function(str) {\n  return wcwidth(stripAnsi(str))\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/columnify/node_modules/wcwidth/index.js":"\"use strict\"\n\nvar defaults = require('defaults')\nvar combining = require('./combining')\n\nvar DEFAULTS = {\n  nul: 0,\n  control: 0\n}\n\nmodule.exports = function wcwidth(str) {\n  return wcswidth(str, DEFAULTS)\n}\n\nmodule.exports.config = function(opts) {\n  opts = defaults(opts || {}, DEFAULTS)\n  return function wcwidth(str) {\n    return wcswidth(str, opts)\n  }\n}\n\n/*\n *  The following functions define the column width of an ISO 10646\n *  character as follows:\n *  - The null character (U+0000) has a column width of 0.\n *  - Other C0/C1 control characters and DEL will lead to a return value\n *    of -1.\n *  - Non-spacing and enclosing combining characters (general category\n *    code Mn or Me in the\n *    Unicode database) have a column width of 0.\n *  - SOFT HYPHEN (U+00AD) has a column width of 1.\n *  - Other format characters (general category code Cf in the Unicode\n *    database) and ZERO WIDTH\n *    SPACE (U+200B) have a column width of 0.\n *  - Hangul Jamo medial vowels and final consonants (U+1160-U+11FF)\n *    have a column width of 0.\n *  - Spacing characters in the East Asian Wide (W) or East Asian\n *    Full-width (F) category as\n *    defined in Unicode Technical Report #11 have a column width of 2.\n *  - All remaining characters (including all printable ISO 8859-1 and\n *    WGL4 characters, Unicode control characters, etc.) have a column\n *    width of 1.\n *  This implementation assumes that characters are encoded in ISO 10646.\n*/\n\nfunction wcswidth(str, opts) {\n  if (typeof str !== 'string') return wcwidth(str, opts)\n\n  var s = 0\n  for (var i = 0; i < str.length; i++) {\n    var n = wcwidth(str.charCodeAt(i), opts)\n    if (n < 0) return -1\n    s += n\n  }\n\n  return s\n}\n\nfunction wcwidth(ucs, opts) {\n  // test for 8-bit control characters\n  if (ucs === 0) return opts.nul\n  if (ucs < 32 || (ucs >= 0x7f && ucs < 0xa0)) return opts.control\n\n  // binary search in table of non-spacing characters\n  if (bisearch(ucs)) return 0\n\n  // if we arrive here, ucs is not a combining or C0/C1 control character\n  return 1 +\n      (ucs >= 0x1100 &&\n       (ucs <= 0x115f ||                       // Hangul Jamo init. consonants\n        ucs == 0x2329 || ucs == 0x232a ||\n        (ucs >= 0x2e80 && ucs <= 0xa4cf &&\n         ucs != 0x303f) ||                     // CJK ... Yi\n        (ucs >= 0xac00 && ucs <= 0xd7a3) ||    // Hangul Syllables\n        (ucs >= 0xf900 && ucs <= 0xfaff) ||    // CJK Compatibility Ideographs\n        (ucs >= 0xfe10 && ucs <= 0xfe19) ||    // Vertical forms\n        (ucs >= 0xfe30 && ucs <= 0xfe6f) ||    // CJK Compatibility Forms\n        (ucs >= 0xff00 && ucs <= 0xff60) ||    // Fullwidth Forms\n        (ucs >= 0xffe0 && ucs <= 0xffe6) ||\n        (ucs >= 0x20000 && ucs <= 0x2fffd) ||\n        (ucs >= 0x30000 && ucs <= 0x3fffd)));\n}\n\nfunction bisearch(ucs) {\n  var min = 0\n  var max = combining.length - 1\n  var mid\n\n  if (ucs < combining[0][0] || ucs > combining[max][1]) return false\n\n  while (max >= min) {\n    mid = Math.floor((min + max) / 2)\n    if (ucs > combining[mid][1]) min = mid + 1\n    else if (ucs < combining[mid][0]) max = mid - 1\n    else return true\n  }\n\n  return false\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/columnify/node_modules/wcwidth/node_modules/defaults/index.js":"var clone = require('clone');\n\nmodule.exports = function(options, defaults) {\n  options = options || {};\n\n  Object.keys(defaults).forEach(function(key) {\n    if (typeof options[key] === 'undefined') {\n      options[key] = clone(defaults[key]);\n    }\n  });\n\n  return options;\n};","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/columnify/node_modules/wcwidth/node_modules/defaults/node_modules/clone/clone.js":"var clone = (function() {\n'use strict';\n\n/**\n * Clones (copies) an Object using deep copying.\n *\n * This function supports circular references by default, but if you are certain\n * there are no circular references in your object, you can save some CPU time\n * by calling clone(obj, false).\n *\n * Caution: if `circular` is false and `parent` contains circular references,\n * your program may enter an infinite loop and crash.\n *\n * @param `parent` - the object to be cloned\n * @param `circular` - set to true if the object to be cloned may contain\n *    circular references. (optional - true by default)\n * @param `depth` - set to a number if the object is only to be cloned to\n *    a particular depth. (optional - defaults to Infinity)\n * @param `prototype` - sets the prototype to be used when cloning an object.\n *    (optional - defaults to parent prototype).\n*/\nfunction clone(parent, circular, depth, prototype) {\n  var filter;\n  if (typeof circular === 'object') {\n    depth = circular.depth;\n    prototype = circular.prototype;\n    filter = circular.filter;\n    circular = circular.circular\n  }\n  // maintain two arrays for circular references, where corresponding parents\n  // and children have the same index\n  var allParents = [];\n  var allChildren = [];\n\n  var useBuffer = typeof Buffer != 'undefined';\n\n  if (typeof circular == 'undefined')\n    circular = true;\n\n  if (typeof depth == 'undefined')\n    depth = Infinity;\n\n  // recurse this function so we don't reset allParents and allChildren\n  function _clone(parent, depth) {\n    // cloning null always returns null\n    if (parent === null)\n      return null;\n\n    if (depth == 0)\n      return parent;\n\n    var child;\n    var proto;\n    if (typeof parent != 'object') {\n      return parent;\n    }\n\n    if (clone.__isArray(parent)) {\n      child = [];\n    } else if (clone.__isRegExp(parent)) {\n      child = new RegExp(parent.source, __getRegExpFlags(parent));\n      if (parent.lastIndex) child.lastIndex = parent.lastIndex;\n    } else if (clone.__isDate(parent)) {\n      child = new Date(parent.getTime());\n    } else if (useBuffer && Buffer.isBuffer(parent)) {\n      child = new Buffer(parent.length);\n      parent.copy(child);\n      return child;\n    } else {\n      if (typeof prototype == 'undefined') {\n        proto = Object.getPrototypeOf(parent);\n        child = Object.create(proto);\n      }\n      else {\n        child = Object.create(prototype);\n        proto = prototype;\n      }\n    }\n\n    if (circular) {\n      var index = allParents.indexOf(parent);\n\n      if (index != -1) {\n        return allChildren[index];\n      }\n      allParents.push(parent);\n      allChildren.push(child);\n    }\n\n    for (var i in parent) {\n      var attrs;\n      if (proto) {\n        attrs = Object.getOwnPropertyDescriptor(proto, i);\n      }\n\n      if (attrs && attrs.set == null) {\n        continue;\n      }\n      child[i] = _clone(parent[i], depth - 1);\n    }\n\n    return child;\n  }\n\n  return _clone(parent, depth);\n}\n\n/**\n * Simple flat clone using prototype, accepts only objects, usefull for property\n * override on FLAT configuration object (no nested props).\n *\n * USE WITH CAUTION! This may not behave as you wish if you do not know how this\n * works.\n */\nclone.clonePrototype = function clonePrototype(parent) {\n  if (parent === null)\n    return null;\n\n  var c = function () {};\n  c.prototype = parent;\n  return new c();\n};\n\n// private utility functions\n\nfunction __objToStr(o) {\n  return Object.prototype.toString.call(o);\n};\nclone.__objToStr = __objToStr;\n\nfunction __isDate(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Date]';\n};\nclone.__isDate = __isDate;\n\nfunction __isArray(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Array]';\n};\nclone.__isArray = __isArray;\n\nfunction __isRegExp(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object RegExp]';\n};\nclone.__isRegExp = __isRegExp;\n\nfunction __getRegExpFlags(re) {\n  var flags = '';\n  if (re.global) flags += 'g';\n  if (re.ignoreCase) flags += 'i';\n  if (re.multiline) flags += 'm';\n  return flags;\n};\nclone.__getRegExpFlags = __getRegExpFlags;\n\nreturn clone;\n})();\n\nif (typeof module === 'object' && module.exports) {\n  module.exports = clone;\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/columnify/node_modules/wcwidth/combining.js":"module.exports = [\n    [ 0x0300, 0x036F ], [ 0x0483, 0x0486 ], [ 0x0488, 0x0489 ],\n    [ 0x0591, 0x05BD ], [ 0x05BF, 0x05BF ], [ 0x05C1, 0x05C2 ],\n    [ 0x05C4, 0x05C5 ], [ 0x05C7, 0x05C7 ], [ 0x0600, 0x0603 ],\n    [ 0x0610, 0x0615 ], [ 0x064B, 0x065E ], [ 0x0670, 0x0670 ],\n    [ 0x06D6, 0x06E4 ], [ 0x06E7, 0x06E8 ], [ 0x06EA, 0x06ED ],\n    [ 0x070F, 0x070F ], [ 0x0711, 0x0711 ], [ 0x0730, 0x074A ],\n    [ 0x07A6, 0x07B0 ], [ 0x07EB, 0x07F3 ], [ 0x0901, 0x0902 ],\n    [ 0x093C, 0x093C ], [ 0x0941, 0x0948 ], [ 0x094D, 0x094D ],\n    [ 0x0951, 0x0954 ], [ 0x0962, 0x0963 ], [ 0x0981, 0x0981 ],\n    [ 0x09BC, 0x09BC ], [ 0x09C1, 0x09C4 ], [ 0x09CD, 0x09CD ],\n    [ 0x09E2, 0x09E3 ], [ 0x0A01, 0x0A02 ], [ 0x0A3C, 0x0A3C ],\n    [ 0x0A41, 0x0A42 ], [ 0x0A47, 0x0A48 ], [ 0x0A4B, 0x0A4D ],\n    [ 0x0A70, 0x0A71 ], [ 0x0A81, 0x0A82 ], [ 0x0ABC, 0x0ABC ],\n    [ 0x0AC1, 0x0AC5 ], [ 0x0AC7, 0x0AC8 ], [ 0x0ACD, 0x0ACD ],\n    [ 0x0AE2, 0x0AE3 ], [ 0x0B01, 0x0B01 ], [ 0x0B3C, 0x0B3C ],\n    [ 0x0B3F, 0x0B3F ], [ 0x0B41, 0x0B43 ], [ 0x0B4D, 0x0B4D ],\n    [ 0x0B56, 0x0B56 ], [ 0x0B82, 0x0B82 ], [ 0x0BC0, 0x0BC0 ],\n    [ 0x0BCD, 0x0BCD ], [ 0x0C3E, 0x0C40 ], [ 0x0C46, 0x0C48 ],\n    [ 0x0C4A, 0x0C4D ], [ 0x0C55, 0x0C56 ], [ 0x0CBC, 0x0CBC ],\n    [ 0x0CBF, 0x0CBF ], [ 0x0CC6, 0x0CC6 ], [ 0x0CCC, 0x0CCD ],\n    [ 0x0CE2, 0x0CE3 ], [ 0x0D41, 0x0D43 ], [ 0x0D4D, 0x0D4D ],\n    [ 0x0DCA, 0x0DCA ], [ 0x0DD2, 0x0DD4 ], [ 0x0DD6, 0x0DD6 ],\n    [ 0x0E31, 0x0E31 ], [ 0x0E34, 0x0E3A ], [ 0x0E47, 0x0E4E ],\n    [ 0x0EB1, 0x0EB1 ], [ 0x0EB4, 0x0EB9 ], [ 0x0EBB, 0x0EBC ],\n    [ 0x0EC8, 0x0ECD ], [ 0x0F18, 0x0F19 ], [ 0x0F35, 0x0F35 ],\n    [ 0x0F37, 0x0F37 ], [ 0x0F39, 0x0F39 ], [ 0x0F71, 0x0F7E ],\n    [ 0x0F80, 0x0F84 ], [ 0x0F86, 0x0F87 ], [ 0x0F90, 0x0F97 ],\n    [ 0x0F99, 0x0FBC ], [ 0x0FC6, 0x0FC6 ], [ 0x102D, 0x1030 ],\n    [ 0x1032, 0x1032 ], [ 0x1036, 0x1037 ], [ 0x1039, 0x1039 ],\n    [ 0x1058, 0x1059 ], [ 0x1160, 0x11FF ], [ 0x135F, 0x135F ],\n    [ 0x1712, 0x1714 ], [ 0x1732, 0x1734 ], [ 0x1752, 0x1753 ],\n    [ 0x1772, 0x1773 ], [ 0x17B4, 0x17B5 ], [ 0x17B7, 0x17BD ],\n    [ 0x17C6, 0x17C6 ], [ 0x17C9, 0x17D3 ], [ 0x17DD, 0x17DD ],\n    [ 0x180B, 0x180D ], [ 0x18A9, 0x18A9 ], [ 0x1920, 0x1922 ],\n    [ 0x1927, 0x1928 ], [ 0x1932, 0x1932 ], [ 0x1939, 0x193B ],\n    [ 0x1A17, 0x1A18 ], [ 0x1B00, 0x1B03 ], [ 0x1B34, 0x1B34 ],\n    [ 0x1B36, 0x1B3A ], [ 0x1B3C, 0x1B3C ], [ 0x1B42, 0x1B42 ],\n    [ 0x1B6B, 0x1B73 ], [ 0x1DC0, 0x1DCA ], [ 0x1DFE, 0x1DFF ],\n    [ 0x200B, 0x200F ], [ 0x202A, 0x202E ], [ 0x2060, 0x2063 ],\n    [ 0x206A, 0x206F ], [ 0x20D0, 0x20EF ], [ 0x302A, 0x302F ],\n    [ 0x3099, 0x309A ], [ 0xA806, 0xA806 ], [ 0xA80B, 0xA80B ],\n    [ 0xA825, 0xA826 ], [ 0xFB1E, 0xFB1E ], [ 0xFE00, 0xFE0F ],\n    [ 0xFE20, 0xFE23 ], [ 0xFEFF, 0xFEFF ], [ 0xFFF9, 0xFFFB ],\n    [ 0x10A01, 0x10A03 ], [ 0x10A05, 0x10A06 ], [ 0x10A0C, 0x10A0F ],\n    [ 0x10A38, 0x10A3A ], [ 0x10A3F, 0x10A3F ], [ 0x1D167, 0x1D169 ],\n    [ 0x1D173, 0x1D182 ], [ 0x1D185, 0x1D18B ], [ 0x1D1AA, 0x1D1AD ],\n    [ 0x1D242, 0x1D244 ], [ 0xE0001, 0xE0001 ], [ 0xE0020, 0xE007F ],\n    [ 0xE0100, 0xE01EF ]\n]\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/node_modules/columnify/utils.js":"\"use strict\"\n\nvar wcwidth = require('./width')\n\n/**\n * repeat string `str` up to total length of `len`\n *\n * @param String str string to repeat\n * @param Number len total length of output string\n */\n\nfunction repeatString(str, len) {\n  return Array.apply(null, {length: len + 1}).join(str).slice(0, len)\n}\n\n/**\n * Pad `str` up to total length `max` with `chr`.\n * If `str` is longer than `max`, padRight will return `str` unaltered.\n *\n * @param String str string to pad\n * @param Number max total length of output string\n * @param String chr optional. Character to pad with. default: ' '\n * @return String padded str\n */\n\nfunction padRight(str, max, chr) {\n  str = str != null ? str : ''\n  str = String(str)\n  var length = max - wcwidth(str)\n  if (length <= 0) return str\n  return str + repeatString(chr || ' ', length)\n}\n\n/**\n * Pad `str` up to total length `max` with `chr`.\n * If `str` is longer than `max`, padCenter will return `str` unaltered.\n *\n * @param String str string to pad\n * @param Number max total length of output string\n * @param String chr optional. Character to pad with. default: ' '\n * @return String padded str\n */\n\nfunction padCenter(str, max, chr) {\n  str = str != null ? str : ''\n  str = String(str)\n  var length = max - wcwidth(str)\n  if (length <= 0) return str\n  var lengthLeft = Math.floor(length/2)\n  var lengthRight = length - lengthLeft\n  return repeatString(chr || ' ', lengthLeft) + str + repeatString(chr || ' ', lengthRight)\n}\n\n/**\n * Pad `str` up to total length `max` with `chr`, on the left.\n * If `str` is longer than `max`, padRight will return `str` unaltered.\n *\n * @param String str string to pad\n * @param Number max total length of output string\n * @param String chr optional. Character to pad with. default: ' '\n * @return String padded str\n */\n\nfunction padLeft(str, max, chr) {\n  str = str != null ? str : ''\n  str = String(str)\n  var length = max - wcwidth(str)\n  if (length <= 0) return str\n  return repeatString(chr || ' ', length) + str\n}\n\n/**\n * Split a String `str` into lines of maxiumum length `max`.\n * Splits on word boundaries. Preserves existing new lines.\n *\n * @param String str string to split\n * @param Number max length of each line\n * @return Array Array containing lines.\n */\n\nfunction splitIntoLines(str, max) {\n  function _splitIntoLines(str, max) {\n    return str.trim().split(' ').reduce(function(lines, word) {\n      var line = lines[lines.length - 1]\n      if (line && wcwidth(line.join(' ')) + wcwidth(word) < max) {\n        lines[lines.length - 1].push(word) // add to line\n      }\n      else lines.push([word]) // new line\n      return lines\n    }, []).map(function(l) {\n      return l.join(' ')\n    })\n  }\n  return str.split('\\n').map(function(str) {\n    return _splitIntoLines(str, max)\n  }).reduce(function(lines, line) {\n    return lines.concat(line)\n  }, [])\n}\n\n/**\n * Add spaces and `truncationChar` between words of\n * `str` which are longer than `max`.\n *\n * @param String str string to split\n * @param Number max length of each line\n * @param Number truncationChar character to append to split words\n * @return String\n */\n\nfunction splitLongWords(str, max, truncationChar) {\n  str = str.trim()\n  var result = []\n  var words = str.split(' ')\n  var remainder = ''\n\n  var truncationWidth = wcwidth(truncationChar)\n\n  while (remainder || words.length) {\n    if (remainder) {\n      var word = remainder\n      remainder = ''\n    } else {\n      var word = words.shift()\n    }\n\n    if (wcwidth(word) > max) {\n      // slice is based on length no wcwidth\n      var i = 0\n      var wwidth = 0\n      var limit = max - truncationWidth\n      while (i < word.length) {\n        var w = wcwidth(word.charAt(i))\n        if (w + wwidth > limit) {\n          break\n        }\n        wwidth += w\n        ++i\n      }\n\n      remainder = word.slice(i) // get remainder\n      // save remainder for next loop\n\n      word = word.slice(0, i) // grab truncated word\n      word += truncationChar // add trailing  or whatever\n    }\n    result.push(word)\n  }\n\n  return result.join(' ')\n}\n\n\n/**\n * Truncate `str` into total width `max`\n * If `str` is shorter than `max`,  will return `str` unaltered.\n *\n * @param String str string to truncated\n * @param Number max total wcwidth of output string\n * @return String truncated str\n */\n\nfunction truncateString(str, max) {\n\n  str = str != null ? str : ''\n  str = String(str)\n\n  if(max == Infinity) return str\n\n  var i = 0\n  var wwidth = 0\n  while (i < str.length) {\n    var w = wcwidth(str.charAt(i))\n    if(w + wwidth > max)\n      break\n    wwidth += w\n    ++i\n  }\n  return str.slice(0, i)\n}\n\n\n\n/**\n * Exports\n */\n\nmodule.exports.padRight = padRight\nmodule.exports.padCenter = padCenter\nmodule.exports.padLeft = padLeft\nmodule.exports.splitIntoLines = splitIntoLines\nmodule.exports.splitLongWords = splitLongWords\nmodule.exports.truncateString = truncateString\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/set.js":"\nmodule.exports = set\n\nset.usage = 'npm set <key> <value> (See `npm config`)'\n\nvar npm = require('./npm.js')\n\nset.completion = npm.commands.config.completion\n\nfunction set (args, cb) {\n  if (!args.length) return cb(set.usage)\n  npm.commands.config(['set'].concat(args), cb)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/shrinkwrap.js":"// emit JSON describing versions of all packages currently installed (for later\n// use with shrinkwrap install)\n\nmodule.exports = exports = shrinkwrap\n\nvar path = require('path')\nvar log = require('npmlog')\nvar writeFileAtomic = require('write-file-atomic')\nvar iferr = require('iferr')\nvar readPackageJson = require('read-package-json')\nvar readPackageTree = require('read-package-tree')\nvar validate = require('aproba')\nvar chain = require('slide').chain\nvar npm = require('./npm.js')\nvar recalculateMetadata = require('./install/deps.js').recalculateMetadata\nvar validatePeerDeps = require('./install/deps.js').validatePeerDeps\nvar isExtraneous = require('./install/is-extraneous.js')\nvar packageId = require('./utils/package-id.js')\nvar moduleName = require('./utils/module-name.js')\nvar output = require('./utils/output.js')\nvar lifecycle = require('./utils/lifecycle.js')\nvar isDevDep = require('./install/is-dev-dep.js')\nvar isProdDep = require('./install/is-prod-dep.js')\nvar isOptDep = require('./install/is-opt-dep.js')\n\nshrinkwrap.usage = 'npm shrinkwrap'\n\nfunction shrinkwrap (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n\n  if (args.length) {\n    log.warn('shrinkwrap', \"doesn't take positional args\")\n  }\n\n  var packagePath = path.join(npm.localPrefix, 'package.json')\n  var prod = npm.config.get('production') || /^prod/.test(npm.config.get('only'))\n\n  readPackageJson(packagePath, iferr(cb, function (pkg) {\n    createShrinkwrap(npm.localPrefix, pkg, !prod, silent, cb)\n  }))\n}\n\nmodule.exports.createShrinkwrap = createShrinkwrap\n\nfunction createShrinkwrap (dir, pkg, dev, silent, cb) {\n  lifecycle(pkg, 'preshrinkwrap', dir, function () {\n    readPackageTree(dir, andRecalculateMetadata(iferr(cb, function (tree) {\n      var pkginfo = treeToShrinkwrap(tree, dev)\n\n      chain([\n        [lifecycle, tree.package, 'shrinkwrap', dir],\n        [shrinkwrap_, pkginfo, silent],\n        [lifecycle, tree.package, 'postshrinkwrap', dir]\n      ], iferr(cb, function (data) {\n        cb(null, data[0])\n      }))\n    })))\n  })\n}\n\nfunction andRecalculateMetadata (next) {\n  validate('F', arguments)\n  return function (er, tree) {\n    validate('EO', arguments)\n    if (er) return next(er)\n    recalculateMetadata(tree, log, next)\n  }\n}\n\nfunction treeToShrinkwrap (tree, dev) {\n  validate('OB', arguments)\n  var pkginfo = {}\n  if (tree.package.name) pkginfo.name = tree.package.name\n  if (tree.package.version) pkginfo.version = tree.package.version\n  var problems = []\n  if (tree.children.length) {\n    shrinkwrapDeps(dev, problems, pkginfo.dependencies = {}, tree)\n  }\n  if (problems.length) pkginfo.problems = problems\n  return pkginfo\n}\n\nfunction shrinkwrapDeps (dev, problems, deps, tree, seen) {\n  validate('BAOO', [dev, problems, deps, tree])\n  if (!seen) seen = {}\n  if (seen[tree.path]) return\n  seen[tree.path] = true\n  Object.keys(tree.missingDeps).forEach(function (name) {\n    var invalid = tree.children.filter(function (dep) { return moduleName(dep) === name })[0]\n    if (invalid) {\n      problems.push('invalid: have ' + invalid.package._id + ' (expected: ' + tree.missingDeps[name] + ') ' + invalid.path)\n    } else if (!tree.package.optionalDependencies || !tree.package.optionalDependencies[name]) {\n      var topname = packageId(tree)\n      problems.push('missing: ' + name + '@' + tree.package.dependencies[name] +\n        (topname ? ', required by ' + topname : ''))\n    }\n  })\n  tree.children.sort(function (aa, bb) { return moduleName(aa).localeCompare(moduleName(bb)) }).forEach(function (child) {\n    var childIsOnlyDev = isOnlyDev(child)\n    if (!dev && childIsOnlyDev) {\n      log.warn('shrinkwrap', 'Excluding devDependency: %s', child.location)\n      return\n    }\n    var pkginfo = deps[moduleName(child)] = {}\n    pkginfo.version = child.package.version\n    pkginfo.from = child.package._from\n    pkginfo.resolved = child.package._resolved\n    if (dev && childIsOnlyDev) pkginfo.dev = true\n    if (isOptional(child)) pkginfo.optional = true\n    if (isExtraneous(child)) {\n      problems.push('extraneous: ' + child.package._id + ' ' + child.path)\n    }\n    validatePeerDeps(child, function (tree, pkgname, version) {\n      problems.push('peer invalid: ' + pkgname + '@' + version +\n        ', required by ' + child.package._id)\n    })\n    if (child.children.length) {\n      shrinkwrapDeps(dev, problems, pkginfo.dependencies = {}, child, seen)\n    }\n  })\n}\n\nfunction shrinkwrap_ (pkginfo, silent, cb) {\n  if (pkginfo.problems) {\n    return cb(new Error('Problems were encountered\\n' +\n                        'Please correct and try again.\\n' +\n                        pkginfo.problems.join('\\n')))\n  }\n\n  save(pkginfo, silent, cb)\n}\n\nfunction save (pkginfo, silent, cb) {\n  // copy the keys over in a well defined order\n  // because javascript objects serialize arbitrarily\n  var swdata\n  try {\n    swdata = JSON.stringify(pkginfo, null, 2) + '\\n'\n  } catch (er) {\n    log.error('shrinkwrap', 'Error converting package info to json')\n    return cb(er)\n  }\n\n  var file = path.resolve(npm.prefix, 'npm-shrinkwrap.json')\n\n  writeFileAtomic(file, swdata, function (er) {\n    if (er) return cb(er)\n    if (silent) return cb(null, pkginfo)\n    output('wrote npm-shrinkwrap.json')\n    cb(null, pkginfo)\n  })\n}\n\n// Returns true if the module `node` is only required direcctly as a dev\n// dependency of the top level or transitively _from_ top level dev\n// dependencies.\n// Dual mode modules (that are both dev AND prod) should return false.\nfunction isOnlyDev (node, seen) {\n  if (!seen) seen = {}\n  return node.requiredBy.length && node.requiredBy.every(andIsOnlyDev(moduleName(node), seen))\n}\n\n// There is a known limitation with this implementation: If a dependency is\n// ONLY required by cycles that are detached from the top level then it will\n// ultimately return true.\n//\n// This is ok though: We don't allow shrinkwraps with extraneous deps and\n// these situation is caught by the extraneous checker before we get here.\nfunction andIsOnlyDev (name, seen) {\n  return function (req) {\n    var isDev = isDevDep(req, name)\n    var isProd = isProdDep(req, name)\n    if (req.isTop) {\n      return isDev && !isProd\n    } else {\n      if (seen[req.path]) return true\n      seen[req.path] = true\n      return isOnlyDev(req, seen)\n    }\n  }\n}\n\nfunction isOptional (node, seen) {\n  if (!seen) seen = {}\n  // If a node is not required by anything, then we've reached\n  // the top level package.\n  if (seen[node.path] || node.requiredBy.length === 0) {\n    return false\n  }\n  seen[node.path] = true\n\n  return node.requiredBy.every(function (req) {\n    return isOptDep(req, node.package.name) || isOptional(req, seen)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/star.js":"module.exports = star\n\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar asyncMap = require('slide').asyncMap\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar usage = require('./utils/usage')\nvar output = require('./utils/output.js')\n\nstar.usage = usage(\n  'star',\n  'npm star [<pkg>...]\\n' +\n  'npm unstar [<pkg>...]'\n)\n\nstar.completion = function (opts, cb) {\n  // FIXME: there used to be registry completion here, but it stopped making\n  // sense somewhere around 50,000 packages on the registry\n  cb()\n}\n\nfunction star (args, cb) {\n  if (!args.length) return cb(star.usage)\n  var s = npm.config.get('unicode') ? '\\u2605 ' : '(*)'\n  var u = npm.config.get('unicode') ? '\\u2606 ' : '( )'\n  var using = !(npm.command.match(/^un/))\n  if (!using) s = u\n  asyncMap(args, function (pkg, cb) {\n    mapToRegistry(pkg, npm.config, function (er, uri, auth) {\n      if (er) return cb(er)\n\n      var params = {\n        starred: using,\n        auth: auth\n      }\n      npm.registry.star(uri, params, function (er, data, raw, req) {\n        if (!er) {\n          output(s + ' ' + pkg)\n          log.verbose('star', data)\n        }\n        cb(er, data, raw, req)\n      })\n    })\n  }, cb)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/stars.js":"module.exports = stars\n\nstars.usage = 'npm stars [<user>]'\n\nvar npm = require('./npm.js')\nvar log = require('npmlog')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar output = require('./utils/output.js')\n\nfunction stars (args, cb) {\n  npm.commands.whoami([], true, function (er, username) {\n    var name = args.length === 1 ? args[0] : username\n\n    if (er) {\n      if (er.code === 'ENEEDAUTH' && !name) {\n        var needAuth = new Error(\"'npm stars' on your own user account requires auth\")\n        needAuth.code = 'ENEEDAUTH'\n        return cb(needAuth)\n      }\n\n      if (er.code !== 'ENEEDAUTH') return cb(er)\n    }\n\n    mapToRegistry('', npm.config, function (er, uri, auth) {\n      if (er) return cb(er)\n\n      var params = {\n        username: name,\n        auth: auth\n      }\n      npm.registry.stars(uri, params, showstars)\n    })\n  })\n\n  function showstars (er, data) {\n    if (er) return cb(er)\n\n    if (data.rows.length === 0) {\n      log.warn('stars', 'user has not starred any packages.')\n    } else {\n      data.rows.forEach(function (a) {\n        output(a.value)\n      })\n    }\n    cb()\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/start.js":"module.exports = require('./utils/lifecycle.js').cmd('start')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/stop.js":"module.exports = require('./utils/lifecycle.js').cmd('stop')\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/substack.js":"module.exports = substack\nvar npm = require('./npm.js')\nvar output = require('./utils/output.js')\n\nvar isms = [\n  '\\u001b[32mbeep \\u001b[35mboop\\u001b[m',\n  'Replace your configs with services',\n  'SEPARATE ALL THE CONCERNS!',\n  'MODULE ALL THE THINGS!',\n  '\\\\o/',\n  'but first, burritos',\n  'full time mad scientist here',\n  'c/,,\\\\'\n]\n\nfunction substack (args, cb) {\n  var i = Math.floor(Math.random() * isms.length)\n  output(isms[i])\n  var c = args.shift()\n  if (c) npm.commands[c](args, cb)\n  else cb()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/team.js":"var mapToRegistry = require('./utils/map-to-registry.js')\nvar npm = require('./npm')\nvar output = require('./utils/output.js')\n\nmodule.exports = team\n\nteam.subcommands = ['create', 'destroy', 'add', 'rm', 'ls', 'edit']\n\nteam.usage =\n  'npm team create <scope:team>\\n' +\n  'npm team destroy <scope:team>\\n' +\n  'npm team add <scope:team> <user>\\n' +\n  'npm team rm <scope:team> <user>\\n' +\n  'npm team ls <scope>|<scope:team>\\n' +\n  'npm team edit <scope:team>'\n\nteam.completion = function (opts, cb) {\n  var argv = opts.conf.argv.remain\n  if (argv.length === 2) {\n    return cb(null, team.subcommands)\n  }\n  switch (argv[2]) {\n    case 'ls':\n    case 'create':\n    case 'destroy':\n    case 'add':\n    case 'rm':\n    case 'edit':\n      return cb(null, [])\n    default:\n      return cb(new Error(argv[2] + ' not recognized'))\n  }\n}\n\nfunction team (args, cb) {\n  // Entities are in the format <scope>:<team>\n  var cmd = args.shift()\n  var entity = (args.shift() || '').split(':')\n  return mapToRegistry('/', npm.config, function (err, uri, auth) {\n    if (err) { return cb(err) }\n    try {\n      return npm.registry.team(cmd, uri, {\n        auth: auth,\n        scope: entity[0],\n        team: entity[1],\n        user: args.shift()\n      }, function (err, data) {\n        !err && data && output(JSON.stringify(data, undefined, 2))\n        cb(err, data)\n      })\n    } catch (e) {\n      cb(e.message + '\\n\\nUsage:\\n' + team.usage)\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/unbuild.js":"module.exports = unbuild\nmodule.exports.rmStuff = rmStuff\nunbuild.usage = 'npm unbuild <folder>\\n(this is plumbing)'\n\nvar readJson = require('read-package-json')\nvar gentlyRm = require('./utils/gently-rm.js')\nvar npm = require('./npm.js')\nvar path = require('path')\nvar isInside = require('path-is-inside')\nvar lifecycle = require('./utils/lifecycle.js')\nvar asyncMap = require('slide').asyncMap\nvar chain = require('slide').chain\nvar log = require('npmlog')\nvar build = require('./build.js')\nvar output = require('./utils/output.js')\n\n// args is a list of folders.\n// remove any bins/etc, and then delete the folder.\nfunction unbuild (args, silent, cb) {\n  if (typeof silent === 'function') {\n    cb = silent\n    silent = false\n  }\n  asyncMap(args, unbuild_(silent), cb)\n}\n\nfunction unbuild_ (silent) {\n  return function (folder, cb_) {\n    function cb (er) {\n      cb_(er, path.relative(npm.root, folder))\n    }\n    folder = path.resolve(folder)\n    var base = isInside(folder, npm.prefix) ? npm.prefix : folder\n    delete build._didBuild[folder]\n    log.verbose('unbuild', folder.substr(npm.prefix.length + 1))\n    readJson(path.resolve(folder, 'package.json'), function (er, pkg) {\n      // if no json, then just trash it, but no scripts or whatever.\n      if (er) return gentlyRm(folder, false, base, cb)\n      chain(\n        [\n          [lifecycle, pkg, 'preuninstall', folder, false, true],\n          [lifecycle, pkg, 'uninstall', folder, false, true],\n          !silent && function (cb) {\n            output('unbuild ' + pkg._id)\n            cb()\n          },\n          [rmStuff, pkg, folder],\n          [lifecycle, pkg, 'postuninstall', folder, false, true],\n          [gentlyRm, folder, false, base]\n        ],\n        cb\n      )\n    })\n  }\n}\n\nfunction rmStuff (pkg, folder, cb) {\n  // if it's global, and folder is in {prefix}/node_modules,\n  // then bins are in {prefix}/bin\n  // otherwise, then bins are in folder/../.bin\n  var parent = pkg.name[0] === '@' ? path.dirname(path.dirname(folder)) : path.dirname(folder)\n  var gnm = npm.dir\n  var top = gnm === parent\n\n  log.verbose('unbuild rmStuff', pkg._id, 'from', gnm)\n  if (!top) log.verbose('unbuild rmStuff', 'in', parent)\n  asyncMap([rmBins, rmMans], function (fn, cb) {\n    fn(pkg, folder, parent, top, cb)\n  }, cb)\n}\n\nfunction rmBins (pkg, folder, parent, top, cb) {\n  if (!pkg.bin) return cb()\n  var binRoot = top ? npm.bin : path.resolve(parent, '.bin')\n  asyncMap(Object.keys(pkg.bin), function (b, cb) {\n    if (process.platform === 'win32') {\n      chain([ [gentlyRm, path.resolve(binRoot, b) + '.cmd', true, folder],\n              [gentlyRm, path.resolve(binRoot, b), true, folder] ], cb)\n    } else {\n      gentlyRm(path.resolve(binRoot, b), true, folder, cb)\n    }\n  }, gentlyRmBinRoot)\n\n  function gentlyRmBinRoot (err) {\n    if (err || top) return cb(err)\n    return gentlyRm(binRoot, true, parent, cb)\n  }\n}\n\nfunction rmMans (pkg, folder, parent, top, cb) {\n  if (!pkg.man ||\n      !top ||\n      process.platform === 'win32' ||\n      !npm.config.get('global')) {\n    return cb()\n  }\n  var manRoot = path.resolve(npm.config.get('prefix'), 'share', 'man')\n  log.verbose('rmMans', 'man files are', pkg.man, 'in', manRoot)\n  asyncMap(pkg.man, function (man, cb) {\n    if (Array.isArray(man)) {\n      man.forEach(rmMan)\n    } else {\n      rmMan(man)\n    }\n\n    function rmMan (man) {\n      log.silly('rmMan', 'preparing to remove', man)\n      var parseMan = man.match(/(.*\\.([0-9]+)(\\.gz)?)$/)\n      if (!parseMan) {\n        log.error(\n          'rmMan', man, 'is not a valid name for a man file.',\n          'Man files must end with a number, ' +\n          'and optionally a .gz suffix if they are compressed.'\n        )\n        return cb()\n      }\n\n      var stem = parseMan[1]\n      var sxn = parseMan[2]\n      var gz = parseMan[3] || ''\n      var bn = path.basename(stem)\n      var manDest = path.join(\n        manRoot,\n        'man' + sxn,\n        (bn.indexOf(pkg.name) === 0 ? bn : pkg.name + '-' + bn) + '.' + sxn + gz\n      )\n      gentlyRm(manDest, true, cb)\n    }\n  }, cb)\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/uninstall.js":"'use strict'\n// remove a package.\n\nmodule.exports = uninstall\nmodule.exports.Uninstaller = Uninstaller\n\nvar util = require('util')\nvar path = require('path')\nvar validate = require('aproba')\nvar chain = require('slide').chain\nvar readJson = require('read-package-json')\nvar npm = require('./npm.js')\nvar Installer = require('./install.js').Installer\nvar getSaveType = require('./install/save.js').getSaveType\nvar removeDeps = require('./install/deps.js').removeDeps\nvar loadExtraneous = require('./install/deps.js').loadExtraneous\nvar log = require('npmlog')\nvar usage = require('./utils/usage')\n\nuninstall.usage = usage(\n  'uninstall',\n  'npm uninstall [<@scope>/]<pkg>[@<version>]... [--save|--save-dev|--save-optional]'\n)\n\nuninstall.completion = require('./utils/completion/installed-shallow.js')\n\nfunction uninstall (args, cb) {\n  validate('AF', arguments)\n  // the /path/to/node_modules/..\n  var dryrun = !!npm.config.get('dry-run')\n\n  if (args.length === 1 && args[0] === '.') args = []\n  args = args.filter(function (a) {\n    return path.resolve(a) !== where\n  })\n\n  var where = npm.config.get('global') || !args.length\n            ? path.resolve(npm.globalDir, '..')\n            : npm.prefix\n\n  if (args.length) {\n    new Uninstaller(where, dryrun, args).run(cb)\n  } else {\n    // remove this package from the global space, if it's installed there\n    readJson(path.resolve(npm.localPrefix, 'package.json'), function (er, pkg) {\n      if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n      if (er) return cb(uninstall.usage)\n      new Uninstaller(where, dryrun, [pkg.name]).run(cb)\n    })\n  }\n}\n\nfunction Uninstaller (where, dryrun, args) {\n  validate('SBA', arguments)\n  Installer.call(this, where, dryrun, args)\n}\nutil.inherits(Uninstaller, Installer)\n\nUninstaller.prototype.loadArgMetadata = function (next) {\n  this.args = this.args.map(function (arg) { return {name: arg} })\n  next()\n}\n\nUninstaller.prototype.loadAllDepsIntoIdealTree = function (cb) {\n  validate('F', arguments)\n  log.silly('uninstall', 'loadAllDepsIntoIdealtree')\n  var saveDeps = getSaveType(this.args)\n\n  var cg = this.progress.loadAllDepsIntoIdealTree\n  var steps = []\n\n  steps.push(\n    [removeDeps, this.args, this.idealTree, saveDeps, cg.newGroup('removeDeps')],\n    [loadExtraneous, this.idealTree, cg.newGroup('loadExtraneous')])\n  chain(steps, cb)\n}\n\nUninstaller.prototype.runPreinstallTopLevelLifecycles = function (cb) { cb() }\nUninstaller.prototype.runPostinstallTopLevelLifecycles = function (cb) { cb() }\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/unpublish.js":"\nmodule.exports = unpublish\n\nvar log = require('npmlog')\nvar npm = require('./npm.js')\nvar readJson = require('read-package-json')\nvar path = require('path')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar npa = require('npm-package-arg')\nvar getPublishConfig = require('./utils/get-publish-config.js')\nvar output = require('./utils/output.js')\n\nunpublish.usage = 'npm unpublish [<@scope>/]<pkg>[@<version>]'\n\nunpublish.completion = function (opts, cb) {\n  if (opts.conf.argv.remain.length >= 3) return cb()\n  npm.commands.whoami([], true, function (er, username) {\n    if (er) return cb()\n\n    var un = encodeURIComponent(username)\n    if (!un) return cb()\n    var byUser = '-/by-user/' + un\n    mapToRegistry(byUser, npm.config, function (er, uri, auth) {\n      if (er) return cb(er)\n\n      npm.registry.get(uri, { auth: auth }, function (er, pkgs) {\n        // do a bit of filtering at this point, so that we don't need\n        // to fetch versions for more than one thing, but also don't\n        // accidentally a whole project.\n        pkgs = pkgs[un]\n        if (!pkgs || !pkgs.length) return cb()\n        var pp = npa(opts.partialWord).name\n        pkgs = pkgs.filter(function (p) {\n          return p.indexOf(pp) === 0\n        })\n        if (pkgs.length > 1) return cb(null, pkgs)\n        mapToRegistry(pkgs[0], npm.config, function (er, uri, auth) {\n          if (er) return cb(er)\n\n          npm.registry.get(uri, { auth: auth }, function (er, d) {\n            if (er) return cb(er)\n            var vers = Object.keys(d.versions)\n            if (!vers.length) return cb(null, pkgs)\n            return cb(null, vers.map(function (v) {\n              return pkgs[0] + '@' + v\n            }))\n          })\n        })\n      })\n    })\n  })\n}\n\nfunction unpublish (args, cb) {\n  if (args.length > 1) return cb(unpublish.usage)\n\n  var thing = args.length ? npa(args[0]) : {}\n  var project = thing.name\n  var version = thing.rawSpec\n\n  log.silly('unpublish', 'args[0]', args[0])\n  log.silly('unpublish', 'thing', thing)\n  if (!version && !npm.config.get('force')) {\n    return cb(\n      'Refusing to delete entire project.\\n' +\n      'Run with --force to do this.\\n' +\n      unpublish.usage\n    )\n  }\n\n  if (!project || path.resolve(project) === npm.localPrefix) {\n    // if there's a package.json in the current folder, then\n    // read the package name and version out of that.\n    var cwdJson = path.join(npm.localPrefix, 'package.json')\n    return readJson(cwdJson, function (er, data) {\n      if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n      if (er) return cb('Usage:\\n' + unpublish.usage)\n      log.verbose('unpublish', data)\n      gotProject(data.name, data.version, data.publishConfig, cb)\n    })\n  }\n  return gotProject(project, version, cb)\n}\n\nfunction gotProject (project, version, publishConfig, cb_) {\n  if (typeof cb_ !== 'function') {\n    cb_ = publishConfig\n    publishConfig = null\n  }\n\n  function cb (er) {\n    if (er) return cb_(er)\n    output('- ' + project + (version ? '@' + version : ''))\n    cb_()\n  }\n\n  var mappedConfig = getPublishConfig(publishConfig, npm.config, npm.registry)\n  var config = mappedConfig.config\n  var registry = mappedConfig.client\n\n  // remove from the cache first\n  npm.commands.cache(['clean', project, version], function (er) {\n    if (er) {\n      log.error('unpublish', 'Failed to clean cache')\n      return cb(er)\n    }\n\n    mapToRegistry(project, config, function (er, uri, auth) {\n      if (er) return cb(er)\n\n      var params = {\n        version: version,\n        auth: auth\n      }\n      registry.unpublish(uri, params, cb)\n    })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/update.js":"module.exports = update\n\nvar url = require('url')\nvar log = require('npmlog')\nvar chain = require('slide').chain\nvar npm = require('./npm.js')\nvar Installer = require('./install.js').Installer\nvar usage = require('./utils/usage')\n\nupdate.usage = usage(\n  'update',\n  'npm update [-g] [<pkg>...]'\n)\n\nupdate.completion = npm.commands.outdated.completion\n\nfunction update (args, cb) {\n  var dryrun = false\n  if (npm.config.get('dry-run')) dryrun = true\n\n  npm.commands.outdated(args, true, function (er, rawOutdated) {\n    if (er) return cb(er)\n    var outdated = rawOutdated.map(function (ww) {\n      return {\n        dep: ww[0],\n        depname: ww[1],\n        current: ww[2],\n        wanted: ww[3],\n        latest: ww[4],\n        req: ww[5],\n        what: ww[1] + '@' + ww[3]\n      }\n    })\n\n    var wanted = outdated.filter(function (ww) {\n      if (ww.current === ww.wanted && ww.wanted !== ww.latest) {\n        log.verbose(\n          'outdated',\n          'not updating', ww.depname,\n          \"because it's currently at the maximum version that matches its specified semver range\"\n        )\n      }\n      return ww.current !== ww.wanted && ww.latest !== 'linked'\n    })\n    if (wanted.length === 0) return cb()\n\n    log.info('outdated', 'updating', wanted)\n    var toInstall = {}\n    wanted.forEach(function (ww) {\n      // use the initial installation method (repo, tar, git) for updating\n      if (url.parse(ww.req).protocol) ww.what = ww.req\n\n      var where = ww.dep.parent && ww.dep.parent.path || ww.dep.path\n      if (toInstall[where]) {\n        toInstall[where].push(ww.what)\n      } else {\n        toInstall[where] = [ww.what]\n      }\n    })\n    chain(Object.keys(toInstall).map(function (where) {\n      return [new Installer(where, dryrun, toInstall[where]), 'run']\n    }), cb)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/version.js":"// npm version <newver>\n\nmodule.exports = version\n\nvar semver = require('semver')\nvar path = require('path')\nvar fs = require('graceful-fs')\nvar writeFileAtomic = require('write-file-atomic')\nvar chain = require('slide').chain\nvar log = require('npmlog')\nvar npm = require('./npm.js')\nvar git = require('./utils/git.js')\nvar assert = require('assert')\nvar lifecycle = require('./utils/lifecycle.js')\nvar parseJSON = require('./utils/parse-json.js')\nvar output = require('./utils/output.js')\n\nversion.usage = 'npm version [<newversion> | major | minor | patch | premajor | preminor | prepatch | prerelease | from-git]' +\n                '\\n(run in package dir)\\n' +\n                \"'npm -v' or 'npm --version' to print npm version \" +\n                '(' + npm.version + ')\\n' +\n                \"'npm view <pkg> version' to view a package's \" +\n                'published version\\n' +\n                \"'npm ls' to inspect current package/dependency versions\"\n\nfunction version (args, silent, cb_) {\n  if (typeof cb_ !== 'function') {\n    cb_ = silent\n    silent = false\n  }\n  if (args.length > 1) return cb_(version.usage)\n\n  readPackage(function (er, data) {\n    if (!args.length) return dump(data, cb_)\n\n    if (er) {\n      log.error('version', 'No valid package.json found')\n      return cb_(er)\n    }\n\n    if (args[0] === 'from-git') {\n      retrieveTagVersion(silent, data, cb_)\n    } else {\n      var newVersion = semver.valid(args[0])\n      if (!newVersion) newVersion = semver.inc(data.version, args[0])\n      if (!newVersion) return cb_(version.usage)\n      persistVersion(newVersion, silent, data, cb_)\n    }\n  })\n}\n\nfunction retrieveTagVersion (silent, data, cb_) {\n  chain([\n    verifyGit,\n    parseLastGitTag\n  ], function (er, results) {\n    if (er) return cb_(er)\n    var localData = {\n      hasGit: true,\n      existingTag: true\n    }\n\n    var version = results[results.length - 1]\n    persistVersion(version, silent, data, localData, cb_)\n  })\n}\n\nfunction parseLastGitTag (cb) {\n  var options = { env: process.env }\n  git.whichAndExec(['describe', '--abbrev=0'], options, function (er, stdout) {\n    if (er) {\n      if (er.message.indexOf('No names found') !== -1) return cb(new Error('No tags found'))\n      return cb(er)\n    }\n\n    var tag = stdout.trim()\n    var prefix = npm.config.get('tag-version-prefix')\n    // Strip the prefix from the start of the tag:\n    if (tag.indexOf(prefix) === 0) tag = tag.slice(prefix.length)\n    var version = semver.valid(tag)\n    if (!version) return cb(new Error(tag + ' is not a valid version'))\n    cb(null, version)\n  })\n}\n\nfunction persistVersion (newVersion, silent, data, localData, cb_) {\n  if (typeof localData === 'function') {\n    cb_ = localData\n    localData = {}\n  }\n\n  if (data.version === newVersion) return cb_(new Error('Version not changed'))\n  data.version = newVersion\n  var lifecycleData = Object.create(data)\n  lifecycleData._id = data.name + '@' + newVersion\n\n  var where = npm.prefix\n  chain([\n    !localData.hasGit && [checkGit, localData],\n    [lifecycle, lifecycleData, 'preversion', where],\n    [updatePackage, newVersion, silent],\n    [lifecycle, lifecycleData, 'version', where],\n    [commit, localData, newVersion],\n    [lifecycle, lifecycleData, 'postversion', where]\n  ], cb_)\n}\n\nfunction readPackage (cb) {\n  var packagePath = path.join(npm.localPrefix, 'package.json')\n  fs.readFile(packagePath, function (er, data) {\n    if (er) return cb(new Error(er))\n    if (data) data = data.toString()\n    try {\n      data = JSON.parse(data)\n    } catch (e) {\n      er = e\n      data = null\n    }\n    cb(er, data)\n  })\n}\n\nfunction updatePackage (newVersion, silent, cb_) {\n  function cb (er) {\n    if (!er && !silent) output('v' + newVersion)\n    cb_(er)\n  }\n\n  readPackage(function (er, data) {\n    if (er) return cb(new Error(er))\n    data.version = newVersion\n    write(data, 'package.json', cb)\n  })\n}\n\nfunction commit (localData, newVersion, cb) {\n  updateShrinkwrap(newVersion, function (er, hasShrinkwrap) {\n    if (er || !localData.hasGit) return cb(er)\n    localData.hasShrinkwrap = hasShrinkwrap\n    _commit(newVersion, localData, cb)\n  })\n}\n\nfunction updateShrinkwrap (newVersion, cb) {\n  fs.readFile(path.join(npm.localPrefix, 'npm-shrinkwrap.json'), function (er, data) {\n    if (er && er.code === 'ENOENT') return cb(null, false)\n\n    try {\n      data = data.toString()\n      data = parseJSON(data)\n    } catch (er) {\n      log.error('version', 'Bad npm-shrinkwrap.json data')\n      return cb(er)\n    }\n\n    data.version = newVersion\n    write(data, 'npm-shrinkwrap.json', function (er) {\n      if (er) {\n        log.error('version', 'Bad npm-shrinkwrap.json data')\n        return cb(er)\n      }\n      cb(null, true)\n    })\n  })\n}\n\nfunction dump (data, cb) {\n  var v = {}\n\n  if (data && data.name && data.version) v[data.name] = data.version\n  v.npm = npm.version\n  Object.keys(process.versions).sort().forEach(function (k) {\n    v[k] = process.versions[k]\n  })\n\n  if (npm.config.get('json')) v = JSON.stringify(v, null, 2)\n\n  output(v)\n  cb()\n}\n\nfunction statGitFolder (cb) {\n  fs.stat(path.join(npm.localPrefix, '.git'), cb)\n}\n\nfunction callGitStatus (cb) {\n  git.whichAndExec(\n    [ 'status', '--porcelain' ],\n    { env: process.env },\n    cb\n  )\n}\n\nfunction cleanStatusLines (stdout) {\n  var lines = stdout.trim().split('\\n').filter(function (line) {\n    return line.trim() && !line.match(/^\\?\\? /)\n  }).map(function (line) {\n    return line.trim()\n  })\n\n  return lines\n}\n\nfunction verifyGit (cb) {\n  function checkStatus (er) {\n    if (er) return cb(er)\n    callGitStatus(checkStdout)\n  }\n\n  function checkStdout (er, stdout) {\n    if (er) return cb(er)\n    var lines = cleanStatusLines(stdout)\n    if (lines.length > 0) {\n      return cb(new Error(\n        'Git working directory not clean.\\n' + lines.join('\\n')\n      ))\n    }\n\n    cb()\n  }\n\n  statGitFolder(checkStatus)\n}\n\nfunction checkGit (localData, cb) {\n  statGitFolder(function (er) {\n    var doGit = !er && npm.config.get('git-tag-version')\n    if (!doGit) {\n      if (er) log.verbose('version', 'error checking for .git', er)\n      log.verbose('version', 'not tagging in git')\n      return cb(null, false)\n    }\n\n    // check for git\n    callGitStatus(function (er, stdout) {\n      if (er && er.code === 'ENOGIT') {\n        log.warn(\n          'version',\n          'This is a Git checkout, but the git command was not found.',\n          'npm could not create a Git tag for this release!'\n        )\n        return cb(null, false)\n      }\n\n      var lines = cleanStatusLines(stdout)\n      if (lines.length && !npm.config.get('force')) {\n        return cb(new Error(\n          'Git working directory not clean.\\n' + lines.join('\\n')\n        ))\n      }\n      localData.hasGit = true\n      cb(null, true)\n    })\n  })\n}\n\nfunction _commit (version, localData, cb) {\n  var packagePath = path.join(npm.localPrefix, 'package.json')\n  var options = { env: process.env }\n  var message = npm.config.get('message').replace(/%s/g, version)\n  var sign = npm.config.get('sign-git-tag')\n  var flag = sign ? '-sm' : '-am'\n  chain(\n    [\n      git.chainableExec([ 'add', packagePath ], options),\n      localData.hasShrinkwrap && git.chainableExec([ 'add', path.join(npm.localPrefix, 'npm-shrinkwrap.json') ], options),\n      git.chainableExec([ 'commit', '-m', message ], options),\n      !localData.existingTag && git.chainableExec([\n        'tag',\n        npm.config.get('tag-version-prefix') + version,\n        flag,\n        message\n      ], options)\n    ],\n    cb\n  )\n}\n\nfunction write (data, file, cb) {\n  assert(data && typeof data === 'object', 'must pass data to version write')\n  assert(typeof file === 'string', 'must pass filename to write to version write')\n\n  log.verbose('version.write', 'data', data, 'to', file)\n  writeFileAtomic(\n    path.join(npm.localPrefix, file),\n    new Buffer(JSON.stringify(data, null, 2) + '\\n'),\n    cb\n  )\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/view.js":"// npm view [pkg [pkg ...]]\nmodule.exports = view\n\nvar npm = require('./npm.js')\nvar readJson = require('read-package-json')\nvar log = require('npmlog')\nvar util = require('util')\nvar semver = require('semver')\nvar mapToRegistry = require('./utils/map-to-registry.js')\nvar npa = require('npm-package-arg')\nvar path = require('path')\nvar usage = require('./utils/usage')\n\nview.usage = usage(\n  'view',\n  'npm view [<@scope>/]<pkg>[@<version>] [<field>[.subfield]...]'\n)\n\nview.completion = function (opts, cb) {\n  if (opts.conf.argv.remain.length <= 2) {\n    // FIXME: there used to be registry completion here, but it stopped making\n    // sense somewhere around 50,000 packages on the registry\n    return cb()\n  }\n  // have the package, get the fields.\n  var tag = npm.config.get('tag')\n  mapToRegistry(opts.conf.argv.remain[2], npm.config, function (er, uri, auth) {\n    if (er) return cb(er)\n\n    npm.registry.get(uri, { auth: auth }, function (er, d) {\n      if (er) return cb(er)\n      var dv = d.versions[d['dist-tags'][tag]]\n      var fields = []\n      d.versions = Object.keys(d.versions).sort(semver.compareLoose)\n      fields = getFields(d).concat(getFields(dv))\n      cb(null, fields)\n    })\n  })\n\n  function getFields (d, f, pref) {\n    f = f || []\n    if (!d) return f\n    pref = pref || []\n    Object.keys(d).forEach(function (k) {\n      if (k.charAt(0) === '_' || k.indexOf('.') !== -1) return\n      var p = pref.concat(k).join('.')\n      f.push(p)\n      if (Array.isArray(d[k])) {\n        d[k].forEach(function (val, i) {\n          var pi = p + '[' + i + ']'\n          if (val && typeof val === 'object') getFields(val, f, [p])\n          else f.push(pi)\n        })\n        return\n      }\n      if (typeof d[k] === 'object') getFields(d[k], f, [p])\n    })\n    return f\n  }\n}\n\nfunction view (args, silent, cb) {\n  if (typeof cb !== 'function') {\n    cb = silent\n    silent = false\n  }\n\n  if (!args.length) args = ['.']\n\n  var pkg = args.shift()\n  var nv = npa(pkg)\n  var name = nv.name\n  var local = (name === '.' || !name)\n\n  if (npm.config.get('global') && local) {\n    return cb(new Error('Cannot use view command in global mode.'))\n  }\n\n  if (local) {\n    var dir = npm.prefix\n    readJson(path.resolve(dir, 'package.json'), function (er, d) {\n      d = d || {}\n      if (er && er.code !== 'ENOENT' && er.code !== 'ENOTDIR') return cb(er)\n      if (!d.name) return cb(new Error('Invalid package.json'))\n\n      var p = d.name\n      nv = npa(p)\n      if (pkg && ~pkg.indexOf('@')) {\n        nv.rawSpec = pkg.split('@')[pkg.indexOf('@')]\n      }\n\n      fetchAndRead(nv, args, silent, cb)\n    })\n  } else {\n    fetchAndRead(nv, args, silent, cb)\n  }\n}\n\nfunction fetchAndRead (nv, args, silent, cb) {\n  // get the data about this package\n  var name = nv.name\n  var version = nv.rawSpec || npm.config.get('tag')\n\n  mapToRegistry(name, npm.config, function (er, uri, auth) {\n    if (er) return cb(er)\n\n    npm.registry.get(uri, { auth: auth }, function (er, data) {\n      if (er) return cb(er)\n      if (data['dist-tags'] && data['dist-tags'].hasOwnProperty(version)) {\n        version = data['dist-tags'][version]\n      }\n\n      if (data.time && data.time.unpublished) {\n        var u = data.time.unpublished\n        er = new Error('Unpublished by ' + u.name + ' on ' + u.time)\n        er.statusCode = 404\n        er.code = 'E404'\n        er.pkgid = data._id\n        return cb(er, data)\n      }\n\n      var results = []\n      var error = null\n      var versions = data.versions || {}\n      data.versions = Object.keys(versions).sort(semver.compareLoose)\n      if (!args.length) args = ['']\n\n      // remove readme unless we asked for it\n      if (args.indexOf('readme') === -1) {\n        delete data.readme\n      }\n\n      Object.keys(versions).forEach(function (v) {\n        if (semver.satisfies(v, version, true)) {\n          args.forEach(function (args) {\n            // remove readme unless we asked for it\n            if (args.indexOf('readme') !== -1) {\n              delete versions[v].readme\n            }\n            results.push(showFields(data, versions[v], args))\n          })\n        }\n      })\n      results = results.reduce(reducer, {})\n      var retval = results\n\n      if (args.length === 1 && args[0] === '') {\n        retval = cleanBlanks(retval)\n        log.silly('cleanup', retval)\n      }\n\n      if (error || silent) cb(error, retval)\n      else printData(results, data._id, cb.bind(null, error, retval))\n    })\n  })\n}\n\nfunction cleanBlanks (obj) {\n  var clean = {}\n  Object.keys(obj).forEach(function (version) {\n    clean[version] = obj[version]['']\n  })\n  return clean\n}\n\nfunction reducer (l, r) {\n  if (r) {\n    Object.keys(r).forEach(function (v) {\n      l[v] = l[v] || {}\n      Object.keys(r[v]).forEach(function (t) {\n        l[v][t] = r[v][t]\n      })\n    })\n  }\n\n  return l\n}\n\n// return whatever was printed\nfunction showFields (data, version, fields) {\n  var o = {}\n  ;[data, version].forEach(function (s) {\n    Object.keys(s).forEach(function (k) {\n      o[k] = s[k]\n    })\n  })\n  return search(o, fields.split('.'), version.version, fields)\n}\n\nfunction search (data, fields, version, title) {\n  var field\n  var tail = fields\n  while (!field && fields.length) field = tail.shift()\n  fields = [field].concat(tail)\n  var o\n  if (!field && !tail.length) {\n    o = {}\n    o[version] = {}\n    o[version][title] = data\n    return o\n  }\n  var index = field.match(/(.+)\\[([^\\]]+)\\]$/)\n  if (index) {\n    field = index[1]\n    index = index[2]\n    if (data.field && data.field.hasOwnProperty(index)) {\n      return search(data[field][index], tail, version, title)\n    } else {\n      field = field + '[' + index + ']'\n    }\n  }\n  if (Array.isArray(data)) {\n    if (data.length === 1) {\n      return search(data[0], fields, version, title)\n    }\n    var results = []\n    data.forEach(function (data, i) {\n      var tl = title.length\n      var newt = title.substr(0, tl - fields.join('.').length - 1) +\n                 '[' + i + ']' + [''].concat(fields).join('.')\n      results.push(search(data, fields.slice(), version, newt))\n    })\n    results = results.reduce(reducer, {})\n    return results\n  }\n  if (!data.hasOwnProperty(field)) return undefined\n  data = data[field]\n  if (tail.length) {\n    if (typeof data === 'object') {\n      // there are more fields to deal with.\n      return search(data, tail, version, title)\n    } else {\n      return new Error('Not an object: ' + data)\n    }\n  }\n  o = {}\n  o[version] = {}\n  o[version][title] = data\n  return o\n}\n\nfunction printData (data, name, cb) {\n  var versions = Object.keys(data)\n  var msg = ''\n  var msgJson = []\n  var includeVersions = versions.length > 1\n  var includeFields\n\n  versions.forEach(function (v) {\n    var fields = Object.keys(data[v])\n    includeFields = includeFields || (fields.length > 1)\n    if (npm.config.get('json')) msgJson.push({})\n    fields.forEach(function (f) {\n      var d = cleanup(data[v][f])\n      if (fields.length === 1 && npm.config.get('json')) {\n        msgJson[msgJson.length - 1][f] = d\n      }\n      if (includeVersions || includeFields || typeof d !== 'string') {\n        if (npm.config.get('json')) {\n          msgJson[msgJson.length - 1][f] = d\n        } else {\n          d = util.inspect(d, false, 5, npm.color)\n        }\n      } else if (typeof d === 'string' && npm.config.get('json')) {\n        d = JSON.stringify(d)\n      }\n      if (!npm.config.get('json')) {\n        if (f && includeFields) f += ' = '\n        if (d.indexOf('\\n') !== -1) d = ' \\n' + d\n        msg += (includeVersions ? name + '@' + v + ' ' : '') +\n               (includeFields ? f : '') + d + '\\n'\n      }\n    })\n  })\n\n  if (npm.config.get('json')) {\n    if (msgJson.length && Object.keys(msgJson[0]).length === 1) {\n      var k = Object.keys(msgJson[0])[0]\n      msgJson = msgJson.map(function (m) { return m[k] })\n    }\n\n    if (msgJson.length === 1) {\n      msg = JSON.stringify(msgJson[0], null, 2) + '\\n'\n    } else if (msgJson.length > 1) {\n      msg = JSON.stringify(msgJson, null, 2) + '\\n'\n    }\n  }\n\n  // preserve output symmetry by adding a whitespace-only line at the end if\n  // there's one at the beginning\n  if (/^\\s*\\n/.test(msg)) msg += '\\n'\n\n  // disable the progress bar entirely, as we can't meaningfully update it if\n  // we may have partial lines printed.\n  log.disableProgress()\n\n  // print directly to stdout to not unnecessarily add blank lines\n  process.stdout.write(msg)\n\n  cb(null, data)\n}\nfunction cleanup (data) {\n  if (Array.isArray(data)) {\n    return data.map(cleanup)\n  }\n  if (!data || typeof data !== 'object') return data\n\n  if (typeof data.versions === 'object' &&\n      data.versions &&\n      !Array.isArray(data.versions)) {\n    data.versions = Object.keys(data.versions || {})\n  }\n\n  var keys = Object.keys(data)\n  keys.forEach(function (d) {\n    if (d.charAt(0) === '_') delete data[d]\n    else if (typeof data[d] === 'object') data[d] = cleanup(data[d])\n  })\n  keys = Object.keys(data)\n  if (keys.length <= 3 &&\n      data.name &&\n      (keys.length === 1 ||\n       keys.length === 3 && data.email && data.url ||\n       keys.length === 2 && (data.email || data.url))) {\n    data = unparsePerson(data)\n  }\n  return data\n}\nfunction unparsePerson (d) {\n  if (typeof d === 'string') return d\n  return d.name +\n    (d.email ? ' <' + d.email + '>' : '') +\n    (d.url ? ' (' + d.url + ')' : '')\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/visnup.js":"module.exports = visnup\nvar npm = require('./npm.js')\nvar output = require('./utils/output.js')\n\nvar handsomeFace = [\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 232, 237, 236, 236, 232, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 235, 236, 235, 233, 237, 235, 233, 232, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 232, 235, 233, 232, 235, 235, 234, 233, 236, 232, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 237, 235, 232, 232, 234, 233, 233, 232, 232, 233, 232, 232, 235, 232, 233, 234, 234, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 232, 232, 232, 239, 238, 235, 233, 232, 232, 232, 232, 232, 232, 232, 233, 235, 232, 233, 233, 232, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 234, 234, 232, 233, 234, 233, 234, 235, 233, 235, 60, 238, 238, 234, 234, 233, 234, 233, 238, 251, 246, 233, 233, 232, 0, 0, 0, 0, 0, 0],\n  [0, 0, 233, 233, 233, 232, 232, 239, 249, 251, 252, 231, 231, 188, 250, 254, 59, 60, 255, 231, 231, 231, 252, 235, 239, 235, 232, 233, 0, 0, 0, 0, 0, 0],\n  [0, 0, 232, 233, 232, 232, 232, 248, 231, 231, 231, 231, 231, 231, 231, 254, 238, 254, 231, 231, 231, 231, 231, 252, 233, 235, 237, 233, 234, 0, 0, 0, 0, 0],\n  [0, 0, 233, 232, 232, 232, 248, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 251, 233, 233, 233, 236, 233, 0, 0, 0, 0],\n  [232, 233, 233, 232, 232, 246, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 249, 233, 234, 234, 0, 0, 0, 0],\n  [232, 232, 232, 232, 233, 249, 231, 255, 255, 255, 255, 254, 109, 60, 239, 237, 238, 237, 235, 235, 235, 235, 236, 235, 235, 235, 234, 232, 232, 232, 232, 232, 233, 0],\n  [0, 232, 232, 233, 233, 233, 233, 233, 233, 233, 233, 233, 235, 236, 238, 238, 235, 188, 254, 254, 145, 236, 252, 254, 254, 254, 254, 249, 236, 235, 232, 232, 233, 0],\n  [0, 0, 233, 237, 249, 239, 233, 252, 231, 231, 231, 231, 231, 231, 254, 235, 235, 254, 231, 231, 251, 235, 237, 231, 231, 231, 231, 7, 237, 235, 232, 233, 233, 0],\n  [0, 0, 0, 0, 233, 248, 239, 233, 231, 231, 231, 231, 254, 233, 233, 235, 254, 255, 231, 254, 237, 236, 254, 239, 235, 235, 233, 233, 232, 232, 233, 232, 0, 0],\n  [0, 0, 0, 232, 233, 246, 255, 255, 236, 236, 236, 236, 236, 255, 231, 231, 231, 231, 231, 231, 252, 234, 248, 231, 231, 231, 231, 248, 232, 232, 232, 0, 0, 0],\n  [0, 0, 0, 0, 235, 237, 7, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 255, 238, 235, 7, 231, 231, 231, 246, 232, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 235, 103, 188, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 252, 232, 238, 231, 231, 255, 244, 232, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 235, 236, 103, 146, 253, 255, 231, 231, 231, 231, 231, 253, 251, 250, 250, 250, 246, 232, 235, 152, 255, 146, 66, 233, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 233, 103, 146, 146, 146, 146, 254, 231, 231, 231, 109, 103, 146, 255, 188, 239, 240, 103, 255, 253, 103, 238, 234, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 232, 235, 109, 146, 146, 146, 146, 146, 252, 152, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 103, 235, 233, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 235, 235, 103, 146, 146, 146, 146, 146, 146, 188, 188, 188, 188, 188, 188, 152, 146, 146, 146, 66, 235, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 233, 235, 66, 146, 146, 146, 146, 152, 255, 146, 240, 239, 241, 109, 146, 146, 146, 103, 233, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 234, 237, 109, 146, 146, 146, 146, 146, 254, 231, 231, 188, 146, 146, 146, 103, 233, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 233, 237, 60, 103, 146, 146, 146, 146, 146, 103, 66, 60, 235, 232, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 232, 233, 233, 236, 235, 237, 235, 237, 237, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n]\n\nfunction visnup (args, cb) {\n  handsomeFace.forEach(function (line) {\n    output(line.map(function (ch) {\n      return '\\u001b[' + (ch ? '48;5;' + ch : ch) + 'm'\n    }).join(' '))\n  })\n\n  var c = args.shift()\n  if (c) npm.commands[c](args, cb)\n  else cb()\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/lib/xmas.js":"// happy xmas\nvar log = require('npmlog')\n\nmodule.exports = function (args, cb) {\n  var s = process.platform === 'win32' ? ' *' : ' \\u2605'\n  var f = '\\uFF0F'\n  var b = '\\uFF3C'\n  var x = process.platform === 'win32' ? ' ' : ''\n  var o = [\n    '\\u0069', '\\u0020', '\\u0020', '\\u0020', '\\u0020', '\\u0020',\n    '\\u0020', '\\u0020', '\\u0020', '\\u0020', '\\u0020', '\\u0020',\n    '\\u0020', '\\u2E1B', '\\u2042', '\\u2E2E', '&', '@', '\\uFF61'\n  ]\n  var oc = [21, 33, 34, 35, 36, 37]\n  var l = '\\u005e'\n\n  function w (s) { process.stderr.write(s) }\n\n  w('\\n')\n  ;(function T (H) {\n    for (var i = 0; i < H; i++) w(' ')\n    w(x + '\\u001b[33m' + s + '\\n')\n    var M = H * 2 - 1\n    for (var L = 1; L <= H; L++) {\n      var O = L * 2 - 2\n      var S = (M - O) / 2\n      for (i = 0; i < S; i++) w(' ')\n      w(x + '\\u001b[32m' + f)\n      for (i = 0; i < O; i++) {\n        w(\n          '\\u001b[' + oc[Math.floor(Math.random() * oc.length)] + 'm' +\n          o[Math.floor(Math.random() * o.length)]\n        )\n      }\n      w(x + '\\u001b[32m' + b + '\\n')\n    }\n    w(' ')\n    for (i = 1; i < H; i++) w('\\u001b[32m' + l)\n    w('| ' + x + ' |')\n    for (i = 1; i < H; i++) w('\\u001b[32m' + l)\n    if (H > 10) {\n      w('\\n ')\n      for (i = 1; i < H; i++) w(' ')\n      w('| ' + x + ' |')\n      for (i = 1; i < H; i++) w(' ')\n    }\n  })(20)\n  w('\\n\\n')\n  log.heading = ''\n  log.addLevel('npm', 100000, log.headingStyle)\n  log.npm('loves you', 'Happy Xmas, Noders!')\n  cb()\n}\nvar dg = false\nObject.defineProperty(module.exports, 'usage', {get: function () {\n  if (dg) module.exports([], function () {})\n  dg = true\n  return ' '\n}})\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/scripts/changelog.js":"'use strict'\n/*\nUsage:\n\nnode scripts/changelog.js [comittish]\n\nGenerates changelog entries in our format as best as its able based on\ncommits starting at comittish, or if that's not passed, latest.\n\nOrdinarily this is run via the gen-changelog shell script, which appends\nthe result to the changelog.\n\n*/\nconst execSync = require('child_process').execSync\nconst branch = process.argv[2] || 'origin/latest'\nconst log = execSync(`git log --reverse --pretty='format:%h %H%d %s (%aN)%n%b%n---%n' ${branch}...`).toString().split(/\\n/)\n\nmain()\n\nfunction shortname (url) {\n  let matched = url.match(/https:\\/\\/github.com\\/([^/]+\\/[^/]+)\\/(?:pull|issues)\\/(\\d+)/)\n  if (!matched) return false\n  let repo = matched[1]\n  let id = matched[2]\n  if (repo !== 'npm/npm') {\n    return `${repo}#${id}`\n  } else {\n    return `#${id}`\n  }\n}\n\nfunction print_commit (c) {\n  console.log(`* [\\`${c.shortid}\\`](https://github.com/npm/npm/commit/${c.fullid})`)\n  if (c.fixes) {\n    let label = shortname(c.fixes)\n    if (label) {\n      console.log(`  [${label}](${c.fixes})`)\n    } else {\n      console.log(`  [#${c.fixes}](https://github.com/npm/npm/issues/${c.fixes})`)\n    }\n  } else if (c.prurl) {\n    let label = shortname(c.prurl)\n    if (label) {\n      console.log(`  [${label}](${c.prurl})`)\n    } else {\n      console.log(`  [#](${c.prurl})`)\n    }\n  }\n  let msg = c.message\n    .replace(/^\\s+/mg, '')\n    .replace(/^[-a-z]+: /, '')\n    .replace(/^/mg, '  ')\n    .replace(/\\n$/, '')\n  // backtickify package@version\n    .replace(/^(\\s*[^@\\s]+@\\d+[.]\\d+[.]\\d+)(\\s*\\S)/g, '$1:$2')\n    .replace(/\\b([^@\\s]+@\\d+[.]\\d+[.]\\d+)\\b/g, '`$1`')\n  // linkify commitids\n    .replace(/\\b([a-f0-9]{7,8})\\b/g, '[`$1`](https://github.com/npm/npm/commit/$1)')\n    .replace(/\\b#(\\d+)\\b/g, '[#$1](https://github.com/npm/npm/issues/$1)')\n  console.log(msg)\n  if (c.credit) {\n    c.credit.forEach(function (credit) {\n      console.log(`  ([@${credit}](https://github.com/${credit}))`)\n    })\n  } else {\n    console.log(`  ([@${c.author}](https://github.com/${c.author}))`)\n  }\n}\n\nfunction main () {\n  let commit\n  log.forEach(function (line) {\n    let m\n    /*eslint no-cond-assign:0*/\n    if (/^---$/.test(line)) {\n      print_commit(commit)\n    } else if (m = line.match(/^([a-f0-9]{7,9}) ([a-f0-9]+) (?:[(]([^)]+)[)] )?(.*?) [(](.*?)[)]/)) {\n      commit = {\n        shortid: m[1],\n        fullid: m[2],\n        branch: m[3],\n        message: m[4],\n        author: m[5],\n        prurl: null,\n        fixes: null,\n        credit: null\n      }\n    } else if (m = line.match(/^PR-URL: (.*)/)) {\n      commit.prurl = m[1]\n    } else if (m = line.match(/^Credit: @(.*)/)) {\n      if (!commit.credit) commit.credit = []\n      commit.credit.push(m[1])\n    } else if (m = line.match(/^Fixes: #?(.*?)/)) {\n      commit.fixes = m[1]\n    } else if (m = line.match(/^Reviewed-By: @(.*)/)) {\n      commit.reviewed = m[1]\n    } else if (/\\S/.test(line)) {\n      commit.message += `\\n${line}`\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-npm/node_modules/npm/scripts/publish-tag.js":"var semver = require('semver')\nvar version = semver.parse(require('../package.json').version)\nconsole.log('v%s.%s-next', version.major, version.minor)\n"}